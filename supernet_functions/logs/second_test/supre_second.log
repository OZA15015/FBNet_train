09/21 04:02:10 AM | Firstly, start to train weights for epoch 0
Files already downloaded and verified
Files already downloaded and verified
09/21 04:02:35 AM | Train: [  1/180] Step 050/1249 Loss 14.590 Prec@(1,3) (12.9%, 52.5%), ce_loss 3.287, lat_loss 22.192
09/21 04:03:01 AM | Train: [  1/180] Step 100/1249 Loss 13.868 Prec@(1,3) (13.6%, 55.6%), ce_loss 3.125, lat_loss 22.191
09/21 04:03:26 AM | Train: [  1/180] Step 150/1249 Loss 13.181 Prec@(1,3) (13.8%, 56.8%), ce_loss 2.970, lat_loss 22.192
09/21 04:03:48 AM | Train: [  1/180] Step 200/1249 Loss 12.549 Prec@(1,3) (14.6%, 59.0%), ce_loss 2.827, lat_loss 22.192
09/21 04:04:10 AM | Train: [  1/180] Step 250/1249 Loss 12.124 Prec@(1,3) (15.2%, 60.4%), ce_loss 2.732, lat_loss 22.193
09/21 04:04:35 AM | Train: [  1/180] Step 300/1249 Loss 11.816 Prec@(1,3) (15.8%, 61.6%), ce_loss 2.662, lat_loss 22.194
09/21 04:04:59 AM | Train: [  1/180] Step 350/1249 Loss 11.576 Prec@(1,3) (16.1%, 62.8%), ce_loss 2.608, lat_loss 22.194
09/21 04:05:24 AM | Train: [  1/180] Step 400/1249 Loss 11.346 Prec@(1,3) (16.6%, 64.2%), ce_loss 2.556, lat_loss 22.194
09/21 04:05:48 AM | Train: [  1/180] Step 450/1249 Loss 11.154 Prec@(1,3) (17.1%, 65.3%), ce_loss 2.513, lat_loss 22.194
09/21 04:06:12 AM | Train: [  1/180] Step 500/1249 Loss 10.978 Prec@(1,3) (17.7%, 66.3%), ce_loss 2.473, lat_loss 22.194
09/21 04:06:36 AM | Train: [  1/180] Step 550/1249 Loss 10.826 Prec@(1,3) (18.3%, 67.2%), ce_loss 2.439, lat_loss 22.194
09/21 04:07:01 AM | Train: [  1/180] Step 600/1249 Loss 10.677 Prec@(1,3) (18.8%, 68.1%), ce_loss 2.405, lat_loss 22.194
09/21 04:07:25 AM | Train: [  1/180] Step 650/1249 Loss 10.572 Prec@(1,3) (19.2%, 68.8%), ce_loss 2.382, lat_loss 22.194
09/21 04:07:48 AM | Train: [  1/180] Step 700/1249 Loss 10.454 Prec@(1,3) (19.6%, 69.7%), ce_loss 2.355, lat_loss 22.194
09/21 04:08:10 AM | Train: [  1/180] Step 750/1249 Loss 10.361 Prec@(1,3) (19.8%, 70.3%), ce_loss 2.334, lat_loss 22.194
09/21 04:08:32 AM | Train: [  1/180] Step 800/1249 Loss 10.263 Prec@(1,3) (20.2%, 71.0%), ce_loss 2.312, lat_loss 22.194
09/21 04:08:50 AM | Train: [  1/180] Step 850/1249 Loss 10.168 Prec@(1,3) (20.6%, 71.6%), ce_loss 2.291, lat_loss 22.194
09/21 04:09:08 AM | Train: [  1/180] Step 900/1249 Loss 10.082 Prec@(1,3) (21.0%, 72.2%), ce_loss 2.271, lat_loss 22.193
09/21 04:09:26 AM | Train: [  1/180] Step 950/1249 Loss 10.000 Prec@(1,3) (21.4%, 72.7%), ce_loss 2.253, lat_loss 22.193
09/21 04:09:45 AM | Train: [  1/180] Step 1000/1249 Loss 9.931 Prec@(1,3) (21.7%, 73.1%), ce_loss 2.237, lat_loss 22.193
09/21 04:10:02 AM | Train: [  1/180] Step 1050/1249 Loss 9.857 Prec@(1,3) (22.1%, 73.6%), ce_loss 2.221, lat_loss 22.194
09/21 04:10:20 AM | Train: [  1/180] Step 1100/1249 Loss 9.788 Prec@(1,3) (22.4%, 74.0%), ce_loss 2.205, lat_loss 22.194
09/21 04:10:38 AM | Train: [  1/180] Step 1150/1249 Loss 9.724 Prec@(1,3) (22.7%, 74.5%), ce_loss 2.191, lat_loss 22.194
09/21 04:10:57 AM | Train: [  1/180] Step 1200/1249 Loss 9.664 Prec@(1,3) (22.9%, 74.9%), ce_loss 2.177, lat_loss 22.194
09/21 04:11:15 AM | Train: [  1/180] Step 1249/1249 Loss 9.612 Prec@(1,3) (23.2%, 75.2%), ce_loss 2.165, lat_loss 22.194
09/21 04:11:15 AM | _w_step_train: [  1/180] Final Prec@1 23.1625% Time 545.36
09/21 04:11:15 AM | Firstly, start to train weights for epoch 1
09/21 04:11:41 AM | Train: [  2/180] Step 050/1249 Loss 8.224 Prec@(1,3) (31.4%, 85.0%), ce_loss 2.153, lat_loss 22.194
09/21 04:12:06 AM | Train: [  2/180] Step 100/1249 Loss 8.168 Prec@(1,3) (31.6%, 84.7%), ce_loss 2.141, lat_loss 22.194
09/21 04:12:31 AM | Train: [  2/180] Step 150/1249 Loss 8.194 Prec@(1,3) (31.5%, 84.5%), ce_loss 2.131, lat_loss 22.194
09/21 04:12:56 AM | Train: [  2/180] Step 200/1249 Loss 8.181 Prec@(1,3) (31.5%, 84.4%), ce_loss 2.121, lat_loss 22.194
09/21 04:13:21 AM | Train: [  2/180] Step 250/1249 Loss 8.166 Prec@(1,3) (31.4%, 84.6%), ce_loss 2.111, lat_loss 22.194
09/21 04:13:50 AM | Train: [  2/180] Step 300/1249 Loss 8.134 Prec@(1,3) (31.5%, 84.7%), ce_loss 2.101, lat_loss 22.193
09/21 04:14:23 AM | Train: [  2/180] Step 350/1249 Loss 8.132 Prec@(1,3) (31.5%, 84.8%), ce_loss 2.092, lat_loss 22.193
09/21 04:14:51 AM | Train: [  2/180] Step 400/1249 Loss 8.105 Prec@(1,3) (31.7%, 84.9%), ce_loss 2.083, lat_loss 22.193
09/21 04:15:18 AM | Train: [  2/180] Step 450/1249 Loss 8.075 Prec@(1,3) (31.9%, 85.0%), ce_loss 2.074, lat_loss 22.193
09/21 04:15:45 AM | Train: [  2/180] Step 500/1249 Loss 8.078 Prec@(1,3) (31.7%, 85.0%), ce_loss 2.067, lat_loss 22.193
09/21 04:16:11 AM | Train: [  2/180] Step 550/1249 Loss 8.064 Prec@(1,3) (31.9%, 85.2%), ce_loss 2.059, lat_loss 22.193
09/21 04:16:40 AM | Train: [  2/180] Step 600/1249 Loss 8.053 Prec@(1,3) (32.0%, 85.1%), ce_loss 2.051, lat_loss 22.193
09/21 04:17:10 AM | Train: [  2/180] Step 650/1249 Loss 8.044 Prec@(1,3) (32.1%, 85.2%), ce_loss 2.045, lat_loss 22.193
09/21 04:17:40 AM | Train: [  2/180] Step 700/1249 Loss 8.029 Prec@(1,3) (32.2%, 85.3%), ce_loss 2.037, lat_loss 22.193
09/21 04:18:09 AM | Train: [  2/180] Step 750/1249 Loss 8.019 Prec@(1,3) (32.4%, 85.4%), ce_loss 2.031, lat_loss 22.193
09/21 04:18:38 AM | Train: [  2/180] Step 800/1249 Loss 8.013 Prec@(1,3) (32.5%, 85.4%), ce_loss 2.025, lat_loss 22.193
09/21 04:19:08 AM | Train: [  2/180] Step 850/1249 Loss 8.000 Prec@(1,3) (32.6%, 85.4%), ce_loss 2.018, lat_loss 22.193
09/21 04:19:38 AM | Train: [  2/180] Step 900/1249 Loss 7.983 Prec@(1,3) (32.8%, 85.5%), ce_loss 2.012, lat_loss 22.193
09/21 04:20:08 AM | Train: [  2/180] Step 950/1249 Loss 7.971 Prec@(1,3) (32.9%, 85.5%), ce_loss 2.006, lat_loss 22.193
09/21 04:20:38 AM | Train: [  2/180] Step 1000/1249 Loss 7.954 Prec@(1,3) (33.0%, 85.6%), ce_loss 1.999, lat_loss 22.193
09/21 04:21:08 AM | Train: [  2/180] Step 1050/1249 Loss 7.944 Prec@(1,3) (33.0%, 85.6%), ce_loss 1.994, lat_loss 22.193
09/21 04:21:38 AM | Train: [  2/180] Step 1100/1249 Loss 7.931 Prec@(1,3) (33.1%, 85.7%), ce_loss 1.988, lat_loss 22.193
09/21 04:22:08 AM | Train: [  2/180] Step 1150/1249 Loss 7.927 Prec@(1,3) (33.1%, 85.7%), ce_loss 1.984, lat_loss 22.193
09/21 04:22:39 AM | Train: [  2/180] Step 1200/1249 Loss 7.919 Prec@(1,3) (33.1%, 85.8%), ce_loss 1.979, lat_loss 22.193
09/21 04:23:08 AM | Train: [  2/180] Step 1249/1249 Loss 7.910 Prec@(1,3) (33.2%, 85.9%), ce_loss 1.974, lat_loss 22.193
09/21 04:23:08 AM | _w_step_train: [  2/180] Final Prec@1 33.1900% Time 713.06
09/21 04:23:08 AM | Firstly, start to train weights for epoch 2
09/21 04:23:41 AM | Train: [  3/180] Step 050/1249 Loss 7.554 Prec@(1,3) (36.8%, 86.5%), ce_loss 1.968, lat_loss 22.193
09/21 04:24:17 AM | Train: [  3/180] Step 100/1249 Loss 7.512 Prec@(1,3) (36.5%, 87.2%), ce_loss 1.963, lat_loss 22.193
09/21 04:24:55 AM | Train: [  3/180] Step 150/1249 Loss 7.531 Prec@(1,3) (37.4%, 87.3%), ce_loss 1.958, lat_loss 22.193
09/21 04:25:29 AM | Train: [  3/180] Step 200/1249 Loss 7.506 Prec@(1,3) (37.6%, 87.6%), ce_loss 1.953, lat_loss 22.193
09/21 04:26:00 AM | Train: [  3/180] Step 250/1249 Loss 7.527 Prec@(1,3) (37.5%, 87.7%), ce_loss 1.948, lat_loss 22.193
09/21 04:26:34 AM | Train: [  3/180] Step 300/1249 Loss 7.497 Prec@(1,3) (37.7%, 88.1%), ce_loss 1.943, lat_loss 22.193
09/21 04:27:12 AM | Train: [  3/180] Step 350/1249 Loss 7.494 Prec@(1,3) (37.8%, 88.1%), ce_loss 1.939, lat_loss 22.193
09/21 04:27:50 AM | Train: [  3/180] Step 400/1249 Loss 7.474 Prec@(1,3) (38.0%, 88.3%), ce_loss 1.934, lat_loss 22.193
09/21 04:28:24 AM | Train: [  3/180] Step 450/1249 Loss 7.460 Prec@(1,3) (38.1%, 88.4%), ce_loss 1.929, lat_loss 22.193
09/21 04:28:52 AM | Train: [  3/180] Step 500/1249 Loss 7.462 Prec@(1,3) (38.0%, 88.4%), ce_loss 1.925, lat_loss 22.193
09/21 04:29:25 AM | Train: [  3/180] Step 550/1249 Loss 7.456 Prec@(1,3) (37.9%, 88.4%), ce_loss 1.921, lat_loss 22.193
09/21 04:30:01 AM | Train: [  3/180] Step 600/1249 Loss 7.443 Prec@(1,3) (37.9%, 88.5%), ce_loss 1.916, lat_loss 22.193
09/21 04:30:39 AM | Train: [  3/180] Step 650/1249 Loss 7.445 Prec@(1,3) (38.1%, 88.4%), ce_loss 1.913, lat_loss 22.193
09/21 04:31:14 AM | Train: [  3/180] Step 700/1249 Loss 7.425 Prec@(1,3) (38.2%, 88.5%), ce_loss 1.908, lat_loss 22.193
09/21 04:31:45 AM | Train: [  3/180] Step 750/1249 Loss 7.405 Prec@(1,3) (38.4%, 88.5%), ce_loss 1.903, lat_loss 22.193
09/21 04:32:13 AM | Train: [  3/180] Step 800/1249 Loss 7.391 Prec@(1,3) (38.4%, 88.6%), ce_loss 1.899, lat_loss 22.193
09/21 04:32:43 AM | Train: [  3/180] Step 850/1249 Loss 7.383 Prec@(1,3) (38.4%, 88.6%), ce_loss 1.895, lat_loss 22.193
09/21 04:33:15 AM | Train: [  3/180] Step 900/1249 Loss 7.367 Prec@(1,3) (38.5%, 88.7%), ce_loss 1.891, lat_loss 22.193
09/21 04:33:47 AM | Train: [  3/180] Step 950/1249 Loss 7.355 Prec@(1,3) (38.6%, 88.8%), ce_loss 1.887, lat_loss 22.193
09/21 04:34:14 AM | Train: [  3/180] Step 1000/1249 Loss 7.333 Prec@(1,3) (38.7%, 88.9%), ce_loss 1.882, lat_loss 22.193
09/21 04:34:40 AM | Train: [  3/180] Step 1050/1249 Loss 7.324 Prec@(1,3) (38.8%, 89.0%), ce_loss 1.878, lat_loss 22.193
09/21 04:35:09 AM | Train: [  3/180] Step 1100/1249 Loss 7.310 Prec@(1,3) (39.0%, 89.1%), ce_loss 1.874, lat_loss 22.193
09/21 04:35:38 AM | Train: [  3/180] Step 1150/1249 Loss 7.304 Prec@(1,3) (39.1%, 89.0%), ce_loss 1.870, lat_loss 22.193
09/21 04:36:07 AM | Train: [  3/180] Step 1200/1249 Loss 7.288 Prec@(1,3) (39.3%, 89.1%), ce_loss 1.866, lat_loss 22.193
09/21 04:36:35 AM | Train: [  3/180] Step 1249/1249 Loss 7.292 Prec@(1,3) (39.2%, 89.1%), ce_loss 1.863, lat_loss 22.193
09/21 04:36:35 AM | _w_step_train: [  3/180] Final Prec@1 39.2150% Time 807.01
09/21 04:36:35 AM | Firstly, start to train weights for epoch 3
09/21 04:37:08 AM | Train: [  4/180] Step 050/1249 Loss 6.851 Prec@(1,3) (44.5%, 91.9%), ce_loss 1.859, lat_loss 22.193
09/21 04:37:40 AM | Train: [  4/180] Step 100/1249 Loss 6.887 Prec@(1,3) (43.5%, 91.0%), ce_loss 1.855, lat_loss 22.193
09/21 04:38:13 AM | Train: [  4/180] Step 150/1249 Loss 6.888 Prec@(1,3) (43.3%, 90.8%), ce_loss 1.851, lat_loss 22.193
09/21 04:38:46 AM | Train: [  4/180] Step 200/1249 Loss 6.852 Prec@(1,3) (43.5%, 90.8%), ce_loss 1.847, lat_loss 22.193
09/21 04:39:19 AM | Train: [  4/180] Step 250/1249 Loss 6.843 Prec@(1,3) (43.4%, 90.9%), ce_loss 1.843, lat_loss 22.193
09/21 04:39:50 AM | Train: [  4/180] Step 300/1249 Loss 6.877 Prec@(1,3) (43.3%, 90.6%), ce_loss 1.840, lat_loss 22.193
09/21 04:40:19 AM | Train: [  4/180] Step 350/1249 Loss 6.879 Prec@(1,3) (43.3%, 90.7%), ce_loss 1.837, lat_loss 22.193
09/21 04:40:49 AM | Train: [  4/180] Step 400/1249 Loss 6.887 Prec@(1,3) (43.2%, 90.7%), ce_loss 1.833, lat_loss 22.193
09/21 04:41:18 AM | Train: [  4/180] Step 450/1249 Loss 6.888 Prec@(1,3) (43.3%, 90.7%), ce_loss 1.830, lat_loss 22.193
09/21 04:41:47 AM | Train: [  4/180] Step 500/1249 Loss 6.871 Prec@(1,3) (43.2%, 90.9%), ce_loss 1.826, lat_loss 22.193
09/21 04:42:17 AM | Train: [  4/180] Step 550/1249 Loss 6.870 Prec@(1,3) (43.2%, 90.9%), ce_loss 1.823, lat_loss 22.193
09/21 04:42:46 AM | Train: [  4/180] Step 600/1249 Loss 6.861 Prec@(1,3) (43.2%, 90.9%), ce_loss 1.820, lat_loss 22.193
09/21 04:43:16 AM | Train: [  4/180] Step 650/1249 Loss 6.845 Prec@(1,3) (43.3%, 90.9%), ce_loss 1.816, lat_loss 22.193
09/21 04:43:45 AM | Train: [  4/180] Step 700/1249 Loss 6.844 Prec@(1,3) (43.3%, 90.9%), ce_loss 1.813, lat_loss 22.193
09/21 04:44:17 AM | Train: [  4/180] Step 750/1249 Loss 6.855 Prec@(1,3) (43.3%, 90.8%), ce_loss 1.810, lat_loss 22.193
09/21 04:44:49 AM | Train: [  4/180] Step 800/1249 Loss 6.846 Prec@(1,3) (43.3%, 90.8%), ce_loss 1.807, lat_loss 22.193
09/21 04:45:22 AM | Train: [  4/180] Step 850/1249 Loss 6.841 Prec@(1,3) (43.4%, 90.9%), ce_loss 1.804, lat_loss 22.193
09/21 04:45:55 AM | Train: [  4/180] Step 900/1249 Loss 6.828 Prec@(1,3) (43.6%, 91.0%), ce_loss 1.800, lat_loss 22.193
09/21 04:46:28 AM | Train: [  4/180] Step 950/1249 Loss 6.824 Prec@(1,3) (43.6%, 91.0%), ce_loss 1.798, lat_loss 22.193
09/21 04:47:00 AM | Train: [  4/180] Step 1000/1249 Loss 6.813 Prec@(1,3) (43.6%, 91.1%), ce_loss 1.794, lat_loss 22.193
09/21 04:47:30 AM | Train: [  4/180] Step 1050/1249 Loss 6.812 Prec@(1,3) (43.6%, 91.0%), ce_loss 1.791, lat_loss 22.193
09/21 04:47:59 AM | Train: [  4/180] Step 1100/1249 Loss 6.797 Prec@(1,3) (43.8%, 91.1%), ce_loss 1.788, lat_loss 22.193
09/21 04:48:28 AM | Train: [  4/180] Step 1150/1249 Loss 6.789 Prec@(1,3) (43.8%, 91.1%), ce_loss 1.785, lat_loss 22.193
09/21 04:48:58 AM | Train: [  4/180] Step 1200/1249 Loss 6.771 Prec@(1,3) (44.0%, 91.2%), ce_loss 1.781, lat_loss 22.193
09/21 04:49:25 AM | Train: [  4/180] Step 1249/1249 Loss 6.754 Prec@(1,3) (44.1%, 91.3%), ce_loss 1.778, lat_loss 22.193
09/21 04:49:25 AM | _w_step_train: [  4/180] Final Prec@1 44.1050% Time 769.95
09/21 04:49:25 AM | Firstly, start to train weights for epoch 4
09/21 04:50:04 AM | Train: [  5/180] Step 050/1249 Loss 6.280 Prec@(1,3) (47.4%, 93.3%), ce_loss 1.774, lat_loss 22.193
09/21 04:50:42 AM | Train: [  5/180] Step 100/1249 Loss 6.435 Prec@(1,3) (47.4%, 92.7%), ce_loss 1.772, lat_loss 22.193
09/21 04:51:20 AM | Train: [  5/180] Step 150/1249 Loss 6.423 Prec@(1,3) (47.6%, 92.7%), ce_loss 1.768, lat_loss 22.193
09/21 04:51:51 AM | Train: [  5/180] Step 200/1249 Loss 6.424 Prec@(1,3) (47.5%, 92.4%), ce_loss 1.765, lat_loss 22.193
09/21 04:52:17 AM | Train: [  5/180] Step 250/1249 Loss 6.483 Prec@(1,3) (47.0%, 92.2%), ce_loss 1.763, lat_loss 22.193
09/21 04:52:49 AM | Train: [  5/180] Step 300/1249 Loss 6.504 Prec@(1,3) (46.9%, 92.0%), ce_loss 1.760, lat_loss 22.193
09/21 04:53:21 AM | Train: [  5/180] Step 350/1249 Loss 6.499 Prec@(1,3) (46.8%, 92.1%), ce_loss 1.757, lat_loss 22.193
09/21 04:53:52 AM | Train: [  5/180] Step 400/1249 Loss 6.500 Prec@(1,3) (46.8%, 92.1%), ce_loss 1.755, lat_loss 22.193
09/21 04:54:17 AM | Train: [  5/180] Step 450/1249 Loss 6.509 Prec@(1,3) (46.7%, 92.1%), ce_loss 1.752, lat_loss 22.193
09/21 04:54:46 AM | Train: [  5/180] Step 500/1249 Loss 6.486 Prec@(1,3) (46.7%, 92.2%), ce_loss 1.749, lat_loss 22.193
09/21 04:55:18 AM | Train: [  5/180] Step 550/1249 Loss 6.472 Prec@(1,3) (46.9%, 92.3%), ce_loss 1.746, lat_loss 22.193
09/21 04:55:50 AM | Train: [  5/180] Step 600/1249 Loss 6.454 Prec@(1,3) (47.1%, 92.3%), ce_loss 1.743, lat_loss 22.193
09/21 04:56:22 AM | Train: [  5/180] Step 650/1249 Loss 6.452 Prec@(1,3) (47.1%, 92.3%), ce_loss 1.741, lat_loss 22.193
09/21 04:56:52 AM | Train: [  5/180] Step 700/1249 Loss 6.447 Prec@(1,3) (47.0%, 92.4%), ce_loss 1.738, lat_loss 22.193
09/21 04:57:17 AM | Train: [  5/180] Step 750/1249 Loss 6.442 Prec@(1,3) (47.0%, 92.4%), ce_loss 1.735, lat_loss 22.193
09/21 04:57:46 AM | Train: [  5/180] Step 800/1249 Loss 6.429 Prec@(1,3) (47.2%, 92.5%), ce_loss 1.733, lat_loss 22.193
09/21 04:58:17 AM | Train: [  5/180] Step 850/1249 Loss 6.419 Prec@(1,3) (47.2%, 92.5%), ce_loss 1.730, lat_loss 22.193
09/21 04:58:48 AM | Train: [  5/180] Step 900/1249 Loss 6.411 Prec@(1,3) (47.3%, 92.6%), ce_loss 1.727, lat_loss 22.193
09/21 04:59:19 AM | Train: [  5/180] Step 950/1249 Loss 6.391 Prec@(1,3) (47.4%, 92.6%), ce_loss 1.724, lat_loss 22.193
09/21 04:59:51 AM | Train: [  5/180] Step 1000/1249 Loss 6.382 Prec@(1,3) (47.5%, 92.6%), ce_loss 1.721, lat_loss 22.193
09/21 05:00:22 AM | Train: [  5/180] Step 1050/1249 Loss 6.374 Prec@(1,3) (47.6%, 92.6%), ce_loss 1.719, lat_loss 22.193
09/21 05:00:53 AM | Train: [  5/180] Step 1100/1249 Loss 6.367 Prec@(1,3) (47.6%, 92.7%), ce_loss 1.716, lat_loss 22.193
09/21 05:01:25 AM | Train: [  5/180] Step 1150/1249 Loss 6.353 Prec@(1,3) (47.7%, 92.7%), ce_loss 1.713, lat_loss 22.193
09/21 05:01:56 AM | Train: [  5/180] Step 1200/1249 Loss 6.346 Prec@(1,3) (47.8%, 92.7%), ce_loss 1.711, lat_loss 22.193
09/21 05:02:26 AM | Train: [  5/180] Step 1249/1249 Loss 6.338 Prec@(1,3) (47.9%, 92.7%), ce_loss 1.708, lat_loss 22.193
09/21 05:02:26 AM | _w_step_train: [  5/180] Final Prec@1 47.9175% Time 780.63
09/21 05:02:26 AM | Firstly, start to train weights for epoch 5
09/21 05:03:02 AM | Train: [  6/180] Step 050/1249 Loss 6.255 Prec@(1,3) (49.0%, 93.6%), ce_loss 1.706, lat_loss 22.193
09/21 05:03:38 AM | Train: [  6/180] Step 100/1249 Loss 6.240 Prec@(1,3) (49.2%, 93.9%), ce_loss 1.703, lat_loss 22.193
09/21 05:04:13 AM | Train: [  6/180] Step 150/1249 Loss 6.181 Prec@(1,3) (49.6%, 93.7%), ce_loss 1.701, lat_loss 22.193
09/21 05:04:46 AM | Train: [  6/180] Step 200/1249 Loss 6.139 Prec@(1,3) (50.1%, 93.4%), ce_loss 1.698, lat_loss 22.193
09/21 05:05:16 AM | Train: [  6/180] Step 250/1249 Loss 6.133 Prec@(1,3) (50.1%, 93.3%), ce_loss 1.695, lat_loss 22.193
09/21 05:05:43 AM | Train: [  6/180] Step 300/1249 Loss 6.119 Prec@(1,3) (50.2%, 93.3%), ce_loss 1.693, lat_loss 22.193
09/21 05:06:12 AM | Train: [  6/180] Step 350/1249 Loss 6.090 Prec@(1,3) (50.5%, 93.4%), ce_loss 1.690, lat_loss 22.193
09/21 05:06:43 AM | Train: [  6/180] Step 400/1249 Loss 6.083 Prec@(1,3) (50.4%, 93.4%), ce_loss 1.688, lat_loss 22.193
09/21 05:07:13 AM | Train: [  6/180] Step 450/1249 Loss 6.067 Prec@(1,3) (50.5%, 93.4%), ce_loss 1.685, lat_loss 22.193
09/21 05:07:43 AM | Train: [  6/180] Step 500/1249 Loss 6.066 Prec@(1,3) (50.5%, 93.4%), ce_loss 1.683, lat_loss 22.193
09/21 05:08:13 AM | Train: [  6/180] Step 550/1249 Loss 6.060 Prec@(1,3) (50.4%, 93.5%), ce_loss 1.680, lat_loss 22.193
09/21 05:08:43 AM | Train: [  6/180] Step 600/1249 Loss 6.062 Prec@(1,3) (50.3%, 93.4%), ce_loss 1.678, lat_loss 22.193
09/21 05:09:13 AM | Train: [  6/180] Step 650/1249 Loss 6.029 Prec@(1,3) (50.6%, 93.5%), ce_loss 1.675, lat_loss 22.193
09/21 05:09:45 AM | Train: [  6/180] Step 700/1249 Loss 6.018 Prec@(1,3) (50.7%, 93.5%), ce_loss 1.673, lat_loss 22.193
09/21 05:10:19 AM | Train: [  6/180] Step 750/1249 Loss 6.011 Prec@(1,3) (50.7%, 93.5%), ce_loss 1.670, lat_loss 22.193
09/21 05:10:54 AM | Train: [  6/180] Step 800/1249 Loss 6.003 Prec@(1,3) (50.8%, 93.5%), ce_loss 1.668, lat_loss 22.193
09/21 05:11:26 AM | Train: [  6/180] Step 850/1249 Loss 5.998 Prec@(1,3) (50.9%, 93.5%), ce_loss 1.665, lat_loss 22.193
09/21 05:12:00 AM | Train: [  6/180] Step 900/1249 Loss 5.985 Prec@(1,3) (51.1%, 93.5%), ce_loss 1.663, lat_loss 22.193
09/21 05:12:32 AM | Train: [  6/180] Step 950/1249 Loss 5.981 Prec@(1,3) (51.2%, 93.6%), ce_loss 1.660, lat_loss 22.193
09/21 05:13:04 AM | Train: [  6/180] Step 1000/1249 Loss 5.977 Prec@(1,3) (51.2%, 93.6%), ce_loss 1.658, lat_loss 22.193
09/21 05:13:30 AM | Train: [  6/180] Step 1050/1249 Loss 5.979 Prec@(1,3) (51.2%, 93.6%), ce_loss 1.656, lat_loss 22.193
09/21 05:14:01 AM | Train: [  6/180] Step 1100/1249 Loss 5.978 Prec@(1,3) (51.2%, 93.6%), ce_loss 1.654, lat_loss 22.193
09/21 05:14:35 AM | Train: [  6/180] Step 1150/1249 Loss 5.971 Prec@(1,3) (51.3%, 93.6%), ce_loss 1.652, lat_loss 22.193
09/21 05:15:08 AM | Train: [  6/180] Step 1200/1249 Loss 5.962 Prec@(1,3) (51.4%, 93.6%), ce_loss 1.649, lat_loss 22.193
09/21 05:15:41 AM | Train: [  6/180] Step 1249/1249 Loss 5.956 Prec@(1,3) (51.5%, 93.6%), ce_loss 1.647, lat_loss 22.193
09/21 05:15:42 AM | _w_step_train: [  6/180] Final Prec@1 51.4800% Time 795.76
09/21 05:15:42 AM | Firstly, start to train weights for epoch 6
09/21 05:16:14 AM | Train: [  7/180] Step 050/1249 Loss 5.712 Prec@(1,3) (51.7%, 94.9%), ce_loss 1.645, lat_loss 22.193
09/21 05:16:46 AM | Train: [  7/180] Step 100/1249 Loss 5.725 Prec@(1,3) (52.6%, 94.8%), ce_loss 1.642, lat_loss 22.193
09/21 05:17:23 AM | Train: [  7/180] Step 150/1249 Loss 5.714 Prec@(1,3) (53.3%, 94.5%), ce_loss 1.640, lat_loss 22.193
09/21 05:18:01 AM | Train: [  7/180] Step 200/1249 Loss 5.786 Prec@(1,3) (53.0%, 94.2%), ce_loss 1.638, lat_loss 22.193
09/21 05:18:37 AM | Train: [  7/180] Step 250/1249 Loss 5.793 Prec@(1,3) (52.9%, 94.2%), ce_loss 1.636, lat_loss 22.193
09/21 05:19:08 AM | Train: [  7/180] Step 300/1249 Loss 5.806 Prec@(1,3) (52.9%, 94.1%), ce_loss 1.634, lat_loss 22.193
09/21 05:19:42 AM | Train: [  7/180] Step 350/1249 Loss 5.779 Prec@(1,3) (52.8%, 94.2%), ce_loss 1.632, lat_loss 22.193
09/21 05:20:20 AM | Train: [  7/180] Step 400/1249 Loss 5.750 Prec@(1,3) (53.0%, 94.3%), ce_loss 1.629, lat_loss 22.193
09/21 05:20:55 AM | Train: [  7/180] Step 450/1249 Loss 5.720 Prec@(1,3) (53.3%, 94.3%), ce_loss 1.627, lat_loss 22.193
09/21 05:21:29 AM | Train: [  7/180] Step 500/1249 Loss 5.726 Prec@(1,3) (53.3%, 94.3%), ce_loss 1.625, lat_loss 22.193
09/21 05:22:01 AM | Train: [  7/180] Step 550/1249 Loss 5.729 Prec@(1,3) (53.4%, 94.3%), ce_loss 1.623, lat_loss 22.193
09/21 05:22:35 AM | Train: [  7/180] Step 600/1249 Loss 5.708 Prec@(1,3) (53.6%, 94.3%), ce_loss 1.620, lat_loss 22.193
09/21 05:23:05 AM | Train: [  7/180] Step 650/1249 Loss 5.695 Prec@(1,3) (53.6%, 94.3%), ce_loss 1.618, lat_loss 22.193
09/21 05:23:34 AM | Train: [  7/180] Step 700/1249 Loss 5.689 Prec@(1,3) (53.7%, 94.3%), ce_loss 1.616, lat_loss 22.193
09/21 05:24:01 AM | Train: [  7/180] Step 750/1249 Loss 5.683 Prec@(1,3) (53.8%, 94.3%), ce_loss 1.614, lat_loss 22.193
09/21 05:24:35 AM | Train: [  7/180] Step 800/1249 Loss 5.665 Prec@(1,3) (53.9%, 94.3%), ce_loss 1.611, lat_loss 22.193
09/21 05:25:11 AM | Train: [  7/180] Step 850/1249 Loss 5.662 Prec@(1,3) (54.0%, 94.3%), ce_loss 1.609, lat_loss 22.193
09/21 05:25:44 AM | Train: [  7/180] Step 900/1249 Loss 5.650 Prec@(1,3) (54.1%, 94.3%), ce_loss 1.607, lat_loss 22.193
09/21 05:26:12 AM | Train: [  7/180] Step 950/1249 Loss 5.640 Prec@(1,3) (54.3%, 94.3%), ce_loss 1.605, lat_loss 22.193
09/21 05:26:38 AM | Train: [  7/180] Step 1000/1249 Loss 5.638 Prec@(1,3) (54.3%, 94.3%), ce_loss 1.603, lat_loss 22.193
09/21 05:27:06 AM | Train: [  7/180] Step 1050/1249 Loss 5.622 Prec@(1,3) (54.5%, 94.3%), ce_loss 1.600, lat_loss 22.193
09/21 05:27:41 AM | Train: [  7/180] Step 1100/1249 Loss 5.612 Prec@(1,3) (54.5%, 94.4%), ce_loss 1.598, lat_loss 22.193
09/21 05:28:15 AM | Train: [  7/180] Step 1150/1249 Loss 5.599 Prec@(1,3) (54.7%, 94.4%), ce_loss 1.596, lat_loss 22.193
09/21 05:28:42 AM | Train: [  7/180] Step 1200/1249 Loss 5.594 Prec@(1,3) (54.8%, 94.4%), ce_loss 1.594, lat_loss 22.193
09/21 05:29:07 AM | Train: [  7/180] Step 1249/1249 Loss 5.594 Prec@(1,3) (54.8%, 94.4%), ce_loss 1.592, lat_loss 22.193
09/21 05:29:08 AM | _w_step_train: [  7/180] Final Prec@1 54.8300% Time 806.03
09/21 05:29:08 AM | Firstly, start to train weights for epoch 7
09/21 05:29:45 AM | Train: [  8/180] Step 050/1249 Loss 5.470 Prec@(1,3) (56.1%, 95.0%), ce_loss 1.590, lat_loss 22.193
09/21 05:30:21 AM | Train: [  8/180] Step 100/1249 Loss 5.533 Prec@(1,3) (55.8%, 94.3%), ce_loss 1.588, lat_loss 22.193
09/21 05:30:51 AM | Train: [  8/180] Step 150/1249 Loss 5.469 Prec@(1,3) (55.9%, 94.4%), ce_loss 1.586, lat_loss 22.193
09/21 05:31:18 AM | Train: [  8/180] Step 200/1249 Loss 5.407 Prec@(1,3) (56.3%, 94.4%), ce_loss 1.583, lat_loss 22.193
09/21 05:31:52 AM | Train: [  8/180] Step 250/1249 Loss 5.397 Prec@(1,3) (56.2%, 94.6%), ce_loss 1.581, lat_loss 22.193
09/21 05:32:27 AM | Train: [  8/180] Step 300/1249 Loss 5.402 Prec@(1,3) (56.3%, 94.6%), ce_loss 1.579, lat_loss 22.193
09/21 05:33:02 AM | Train: [  8/180] Step 350/1249 Loss 5.391 Prec@(1,3) (56.5%, 94.7%), ce_loss 1.577, lat_loss 22.193
09/21 05:33:36 AM | Train: [  8/180] Step 400/1249 Loss 5.405 Prec@(1,3) (56.3%, 94.7%), ce_loss 1.575, lat_loss 22.193
09/21 05:34:09 AM | Train: [  8/180] Step 450/1249 Loss 5.395 Prec@(1,3) (56.3%, 94.8%), ce_loss 1.573, lat_loss 22.193
09/21 05:34:37 AM | Train: [  8/180] Step 500/1249 Loss 5.381 Prec@(1,3) (56.5%, 94.8%), ce_loss 1.571, lat_loss 22.192
09/21 05:35:05 AM | Train: [  8/180] Step 550/1249 Loss 5.385 Prec@(1,3) (56.6%, 94.7%), ce_loss 1.569, lat_loss 22.192
09/21 05:35:38 AM | Train: [  8/180] Step 600/1249 Loss 5.389 Prec@(1,3) (56.6%, 94.7%), ce_loss 1.568, lat_loss 22.192
09/21 05:36:11 AM | Train: [  8/180] Step 650/1249 Loss 5.387 Prec@(1,3) (56.6%, 94.7%), ce_loss 1.566, lat_loss 22.192
09/21 05:36:44 AM | Train: [  8/180] Step 700/1249 Loss 5.370 Prec@(1,3) (56.9%, 94.6%), ce_loss 1.563, lat_loss 22.192
09/21 05:37:18 AM | Train: [  8/180] Step 750/1249 Loss 5.371 Prec@(1,3) (56.8%, 94.6%), ce_loss 1.562, lat_loss 22.192
09/21 05:37:56 AM | Train: [  8/180] Step 800/1249 Loss 5.366 Prec@(1,3) (56.9%, 94.7%), ce_loss 1.560, lat_loss 22.192
09/21 05:38:33 AM | Train: [  8/180] Step 850/1249 Loss 5.354 Prec@(1,3) (57.0%, 94.7%), ce_loss 1.558, lat_loss 22.192
09/21 05:39:03 AM | Train: [  8/180] Step 900/1249 Loss 5.344 Prec@(1,3) (57.2%, 94.7%), ce_loss 1.556, lat_loss 22.192
09/21 05:39:36 AM | Train: [  8/180] Step 950/1249 Loss 5.351 Prec@(1,3) (57.1%, 94.7%), ce_loss 1.554, lat_loss 22.192
09/21 05:40:10 AM | Train: [  8/180] Step 1000/1249 Loss 5.328 Prec@(1,3) (57.2%, 94.8%), ce_loss 1.552, lat_loss 22.192
09/21 05:40:44 AM | Train: [  8/180] Step 1050/1249 Loss 5.322 Prec@(1,3) (57.3%, 94.8%), ce_loss 1.550, lat_loss 22.192
09/21 05:41:17 AM | Train: [  8/180] Step 1100/1249 Loss 5.323 Prec@(1,3) (57.3%, 94.8%), ce_loss 1.548, lat_loss 22.192
09/21 05:41:51 AM | Train: [  8/180] Step 1150/1249 Loss 5.306 Prec@(1,3) (57.4%, 94.9%), ce_loss 1.546, lat_loss 22.192
09/21 05:42:25 AM | Train: [  8/180] Step 1200/1249 Loss 5.293 Prec@(1,3) (57.5%, 94.9%), ce_loss 1.544, lat_loss 22.192
09/21 05:42:59 AM | Train: [  8/180] Step 1249/1249 Loss 5.281 Prec@(1,3) (57.6%, 94.9%), ce_loss 1.542, lat_loss 22.192
09/21 05:42:59 AM | _w_step_train: [  8/180] Final Prec@1 57.6250% Time 831.26
09/21 05:42:59 AM | Firstly, start to train weights for epoch 8
09/21 05:43:33 AM | Train: [  9/180] Step 050/1249 Loss 4.817 Prec@(1,3) (61.3%, 96.1%), ce_loss 1.539, lat_loss 22.192
09/21 05:44:08 AM | Train: [  9/180] Step 100/1249 Loss 5.054 Prec@(1,3) (59.9%, 95.3%), ce_loss 1.538, lat_loss 22.192
09/21 05:44:43 AM | Train: [  9/180] Step 150/1249 Loss 5.061 Prec@(1,3) (59.8%, 95.1%), ce_loss 1.536, lat_loss 22.192
09/21 05:45:13 AM | Train: [  9/180] Step 200/1249 Loss 5.089 Prec@(1,3) (59.5%, 95.1%), ce_loss 1.534, lat_loss 22.192
09/21 05:45:43 AM | Train: [  9/180] Step 250/1249 Loss 5.032 Prec@(1,3) (59.6%, 95.5%), ce_loss 1.532, lat_loss 22.192
09/21 05:46:14 AM | Train: [  9/180] Step 300/1249 Loss 5.019 Prec@(1,3) (59.7%, 95.5%), ce_loss 1.530, lat_loss 22.192
09/21 05:46:48 AM | Train: [  9/180] Step 350/1249 Loss 5.030 Prec@(1,3) (59.4%, 95.3%), ce_loss 1.528, lat_loss 22.192
09/21 05:47:24 AM | Train: [  9/180] Step 400/1249 Loss 5.017 Prec@(1,3) (59.5%, 95.4%), ce_loss 1.526, lat_loss 22.192
09/21 05:47:58 AM | Train: [  9/180] Step 450/1249 Loss 5.020 Prec@(1,3) (59.5%, 95.4%), ce_loss 1.524, lat_loss 22.192
09/21 05:48:32 AM | Train: [  9/180] Step 500/1249 Loss 4.996 Prec@(1,3) (59.6%, 95.6%), ce_loss 1.522, lat_loss 22.192
09/21 05:49:05 AM | Train: [  9/180] Step 550/1249 Loss 5.001 Prec@(1,3) (59.6%, 95.6%), ce_loss 1.520, lat_loss 22.192
09/21 05:49:39 AM | Train: [  9/180] Step 600/1249 Loss 5.001 Prec@(1,3) (59.6%, 95.6%), ce_loss 1.518, lat_loss 22.192
09/21 05:50:13 AM | Train: [  9/180] Step 650/1249 Loss 4.983 Prec@(1,3) (59.7%, 95.6%), ce_loss 1.516, lat_loss 22.192
09/21 05:50:47 AM | Train: [  9/180] Step 700/1249 Loss 4.986 Prec@(1,3) (59.8%, 95.6%), ce_loss 1.514, lat_loss 22.192
09/21 05:51:19 AM | Train: [  9/180] Step 750/1249 Loss 4.996 Prec@(1,3) (59.8%, 95.5%), ce_loss 1.512, lat_loss 22.192
09/21 05:51:48 AM | Train: [  9/180] Step 800/1249 Loss 5.003 Prec@(1,3) (59.7%, 95.5%), ce_loss 1.511, lat_loss 22.192
09/21 05:52:18 AM | Train: [  9/180] Step 850/1249 Loss 4.997 Prec@(1,3) (59.8%, 95.6%), ce_loss 1.509, lat_loss 22.192
09/21 05:52:48 AM | Train: [  9/180] Step 900/1249 Loss 4.991 Prec@(1,3) (59.9%, 95.6%), ce_loss 1.507, lat_loss 22.192
09/21 05:53:17 AM | Train: [  9/180] Step 950/1249 Loss 4.971 Prec@(1,3) (60.1%, 95.7%), ce_loss 1.505, lat_loss 22.192
09/21 05:53:47 AM | Train: [  9/180] Step 1000/1249 Loss 4.980 Prec@(1,3) (60.0%, 95.7%), ce_loss 1.503, lat_loss 22.192
09/21 05:54:15 AM | Train: [  9/180] Step 1050/1249 Loss 4.976 Prec@(1,3) (60.1%, 95.7%), ce_loss 1.502, lat_loss 22.192
09/21 05:54:45 AM | Train: [  9/180] Step 1100/1249 Loss 4.983 Prec@(1,3) (60.1%, 95.7%), ce_loss 1.500, lat_loss 22.192
09/21 05:55:14 AM | Train: [  9/180] Step 1150/1249 Loss 4.980 Prec@(1,3) (60.1%, 95.7%), ce_loss 1.498, lat_loss 22.192
09/21 05:55:46 AM | Train: [  9/180] Step 1200/1249 Loss 4.977 Prec@(1,3) (60.1%, 95.7%), ce_loss 1.496, lat_loss 22.192
09/21 05:56:20 AM | Train: [  9/180] Step 1249/1249 Loss 4.978 Prec@(1,3) (60.0%, 95.7%), ce_loss 1.495, lat_loss 22.192
09/21 05:56:20 AM | _w_step_train: [  9/180] Final Prec@1 60.0350% Time 800.89
09/21 05:56:20 AM | Firstly, start to train weights for epoch 9
09/21 05:56:54 AM | Train: [ 10/180] Step 050/1249 Loss 4.800 Prec@(1,3) (60.9%, 95.8%), ce_loss 1.493, lat_loss 22.192
09/21 05:57:28 AM | Train: [ 10/180] Step 100/1249 Loss 4.782 Prec@(1,3) (61.2%, 95.9%), ce_loss 1.491, lat_loss 22.192
09/21 05:58:01 AM | Train: [ 10/180] Step 150/1249 Loss 4.866 Prec@(1,3) (60.6%, 95.7%), ce_loss 1.490, lat_loss 22.192
09/21 05:58:36 AM | Train: [ 10/180] Step 200/1249 Loss 4.828 Prec@(1,3) (61.2%, 95.9%), ce_loss 1.488, lat_loss 22.192
09/21 05:59:10 AM | Train: [ 10/180] Step 250/1249 Loss 4.819 Prec@(1,3) (61.4%, 96.0%), ce_loss 1.486, lat_loss 22.192
09/21 05:59:42 AM | Train: [ 10/180] Step 300/1249 Loss 4.795 Prec@(1,3) (61.5%, 96.1%), ce_loss 1.484, lat_loss 22.192
09/21 06:00:15 AM | Train: [ 10/180] Step 350/1249 Loss 4.771 Prec@(1,3) (61.6%, 96.1%), ce_loss 1.482, lat_loss 22.192
09/21 06:00:52 AM | Train: [ 10/180] Step 400/1249 Loss 4.779 Prec@(1,3) (61.5%, 96.1%), ce_loss 1.480, lat_loss 22.192
09/21 06:01:30 AM | Train: [ 10/180] Step 450/1249 Loss 4.756 Prec@(1,3) (61.8%, 96.1%), ce_loss 1.479, lat_loss 22.192
09/21 06:02:04 AM | Train: [ 10/180] Step 500/1249 Loss 4.754 Prec@(1,3) (61.8%, 96.1%), ce_loss 1.477, lat_loss 22.192
09/21 06:02:34 AM | Train: [ 10/180] Step 550/1249 Loss 4.731 Prec@(1,3) (61.9%, 96.2%), ce_loss 1.475, lat_loss 22.192
09/21 06:03:01 AM | Train: [ 10/180] Step 600/1249 Loss 4.703 Prec@(1,3) (62.1%, 96.3%), ce_loss 1.473, lat_loss 22.192
09/21 06:03:29 AM | Train: [ 10/180] Step 650/1249 Loss 4.700 Prec@(1,3) (62.3%, 96.3%), ce_loss 1.471, lat_loss 22.192
09/21 06:03:58 AM | Train: [ 10/180] Step 700/1249 Loss 4.703 Prec@(1,3) (62.3%, 96.2%), ce_loss 1.469, lat_loss 22.192
09/21 06:04:27 AM | Train: [ 10/180] Step 750/1249 Loss 4.709 Prec@(1,3) (62.3%, 96.2%), ce_loss 1.468, lat_loss 22.192
09/21 06:05:00 AM | Train: [ 10/180] Step 800/1249 Loss 4.707 Prec@(1,3) (62.4%, 96.2%), ce_loss 1.466, lat_loss 22.192
09/21 06:05:36 AM | Train: [ 10/180] Step 850/1249 Loss 4.702 Prec@(1,3) (62.5%, 96.1%), ce_loss 1.464, lat_loss 22.192
09/21 06:06:11 AM | Train: [ 10/180] Step 900/1249 Loss 4.711 Prec@(1,3) (62.5%, 96.2%), ce_loss 1.463, lat_loss 22.192
09/21 06:06:48 AM | Train: [ 10/180] Step 950/1249 Loss 4.707 Prec@(1,3) (62.5%, 96.2%), ce_loss 1.461, lat_loss 22.192
09/21 06:07:24 AM | Train: [ 10/180] Step 1000/1249 Loss 4.707 Prec@(1,3) (62.4%, 96.2%), ce_loss 1.459, lat_loss 22.192
09/21 06:07:58 AM | Train: [ 10/180] Step 1050/1249 Loss 4.711 Prec@(1,3) (62.3%, 96.2%), ce_loss 1.458, lat_loss 22.192
09/21 06:08:32 AM | Train: [ 10/180] Step 1100/1249 Loss 4.711 Prec@(1,3) (62.4%, 96.2%), ce_loss 1.456, lat_loss 22.192
09/21 06:09:04 AM | Train: [ 10/180] Step 1150/1249 Loss 4.707 Prec@(1,3) (62.4%, 96.3%), ce_loss 1.455, lat_loss 22.192
09/21 06:09:34 AM | Train: [ 10/180] Step 1200/1249 Loss 4.694 Prec@(1,3) (62.5%, 96.3%), ce_loss 1.453, lat_loss 22.192
09/21 06:10:02 AM | Train: [ 10/180] Step 1249/1249 Loss 4.690 Prec@(1,3) (62.6%, 96.3%), ce_loss 1.451, lat_loss 22.192
09/21 06:10:02 AM | _w_step_train: [ 10/180] Final Prec@1 62.5750% Time 822.17
09/21 06:10:02 AM | Start to train weights for epoch 10
09/21 06:10:38 AM | Train: [ 11/180] Step 050/1249 Loss 4.496 Prec@(1,3) (65.1%, 96.8%), ce_loss 1.449, lat_loss 22.192
09/21 06:11:12 AM | Train: [ 11/180] Step 100/1249 Loss 4.469 Prec@(1,3) (64.8%, 96.7%), ce_loss 1.447, lat_loss 22.192
09/21 06:11:45 AM | Train: [ 11/180] Step 150/1249 Loss 4.510 Prec@(1,3) (64.6%, 96.5%), ce_loss 1.446, lat_loss 22.192
09/21 06:12:18 AM | Train: [ 11/180] Step 200/1249 Loss 4.556 Prec@(1,3) (64.2%, 96.7%), ce_loss 1.444, lat_loss 22.192
09/21 06:12:50 AM | Train: [ 11/180] Step 250/1249 Loss 4.536 Prec@(1,3) (64.5%, 96.7%), ce_loss 1.443, lat_loss 22.192
09/21 06:13:20 AM | Train: [ 11/180] Step 300/1249 Loss 4.529 Prec@(1,3) (64.3%, 96.7%), ce_loss 1.441, lat_loss 22.192
09/21 06:13:50 AM | Train: [ 11/180] Step 350/1249 Loss 4.513 Prec@(1,3) (64.4%, 96.6%), ce_loss 1.439, lat_loss 22.192
09/21 06:14:20 AM | Train: [ 11/180] Step 400/1249 Loss 4.493 Prec@(1,3) (64.5%, 96.6%), ce_loss 1.437, lat_loss 22.192
09/21 06:14:50 AM | Train: [ 11/180] Step 450/1249 Loss 4.492 Prec@(1,3) (64.4%, 96.7%), ce_loss 1.436, lat_loss 22.192
09/21 06:15:19 AM | Train: [ 11/180] Step 500/1249 Loss 4.514 Prec@(1,3) (64.3%, 96.6%), ce_loss 1.434, lat_loss 22.192
09/21 06:15:50 AM | Train: [ 11/180] Step 550/1249 Loss 4.500 Prec@(1,3) (64.4%, 96.7%), ce_loss 1.433, lat_loss 22.192
09/21 06:16:20 AM | Train: [ 11/180] Step 600/1249 Loss 4.497 Prec@(1,3) (64.4%, 96.7%), ce_loss 1.431, lat_loss 22.192
09/21 06:16:50 AM | Train: [ 11/180] Step 650/1249 Loss 4.501 Prec@(1,3) (64.4%, 96.6%), ce_loss 1.429, lat_loss 22.192
09/21 06:17:20 AM | Train: [ 11/180] Step 700/1249 Loss 4.505 Prec@(1,3) (64.4%, 96.6%), ce_loss 1.428, lat_loss 22.192
09/21 06:17:49 AM | Train: [ 11/180] Step 750/1249 Loss 4.513 Prec@(1,3) (64.2%, 96.6%), ce_loss 1.426, lat_loss 22.192
09/21 06:18:23 AM | Train: [ 11/180] Step 800/1249 Loss 4.502 Prec@(1,3) (64.3%, 96.6%), ce_loss 1.425, lat_loss 22.192
09/21 06:18:56 AM | Train: [ 11/180] Step 850/1249 Loss 4.501 Prec@(1,3) (64.4%, 96.6%), ce_loss 1.423, lat_loss 22.192
09/21 06:19:25 AM | Train: [ 11/180] Step 900/1249 Loss 4.504 Prec@(1,3) (64.3%, 96.6%), ce_loss 1.422, lat_loss 22.192
09/21 06:19:56 AM | Train: [ 11/180] Step 950/1249 Loss 4.498 Prec@(1,3) (64.4%, 96.6%), ce_loss 1.420, lat_loss 22.192
09/21 06:20:34 AM | Train: [ 11/180] Step 1000/1249 Loss 4.495 Prec@(1,3) (64.4%, 96.6%), ce_loss 1.419, lat_loss 22.192
09/21 06:21:12 AM | Train: [ 11/180] Step 1050/1249 Loss 4.498 Prec@(1,3) (64.3%, 96.6%), ce_loss 1.417, lat_loss 22.192
09/21 06:21:48 AM | Train: [ 11/180] Step 1100/1249 Loss 4.495 Prec@(1,3) (64.3%, 96.6%), ce_loss 1.416, lat_loss 22.192
09/21 06:22:18 AM | Train: [ 11/180] Step 1150/1249 Loss 4.480 Prec@(1,3) (64.4%, 96.7%), ce_loss 1.414, lat_loss 22.192
09/21 06:22:49 AM | Train: [ 11/180] Step 1200/1249 Loss 4.475 Prec@(1,3) (64.4%, 96.7%), ce_loss 1.412, lat_loss 22.192
09/21 06:23:23 AM | Train: [ 11/180] Step 1249/1249 Loss 4.472 Prec@(1,3) (64.4%, 96.6%), ce_loss 1.411, lat_loss 22.192
09/21 06:23:23 AM | _w_step_train: [ 11/180] Final Prec@1 64.4400% Time 801.09
09/21 06:23:23 AM | Start to train theta for epoch 10
09/21 06:23:49 AM | Train: [ 11/180] Step 050/312 Loss 4.507 Prec@(1,3) (63.8%, 96.6%), ce_loss 1.409, lat_loss 22.192
09/21 06:24:14 AM | Train: [ 11/180] Step 100/312 Loss 4.435 Prec@(1,3) (64.9%, 96.3%), ce_loss 1.408, lat_loss 22.192
09/21 06:24:39 AM | Train: [ 11/180] Step 150/312 Loss 4.499 Prec@(1,3) (64.7%, 96.4%), ce_loss 1.406, lat_loss 22.192
09/21 06:24:58 AM | Train: [ 11/180] Step 200/312 Loss 4.468 Prec@(1,3) (64.6%, 96.6%), ce_loss 1.405, lat_loss 22.192
09/21 06:25:16 AM | Train: [ 11/180] Step 250/312 Loss 4.446 Prec@(1,3) (64.7%, 96.6%), ce_loss 1.403, lat_loss 22.192
09/21 06:25:40 AM | Train: [ 11/180] Step 300/312 Loss 4.414 Prec@(1,3) (65.1%, 96.6%), ce_loss 1.402, lat_loss 22.192
09/21 06:25:48 AM | Train: [ 11/180] Step 312/312 Loss 4.410 Prec@(1,3) (65.3%, 96.5%), ce_loss 1.401, lat_loss 22.192
09/21 06:25:49 AM | _theta_step_train: [ 11/180] Final Prec@1 65.2600% Time 145.44
09/21 06:25:55 AM | Valid: [ 11/180] Step 050/312 Loss 3.971 Prec@(1,3) (68.0%, 97.7%), ce_loss 1.400, lat_loss 22.192
09/21 06:26:00 AM | Valid: [ 11/180] Step 100/312 Loss 4.125 Prec@(1,3) (66.9%, 97.0%), ce_loss 1.398, lat_loss 22.192
09/21 06:26:05 AM | Valid: [ 11/180] Step 150/312 Loss 4.137 Prec@(1,3) (67.4%, 96.6%), ce_loss 1.396, lat_loss 22.192
09/21 06:26:10 AM | Valid: [ 11/180] Step 200/312 Loss 4.181 Prec@(1,3) (66.7%, 96.7%), ce_loss 1.395, lat_loss 22.192
09/21 06:26:16 AM | Valid: [ 11/180] Step 250/312 Loss 4.203 Prec@(1,3) (66.6%, 96.8%), ce_loss 1.394, lat_loss 22.192
09/21 06:26:21 AM | Valid: [ 11/180] Step 300/312 Loss 4.195 Prec@(1,3) (66.6%, 96.8%), ce_loss 1.392, lat_loss 22.192
09/21 06:26:22 AM | Valid: [ 11/180] Step 312/312 Loss 4.199 Prec@(1,3) (66.7%, 96.8%), ce_loss 1.392, lat_loss 22.192
09/21 06:26:22 AM | val: [ 11/180] Final Prec@1 66.6700% Time 33.90
09/21 06:26:22 AM | Best top1 acc by now. Save model
09/21 06:26:23 AM | Start to train weights for epoch 11
09/21 06:26:58 AM | Train: [ 12/180] Step 050/1249 Loss 4.479 Prec@(1,3) (66.2%, 95.6%), ce_loss 1.390, lat_loss 22.192
09/21 06:27:32 AM | Train: [ 12/180] Step 100/1249 Loss 4.419 Prec@(1,3) (66.6%, 95.9%), ce_loss 1.389, lat_loss 22.192
09/21 06:28:03 AM | Train: [ 12/180] Step 150/1249 Loss 4.383 Prec@(1,3) (66.8%, 95.9%), ce_loss 1.387, lat_loss 22.191
09/21 06:28:33 AM | Train: [ 12/180] Step 200/1249 Loss 4.380 Prec@(1,3) (66.2%, 96.1%), ce_loss 1.386, lat_loss 22.191
09/21 06:29:03 AM | Train: [ 12/180] Step 250/1249 Loss 4.423 Prec@(1,3) (65.6%, 96.2%), ce_loss 1.385, lat_loss 22.191
09/21 06:29:33 AM | Train: [ 12/180] Step 300/1249 Loss 4.424 Prec@(1,3) (65.5%, 96.4%), ce_loss 1.384, lat_loss 22.191
09/21 06:30:03 AM | Train: [ 12/180] Step 350/1249 Loss 4.404 Prec@(1,3) (65.4%, 96.4%), ce_loss 1.382, lat_loss 22.191
09/21 06:30:31 AM | Train: [ 12/180] Step 400/1249 Loss 4.387 Prec@(1,3) (65.4%, 96.4%), ce_loss 1.381, lat_loss 22.191
09/21 06:31:00 AM | Train: [ 12/180] Step 450/1249 Loss 4.398 Prec@(1,3) (65.3%, 96.5%), ce_loss 1.379, lat_loss 22.191
09/21 06:31:30 AM | Train: [ 12/180] Step 500/1249 Loss 4.392 Prec@(1,3) (65.4%, 96.5%), ce_loss 1.378, lat_loss 22.191
09/21 06:31:59 AM | Train: [ 12/180] Step 550/1249 Loss 4.378 Prec@(1,3) (65.5%, 96.5%), ce_loss 1.377, lat_loss 22.191
09/21 06:32:28 AM | Train: [ 12/180] Step 600/1249 Loss 4.359 Prec@(1,3) (65.6%, 96.6%), ce_loss 1.375, lat_loss 22.191
09/21 06:32:57 AM | Train: [ 12/180] Step 650/1249 Loss 4.364 Prec@(1,3) (65.6%, 96.6%), ce_loss 1.374, lat_loss 22.191
09/21 06:33:26 AM | Train: [ 12/180] Step 700/1249 Loss 4.344 Prec@(1,3) (65.7%, 96.7%), ce_loss 1.372, lat_loss 22.191
09/21 06:33:56 AM | Train: [ 12/180] Step 750/1249 Loss 4.352 Prec@(1,3) (65.7%, 96.6%), ce_loss 1.371, lat_loss 22.191
09/21 06:34:25 AM | Train: [ 12/180] Step 800/1249 Loss 4.343 Prec@(1,3) (65.8%, 96.6%), ce_loss 1.370, lat_loss 22.191
09/21 06:34:55 AM | Train: [ 12/180] Step 850/1249 Loss 4.345 Prec@(1,3) (65.7%, 96.6%), ce_loss 1.369, lat_loss 22.190
09/21 06:35:24 AM | Train: [ 12/180] Step 900/1249 Loss 4.334 Prec@(1,3) (65.8%, 96.6%), ce_loss 1.367, lat_loss 22.190
09/21 06:35:57 AM | Train: [ 12/180] Step 950/1249 Loss 4.312 Prec@(1,3) (65.9%, 96.7%), ce_loss 1.366, lat_loss 22.190
09/21 06:36:30 AM | Train: [ 12/180] Step 1000/1249 Loss 4.300 Prec@(1,3) (66.0%, 96.7%), ce_loss 1.364, lat_loss 22.190
09/21 06:37:03 AM | Train: [ 12/180] Step 1050/1249 Loss 4.306 Prec@(1,3) (65.9%, 96.7%), ce_loss 1.363, lat_loss 22.190
09/21 06:37:33 AM | Train: [ 12/180] Step 1100/1249 Loss 4.304 Prec@(1,3) (65.9%, 96.7%), ce_loss 1.362, lat_loss 22.190
09/21 06:37:59 AM | Train: [ 12/180] Step 1150/1249 Loss 4.301 Prec@(1,3) (65.9%, 96.7%), ce_loss 1.360, lat_loss 22.190
09/21 06:38:26 AM | Train: [ 12/180] Step 1200/1249 Loss 4.303 Prec@(1,3) (65.9%, 96.7%), ce_loss 1.359, lat_loss 22.190
09/21 06:38:58 AM | Train: [ 12/180] Step 1249/1249 Loss 4.297 Prec@(1,3) (65.9%, 96.7%), ce_loss 1.358, lat_loss 22.190
09/21 06:38:58 AM | _w_step_train: [ 12/180] Final Prec@1 65.9425% Time 755.53
09/21 06:38:58 AM | Start to train theta for epoch 11
09/21 06:39:24 AM | Train: [ 12/180] Step 050/312 Loss 4.459 Prec@(1,3) (65.3%, 96.6%), ce_loss 1.357, lat_loss 22.190
09/21 06:39:49 AM | Train: [ 12/180] Step 100/312 Loss 4.223 Prec@(1,3) (66.7%, 97.1%), ce_loss 1.355, lat_loss 22.190
09/21 06:40:14 AM | Train: [ 12/180] Step 150/312 Loss 4.208 Prec@(1,3) (66.7%, 97.2%), ce_loss 1.354, lat_loss 22.190
09/21 06:40:36 AM | Train: [ 12/180] Step 200/312 Loss 4.283 Prec@(1,3) (66.1%, 97.0%), ce_loss 1.353, lat_loss 22.190
09/21 06:40:57 AM | Train: [ 12/180] Step 250/312 Loss 4.238 Prec@(1,3) (66.4%, 97.0%), ce_loss 1.351, lat_loss 22.190
09/21 06:41:16 AM | Train: [ 12/180] Step 300/312 Loss 4.288 Prec@(1,3) (66.1%, 97.0%), ce_loss 1.350, lat_loss 22.189
09/21 06:41:20 AM | Train: [ 12/180] Step 312/312 Loss 4.273 Prec@(1,3) (66.2%, 97.0%), ce_loss 1.350, lat_loss 22.189
09/21 06:41:20 AM | _theta_step_train: [ 12/180] Final Prec@1 66.2400% Time 142.18
09/21 06:41:26 AM | Valid: [ 12/180] Step 050/312 Loss 3.931 Prec@(1,3) (67.6%, 97.2%), ce_loss 1.349, lat_loss 22.189
09/21 06:41:32 AM | Valid: [ 12/180] Step 100/312 Loss 3.990 Prec@(1,3) (67.9%, 96.8%), ce_loss 1.347, lat_loss 22.189
09/21 06:41:38 AM | Valid: [ 12/180] Step 150/312 Loss 3.996 Prec@(1,3) (68.1%, 96.8%), ce_loss 1.346, lat_loss 22.189
09/21 06:41:45 AM | Valid: [ 12/180] Step 200/312 Loss 4.028 Prec@(1,3) (67.8%, 96.9%), ce_loss 1.345, lat_loss 22.189
09/21 06:41:51 AM | Valid: [ 12/180] Step 250/312 Loss 4.028 Prec@(1,3) (67.9%, 97.0%), ce_loss 1.343, lat_loss 22.189
09/21 06:41:57 AM | Valid: [ 12/180] Step 300/312 Loss 3.984 Prec@(1,3) (68.4%, 97.1%), ce_loss 1.342, lat_loss 22.189
09/21 06:41:58 AM | Valid: [ 12/180] Step 312/312 Loss 3.997 Prec@(1,3) (68.3%, 97.1%), ce_loss 1.341, lat_loss 22.189
09/21 06:41:58 AM | val: [ 12/180] Final Prec@1 68.3000% Time 37.75
09/21 06:41:58 AM | Best top1 acc by now. Save model
09/21 06:41:58 AM | Start to train weights for epoch 12
09/21 06:42:38 AM | Train: [ 13/180] Step 050/1249 Loss 4.317 Prec@(1,3) (65.5%, 97.1%), ce_loss 1.340, lat_loss 22.189
09/21 06:43:12 AM | Train: [ 13/180] Step 100/1249 Loss 4.300 Prec@(1,3) (64.6%, 97.4%), ce_loss 1.339, lat_loss 22.189
09/21 06:43:42 AM | Train: [ 13/180] Step 150/1249 Loss 4.314 Prec@(1,3) (65.1%, 97.3%), ce_loss 1.338, lat_loss 22.189
09/21 06:44:09 AM | Train: [ 13/180] Step 200/1249 Loss 4.273 Prec@(1,3) (65.9%, 97.2%), ce_loss 1.337, lat_loss 22.188
09/21 06:44:43 AM | Train: [ 13/180] Step 250/1249 Loss 4.237 Prec@(1,3) (66.2%, 97.2%), ce_loss 1.336, lat_loss 22.188
09/21 06:45:18 AM | Train: [ 13/180] Step 300/1249 Loss 4.223 Prec@(1,3) (66.2%, 97.3%), ce_loss 1.334, lat_loss 22.188
09/21 06:45:51 AM | Train: [ 13/180] Step 350/1249 Loss 4.215 Prec@(1,3) (66.5%, 97.1%), ce_loss 1.333, lat_loss 22.188
09/21 06:46:17 AM | Train: [ 13/180] Step 400/1249 Loss 4.219 Prec@(1,3) (66.3%, 97.2%), ce_loss 1.332, lat_loss 22.188
09/21 06:46:43 AM | Train: [ 13/180] Step 450/1249 Loss 4.218 Prec@(1,3) (66.3%, 97.1%), ce_loss 1.331, lat_loss 22.188
09/21 06:47:12 AM | Train: [ 13/180] Step 500/1249 Loss 4.195 Prec@(1,3) (66.5%, 97.1%), ce_loss 1.330, lat_loss 22.188
09/21 06:47:45 AM | Train: [ 13/180] Step 550/1249 Loss 4.203 Prec@(1,3) (66.5%, 97.1%), ce_loss 1.329, lat_loss 22.188
09/21 06:48:20 AM | Train: [ 13/180] Step 600/1249 Loss 4.200 Prec@(1,3) (66.6%, 97.0%), ce_loss 1.327, lat_loss 22.188
09/21 06:48:54 AM | Train: [ 13/180] Step 650/1249 Loss 4.188 Prec@(1,3) (66.6%, 97.1%), ce_loss 1.326, lat_loss 22.188
09/21 06:49:23 AM | Train: [ 13/180] Step 700/1249 Loss 4.186 Prec@(1,3) (66.5%, 97.1%), ce_loss 1.325, lat_loss 22.188
09/21 06:49:50 AM | Train: [ 13/180] Step 750/1249 Loss 4.188 Prec@(1,3) (66.4%, 97.1%), ce_loss 1.324, lat_loss 22.188
09/21 06:50:19 AM | Train: [ 13/180] Step 800/1249 Loss 4.199 Prec@(1,3) (66.4%, 97.1%), ce_loss 1.323, lat_loss 22.187
09/21 06:50:54 AM | Train: [ 13/180] Step 850/1249 Loss 4.200 Prec@(1,3) (66.4%, 97.1%), ce_loss 1.322, lat_loss 22.187
09/21 06:51:28 AM | Train: [ 13/180] Step 900/1249 Loss 4.197 Prec@(1,3) (66.4%, 97.1%), ce_loss 1.321, lat_loss 22.187
09/21 06:51:55 AM | Train: [ 13/180] Step 950/1249 Loss 4.193 Prec@(1,3) (66.5%, 97.1%), ce_loss 1.320, lat_loss 22.187
09/21 06:52:23 AM | Train: [ 13/180] Step 1000/1249 Loss 4.190 Prec@(1,3) (66.5%, 97.1%), ce_loss 1.318, lat_loss 22.187
09/21 06:52:57 AM | Train: [ 13/180] Step 1050/1249 Loss 4.183 Prec@(1,3) (66.6%, 97.2%), ce_loss 1.317, lat_loss 22.187
09/21 06:53:31 AM | Train: [ 13/180] Step 1100/1249 Loss 4.180 Prec@(1,3) (66.7%, 97.2%), ce_loss 1.316, lat_loss 22.187
09/21 06:54:05 AM | Train: [ 13/180] Step 1150/1249 Loss 4.191 Prec@(1,3) (66.7%, 97.2%), ce_loss 1.315, lat_loss 22.187
09/21 06:54:33 AM | Train: [ 13/180] Step 1200/1249 Loss 4.183 Prec@(1,3) (66.8%, 97.2%), ce_loss 1.314, lat_loss 22.187
09/21 06:55:01 AM | Train: [ 13/180] Step 1249/1249 Loss 4.173 Prec@(1,3) (66.9%, 97.2%), ce_loss 1.313, lat_loss 22.187
09/21 06:55:01 AM | _w_step_train: [ 13/180] Final Prec@1 66.9375% Time 782.33
09/21 06:55:01 AM | Start to train theta for epoch 12
09/21 06:55:25 AM | Train: [ 13/180] Step 050/312 Loss 3.944 Prec@(1,3) (67.8%, 97.4%), ce_loss 1.312, lat_loss 22.187
09/21 06:55:47 AM | Train: [ 13/180] Step 100/312 Loss 4.052 Prec@(1,3) (66.6%, 97.3%), ce_loss 1.311, lat_loss 22.187
09/21 06:56:11 AM | Train: [ 13/180] Step 150/312 Loss 4.075 Prec@(1,3) (67.2%, 97.0%), ce_loss 1.310, lat_loss 22.186
09/21 06:56:35 AM | Train: [ 13/180] Step 200/312 Loss 4.025 Prec@(1,3) (67.3%, 97.3%), ce_loss 1.308, lat_loss 22.186
09/21 06:57:01 AM | Train: [ 13/180] Step 250/312 Loss 4.013 Prec@(1,3) (67.6%, 97.5%), ce_loss 1.307, lat_loss 22.186
09/21 06:57:27 AM | Train: [ 13/180] Step 300/312 Loss 4.003 Prec@(1,3) (67.8%, 97.4%), ce_loss 1.306, lat_loss 22.186
09/21 06:57:33 AM | Train: [ 13/180] Step 312/312 Loss 4.006 Prec@(1,3) (67.8%, 97.4%), ce_loss 1.306, lat_loss 22.186
09/21 06:57:33 AM | _theta_step_train: [ 13/180] Final Prec@1 67.7700% Time 152.68
09/21 06:57:40 AM | Valid: [ 13/180] Step 050/312 Loss 3.733 Prec@(1,3) (71.1%, 98.2%), ce_loss 1.304, lat_loss 22.186
09/21 06:57:45 AM | Valid: [ 13/180] Step 100/312 Loss 3.859 Prec@(1,3) (70.2%, 97.4%), ce_loss 1.303, lat_loss 22.186
09/21 06:57:50 AM | Valid: [ 13/180] Step 150/312 Loss 3.860 Prec@(1,3) (70.1%, 97.3%), ce_loss 1.302, lat_loss 22.186
09/21 06:57:56 AM | Valid: [ 13/180] Step 200/312 Loss 3.889 Prec@(1,3) (69.2%, 97.3%), ce_loss 1.301, lat_loss 22.186
09/21 06:58:01 AM | Valid: [ 13/180] Step 250/312 Loss 3.921 Prec@(1,3) (69.0%, 97.3%), ce_loss 1.300, lat_loss 22.186
09/21 06:58:07 AM | Valid: [ 13/180] Step 300/312 Loss 3.927 Prec@(1,3) (68.9%, 97.4%), ce_loss 1.299, lat_loss 22.186
09/21 06:58:08 AM | Valid: [ 13/180] Step 312/312 Loss 3.926 Prec@(1,3) (68.9%, 97.4%), ce_loss 1.298, lat_loss 22.186
09/21 06:58:08 AM | val: [ 13/180] Final Prec@1 68.9200% Time 34.75
09/21 06:58:08 AM | Best top1 acc by now. Save model
09/21 06:58:08 AM | Start to train weights for epoch 13
09/21 06:58:41 AM | Train: [ 14/180] Step 050/1249 Loss 4.061 Prec@(1,3) (69.1%, 97.0%), ce_loss 1.297, lat_loss 22.186
09/21 06:59:15 AM | Train: [ 14/180] Step 100/1249 Loss 3.967 Prec@(1,3) (68.8%, 97.6%), ce_loss 1.296, lat_loss 22.186
09/21 06:59:52 AM | Train: [ 14/180] Step 150/1249 Loss 3.977 Prec@(1,3) (68.9%, 97.5%), ce_loss 1.295, lat_loss 22.186
09/21 07:00:30 AM | Train: [ 14/180] Step 200/1249 Loss 4.034 Prec@(1,3) (68.7%, 97.2%), ce_loss 1.294, lat_loss 22.186
09/21 07:01:08 AM | Train: [ 14/180] Step 250/1249 Loss 4.108 Prec@(1,3) (68.2%, 97.2%), ce_loss 1.293, lat_loss 22.186
09/21 07:01:38 AM | Train: [ 14/180] Step 300/1249 Loss 4.105 Prec@(1,3) (67.9%, 97.3%), ce_loss 1.292, lat_loss 22.186
09/21 07:02:15 AM | Train: [ 14/180] Step 350/1249 Loss 4.123 Prec@(1,3) (67.6%, 97.3%), ce_loss 1.291, lat_loss 22.186
09/21 07:02:50 AM | Train: [ 14/180] Step 400/1249 Loss 4.077 Prec@(1,3) (68.0%, 97.3%), ce_loss 1.290, lat_loss 22.185
09/21 07:03:22 AM | Train: [ 14/180] Step 450/1249 Loss 4.077 Prec@(1,3) (67.9%, 97.3%), ce_loss 1.289, lat_loss 22.185
09/21 07:03:52 AM | Train: [ 14/180] Step 500/1249 Loss 4.069 Prec@(1,3) (68.0%, 97.3%), ce_loss 1.288, lat_loss 22.185
09/21 07:04:25 AM | Train: [ 14/180] Step 550/1249 Loss 4.051 Prec@(1,3) (68.2%, 97.3%), ce_loss 1.287, lat_loss 22.185
09/21 07:04:58 AM | Train: [ 14/180] Step 600/1249 Loss 4.047 Prec@(1,3) (68.3%, 97.3%), ce_loss 1.286, lat_loss 22.185
09/21 07:05:30 AM | Train: [ 14/180] Step 650/1249 Loss 4.046 Prec@(1,3) (68.3%, 97.3%), ce_loss 1.285, lat_loss 22.185
09/21 07:05:57 AM | Train: [ 14/180] Step 700/1249 Loss 4.038 Prec@(1,3) (68.4%, 97.3%), ce_loss 1.284, lat_loss 22.185
09/21 07:06:25 AM | Train: [ 14/180] Step 750/1249 Loss 4.019 Prec@(1,3) (68.6%, 97.3%), ce_loss 1.283, lat_loss 22.185
09/21 07:06:55 AM | Train: [ 14/180] Step 800/1249 Loss 4.023 Prec@(1,3) (68.5%, 97.3%), ce_loss 1.282, lat_loss 22.185
09/21 07:07:28 AM | Train: [ 14/180] Step 850/1249 Loss 4.017 Prec@(1,3) (68.5%, 97.3%), ce_loss 1.281, lat_loss 22.185
09/21 07:08:01 AM | Train: [ 14/180] Step 900/1249 Loss 4.016 Prec@(1,3) (68.4%, 97.4%), ce_loss 1.280, lat_loss 22.185
09/21 07:08:32 AM | Train: [ 14/180] Step 950/1249 Loss 4.015 Prec@(1,3) (68.5%, 97.4%), ce_loss 1.279, lat_loss 22.185
09/21 07:09:02 AM | Train: [ 14/180] Step 1000/1249 Loss 4.016 Prec@(1,3) (68.5%, 97.3%), ce_loss 1.278, lat_loss 22.185
09/21 07:09:38 AM | Train: [ 14/180] Step 1050/1249 Loss 4.014 Prec@(1,3) (68.4%, 97.3%), ce_loss 1.277, lat_loss 22.185
09/21 07:10:11 AM | Train: [ 14/180] Step 1100/1249 Loss 4.016 Prec@(1,3) (68.5%, 97.3%), ce_loss 1.276, lat_loss 22.185
09/21 07:10:39 AM | Train: [ 14/180] Step 1150/1249 Loss 4.016 Prec@(1,3) (68.5%, 97.3%), ce_loss 1.275, lat_loss 22.185
09/21 07:11:05 AM | Train: [ 14/180] Step 1200/1249 Loss 4.011 Prec@(1,3) (68.6%, 97.3%), ce_loss 1.274, lat_loss 22.184
09/21 07:11:31 AM | Train: [ 14/180] Step 1249/1249 Loss 4.019 Prec@(1,3) (68.5%, 97.3%), ce_loss 1.273, lat_loss 22.184
09/21 07:11:31 AM | _w_step_train: [ 14/180] Final Prec@1 68.5025% Time 802.59
09/21 07:11:31 AM | Start to train theta for epoch 13
09/21 07:11:58 AM | Train: [ 14/180] Step 050/312 Loss 3.877 Prec@(1,3) (69.7%, 97.5%), ce_loss 1.272, lat_loss 22.184
09/21 07:12:22 AM | Train: [ 14/180] Step 100/312 Loss 3.878 Prec@(1,3) (69.6%, 97.6%), ce_loss 1.271, lat_loss 22.184
09/21 07:12:44 AM | Train: [ 14/180] Step 150/312 Loss 3.886 Prec@(1,3) (69.4%, 97.5%), ce_loss 1.270, lat_loss 22.184
09/21 07:13:03 AM | Train: [ 14/180] Step 200/312 Loss 3.868 Prec@(1,3) (69.8%, 97.6%), ce_loss 1.269, lat_loss 22.184
09/21 07:13:22 AM | Train: [ 14/180] Step 250/312 Loss 3.821 Prec@(1,3) (70.4%, 97.5%), ce_loss 1.268, lat_loss 22.184
09/21 07:13:46 AM | Train: [ 14/180] Step 300/312 Loss 3.806 Prec@(1,3) (70.3%, 97.5%), ce_loss 1.267, lat_loss 22.184
09/21 07:13:51 AM | Train: [ 14/180] Step 312/312 Loss 3.809 Prec@(1,3) (70.3%, 97.5%), ce_loss 1.267, lat_loss 22.184
09/21 07:13:51 AM | _theta_step_train: [ 14/180] Final Prec@1 70.2800% Time 140.39
09/21 07:13:57 AM | Valid: [ 14/180] Step 050/312 Loss 3.734 Prec@(1,3) (69.7%, 97.9%), ce_loss 1.266, lat_loss 22.184
09/21 07:14:02 AM | Valid: [ 14/180] Step 100/312 Loss 3.716 Prec@(1,3) (70.3%, 97.9%), ce_loss 1.264, lat_loss 22.184
09/21 07:14:07 AM | Valid: [ 14/180] Step 150/312 Loss 3.691 Prec@(1,3) (70.7%, 97.5%), ce_loss 1.263, lat_loss 22.184
09/21 07:14:12 AM | Valid: [ 14/180] Step 200/312 Loss 3.732 Prec@(1,3) (70.4%, 97.6%), ce_loss 1.262, lat_loss 22.184
09/21 07:14:18 AM | Valid: [ 14/180] Step 250/312 Loss 3.744 Prec@(1,3) (70.3%, 97.6%), ce_loss 1.261, lat_loss 22.184
09/21 07:14:23 AM | Valid: [ 14/180] Step 300/312 Loss 3.762 Prec@(1,3) (70.4%, 97.5%), ce_loss 1.260, lat_loss 22.184
09/21 07:14:24 AM | Valid: [ 14/180] Step 312/312 Loss 3.768 Prec@(1,3) (70.3%, 97.5%), ce_loss 1.260, lat_loss 22.183
09/21 07:14:24 AM | val: [ 14/180] Final Prec@1 70.3100% Time 33.05
09/21 07:14:24 AM | Best top1 acc by now. Save model
09/21 07:14:25 AM | Start to train weights for epoch 14
09/21 07:15:01 AM | Train: [ 15/180] Step 050/1249 Loss 3.912 Prec@(1,3) (70.5%, 96.8%), ce_loss 1.259, lat_loss 22.183
09/21 07:15:33 AM | Train: [ 15/180] Step 100/1249 Loss 3.871 Prec@(1,3) (70.1%, 97.0%), ce_loss 1.258, lat_loss 22.183
09/21 07:15:58 AM | Train: [ 15/180] Step 150/1249 Loss 3.894 Prec@(1,3) (70.0%, 97.1%), ce_loss 1.257, lat_loss 22.183
09/21 07:16:28 AM | Train: [ 15/180] Step 200/1249 Loss 3.913 Prec@(1,3) (69.8%, 97.1%), ce_loss 1.256, lat_loss 22.183
09/21 07:16:57 AM | Train: [ 15/180] Step 250/1249 Loss 3.932 Prec@(1,3) (69.7%, 97.0%), ce_loss 1.256, lat_loss 22.183
09/21 07:17:26 AM | Train: [ 15/180] Step 300/1249 Loss 3.925 Prec@(1,3) (69.8%, 97.1%), ce_loss 1.255, lat_loss 22.183
09/21 07:17:55 AM | Train: [ 15/180] Step 350/1249 Loss 3.922 Prec@(1,3) (69.8%, 97.1%), ce_loss 1.254, lat_loss 22.183
09/21 07:18:27 AM | Train: [ 15/180] Step 400/1249 Loss 3.904 Prec@(1,3) (70.0%, 97.2%), ce_loss 1.253, lat_loss 22.183
09/21 07:18:58 AM | Train: [ 15/180] Step 450/1249 Loss 3.898 Prec@(1,3) (70.0%, 97.2%), ce_loss 1.252, lat_loss 22.183
09/21 07:19:27 AM | Train: [ 15/180] Step 500/1249 Loss 3.890 Prec@(1,3) (70.0%, 97.2%), ce_loss 1.251, lat_loss 22.183
09/21 07:19:57 AM | Train: [ 15/180] Step 550/1249 Loss 3.898 Prec@(1,3) (69.9%, 97.3%), ce_loss 1.250, lat_loss 22.183
09/21 07:20:27 AM | Train: [ 15/180] Step 600/1249 Loss 3.904 Prec@(1,3) (69.8%, 97.3%), ce_loss 1.249, lat_loss 22.182
09/21 07:20:57 AM | Train: [ 15/180] Step 650/1249 Loss 3.912 Prec@(1,3) (69.7%, 97.3%), ce_loss 1.248, lat_loss 22.182
09/21 07:21:30 AM | Train: [ 15/180] Step 700/1249 Loss 3.913 Prec@(1,3) (69.7%, 97.2%), ce_loss 1.247, lat_loss 22.182
09/21 07:22:01 AM | Train: [ 15/180] Step 750/1249 Loss 3.925 Prec@(1,3) (69.5%, 97.2%), ce_loss 1.247, lat_loss 22.182
09/21 07:22:30 AM | Train: [ 15/180] Step 800/1249 Loss 3.926 Prec@(1,3) (69.5%, 97.2%), ce_loss 1.246, lat_loss 22.182
09/21 07:23:01 AM | Train: [ 15/180] Step 850/1249 Loss 3.937 Prec@(1,3) (69.4%, 97.2%), ce_loss 1.245, lat_loss 22.182
09/21 07:23:35 AM | Train: [ 15/180] Step 900/1249 Loss 3.930 Prec@(1,3) (69.5%, 97.2%), ce_loss 1.244, lat_loss 22.182
09/21 07:24:06 AM | Train: [ 15/180] Step 950/1249 Loss 3.922 Prec@(1,3) (69.5%, 97.2%), ce_loss 1.243, lat_loss 22.182
09/21 07:24:37 AM | Train: [ 15/180] Step 1000/1249 Loss 3.919 Prec@(1,3) (69.5%, 97.3%), ce_loss 1.242, lat_loss 22.182
09/21 07:25:12 AM | Train: [ 15/180] Step 1050/1249 Loss 3.909 Prec@(1,3) (69.5%, 97.3%), ce_loss 1.241, lat_loss 22.182
09/21 07:25:43 AM | Train: [ 15/180] Step 1100/1249 Loss 3.909 Prec@(1,3) (69.4%, 97.3%), ce_loss 1.240, lat_loss 22.182
09/21 07:26:14 AM | Train: [ 15/180] Step 1150/1249 Loss 3.903 Prec@(1,3) (69.5%, 97.3%), ce_loss 1.239, lat_loss 22.182
09/21 07:26:45 AM | Train: [ 15/180] Step 1200/1249 Loss 3.895 Prec@(1,3) (69.5%, 97.3%), ce_loss 1.239, lat_loss 22.181
09/21 07:27:15 AM | Train: [ 15/180] Step 1249/1249 Loss 3.890 Prec@(1,3) (69.5%, 97.4%), ce_loss 1.238, lat_loss 22.181
09/21 07:27:15 AM | _w_step_train: [ 15/180] Final Prec@1 69.5050% Time 770.48
09/21 07:27:15 AM | Start to train theta for epoch 14
09/21 07:27:41 AM | Train: [ 15/180] Step 050/312 Loss 3.706 Prec@(1,3) (71.3%, 97.5%), ce_loss 1.237, lat_loss 22.181
09/21 07:28:05 AM | Train: [ 15/180] Step 100/312 Loss 3.803 Prec@(1,3) (70.2%, 97.5%), ce_loss 1.236, lat_loss 22.181
09/21 07:28:25 AM | Train: [ 15/180] Step 150/312 Loss 3.878 Prec@(1,3) (69.7%, 97.2%), ce_loss 1.235, lat_loss 22.181
09/21 07:28:51 AM | Train: [ 15/180] Step 200/312 Loss 3.900 Prec@(1,3) (69.6%, 97.2%), ce_loss 1.234, lat_loss 22.181
09/21 07:29:18 AM | Train: [ 15/180] Step 250/312 Loss 3.888 Prec@(1,3) (69.9%, 97.1%), ce_loss 1.233, lat_loss 22.181
09/21 07:29:45 AM | Train: [ 15/180] Step 300/312 Loss 3.849 Prec@(1,3) (70.1%, 97.3%), ce_loss 1.233, lat_loss 22.181
09/21 07:29:50 AM | Train: [ 15/180] Step 312/312 Loss 3.848 Prec@(1,3) (70.2%, 97.3%), ce_loss 1.232, lat_loss 22.181
09/21 07:29:50 AM | _theta_step_train: [ 15/180] Final Prec@1 70.1800% Time 154.66
09/21 07:29:56 AM | Valid: [ 15/180] Step 050/312 Loss 3.642 Prec@(1,3) (70.1%, 98.1%), ce_loss 1.231, lat_loss 22.181
09/21 07:30:01 AM | Valid: [ 15/180] Step 100/312 Loss 3.725 Prec@(1,3) (69.9%, 97.8%), ce_loss 1.230, lat_loss 22.181
09/21 07:30:07 AM | Valid: [ 15/180] Step 150/312 Loss 3.751 Prec@(1,3) (69.9%, 97.6%), ce_loss 1.230, lat_loss 22.181
09/21 07:30:12 AM | Valid: [ 15/180] Step 200/312 Loss 3.771 Prec@(1,3) (69.7%, 97.8%), ce_loss 1.229, lat_loss 22.181
09/21 07:30:17 AM | Valid: [ 15/180] Step 250/312 Loss 3.761 Prec@(1,3) (70.0%, 97.8%), ce_loss 1.228, lat_loss 22.181
09/21 07:30:23 AM | Valid: [ 15/180] Step 300/312 Loss 3.763 Prec@(1,3) (70.4%, 97.8%), ce_loss 1.227, lat_loss 22.180
09/21 07:30:24 AM | Valid: [ 15/180] Step 312/312 Loss 3.763 Prec@(1,3) (70.4%, 97.8%), ce_loss 1.227, lat_loss 22.180
09/21 07:30:24 AM | val: [ 15/180] Final Prec@1 70.4300% Time 34.32
09/21 07:30:24 AM | Best top1 acc by now. Save model
09/21 07:30:24 AM | Start to train weights for epoch 15
09/21 07:30:56 AM | Train: [ 16/180] Step 050/1249 Loss 3.667 Prec@(1,3) (70.3%, 97.9%), ce_loss 1.226, lat_loss 22.180
09/21 07:31:27 AM | Train: [ 16/180] Step 100/1249 Loss 3.666 Prec@(1,3) (71.2%, 97.7%), ce_loss 1.225, lat_loss 22.180
09/21 07:31:57 AM | Train: [ 16/180] Step 150/1249 Loss 3.660 Prec@(1,3) (71.2%, 97.8%), ce_loss 1.224, lat_loss 22.180
09/21 07:32:27 AM | Train: [ 16/180] Step 200/1249 Loss 3.711 Prec@(1,3) (70.7%, 97.7%), ce_loss 1.223, lat_loss 22.180
09/21 07:32:57 AM | Train: [ 16/180] Step 250/1249 Loss 3.804 Prec@(1,3) (70.1%, 97.5%), ce_loss 1.223, lat_loss 22.180
09/21 07:33:27 AM | Train: [ 16/180] Step 300/1249 Loss 3.793 Prec@(1,3) (70.1%, 97.5%), ce_loss 1.222, lat_loss 22.180
09/21 07:34:01 AM | Train: [ 16/180] Step 350/1249 Loss 3.776 Prec@(1,3) (70.5%, 97.5%), ce_loss 1.221, lat_loss 22.180
09/21 07:34:35 AM | Train: [ 16/180] Step 400/1249 Loss 3.778 Prec@(1,3) (70.4%, 97.4%), ce_loss 1.220, lat_loss 22.180
09/21 07:35:08 AM | Train: [ 16/180] Step 450/1249 Loss 3.793 Prec@(1,3) (70.3%, 97.5%), ce_loss 1.219, lat_loss 22.180
09/21 07:35:38 AM | Train: [ 16/180] Step 500/1249 Loss 3.803 Prec@(1,3) (70.2%, 97.4%), ce_loss 1.219, lat_loss 22.180
09/21 07:36:06 AM | Train: [ 16/180] Step 550/1249 Loss 3.791 Prec@(1,3) (70.3%, 97.5%), ce_loss 1.218, lat_loss 22.180
09/21 07:36:36 AM | Train: [ 16/180] Step 600/1249 Loss 3.798 Prec@(1,3) (70.3%, 97.5%), ce_loss 1.217, lat_loss 22.179
09/21 07:37:06 AM | Train: [ 16/180] Step 650/1249 Loss 3.791 Prec@(1,3) (70.4%, 97.5%), ce_loss 1.216, lat_loss 22.179
09/21 07:37:36 AM | Train: [ 16/180] Step 700/1249 Loss 3.801 Prec@(1,3) (70.2%, 97.5%), ce_loss 1.215, lat_loss 22.179
09/21 07:38:06 AM | Train: [ 16/180] Step 750/1249 Loss 3.802 Prec@(1,3) (70.2%, 97.4%), ce_loss 1.215, lat_loss 22.179
09/21 07:38:35 AM | Train: [ 16/180] Step 800/1249 Loss 3.790 Prec@(1,3) (70.3%, 97.5%), ce_loss 1.214, lat_loss 22.179
09/21 07:39:04 AM | Train: [ 16/180] Step 850/1249 Loss 3.798 Prec@(1,3) (70.3%, 97.5%), ce_loss 1.213, lat_loss 22.179
09/21 07:39:35 AM | Train: [ 16/180] Step 900/1249 Loss 3.791 Prec@(1,3) (70.3%, 97.5%), ce_loss 1.212, lat_loss 22.179
09/21 07:40:08 AM | Train: [ 16/180] Step 950/1249 Loss 3.787 Prec@(1,3) (70.4%, 97.5%), ce_loss 1.211, lat_loss 22.179
09/21 07:40:43 AM | Train: [ 16/180] Step 1000/1249 Loss 3.788 Prec@(1,3) (70.4%, 97.5%), ce_loss 1.211, lat_loss 22.179
09/21 07:41:16 AM | Train: [ 16/180] Step 1050/1249 Loss 3.786 Prec@(1,3) (70.4%, 97.5%), ce_loss 1.210, lat_loss 22.179
09/21 07:41:43 AM | Train: [ 16/180] Step 1100/1249 Loss 3.785 Prec@(1,3) (70.5%, 97.5%), ce_loss 1.209, lat_loss 22.179
09/21 07:42:11 AM | Train: [ 16/180] Step 1150/1249 Loss 3.784 Prec@(1,3) (70.5%, 97.5%), ce_loss 1.208, lat_loss 22.179
09/21 07:42:39 AM | Train: [ 16/180] Step 1200/1249 Loss 3.790 Prec@(1,3) (70.5%, 97.5%), ce_loss 1.208, lat_loss 22.179
09/21 07:43:07 AM | Train: [ 16/180] Step 1249/1249 Loss 3.790 Prec@(1,3) (70.4%, 97.5%), ce_loss 1.207, lat_loss 22.178
09/21 07:43:07 AM | _w_step_train: [ 16/180] Final Prec@1 70.4150% Time 762.77
09/21 07:43:07 AM | Start to train theta for epoch 15
09/21 07:43:35 AM | Train: [ 16/180] Step 050/312 Loss 3.915 Prec@(1,3) (69.4%, 96.9%), ce_loss 1.206, lat_loss 22.178
09/21 07:44:02 AM | Train: [ 16/180] Step 100/312 Loss 3.738 Prec@(1,3) (70.8%, 97.2%), ce_loss 1.205, lat_loss 22.178
09/21 07:44:30 AM | Train: [ 16/180] Step 150/312 Loss 3.800 Prec@(1,3) (70.7%, 97.4%), ce_loss 1.205, lat_loss 22.178
09/21 07:44:57 AM | Train: [ 16/180] Step 200/312 Loss 3.821 Prec@(1,3) (70.6%, 97.3%), ce_loss 1.204, lat_loss 22.178
09/21 07:45:25 AM | Train: [ 16/180] Step 250/312 Loss 3.831 Prec@(1,3) (70.5%, 97.3%), ce_loss 1.203, lat_loss 22.178
09/21 07:45:46 AM | Train: [ 16/180] Step 300/312 Loss 3.832 Prec@(1,3) (70.2%, 97.4%), ce_loss 1.202, lat_loss 22.178
09/21 07:45:51 AM | Train: [ 16/180] Step 312/312 Loss 3.856 Prec@(1,3) (70.0%, 97.3%), ce_loss 1.202, lat_loss 22.178
09/21 07:45:51 AM | _theta_step_train: [ 16/180] Final Prec@1 70.0400% Time 163.90
09/21 07:45:57 AM | Valid: [ 16/180] Step 050/312 Loss 3.934 Prec@(1,3) (69.2%, 98.0%), ce_loss 1.202, lat_loss 22.178
09/21 07:46:02 AM | Valid: [ 16/180] Step 100/312 Loss 3.995 Prec@(1,3) (68.8%, 97.8%), ce_loss 1.201, lat_loss 22.178
09/21 07:46:07 AM | Valid: [ 16/180] Step 150/312 Loss 3.945 Prec@(1,3) (69.5%, 97.5%), ce_loss 1.200, lat_loss 22.178
09/21 07:46:13 AM | Valid: [ 16/180] Step 200/312 Loss 3.866 Prec@(1,3) (69.9%, 97.6%), ce_loss 1.200, lat_loss 22.178
09/21 07:46:18 AM | Valid: [ 16/180] Step 250/312 Loss 3.889 Prec@(1,3) (69.9%, 97.5%), ce_loss 1.199, lat_loss 22.178
09/21 07:46:23 AM | Valid: [ 16/180] Step 300/312 Loss 3.891 Prec@(1,3) (69.8%, 97.5%), ce_loss 1.198, lat_loss 22.178
09/21 07:46:25 AM | Valid: [ 16/180] Step 312/312 Loss 3.889 Prec@(1,3) (69.8%, 97.6%), ce_loss 1.198, lat_loss 22.178
09/21 07:46:25 AM | val: [ 16/180] Final Prec@1 69.7600% Time 33.54
09/21 07:46:25 AM | Start to train weights for epoch 16
09/21 07:46:55 AM | Train: [ 17/180] Step 050/1249 Loss 3.660 Prec@(1,3) (71.6%, 97.5%), ce_loss 1.197, lat_loss 22.178
09/21 07:47:27 AM | Train: [ 17/180] Step 100/1249 Loss 3.646 Prec@(1,3) (71.9%, 97.5%), ce_loss 1.196, lat_loss 22.178
09/21 07:47:58 AM | Train: [ 17/180] Step 150/1249 Loss 3.714 Prec@(1,3) (71.3%, 97.4%), ce_loss 1.196, lat_loss 22.177
09/21 07:48:29 AM | Train: [ 17/180] Step 200/1249 Loss 3.698 Prec@(1,3) (71.3%, 97.5%), ce_loss 1.195, lat_loss 22.177
09/21 07:49:00 AM | Train: [ 17/180] Step 250/1249 Loss 3.706 Prec@(1,3) (71.1%, 97.4%), ce_loss 1.194, lat_loss 22.177
09/21 07:49:31 AM | Train: [ 17/180] Step 300/1249 Loss 3.664 Prec@(1,3) (71.5%, 97.5%), ce_loss 1.193, lat_loss 22.177
09/21 07:50:03 AM | Train: [ 17/180] Step 350/1249 Loss 3.675 Prec@(1,3) (71.4%, 97.5%), ce_loss 1.193, lat_loss 22.177
09/21 07:50:35 AM | Train: [ 17/180] Step 400/1249 Loss 3.687 Prec@(1,3) (71.3%, 97.5%), ce_loss 1.192, lat_loss 22.177
09/21 07:51:04 AM | Train: [ 17/180] Step 450/1249 Loss 3.688 Prec@(1,3) (71.2%, 97.5%), ce_loss 1.191, lat_loss 22.177
09/21 07:51:37 AM | Train: [ 17/180] Step 500/1249 Loss 3.680 Prec@(1,3) (71.3%, 97.6%), ce_loss 1.190, lat_loss 22.177
09/21 07:52:11 AM | Train: [ 17/180] Step 550/1249 Loss 3.677 Prec@(1,3) (71.3%, 97.6%), ce_loss 1.190, lat_loss 22.177
09/21 07:52:43 AM | Train: [ 17/180] Step 600/1249 Loss 3.677 Prec@(1,3) (71.2%, 97.6%), ce_loss 1.189, lat_loss 22.177
09/21 07:53:12 AM | Train: [ 17/180] Step 650/1249 Loss 3.676 Prec@(1,3) (71.2%, 97.7%), ce_loss 1.188, lat_loss 22.177
09/21 07:53:38 AM | Train: [ 17/180] Step 700/1249 Loss 3.659 Prec@(1,3) (71.3%, 97.7%), ce_loss 1.187, lat_loss 22.177
09/21 07:54:05 AM | Train: [ 17/180] Step 750/1249 Loss 3.664 Prec@(1,3) (71.3%, 97.7%), ce_loss 1.187, lat_loss 22.177
09/21 07:54:34 AM | Train: [ 17/180] Step 800/1249 Loss 3.653 Prec@(1,3) (71.4%, 97.7%), ce_loss 1.186, lat_loss 22.177
09/21 07:55:07 AM | Train: [ 17/180] Step 850/1249 Loss 3.656 Prec@(1,3) (71.4%, 97.7%), ce_loss 1.185, lat_loss 22.177
09/21 07:55:43 AM | Train: [ 17/180] Step 900/1249 Loss 3.661 Prec@(1,3) (71.3%, 97.7%), ce_loss 1.184, lat_loss 22.176
09/21 07:56:20 AM | Train: [ 17/180] Step 950/1249 Loss 3.653 Prec@(1,3) (71.4%, 97.7%), ce_loss 1.184, lat_loss 22.176
09/21 07:56:51 AM | Train: [ 17/180] Step 1000/1249 Loss 3.659 Prec@(1,3) (71.4%, 97.7%), ce_loss 1.183, lat_loss 22.176
09/21 07:57:20 AM | Train: [ 17/180] Step 1050/1249 Loss 3.659 Prec@(1,3) (71.4%, 97.7%), ce_loss 1.182, lat_loss 22.176
09/21 07:57:50 AM | Train: [ 17/180] Step 1100/1249 Loss 3.659 Prec@(1,3) (71.4%, 97.7%), ce_loss 1.182, lat_loss 22.176
09/21 07:58:23 AM | Train: [ 17/180] Step 1150/1249 Loss 3.657 Prec@(1,3) (71.3%, 97.7%), ce_loss 1.181, lat_loss 22.176
09/21 07:58:57 AM | Train: [ 17/180] Step 1200/1249 Loss 3.656 Prec@(1,3) (71.4%, 97.7%), ce_loss 1.180, lat_loss 22.176
09/21 07:59:30 AM | Train: [ 17/180] Step 1249/1249 Loss 3.661 Prec@(1,3) (71.3%, 97.7%), ce_loss 1.179, lat_loss 22.176
09/21 07:59:30 AM | _w_step_train: [ 17/180] Final Prec@1 71.3200% Time 785.66
09/21 07:59:30 AM | Start to train theta for epoch 16
09/21 07:59:55 AM | Train: [ 17/180] Step 050/312 Loss 3.688 Prec@(1,3) (70.8%, 97.8%), ce_loss 1.179, lat_loss 22.176
09/21 08:00:21 AM | Train: [ 17/180] Step 100/312 Loss 3.739 Prec@(1,3) (71.0%, 97.8%), ce_loss 1.178, lat_loss 22.176
09/21 08:00:45 AM | Train: [ 17/180] Step 150/312 Loss 3.689 Prec@(1,3) (71.6%, 97.8%), ce_loss 1.177, lat_loss 22.176
09/21 08:01:06 AM | Train: [ 17/180] Step 200/312 Loss 3.677 Prec@(1,3) (71.9%, 97.7%), ce_loss 1.177, lat_loss 22.176
09/21 08:01:27 AM | Train: [ 17/180] Step 250/312 Loss 3.674 Prec@(1,3) (72.0%, 97.8%), ce_loss 1.176, lat_loss 22.176
09/21 08:01:48 AM | Train: [ 17/180] Step 300/312 Loss 3.711 Prec@(1,3) (71.6%, 97.6%), ce_loss 1.175, lat_loss 22.176
09/21 08:01:53 AM | Train: [ 17/180] Step 312/312 Loss 3.704 Prec@(1,3) (71.6%, 97.7%), ce_loss 1.175, lat_loss 22.176
09/21 08:01:53 AM | _theta_step_train: [ 17/180] Final Prec@1 71.6300% Time 142.30
09/21 08:01:59 AM | Valid: [ 17/180] Step 050/312 Loss 3.775 Prec@(1,3) (70.0%, 97.4%), ce_loss 1.175, lat_loss 22.176
09/21 08:02:04 AM | Valid: [ 17/180] Step 100/312 Loss 3.836 Prec@(1,3) (70.4%, 97.4%), ce_loss 1.174, lat_loss 22.176
09/21 08:02:09 AM | Valid: [ 17/180] Step 150/312 Loss 3.818 Prec@(1,3) (70.6%, 97.4%), ce_loss 1.173, lat_loss 22.176
09/21 08:02:14 AM | Valid: [ 17/180] Step 200/312 Loss 3.783 Prec@(1,3) (71.0%, 97.6%), ce_loss 1.173, lat_loss 22.176
09/21 08:02:19 AM | Valid: [ 17/180] Step 250/312 Loss 3.780 Prec@(1,3) (70.9%, 97.5%), ce_loss 1.172, lat_loss 22.176
09/21 08:02:24 AM | Valid: [ 17/180] Step 300/312 Loss 3.761 Prec@(1,3) (71.0%, 97.6%), ce_loss 1.171, lat_loss 22.176
09/21 08:02:25 AM | Valid: [ 17/180] Step 312/312 Loss 3.760 Prec@(1,3) (70.9%, 97.6%), ce_loss 1.171, lat_loss 22.176
09/21 08:02:25 AM | val: [ 17/180] Final Prec@1 70.8900% Time 32.71
09/21 08:02:25 AM | Best top1 acc by now. Save model
09/21 08:02:26 AM | Start to train weights for epoch 17
09/21 08:03:03 AM | Train: [ 18/180] Step 050/1249 Loss 3.601 Prec@(1,3) (71.6%, 97.7%), ce_loss 1.171, lat_loss 22.176
09/21 08:03:35 AM | Train: [ 18/180] Step 100/1249 Loss 3.655 Prec@(1,3) (71.5%, 97.7%), ce_loss 1.170, lat_loss 22.176
09/21 08:04:03 AM | Train: [ 18/180] Step 150/1249 Loss 3.711 Prec@(1,3) (71.1%, 97.6%), ce_loss 1.169, lat_loss 22.176
09/21 08:04:31 AM | Train: [ 18/180] Step 200/1249 Loss 3.756 Prec@(1,3) (70.6%, 97.6%), ce_loss 1.169, lat_loss 22.175
09/21 08:05:00 AM | Train: [ 18/180] Step 250/1249 Loss 3.700 Prec@(1,3) (71.2%, 97.6%), ce_loss 1.168, lat_loss 22.175
09/21 08:05:36 AM | Train: [ 18/180] Step 300/1249 Loss 3.678 Prec@(1,3) (71.5%, 97.6%), ce_loss 1.167, lat_loss 22.175
09/21 08:06:05 AM | Train: [ 18/180] Step 350/1249 Loss 3.692 Prec@(1,3) (71.4%, 97.6%), ce_loss 1.167, lat_loss 22.175
09/21 08:06:31 AM | Train: [ 18/180] Step 400/1249 Loss 3.681 Prec@(1,3) (71.7%, 97.6%), ce_loss 1.166, lat_loss 22.175
09/21 08:07:02 AM | Train: [ 18/180] Step 450/1249 Loss 3.671 Prec@(1,3) (71.8%, 97.6%), ce_loss 1.165, lat_loss 22.175
09/21 08:07:35 AM | Train: [ 18/180] Step 500/1249 Loss 3.649 Prec@(1,3) (71.9%, 97.6%), ce_loss 1.165, lat_loss 22.175
09/21 08:08:06 AM | Train: [ 18/180] Step 550/1249 Loss 3.656 Prec@(1,3) (71.8%, 97.5%), ce_loss 1.164, lat_loss 22.175
09/21 08:08:33 AM | Train: [ 18/180] Step 600/1249 Loss 3.686 Prec@(1,3) (71.6%, 97.5%), ce_loss 1.163, lat_loss 22.175
09/21 08:08:59 AM | Train: [ 18/180] Step 650/1249 Loss 3.680 Prec@(1,3) (71.7%, 97.5%), ce_loss 1.163, lat_loss 22.175
09/21 08:09:28 AM | Train: [ 18/180] Step 700/1249 Loss 3.690 Prec@(1,3) (71.7%, 97.5%), ce_loss 1.162, lat_loss 22.175
09/21 08:10:01 AM | Train: [ 18/180] Step 750/1249 Loss 3.692 Prec@(1,3) (71.7%, 97.5%), ce_loss 1.162, lat_loss 22.175
09/21 08:10:32 AM | Train: [ 18/180] Step 800/1249 Loss 3.674 Prec@(1,3) (71.8%, 97.5%), ce_loss 1.161, lat_loss 22.175
09/21 08:11:04 AM | Train: [ 18/180] Step 850/1249 Loss 3.662 Prec@(1,3) (71.8%, 97.5%), ce_loss 1.160, lat_loss 22.175
09/21 08:11:36 AM | Train: [ 18/180] Step 900/1249 Loss 3.654 Prec@(1,3) (71.9%, 97.5%), ce_loss 1.159, lat_loss 22.175
09/21 08:12:11 AM | Train: [ 18/180] Step 950/1249 Loss 3.650 Prec@(1,3) (71.9%, 97.6%), ce_loss 1.159, lat_loss 22.175
09/21 08:12:46 AM | Train: [ 18/180] Step 1000/1249 Loss 3.643 Prec@(1,3) (71.9%, 97.6%), ce_loss 1.158, lat_loss 22.175
09/21 08:13:20 AM | Train: [ 18/180] Step 1050/1249 Loss 3.651 Prec@(1,3) (71.9%, 97.6%), ce_loss 1.158, lat_loss 22.175
09/21 08:13:52 AM | Train: [ 18/180] Step 1100/1249 Loss 3.645 Prec@(1,3) (71.9%, 97.6%), ce_loss 1.157, lat_loss 22.175
09/21 08:14:24 AM | Train: [ 18/180] Step 1150/1249 Loss 3.641 Prec@(1,3) (71.9%, 97.6%), ce_loss 1.156, lat_loss 22.175
09/21 08:14:51 AM | Train: [ 18/180] Step 1200/1249 Loss 3.637 Prec@(1,3) (71.9%, 97.6%), ce_loss 1.156, lat_loss 22.175
09/21 08:15:19 AM | Train: [ 18/180] Step 1249/1249 Loss 3.631 Prec@(1,3) (72.0%, 97.6%), ce_loss 1.155, lat_loss 22.175
09/21 08:15:19 AM | _w_step_train: [ 18/180] Final Prec@1 71.9750% Time 773.90
09/21 08:15:19 AM | Start to train theta for epoch 17
09/21 08:15:47 AM | Train: [ 18/180] Step 050/312 Loss 3.480 Prec@(1,3) (72.5%, 97.5%), ce_loss 1.154, lat_loss 22.175
09/21 08:16:11 AM | Train: [ 18/180] Step 100/312 Loss 3.439 Prec@(1,3) (72.9%, 97.6%), ce_loss 1.153, lat_loss 22.175
09/21 08:16:30 AM | Train: [ 18/180] Step 150/312 Loss 3.562 Prec@(1,3) (72.1%, 97.7%), ce_loss 1.153, lat_loss 22.175
09/21 08:16:51 AM | Train: [ 18/180] Step 200/312 Loss 3.571 Prec@(1,3) (72.1%, 97.6%), ce_loss 1.152, lat_loss 22.175
09/21 08:17:10 AM | Train: [ 18/180] Step 250/312 Loss 3.567 Prec@(1,3) (72.1%, 97.7%), ce_loss 1.152, lat_loss 22.175
09/21 08:17:29 AM | Train: [ 18/180] Step 300/312 Loss 3.574 Prec@(1,3) (72.3%, 97.7%), ce_loss 1.151, lat_loss 22.175
09/21 08:17:35 AM | Train: [ 18/180] Step 312/312 Loss 3.577 Prec@(1,3) (72.2%, 97.7%), ce_loss 1.151, lat_loss 22.175
09/21 08:17:35 AM | _theta_step_train: [ 18/180] Final Prec@1 72.2500% Time 135.70
09/21 08:17:42 AM | Valid: [ 18/180] Step 050/312 Loss 3.488 Prec@(1,3) (72.1%, 97.7%), ce_loss 1.150, lat_loss 22.175
09/21 08:17:48 AM | Valid: [ 18/180] Step 100/312 Loss 3.515 Prec@(1,3) (72.3%, 97.4%), ce_loss 1.150, lat_loss 22.175
09/21 08:17:54 AM | Valid: [ 18/180] Step 150/312 Loss 3.565 Prec@(1,3) (72.5%, 97.4%), ce_loss 1.149, lat_loss 22.175
09/21 08:18:00 AM | Valid: [ 18/180] Step 200/312 Loss 3.557 Prec@(1,3) (72.6%, 97.6%), ce_loss 1.148, lat_loss 22.175
09/21 08:18:06 AM | Valid: [ 18/180] Step 250/312 Loss 3.564 Prec@(1,3) (72.7%, 97.6%), ce_loss 1.148, lat_loss 22.174
09/21 08:18:12 AM | Valid: [ 18/180] Step 300/312 Loss 3.572 Prec@(1,3) (72.7%, 97.6%), ce_loss 1.147, lat_loss 22.174
09/21 08:18:13 AM | Valid: [ 18/180] Step 312/312 Loss 3.581 Prec@(1,3) (72.8%, 97.7%), ce_loss 1.147, lat_loss 22.174
09/21 08:18:13 AM | val: [ 18/180] Final Prec@1 72.7500% Time 38.19
09/21 08:18:13 AM | Best top1 acc by now. Save model
09/21 08:18:14 AM | Start to train weights for epoch 18
09/21 08:18:49 AM | Train: [ 19/180] Step 050/1249 Loss 3.397 Prec@(1,3) (73.0%, 98.1%), ce_loss 1.146, lat_loss 22.174
09/21 08:19:15 AM | Train: [ 19/180] Step 100/1249 Loss 3.485 Prec@(1,3) (72.3%, 98.0%), ce_loss 1.146, lat_loss 22.174
09/21 08:19:42 AM | Train: [ 19/180] Step 150/1249 Loss 3.524 Prec@(1,3) (72.4%, 97.9%), ce_loss 1.145, lat_loss 22.174
09/21 08:20:16 AM | Train: [ 19/180] Step 200/1249 Loss 3.556 Prec@(1,3) (72.6%, 97.9%), ce_loss 1.144, lat_loss 22.174
09/21 08:20:50 AM | Train: [ 19/180] Step 250/1249 Loss 3.573 Prec@(1,3) (72.6%, 97.8%), ce_loss 1.144, lat_loss 22.174
09/21 08:21:22 AM | Train: [ 19/180] Step 300/1249 Loss 3.591 Prec@(1,3) (72.3%, 97.7%), ce_loss 1.143, lat_loss 22.174
09/21 08:21:53 AM | Train: [ 19/180] Step 350/1249 Loss 3.628 Prec@(1,3) (72.0%, 97.7%), ce_loss 1.143, lat_loss 22.174
09/21 08:22:24 AM | Train: [ 19/180] Step 400/1249 Loss 3.609 Prec@(1,3) (72.0%, 97.8%), ce_loss 1.142, lat_loss 22.174
09/21 08:22:58 AM | Train: [ 19/180] Step 450/1249 Loss 3.602 Prec@(1,3) (72.1%, 97.8%), ce_loss 1.142, lat_loss 22.174
09/21 08:23:31 AM | Train: [ 19/180] Step 500/1249 Loss 3.599 Prec@(1,3) (72.0%, 97.8%), ce_loss 1.141, lat_loss 22.174
09/21 08:24:01 AM | Train: [ 19/180] Step 550/1249 Loss 3.608 Prec@(1,3) (72.0%, 97.8%), ce_loss 1.140, lat_loss 22.174
09/21 08:24:31 AM | Train: [ 19/180] Step 600/1249 Loss 3.605 Prec@(1,3) (71.9%, 97.8%), ce_loss 1.140, lat_loss 22.174
09/21 08:25:01 AM | Train: [ 19/180] Step 650/1249 Loss 3.593 Prec@(1,3) (72.0%, 97.8%), ce_loss 1.139, lat_loss 22.174
09/21 08:25:30 AM | Train: [ 19/180] Step 700/1249 Loss 3.600 Prec@(1,3) (72.0%, 97.9%), ce_loss 1.139, lat_loss 22.174
09/21 08:26:00 AM | Train: [ 19/180] Step 750/1249 Loss 3.583 Prec@(1,3) (72.1%, 97.9%), ce_loss 1.138, lat_loss 22.174
09/21 08:26:32 AM | Train: [ 19/180] Step 800/1249 Loss 3.583 Prec@(1,3) (72.1%, 97.9%), ce_loss 1.137, lat_loss 22.174
09/21 08:27:03 AM | Train: [ 19/180] Step 850/1249 Loss 3.573 Prec@(1,3) (72.2%, 97.9%), ce_loss 1.137, lat_loss 22.174
09/21 08:27:35 AM | Train: [ 19/180] Step 900/1249 Loss 3.565 Prec@(1,3) (72.3%, 97.9%), ce_loss 1.136, lat_loss 22.174
09/21 08:28:07 AM | Train: [ 19/180] Step 950/1249 Loss 3.563 Prec@(1,3) (72.3%, 97.9%), ce_loss 1.135, lat_loss 22.174
09/21 08:28:34 AM | Train: [ 19/180] Step 1000/1249 Loss 3.557 Prec@(1,3) (72.4%, 97.9%), ce_loss 1.135, lat_loss 22.174
09/21 08:29:03 AM | Train: [ 19/180] Step 1050/1249 Loss 3.551 Prec@(1,3) (72.4%, 97.9%), ce_loss 1.134, lat_loss 22.174
09/21 08:29:35 AM | Train: [ 19/180] Step 1100/1249 Loss 3.549 Prec@(1,3) (72.4%, 97.9%), ce_loss 1.134, lat_loss 22.174
09/21 08:30:07 AM | Train: [ 19/180] Step 1150/1249 Loss 3.549 Prec@(1,3) (72.5%, 97.9%), ce_loss 1.133, lat_loss 22.174
09/21 08:30:39 AM | Train: [ 19/180] Step 1200/1249 Loss 3.553 Prec@(1,3) (72.5%, 97.9%), ce_loss 1.133, lat_loss 22.174
09/21 08:31:09 AM | Train: [ 19/180] Step 1249/1249 Loss 3.556 Prec@(1,3) (72.5%, 97.9%), ce_loss 1.132, lat_loss 22.174
09/21 08:31:09 AM | _w_step_train: [ 19/180] Final Prec@1 72.4850% Time 775.39
09/21 08:31:09 AM | Start to train theta for epoch 18
09/21 08:31:29 AM | Train: [ 19/180] Step 050/312 Loss 3.510 Prec@(1,3) (73.0%, 97.9%), ce_loss 1.131, lat_loss 22.174
09/21 08:31:54 AM | Train: [ 19/180] Step 100/312 Loss 3.521 Prec@(1,3) (73.2%, 97.7%), ce_loss 1.131, lat_loss 22.174
09/21 08:32:19 AM | Train: [ 19/180] Step 150/312 Loss 3.497 Prec@(1,3) (73.6%, 97.9%), ce_loss 1.130, lat_loss 22.174
09/21 08:32:43 AM | Train: [ 19/180] Step 200/312 Loss 3.528 Prec@(1,3) (73.4%, 97.5%), ce_loss 1.130, lat_loss 22.174
09/21 08:33:04 AM | Train: [ 19/180] Step 250/312 Loss 3.552 Prec@(1,3) (73.1%, 97.5%), ce_loss 1.129, lat_loss 22.174
09/21 08:33:24 AM | Train: [ 19/180] Step 300/312 Loss 3.528 Prec@(1,3) (73.3%, 97.5%), ce_loss 1.128, lat_loss 22.174
09/21 08:33:29 AM | Train: [ 19/180] Step 312/312 Loss 3.535 Prec@(1,3) (73.3%, 97.6%), ce_loss 1.128, lat_loss 22.174
09/21 08:33:29 AM | _theta_step_train: [ 19/180] Final Prec@1 73.2600% Time 140.44
09/21 08:33:36 AM | Valid: [ 19/180] Step 050/312 Loss 3.363 Prec@(1,3) (73.9%, 98.3%), ce_loss 1.128, lat_loss 22.174
09/21 08:33:41 AM | Valid: [ 19/180] Step 100/312 Loss 3.457 Prec@(1,3) (73.4%, 97.9%), ce_loss 1.127, lat_loss 22.174
09/21 08:33:46 AM | Valid: [ 19/180] Step 150/312 Loss 3.415 Prec@(1,3) (74.2%, 97.8%), ce_loss 1.127, lat_loss 22.174
09/21 08:33:52 AM | Valid: [ 19/180] Step 200/312 Loss 3.431 Prec@(1,3) (73.9%, 98.0%), ce_loss 1.126, lat_loss 22.174
09/21 08:33:57 AM | Valid: [ 19/180] Step 250/312 Loss 3.450 Prec@(1,3) (73.8%, 98.0%), ce_loss 1.125, lat_loss 22.174
09/21 08:34:02 AM | Valid: [ 19/180] Step 300/312 Loss 3.470 Prec@(1,3) (73.7%, 98.0%), ce_loss 1.125, lat_loss 22.174
09/21 08:34:04 AM | Valid: [ 19/180] Step 312/312 Loss 3.459 Prec@(1,3) (73.9%, 98.0%), ce_loss 1.125, lat_loss 22.174
09/21 08:34:04 AM | val: [ 19/180] Final Prec@1 73.9100% Time 34.47
09/21 08:34:04 AM | Best top1 acc by now. Save model
09/21 08:34:04 AM | Start to train weights for epoch 19
09/21 08:34:38 AM | Train: [ 20/180] Step 050/1249 Loss 3.283 Prec@(1,3) (73.1%, 98.4%), ce_loss 1.124, lat_loss 22.174
09/21 08:35:08 AM | Train: [ 20/180] Step 100/1249 Loss 3.294 Prec@(1,3) (73.7%, 98.4%), ce_loss 1.123, lat_loss 22.174
09/21 08:35:38 AM | Train: [ 20/180] Step 150/1249 Loss 3.338 Prec@(1,3) (73.5%, 98.1%), ce_loss 1.123, lat_loss 22.174
09/21 08:36:09 AM | Train: [ 20/180] Step 200/1249 Loss 3.345 Prec@(1,3) (73.8%, 98.2%), ce_loss 1.122, lat_loss 22.174
09/21 08:36:40 AM | Train: [ 20/180] Step 250/1249 Loss 3.326 Prec@(1,3) (73.9%, 98.2%), ce_loss 1.122, lat_loss 22.174
09/21 08:37:14 AM | Train: [ 20/180] Step 300/1249 Loss 3.389 Prec@(1,3) (73.4%, 98.2%), ce_loss 1.121, lat_loss 22.174
09/21 08:37:46 AM | Train: [ 20/180] Step 350/1249 Loss 3.412 Prec@(1,3) (73.3%, 98.2%), ce_loss 1.120, lat_loss 22.174
09/21 08:38:19 AM | Train: [ 20/180] Step 400/1249 Loss 3.433 Prec@(1,3) (73.1%, 98.1%), ce_loss 1.120, lat_loss 22.174
09/21 08:38:54 AM | Train: [ 20/180] Step 450/1249 Loss 3.440 Prec@(1,3) (73.2%, 98.1%), ce_loss 1.119, lat_loss 22.174
09/21 08:39:26 AM | Train: [ 20/180] Step 500/1249 Loss 3.444 Prec@(1,3) (73.2%, 98.1%), ce_loss 1.119, lat_loss 22.174
09/21 08:39:54 AM | Train: [ 20/180] Step 550/1249 Loss 3.450 Prec@(1,3) (73.1%, 98.0%), ce_loss 1.118, lat_loss 22.174
09/21 08:40:25 AM | Train: [ 20/180] Step 600/1249 Loss 3.436 Prec@(1,3) (73.2%, 98.0%), ce_loss 1.118, lat_loss 22.174
09/21 08:40:59 AM | Train: [ 20/180] Step 650/1249 Loss 3.434 Prec@(1,3) (73.3%, 98.0%), ce_loss 1.117, lat_loss 22.174
09/21 08:41:33 AM | Train: [ 20/180] Step 700/1249 Loss 3.443 Prec@(1,3) (73.3%, 98.0%), ce_loss 1.117, lat_loss 22.173
09/21 08:42:05 AM | Train: [ 20/180] Step 750/1249 Loss 3.452 Prec@(1,3) (73.3%, 97.9%), ce_loss 1.116, lat_loss 22.173
09/21 08:42:34 AM | Train: [ 20/180] Step 800/1249 Loss 3.450 Prec@(1,3) (73.3%, 97.9%), ce_loss 1.116, lat_loss 22.173
09/21 08:42:59 AM | Train: [ 20/180] Step 850/1249 Loss 3.443 Prec@(1,3) (73.4%, 97.9%), ce_loss 1.115, lat_loss 22.173
09/21 08:43:26 AM | Train: [ 20/180] Step 900/1249 Loss 3.449 Prec@(1,3) (73.2%, 98.0%), ce_loss 1.114, lat_loss 22.173
09/21 08:43:59 AM | Train: [ 20/180] Step 950/1249 Loss 3.451 Prec@(1,3) (73.2%, 98.0%), ce_loss 1.114, lat_loss 22.173
09/21 08:44:30 AM | Train: [ 20/180] Step 1000/1249 Loss 3.451 Prec@(1,3) (73.2%, 98.0%), ce_loss 1.113, lat_loss 22.173
09/21 08:44:59 AM | Train: [ 20/180] Step 1050/1249 Loss 3.443 Prec@(1,3) (73.3%, 98.0%), ce_loss 1.113, lat_loss 22.173
09/21 08:45:28 AM | Train: [ 20/180] Step 1100/1249 Loss 3.435 Prec@(1,3) (73.4%, 98.0%), ce_loss 1.112, lat_loss 22.173
09/21 08:45:58 AM | Train: [ 20/180] Step 1150/1249 Loss 3.439 Prec@(1,3) (73.3%, 98.0%), ce_loss 1.112, lat_loss 22.173
09/21 08:46:29 AM | Train: [ 20/180] Step 1200/1249 Loss 3.445 Prec@(1,3) (73.3%, 98.0%), ce_loss 1.111, lat_loss 22.173
09/21 08:46:59 AM | Train: [ 20/180] Step 1249/1249 Loss 3.455 Prec@(1,3) (73.3%, 98.0%), ce_loss 1.111, lat_loss 22.173
09/21 08:46:59 AM | _w_step_train: [ 20/180] Final Prec@1 73.2575% Time 774.53
09/21 08:46:59 AM | Start to train theta for epoch 19
09/21 08:47:22 AM | Train: [ 20/180] Step 050/312 Loss 3.278 Prec@(1,3) (74.9%, 98.0%), ce_loss 1.110, lat_loss 22.173
09/21 08:47:44 AM | Train: [ 20/180] Step 100/312 Loss 3.393 Prec@(1,3) (73.9%, 97.7%), ce_loss 1.109, lat_loss 22.173
09/21 08:48:04 AM | Train: [ 20/180] Step 150/312 Loss 3.439 Prec@(1,3) (73.4%, 97.8%), ce_loss 1.109, lat_loss 22.173
09/21 08:48:25 AM | Train: [ 20/180] Step 200/312 Loss 3.415 Prec@(1,3) (73.5%, 97.8%), ce_loss 1.108, lat_loss 22.173
09/21 08:48:46 AM | Train: [ 20/180] Step 250/312 Loss 3.464 Prec@(1,3) (73.2%, 97.7%), ce_loss 1.108, lat_loss 22.173
09/21 08:49:07 AM | Train: [ 20/180] Step 300/312 Loss 3.464 Prec@(1,3) (73.3%, 97.6%), ce_loss 1.107, lat_loss 22.173
09/21 08:49:13 AM | Train: [ 20/180] Step 312/312 Loss 3.447 Prec@(1,3) (73.5%, 97.6%), ce_loss 1.107, lat_loss 22.173
09/21 08:49:13 AM | _theta_step_train: [ 20/180] Final Prec@1 73.4900% Time 133.97
09/21 08:49:19 AM | Valid: [ 20/180] Step 050/312 Loss 3.282 Prec@(1,3) (74.9%, 98.5%), ce_loss 1.107, lat_loss 22.173
09/21 08:49:24 AM | Valid: [ 20/180] Step 100/312 Loss 3.385 Prec@(1,3) (74.1%, 98.3%), ce_loss 1.106, lat_loss 22.173
09/21 08:49:29 AM | Valid: [ 20/180] Step 150/312 Loss 3.324 Prec@(1,3) (75.0%, 98.1%), ce_loss 1.106, lat_loss 22.173
09/21 08:49:35 AM | Valid: [ 20/180] Step 200/312 Loss 3.353 Prec@(1,3) (74.4%, 98.1%), ce_loss 1.105, lat_loss 22.173
09/21 08:49:40 AM | Valid: [ 20/180] Step 250/312 Loss 3.338 Prec@(1,3) (74.3%, 98.2%), ce_loss 1.104, lat_loss 22.173
09/21 08:49:46 AM | Valid: [ 20/180] Step 300/312 Loss 3.359 Prec@(1,3) (73.9%, 98.2%), ce_loss 1.104, lat_loss 22.173
09/21 08:49:47 AM | Valid: [ 20/180] Step 312/312 Loss 3.356 Prec@(1,3) (74.1%, 98.2%), ce_loss 1.104, lat_loss 22.173
09/21 08:49:47 AM | val: [ 20/180] Final Prec@1 74.0500% Time 34.31
09/21 08:49:47 AM | Best top1 acc by now. Save model
09/21 08:49:47 AM | Start to train weights for epoch 20
09/21 08:50:20 AM | Train: [ 21/180] Step 050/1249 Loss 3.324 Prec@(1,3) (74.1%, 98.2%), ce_loss 1.103, lat_loss 22.173
09/21 08:50:47 AM | Train: [ 21/180] Step 100/1249 Loss 3.467 Prec@(1,3) (72.8%, 98.1%), ce_loss 1.103, lat_loss 22.173
09/21 08:51:16 AM | Train: [ 21/180] Step 150/1249 Loss 3.388 Prec@(1,3) (73.3%, 98.3%), ce_loss 1.102, lat_loss 22.173
09/21 08:51:48 AM | Train: [ 21/180] Step 200/1249 Loss 3.413 Prec@(1,3) (73.3%, 98.2%), ce_loss 1.102, lat_loss 22.173
09/21 08:52:19 AM | Train: [ 21/180] Step 250/1249 Loss 3.405 Prec@(1,3) (73.7%, 98.2%), ce_loss 1.101, lat_loss 22.173
09/21 08:52:44 AM | Train: [ 21/180] Step 300/1249 Loss 3.407 Prec@(1,3) (73.7%, 98.2%), ce_loss 1.101, lat_loss 22.172
09/21 08:53:13 AM | Train: [ 21/180] Step 350/1249 Loss 3.376 Prec@(1,3) (74.0%, 98.2%), ce_loss 1.100, lat_loss 22.172
09/21 08:53:47 AM | Train: [ 21/180] Step 400/1249 Loss 3.370 Prec@(1,3) (74.2%, 98.2%), ce_loss 1.099, lat_loss 22.172
09/21 08:54:21 AM | Train: [ 21/180] Step 450/1249 Loss 3.378 Prec@(1,3) (74.1%, 98.0%), ce_loss 1.099, lat_loss 22.172
09/21 08:54:49 AM | Train: [ 21/180] Step 500/1249 Loss 3.384 Prec@(1,3) (74.0%, 98.0%), ce_loss 1.098, lat_loss 22.172
09/21 08:55:20 AM | Train: [ 21/180] Step 550/1249 Loss 3.385 Prec@(1,3) (74.1%, 98.0%), ce_loss 1.098, lat_loss 22.172
09/21 08:55:52 AM | Train: [ 21/180] Step 600/1249 Loss 3.393 Prec@(1,3) (74.0%, 98.0%), ce_loss 1.097, lat_loss 22.172
09/21 08:56:24 AM | Train: [ 21/180] Step 650/1249 Loss 3.392 Prec@(1,3) (74.0%, 98.0%), ce_loss 1.097, lat_loss 22.172
09/21 08:56:56 AM | Train: [ 21/180] Step 700/1249 Loss 3.394 Prec@(1,3) (74.0%, 98.0%), ce_loss 1.096, lat_loss 22.172
09/21 08:57:27 AM | Train: [ 21/180] Step 750/1249 Loss 3.402 Prec@(1,3) (73.9%, 98.0%), ce_loss 1.096, lat_loss 22.172
09/21 08:57:59 AM | Train: [ 21/180] Step 800/1249 Loss 3.397 Prec@(1,3) (73.9%, 98.0%), ce_loss 1.095, lat_loss 22.172
09/21 08:58:36 AM | Train: [ 21/180] Step 850/1249 Loss 3.408 Prec@(1,3) (73.8%, 98.0%), ce_loss 1.095, lat_loss 22.172
09/21 08:59:12 AM | Train: [ 21/180] Step 900/1249 Loss 3.399 Prec@(1,3) (73.8%, 98.0%), ce_loss 1.094, lat_loss 22.172
09/21 08:59:49 AM | Train: [ 21/180] Step 950/1249 Loss 3.395 Prec@(1,3) (73.9%, 98.0%), ce_loss 1.094, lat_loss 22.172
09/21 09:00:19 AM | Train: [ 21/180] Step 1000/1249 Loss 3.400 Prec@(1,3) (73.9%, 98.0%), ce_loss 1.093, lat_loss 22.172
09/21 09:00:54 AM | Train: [ 21/180] Step 1050/1249 Loss 3.405 Prec@(1,3) (73.9%, 98.0%), ce_loss 1.093, lat_loss 22.172
09/21 09:01:28 AM | Train: [ 21/180] Step 1100/1249 Loss 3.403 Prec@(1,3) (73.9%, 98.0%), ce_loss 1.092, lat_loss 22.172
09/21 09:01:57 AM | Train: [ 21/180] Step 1150/1249 Loss 3.405 Prec@(1,3) (73.8%, 98.0%), ce_loss 1.092, lat_loss 22.172
09/21 09:02:22 AM | Train: [ 21/180] Step 1200/1249 Loss 3.406 Prec@(1,3) (73.8%, 98.0%), ce_loss 1.091, lat_loss 22.172
09/21 09:02:50 AM | Train: [ 21/180] Step 1249/1249 Loss 3.404 Prec@(1,3) (73.8%, 98.0%), ce_loss 1.091, lat_loss 22.172
09/21 09:02:50 AM | _w_step_train: [ 21/180] Final Prec@1 73.7800% Time 782.66
09/21 09:02:50 AM | Start to train theta for epoch 20
09/21 09:03:12 AM | Train: [ 21/180] Step 050/312 Loss 3.594 Prec@(1,3) (74.0%, 97.9%), ce_loss 1.090, lat_loss 22.172
09/21 09:03:34 AM | Train: [ 21/180] Step 100/312 Loss 3.634 Prec@(1,3) (72.3%, 97.7%), ce_loss 1.090, lat_loss 22.172
09/21 09:03:56 AM | Train: [ 21/180] Step 150/312 Loss 3.516 Prec@(1,3) (73.6%, 97.9%), ce_loss 1.089, lat_loss 22.172
09/21 09:04:15 AM | Train: [ 21/180] Step 200/312 Loss 3.540 Prec@(1,3) (73.1%, 97.9%), ce_loss 1.089, lat_loss 22.172
09/21 09:04:33 AM | Train: [ 21/180] Step 250/312 Loss 3.539 Prec@(1,3) (73.0%, 97.9%), ce_loss 1.089, lat_loss 22.172
09/21 09:04:54 AM | Train: [ 21/180] Step 300/312 Loss 3.554 Prec@(1,3) (72.9%, 97.9%), ce_loss 1.088, lat_loss 22.172
09/21 09:05:00 AM | Train: [ 21/180] Step 312/312 Loss 3.561 Prec@(1,3) (72.9%, 97.8%), ce_loss 1.088, lat_loss 22.172
09/21 09:05:00 AM | _theta_step_train: [ 21/180] Final Prec@1 72.8900% Time 130.22
09/21 09:05:06 AM | Valid: [ 21/180] Step 050/312 Loss 3.378 Prec@(1,3) (73.4%, 98.6%), ce_loss 1.088, lat_loss 22.172
09/21 09:05:12 AM | Valid: [ 21/180] Step 100/312 Loss 3.534 Prec@(1,3) (72.7%, 98.2%), ce_loss 1.087, lat_loss 22.172
09/21 09:05:18 AM | Valid: [ 21/180] Step 150/312 Loss 3.490 Prec@(1,3) (73.2%, 98.1%), ce_loss 1.087, lat_loss 22.172
09/21 09:05:23 AM | Valid: [ 21/180] Step 200/312 Loss 3.497 Prec@(1,3) (72.8%, 98.1%), ce_loss 1.086, lat_loss 22.172
09/21 09:05:29 AM | Valid: [ 21/180] Step 250/312 Loss 3.512 Prec@(1,3) (72.8%, 98.2%), ce_loss 1.086, lat_loss 22.172
09/21 09:05:34 AM | Valid: [ 21/180] Step 300/312 Loss 3.520 Prec@(1,3) (72.7%, 98.1%), ce_loss 1.085, lat_loss 22.172
09/21 09:05:35 AM | Valid: [ 21/180] Step 312/312 Loss 3.534 Prec@(1,3) (72.6%, 98.1%), ce_loss 1.085, lat_loss 22.172
09/21 09:05:35 AM | val: [ 21/180] Final Prec@1 72.6200% Time 35.35
09/21 09:05:35 AM | Start to train weights for epoch 21
09/21 09:06:07 AM | Train: [ 22/180] Step 050/1249 Loss 3.471 Prec@(1,3) (73.7%, 98.0%), ce_loss 1.085, lat_loss 22.172
09/21 09:06:41 AM | Train: [ 22/180] Step 100/1249 Loss 3.433 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.084, lat_loss 22.172
09/21 09:07:19 AM | Train: [ 22/180] Step 150/1249 Loss 3.364 Prec@(1,3) (74.5%, 98.2%), ce_loss 1.084, lat_loss 22.172
09/21 09:07:57 AM | Train: [ 22/180] Step 200/1249 Loss 3.385 Prec@(1,3) (74.7%, 98.1%), ce_loss 1.083, lat_loss 22.172
09/21 09:08:24 AM | Train: [ 22/180] Step 250/1249 Loss 3.418 Prec@(1,3) (74.4%, 98.1%), ce_loss 1.083, lat_loss 22.172
09/21 09:08:50 AM | Train: [ 22/180] Step 300/1249 Loss 3.431 Prec@(1,3) (74.4%, 98.0%), ce_loss 1.083, lat_loss 22.172
09/21 09:09:19 AM | Train: [ 22/180] Step 350/1249 Loss 3.440 Prec@(1,3) (74.2%, 98.1%), ce_loss 1.082, lat_loss 22.171
09/21 09:09:53 AM | Train: [ 22/180] Step 400/1249 Loss 3.440 Prec@(1,3) (74.1%, 98.1%), ce_loss 1.082, lat_loss 22.171
09/21 09:10:25 AM | Train: [ 22/180] Step 450/1249 Loss 3.433 Prec@(1,3) (74.1%, 98.2%), ce_loss 1.081, lat_loss 22.171
09/21 09:10:53 AM | Train: [ 22/180] Step 500/1249 Loss 3.431 Prec@(1,3) (74.0%, 98.2%), ce_loss 1.081, lat_loss 22.171
09/21 09:11:28 AM | Train: [ 22/180] Step 550/1249 Loss 3.462 Prec@(1,3) (73.7%, 98.1%), ce_loss 1.080, lat_loss 22.171
09/21 09:12:05 AM | Train: [ 22/180] Step 600/1249 Loss 3.467 Prec@(1,3) (73.6%, 98.1%), ce_loss 1.080, lat_loss 22.171
09/21 09:12:39 AM | Train: [ 22/180] Step 650/1249 Loss 3.491 Prec@(1,3) (73.3%, 98.1%), ce_loss 1.080, lat_loss 22.171
09/21 09:13:07 AM | Train: [ 22/180] Step 700/1249 Loss 3.487 Prec@(1,3) (73.3%, 98.1%), ce_loss 1.079, lat_loss 22.171
09/21 09:13:36 AM | Train: [ 22/180] Step 750/1249 Loss 3.484 Prec@(1,3) (73.3%, 98.1%), ce_loss 1.079, lat_loss 22.171
09/21 09:14:05 AM | Train: [ 22/180] Step 800/1249 Loss 3.496 Prec@(1,3) (73.3%, 98.0%), ce_loss 1.078, lat_loss 22.171
09/21 09:14:34 AM | Train: [ 22/180] Step 850/1249 Loss 3.498 Prec@(1,3) (73.3%, 98.0%), ce_loss 1.078, lat_loss 22.171
09/21 09:15:03 AM | Train: [ 22/180] Step 900/1249 Loss 3.494 Prec@(1,3) (73.4%, 98.0%), ce_loss 1.078, lat_loss 22.171
09/21 09:15:33 AM | Train: [ 22/180] Step 950/1249 Loss 3.479 Prec@(1,3) (73.4%, 98.0%), ce_loss 1.077, lat_loss 22.171
09/21 09:16:05 AM | Train: [ 22/180] Step 1000/1249 Loss 3.485 Prec@(1,3) (73.4%, 98.1%), ce_loss 1.077, lat_loss 22.171
09/21 09:16:39 AM | Train: [ 22/180] Step 1050/1249 Loss 3.489 Prec@(1,3) (73.4%, 98.0%), ce_loss 1.076, lat_loss 22.171
09/21 09:17:12 AM | Train: [ 22/180] Step 1100/1249 Loss 3.482 Prec@(1,3) (73.4%, 98.1%), ce_loss 1.076, lat_loss 22.171
09/21 09:17:42 AM | Train: [ 22/180] Step 1150/1249 Loss 3.476 Prec@(1,3) (73.4%, 98.0%), ce_loss 1.075, lat_loss 22.171
09/21 09:18:08 AM | Train: [ 22/180] Step 1200/1249 Loss 3.467 Prec@(1,3) (73.4%, 98.0%), ce_loss 1.075, lat_loss 22.171
09/21 09:18:35 AM | Train: [ 22/180] Step 1249/1249 Loss 3.463 Prec@(1,3) (73.5%, 98.0%), ce_loss 1.074, lat_loss 22.171
09/21 09:18:35 AM | _w_step_train: [ 22/180] Final Prec@1 73.4975% Time 779.81
09/21 09:18:35 AM | Start to train theta for epoch 21
09/21 09:19:01 AM | Train: [ 22/180] Step 050/312 Loss 3.348 Prec@(1,3) (74.9%, 97.9%), ce_loss 1.074, lat_loss 22.171
09/21 09:19:26 AM | Train: [ 22/180] Step 100/312 Loss 3.445 Prec@(1,3) (73.4%, 97.9%), ce_loss 1.073, lat_loss 22.171
09/21 09:19:50 AM | Train: [ 22/180] Step 150/312 Loss 3.474 Prec@(1,3) (73.4%, 97.6%), ce_loss 1.073, lat_loss 22.171
09/21 09:20:13 AM | Train: [ 22/180] Step 200/312 Loss 3.481 Prec@(1,3) (73.2%, 97.6%), ce_loss 1.073, lat_loss 22.171
09/21 09:20:38 AM | Train: [ 22/180] Step 250/312 Loss 3.487 Prec@(1,3) (73.3%, 97.6%), ce_loss 1.072, lat_loss 22.171
09/21 09:21:03 AM | Train: [ 22/180] Step 300/312 Loss 3.482 Prec@(1,3) (73.3%, 97.6%), ce_loss 1.072, lat_loss 22.171
09/21 09:21:09 AM | Train: [ 22/180] Step 312/312 Loss 3.475 Prec@(1,3) (73.2%, 97.6%), ce_loss 1.072, lat_loss 22.171
09/21 09:21:09 AM | _theta_step_train: [ 22/180] Final Prec@1 73.1900% Time 153.88
09/21 09:21:16 AM | Valid: [ 22/180] Step 050/312 Loss 3.648 Prec@(1,3) (72.4%, 98.2%), ce_loss 1.071, lat_loss 22.171
09/21 09:21:21 AM | Valid: [ 22/180] Step 100/312 Loss 4.000 Prec@(1,3) (70.7%, 97.5%), ce_loss 1.071, lat_loss 22.171
09/21 09:21:27 AM | Valid: [ 22/180] Step 150/312 Loss 3.924 Prec@(1,3) (71.0%, 97.5%), ce_loss 1.071, lat_loss 22.171
09/21 09:21:32 AM | Valid: [ 22/180] Step 200/312 Loss 3.885 Prec@(1,3) (71.0%, 97.6%), ce_loss 1.071, lat_loss 22.171
09/21 09:21:37 AM | Valid: [ 22/180] Step 250/312 Loss 3.910 Prec@(1,3) (70.8%, 97.6%), ce_loss 1.070, lat_loss 22.171
09/21 09:21:43 AM | Valid: [ 22/180] Step 300/312 Loss 3.885 Prec@(1,3) (70.7%, 97.6%), ce_loss 1.070, lat_loss 22.171
09/21 09:21:44 AM | Valid: [ 22/180] Step 312/312 Loss 3.892 Prec@(1,3) (70.6%, 97.6%), ce_loss 1.070, lat_loss 22.171
09/21 09:21:44 AM | val: [ 22/180] Final Prec@1 70.5700% Time 34.94
09/21 09:21:44 AM | Start to train weights for epoch 22
09/21 09:22:20 AM | Train: [ 23/180] Step 050/1249 Loss 3.538 Prec@(1,3) (72.5%, 98.1%), ce_loss 1.070, lat_loss 22.171
09/21 09:22:53 AM | Train: [ 23/180] Step 100/1249 Loss 3.613 Prec@(1,3) (72.4%, 97.9%), ce_loss 1.069, lat_loss 22.171
09/21 09:23:27 AM | Train: [ 23/180] Step 150/1249 Loss 3.574 Prec@(1,3) (72.3%, 98.0%), ce_loss 1.069, lat_loss 22.171
09/21 09:24:02 AM | Train: [ 23/180] Step 200/1249 Loss 3.463 Prec@(1,3) (73.2%, 98.1%), ce_loss 1.068, lat_loss 22.171
09/21 09:24:39 AM | Train: [ 23/180] Step 250/1249 Loss 3.451 Prec@(1,3) (73.3%, 98.1%), ce_loss 1.068, lat_loss 22.171
09/21 09:25:13 AM | Train: [ 23/180] Step 300/1249 Loss 3.440 Prec@(1,3) (73.4%, 98.1%), ce_loss 1.067, lat_loss 22.171
09/21 09:25:46 AM | Train: [ 23/180] Step 350/1249 Loss 3.430 Prec@(1,3) (73.7%, 98.1%), ce_loss 1.067, lat_loss 22.171
09/21 09:26:15 AM | Train: [ 23/180] Step 400/1249 Loss 3.420 Prec@(1,3) (73.6%, 98.1%), ce_loss 1.067, lat_loss 22.171
09/21 09:26:43 AM | Train: [ 23/180] Step 450/1249 Loss 3.400 Prec@(1,3) (73.6%, 98.1%), ce_loss 1.066, lat_loss 22.171
09/21 09:27:12 AM | Train: [ 23/180] Step 500/1249 Loss 3.394 Prec@(1,3) (73.6%, 98.1%), ce_loss 1.066, lat_loss 22.171
09/21 09:27:40 AM | Train: [ 23/180] Step 550/1249 Loss 3.383 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.065, lat_loss 22.171
09/21 09:28:14 AM | Train: [ 23/180] Step 600/1249 Loss 3.381 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.065, lat_loss 22.171
09/21 09:28:49 AM | Train: [ 23/180] Step 650/1249 Loss 3.376 Prec@(1,3) (74.0%, 98.0%), ce_loss 1.064, lat_loss 22.171
09/21 09:29:21 AM | Train: [ 23/180] Step 700/1249 Loss 3.387 Prec@(1,3) (73.9%, 98.0%), ce_loss 1.064, lat_loss 22.171
09/21 09:29:48 AM | Train: [ 23/180] Step 750/1249 Loss 3.371 Prec@(1,3) (74.1%, 98.1%), ce_loss 1.063, lat_loss 22.171
09/21 09:30:21 AM | Train: [ 23/180] Step 800/1249 Loss 3.368 Prec@(1,3) (74.2%, 98.1%), ce_loss 1.063, lat_loss 22.171
09/21 09:30:53 AM | Train: [ 23/180] Step 850/1249 Loss 3.374 Prec@(1,3) (74.1%, 98.0%), ce_loss 1.063, lat_loss 22.171
09/21 09:31:27 AM | Train: [ 23/180] Step 900/1249 Loss 3.369 Prec@(1,3) (74.1%, 98.1%), ce_loss 1.062, lat_loss 22.171
09/21 09:32:00 AM | Train: [ 23/180] Step 950/1249 Loss 3.377 Prec@(1,3) (74.0%, 98.1%), ce_loss 1.062, lat_loss 22.171
09/21 09:32:28 AM | Train: [ 23/180] Step 1000/1249 Loss 3.381 Prec@(1,3) (74.0%, 98.1%), ce_loss 1.061, lat_loss 22.171
09/21 09:32:56 AM | Train: [ 23/180] Step 1050/1249 Loss 3.390 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.061, lat_loss 22.171
09/21 09:33:30 AM | Train: [ 23/180] Step 1100/1249 Loss 3.383 Prec@(1,3) (74.0%, 98.1%), ce_loss 1.061, lat_loss 22.171
09/21 09:34:04 AM | Train: [ 23/180] Step 1150/1249 Loss 3.385 Prec@(1,3) (74.0%, 98.1%), ce_loss 1.060, lat_loss 22.171
09/21 09:34:37 AM | Train: [ 23/180] Step 1200/1249 Loss 3.384 Prec@(1,3) (74.0%, 98.1%), ce_loss 1.060, lat_loss 22.171
09/21 09:35:05 AM | Train: [ 23/180] Step 1249/1249 Loss 3.376 Prec@(1,3) (74.1%, 98.1%), ce_loss 1.059, lat_loss 22.171
09/21 09:35:05 AM | _w_step_train: [ 23/180] Final Prec@1 74.0500% Time 800.65
09/21 09:35:05 AM | Start to train theta for epoch 22
09/21 09:35:28 AM | Train: [ 23/180] Step 050/312 Loss 3.417 Prec@(1,3) (73.3%, 97.9%), ce_loss 1.059, lat_loss 22.171
09/21 09:35:48 AM | Train: [ 23/180] Step 100/312 Loss 3.434 Prec@(1,3) (73.3%, 97.9%), ce_loss 1.059, lat_loss 22.171
09/21 09:36:08 AM | Train: [ 23/180] Step 150/312 Loss 3.467 Prec@(1,3) (73.2%, 97.9%), ce_loss 1.058, lat_loss 22.170
09/21 09:36:28 AM | Train: [ 23/180] Step 200/312 Loss 3.439 Prec@(1,3) (73.6%, 97.9%), ce_loss 1.058, lat_loss 22.170
09/21 09:36:48 AM | Train: [ 23/180] Step 250/312 Loss 3.414 Prec@(1,3) (73.7%, 97.9%), ce_loss 1.057, lat_loss 22.170
09/21 09:37:07 AM | Train: [ 23/180] Step 300/312 Loss 3.376 Prec@(1,3) (74.0%, 97.9%), ce_loss 1.057, lat_loss 22.170
09/21 09:37:12 AM | Train: [ 23/180] Step 312/312 Loss 3.368 Prec@(1,3) (74.0%, 98.0%), ce_loss 1.057, lat_loss 22.170
09/21 09:37:12 AM | _theta_step_train: [ 23/180] Final Prec@1 74.0000% Time 127.47
09/21 09:37:18 AM | Valid: [ 23/180] Step 050/312 Loss 3.455 Prec@(1,3) (73.2%, 98.3%), ce_loss 1.056, lat_loss 22.170
09/21 09:37:24 AM | Valid: [ 23/180] Step 100/312 Loss 3.683 Prec@(1,3) (72.0%, 97.6%), ce_loss 1.056, lat_loss 22.170
09/21 09:37:29 AM | Valid: [ 23/180] Step 150/312 Loss 3.583 Prec@(1,3) (73.1%, 97.6%), ce_loss 1.056, lat_loss 22.170
09/21 09:37:35 AM | Valid: [ 23/180] Step 200/312 Loss 3.577 Prec@(1,3) (73.1%, 97.7%), ce_loss 1.055, lat_loss 22.170
09/21 09:37:40 AM | Valid: [ 23/180] Step 250/312 Loss 3.600 Prec@(1,3) (72.8%, 97.7%), ce_loss 1.055, lat_loss 22.170
09/21 09:37:45 AM | Valid: [ 23/180] Step 300/312 Loss 3.590 Prec@(1,3) (72.8%, 97.8%), ce_loss 1.055, lat_loss 22.170
09/21 09:37:47 AM | Valid: [ 23/180] Step 312/312 Loss 3.614 Prec@(1,3) (72.5%, 97.8%), ce_loss 1.055, lat_loss 22.170
09/21 09:37:47 AM | val: [ 23/180] Final Prec@1 72.5500% Time 34.45
09/21 09:37:47 AM | Start to train weights for epoch 23
09/21 09:38:19 AM | Train: [ 24/180] Step 050/1249 Loss 3.332 Prec@(1,3) (74.9%, 98.3%), ce_loss 1.054, lat_loss 22.170
09/21 09:38:49 AM | Train: [ 24/180] Step 100/1249 Loss 3.346 Prec@(1,3) (74.7%, 98.2%), ce_loss 1.054, lat_loss 22.170
09/21 09:39:25 AM | Train: [ 24/180] Step 150/1249 Loss 3.273 Prec@(1,3) (74.8%, 98.3%), ce_loss 1.053, lat_loss 22.170
09/21 09:40:01 AM | Train: [ 24/180] Step 200/1249 Loss 3.310 Prec@(1,3) (74.5%, 98.3%), ce_loss 1.053, lat_loss 22.170
09/21 09:40:29 AM | Train: [ 24/180] Step 250/1249 Loss 3.310 Prec@(1,3) (74.5%, 98.3%), ce_loss 1.053, lat_loss 22.170
09/21 09:40:56 AM | Train: [ 24/180] Step 300/1249 Loss 3.301 Prec@(1,3) (74.4%, 98.3%), ce_loss 1.052, lat_loss 22.170
09/21 09:41:25 AM | Train: [ 24/180] Step 350/1249 Loss 3.279 Prec@(1,3) (74.7%, 98.3%), ce_loss 1.052, lat_loss 22.170
09/21 09:42:00 AM | Train: [ 24/180] Step 400/1249 Loss 3.268 Prec@(1,3) (74.7%, 98.3%), ce_loss 1.051, lat_loss 22.170
09/21 09:42:32 AM | Train: [ 24/180] Step 450/1249 Loss 3.280 Prec@(1,3) (74.6%, 98.3%), ce_loss 1.051, lat_loss 22.170
09/21 09:43:02 AM | Train: [ 24/180] Step 500/1249 Loss 3.281 Prec@(1,3) (74.6%, 98.3%), ce_loss 1.051, lat_loss 22.170
09/21 09:43:36 AM | Train: [ 24/180] Step 550/1249 Loss 3.261 Prec@(1,3) (74.7%, 98.2%), ce_loss 1.050, lat_loss 22.170
09/21 09:44:11 AM | Train: [ 24/180] Step 600/1249 Loss 3.273 Prec@(1,3) (74.6%, 98.2%), ce_loss 1.050, lat_loss 22.170
09/21 09:44:42 AM | Train: [ 24/180] Step 650/1249 Loss 3.287 Prec@(1,3) (74.5%, 98.2%), ce_loss 1.049, lat_loss 22.170
09/21 09:45:11 AM | Train: [ 24/180] Step 700/1249 Loss 3.294 Prec@(1,3) (74.5%, 98.1%), ce_loss 1.049, lat_loss 22.170
09/21 09:45:41 AM | Train: [ 24/180] Step 750/1249 Loss 3.297 Prec@(1,3) (74.5%, 98.2%), ce_loss 1.049, lat_loss 22.170
09/21 09:46:11 AM | Train: [ 24/180] Step 800/1249 Loss 3.286 Prec@(1,3) (74.6%, 98.2%), ce_loss 1.048, lat_loss 22.170
09/21 09:46:39 AM | Train: [ 24/180] Step 850/1249 Loss 3.281 Prec@(1,3) (74.7%, 98.2%), ce_loss 1.048, lat_loss 22.170
09/21 09:47:07 AM | Train: [ 24/180] Step 900/1249 Loss 3.285 Prec@(1,3) (74.7%, 98.2%), ce_loss 1.047, lat_loss 22.170
09/21 09:47:38 AM | Train: [ 24/180] Step 950/1249 Loss 3.287 Prec@(1,3) (74.7%, 98.2%), ce_loss 1.047, lat_loss 22.170
09/21 09:48:12 AM | Train: [ 24/180] Step 1000/1249 Loss 3.296 Prec@(1,3) (74.6%, 98.2%), ce_loss 1.047, lat_loss 22.170
09/21 09:48:46 AM | Train: [ 24/180] Step 1050/1249 Loss 3.287 Prec@(1,3) (74.6%, 98.2%), ce_loss 1.046, lat_loss 22.170
09/21 09:49:21 AM | Train: [ 24/180] Step 1100/1249 Loss 3.294 Prec@(1,3) (74.6%, 98.2%), ce_loss 1.046, lat_loss 22.169
09/21 09:49:50 AM | Train: [ 24/180] Step 1150/1249 Loss 3.286 Prec@(1,3) (74.7%, 98.2%), ce_loss 1.045, lat_loss 22.169
09/21 09:50:20 AM | Train: [ 24/180] Step 1200/1249 Loss 3.281 Prec@(1,3) (74.7%, 98.2%), ce_loss 1.045, lat_loss 22.169
09/21 09:50:51 AM | Train: [ 24/180] Step 1249/1249 Loss 3.277 Prec@(1,3) (74.8%, 98.2%), ce_loss 1.044, lat_loss 22.169
09/21 09:50:51 AM | _w_step_train: [ 24/180] Final Prec@1 74.7650% Time 784.00
09/21 09:50:51 AM | Start to train theta for epoch 23
09/21 09:51:16 AM | Train: [ 24/180] Step 050/312 Loss 3.543 Prec@(1,3) (73.0%, 98.3%), ce_loss 1.044, lat_loss 22.169
09/21 09:51:41 AM | Train: [ 24/180] Step 100/312 Loss 3.448 Prec@(1,3) (74.2%, 98.3%), ce_loss 1.044, lat_loss 22.169
09/21 09:52:04 AM | Train: [ 24/180] Step 150/312 Loss 3.411 Prec@(1,3) (74.0%, 98.2%), ce_loss 1.043, lat_loss 22.169
09/21 09:52:26 AM | Train: [ 24/180] Step 200/312 Loss 3.381 Prec@(1,3) (74.3%, 98.2%), ce_loss 1.043, lat_loss 22.169
09/21 09:52:52 AM | Train: [ 24/180] Step 250/312 Loss 3.370 Prec@(1,3) (74.4%, 98.3%), ce_loss 1.043, lat_loss 22.169
09/21 09:53:16 AM | Train: [ 24/180] Step 300/312 Loss 3.354 Prec@(1,3) (74.8%, 98.1%), ce_loss 1.042, lat_loss 22.169
09/21 09:53:21 AM | Train: [ 24/180] Step 312/312 Loss 3.360 Prec@(1,3) (74.7%, 98.1%), ce_loss 1.042, lat_loss 22.169
09/21 09:53:21 AM | _theta_step_train: [ 24/180] Final Prec@1 74.7000% Time 150.28
09/21 09:53:27 AM | Valid: [ 24/180] Step 050/312 Loss 3.701 Prec@(1,3) (71.0%, 98.3%), ce_loss 1.042, lat_loss 22.169
09/21 09:53:32 AM | Valid: [ 24/180] Step 100/312 Loss 3.713 Prec@(1,3) (71.5%, 97.8%), ce_loss 1.042, lat_loss 22.169
09/21 09:53:38 AM | Valid: [ 24/180] Step 150/312 Loss 3.596 Prec@(1,3) (72.8%, 97.6%), ce_loss 1.041, lat_loss 22.169
09/21 09:53:43 AM | Valid: [ 24/180] Step 200/312 Loss 3.632 Prec@(1,3) (72.5%, 97.7%), ce_loss 1.041, lat_loss 22.169
09/21 09:53:48 AM | Valid: [ 24/180] Step 250/312 Loss 3.598 Prec@(1,3) (72.5%, 97.8%), ce_loss 1.041, lat_loss 22.169
09/21 09:53:53 AM | Valid: [ 24/180] Step 300/312 Loss 3.604 Prec@(1,3) (72.5%, 97.8%), ce_loss 1.040, lat_loss 22.169
09/21 09:53:54 AM | Valid: [ 24/180] Step 312/312 Loss 3.616 Prec@(1,3) (72.4%, 97.9%), ce_loss 1.040, lat_loss 22.169
09/21 09:53:54 AM | val: [ 24/180] Final Prec@1 72.4400% Time 33.28
09/21 09:53:54 AM | Start to train weights for epoch 24
09/21 09:54:24 AM | Train: [ 25/180] Step 050/1249 Loss 3.153 Prec@(1,3) (74.9%, 98.1%), ce_loss 1.040, lat_loss 22.169
09/21 09:54:53 AM | Train: [ 25/180] Step 100/1249 Loss 3.202 Prec@(1,3) (74.3%, 98.1%), ce_loss 1.039, lat_loss 22.169
09/21 09:55:27 AM | Train: [ 25/180] Step 150/1249 Loss 3.163 Prec@(1,3) (75.1%, 98.3%), ce_loss 1.039, lat_loss 22.169
09/21 09:55:59 AM | Train: [ 25/180] Step 200/1249 Loss 3.193 Prec@(1,3) (75.1%, 98.3%), ce_loss 1.039, lat_loss 22.169
09/21 09:56:25 AM | Train: [ 25/180] Step 250/1249 Loss 3.225 Prec@(1,3) (74.8%, 98.3%), ce_loss 1.038, lat_loss 22.169
09/21 09:56:53 AM | Train: [ 25/180] Step 300/1249 Loss 3.214 Prec@(1,3) (74.8%, 98.3%), ce_loss 1.038, lat_loss 22.169
09/21 09:57:21 AM | Train: [ 25/180] Step 350/1249 Loss 3.196 Prec@(1,3) (74.9%, 98.3%), ce_loss 1.037, lat_loss 22.169
09/21 09:57:51 AM | Train: [ 25/180] Step 400/1249 Loss 3.183 Prec@(1,3) (75.0%, 98.3%), ce_loss 1.037, lat_loss 22.169
09/21 09:58:20 AM | Train: [ 25/180] Step 450/1249 Loss 3.185 Prec@(1,3) (74.9%, 98.3%), ce_loss 1.037, lat_loss 22.169
09/21 09:58:50 AM | Train: [ 25/180] Step 500/1249 Loss 3.199 Prec@(1,3) (74.8%, 98.3%), ce_loss 1.036, lat_loss 22.169
09/21 09:59:20 AM | Train: [ 25/180] Step 550/1249 Loss 3.190 Prec@(1,3) (74.9%, 98.3%), ce_loss 1.036, lat_loss 22.169
09/21 09:59:53 AM | Train: [ 25/180] Step 600/1249 Loss 3.211 Prec@(1,3) (74.8%, 98.2%), ce_loss 1.035, lat_loss 22.169
09/21 10:00:27 AM | Train: [ 25/180] Step 650/1249 Loss 3.197 Prec@(1,3) (75.0%, 98.2%), ce_loss 1.035, lat_loss 22.168
09/21 10:01:00 AM | Train: [ 25/180] Step 700/1249 Loss 3.180 Prec@(1,3) (75.1%, 98.2%), ce_loss 1.035, lat_loss 22.168
09/21 10:01:31 AM | Train: [ 25/180] Step 750/1249 Loss 3.191 Prec@(1,3) (75.0%, 98.2%), ce_loss 1.034, lat_loss 22.168
09/21 10:02:03 AM | Train: [ 25/180] Step 800/1249 Loss 3.193 Prec@(1,3) (75.1%, 98.2%), ce_loss 1.034, lat_loss 22.168
09/21 10:02:40 AM | Train: [ 25/180] Step 850/1249 Loss 3.183 Prec@(1,3) (75.2%, 98.2%), ce_loss 1.033, lat_loss 22.168
09/21 10:03:15 AM | Train: [ 25/180] Step 900/1249 Loss 3.180 Prec@(1,3) (75.2%, 98.2%), ce_loss 1.033, lat_loss 22.168
09/21 10:03:51 AM | Train: [ 25/180] Step 950/1249 Loss 3.181 Prec@(1,3) (75.2%, 98.2%), ce_loss 1.033, lat_loss 22.168
09/21 10:04:27 AM | Train: [ 25/180] Step 1000/1249 Loss 3.187 Prec@(1,3) (75.2%, 98.2%), ce_loss 1.032, lat_loss 22.168
09/21 10:04:55 AM | Train: [ 25/180] Step 1050/1249 Loss 3.191 Prec@(1,3) (75.2%, 98.2%), ce_loss 1.032, lat_loss 22.168
09/21 10:05:24 AM | Train: [ 25/180] Step 1100/1249 Loss 3.187 Prec@(1,3) (75.3%, 98.2%), ce_loss 1.031, lat_loss 22.168
09/21 10:05:53 AM | Train: [ 25/180] Step 1150/1249 Loss 3.183 Prec@(1,3) (75.3%, 98.2%), ce_loss 1.031, lat_loss 22.168
09/21 10:06:17 AM | Train: [ 25/180] Step 1200/1249 Loss 3.176 Prec@(1,3) (75.3%, 98.3%), ce_loss 1.031, lat_loss 22.168
09/21 10:06:42 AM | Train: [ 25/180] Step 1249/1249 Loss 3.180 Prec@(1,3) (75.4%, 98.3%), ce_loss 1.030, lat_loss 22.168
09/21 10:06:42 AM | _w_step_train: [ 25/180] Final Prec@1 75.3675% Time 767.77
09/21 10:06:42 AM | Start to train theta for epoch 24
09/21 10:07:03 AM | Train: [ 25/180] Step 050/312 Loss 3.529 Prec@(1,3) (72.9%, 97.2%), ce_loss 1.030, lat_loss 22.168
09/21 10:07:22 AM | Train: [ 25/180] Step 100/312 Loss 3.362 Prec@(1,3) (74.5%, 97.8%), ce_loss 1.030, lat_loss 22.168
09/21 10:07:41 AM | Train: [ 25/180] Step 150/312 Loss 3.387 Prec@(1,3) (74.5%, 97.8%), ce_loss 1.029, lat_loss 22.168
09/21 10:08:00 AM | Train: [ 25/180] Step 200/312 Loss 3.312 Prec@(1,3) (75.0%, 97.8%), ce_loss 1.029, lat_loss 22.168
09/21 10:08:20 AM | Train: [ 25/180] Step 250/312 Loss 3.304 Prec@(1,3) (75.1%, 97.8%), ce_loss 1.028, lat_loss 22.168
09/21 10:08:39 AM | Train: [ 25/180] Step 300/312 Loss 3.327 Prec@(1,3) (74.9%, 97.7%), ce_loss 1.028, lat_loss 22.168
09/21 10:08:44 AM | Train: [ 25/180] Step 312/312 Loss 3.318 Prec@(1,3) (75.0%, 97.8%), ce_loss 1.028, lat_loss 22.168
09/21 10:08:44 AM | _theta_step_train: [ 25/180] Final Prec@1 74.9900% Time 122.35
09/21 10:08:50 AM | Valid: [ 25/180] Step 050/312 Loss 3.448 Prec@(1,3) (74.2%, 97.8%), ce_loss 1.028, lat_loss 22.168
09/21 10:08:54 AM | Valid: [ 25/180] Step 100/312 Loss 3.627 Prec@(1,3) (72.9%, 97.6%), ce_loss 1.028, lat_loss 22.168
09/21 10:08:59 AM | Valid: [ 25/180] Step 150/312 Loss 3.571 Prec@(1,3) (73.2%, 97.4%), ce_loss 1.027, lat_loss 22.167
09/21 10:09:04 AM | Valid: [ 25/180] Step 200/312 Loss 3.557 Prec@(1,3) (73.1%, 97.7%), ce_loss 1.027, lat_loss 22.167
09/21 10:09:09 AM | Valid: [ 25/180] Step 250/312 Loss 3.562 Prec@(1,3) (73.3%, 97.6%), ce_loss 1.027, lat_loss 22.167
09/21 10:09:13 AM | Valid: [ 25/180] Step 300/312 Loss 3.572 Prec@(1,3) (73.3%, 97.6%), ce_loss 1.026, lat_loss 22.167
09/21 10:09:14 AM | Valid: [ 25/180] Step 312/312 Loss 3.569 Prec@(1,3) (73.3%, 97.6%), ce_loss 1.026, lat_loss 22.167
09/21 10:09:14 AM | val: [ 25/180] Final Prec@1 73.2800% Time 30.04
09/21 10:09:14 AM | Start to train weights for epoch 25
09/21 10:09:39 AM | Train: [ 26/180] Step 050/1249 Loss 3.197 Prec@(1,3) (75.2%, 98.3%), ce_loss 1.026, lat_loss 22.167
09/21 10:10:00 AM | Train: [ 26/180] Step 100/1249 Loss 3.207 Prec@(1,3) (75.3%, 98.4%), ce_loss 1.026, lat_loss 22.167
09/21 10:10:21 AM | Train: [ 26/180] Step 150/1249 Loss 3.309 Prec@(1,3) (74.9%, 98.2%), ce_loss 1.025, lat_loss 22.167
09/21 10:10:45 AM | Train: [ 26/180] Step 200/1249 Loss 3.255 Prec@(1,3) (75.3%, 98.3%), ce_loss 1.025, lat_loss 22.167
09/21 10:11:09 AM | Train: [ 26/180] Step 250/1249 Loss 3.297 Prec@(1,3) (75.0%, 98.2%), ce_loss 1.025, lat_loss 22.167
09/21 10:11:34 AM | Train: [ 26/180] Step 300/1249 Loss 3.305 Prec@(1,3) (74.8%, 98.2%), ce_loss 1.024, lat_loss 22.167
09/21 10:11:59 AM | Train: [ 26/180] Step 350/1249 Loss 3.308 Prec@(1,3) (74.8%, 98.2%), ce_loss 1.024, lat_loss 22.167
09/21 10:12:23 AM | Train: [ 26/180] Step 400/1249 Loss 3.311 Prec@(1,3) (74.8%, 98.1%), ce_loss 1.024, lat_loss 22.167
09/21 10:12:47 AM | Train: [ 26/180] Step 450/1249 Loss 3.292 Prec@(1,3) (75.1%, 98.1%), ce_loss 1.023, lat_loss 22.167
09/21 10:13:12 AM | Train: [ 26/180] Step 500/1249 Loss 3.298 Prec@(1,3) (74.9%, 98.1%), ce_loss 1.023, lat_loss 22.166
09/21 10:13:36 AM | Train: [ 26/180] Step 550/1249 Loss 3.312 Prec@(1,3) (74.7%, 98.1%), ce_loss 1.023, lat_loss 22.166
09/21 10:14:00 AM | Train: [ 26/180] Step 600/1249 Loss 3.296 Prec@(1,3) (74.8%, 98.1%), ce_loss 1.022, lat_loss 22.166
09/21 10:14:25 AM | Train: [ 26/180] Step 650/1249 Loss 3.308 Prec@(1,3) (74.8%, 98.1%), ce_loss 1.022, lat_loss 22.166
09/21 10:14:50 AM | Train: [ 26/180] Step 700/1249 Loss 3.301 Prec@(1,3) (74.9%, 98.1%), ce_loss 1.022, lat_loss 22.166
09/21 10:15:12 AM | Train: [ 26/180] Step 750/1249 Loss 3.300 Prec@(1,3) (75.0%, 98.1%), ce_loss 1.021, lat_loss 22.166
09/21 10:15:36 AM | Train: [ 26/180] Step 800/1249 Loss 3.303 Prec@(1,3) (75.0%, 98.1%), ce_loss 1.021, lat_loss 22.166
09/21 10:16:01 AM | Train: [ 26/180] Step 850/1249 Loss 3.300 Prec@(1,3) (75.0%, 98.1%), ce_loss 1.021, lat_loss 22.166
09/21 10:16:26 AM | Train: [ 26/180] Step 900/1249 Loss 3.289 Prec@(1,3) (75.0%, 98.1%), ce_loss 1.020, lat_loss 22.166
09/21 10:16:50 AM | Train: [ 26/180] Step 950/1249 Loss 3.290 Prec@(1,3) (75.0%, 98.1%), ce_loss 1.020, lat_loss 22.166
09/21 10:17:12 AM | Train: [ 26/180] Step 1000/1249 Loss 3.295 Prec@(1,3) (75.0%, 98.1%), ce_loss 1.020, lat_loss 22.166
09/21 10:17:34 AM | Train: [ 26/180] Step 1050/1249 Loss 3.296 Prec@(1,3) (74.9%, 98.1%), ce_loss 1.019, lat_loss 22.166
09/21 10:17:56 AM | Train: [ 26/180] Step 1100/1249 Loss 3.292 Prec@(1,3) (74.9%, 98.1%), ce_loss 1.019, lat_loss 22.166
09/21 10:18:18 AM | Train: [ 26/180] Step 1150/1249 Loss 3.282 Prec@(1,3) (75.0%, 98.1%), ce_loss 1.019, lat_loss 22.165
09/21 10:18:40 AM | Train: [ 26/180] Step 1200/1249 Loss 3.277 Prec@(1,3) (75.0%, 98.1%), ce_loss 1.018, lat_loss 22.165
09/21 10:19:04 AM | Train: [ 26/180] Step 1249/1249 Loss 3.286 Prec@(1,3) (74.9%, 98.1%), ce_loss 1.018, lat_loss 22.165
09/21 10:19:04 AM | _w_step_train: [ 26/180] Final Prec@1 74.9475% Time 589.60
09/21 10:19:04 AM | Start to train theta for epoch 25
09/21 10:19:23 AM | Train: [ 26/180] Step 050/312 Loss 3.508 Prec@(1,3) (73.6%, 98.0%), ce_loss 1.018, lat_loss 22.165
09/21 10:19:42 AM | Train: [ 26/180] Step 100/312 Loss 3.526 Prec@(1,3) (72.7%, 97.9%), ce_loss 1.017, lat_loss 22.165
09/21 10:20:02 AM | Train: [ 26/180] Step 150/312 Loss 3.555 Prec@(1,3) (72.5%, 98.0%), ce_loss 1.017, lat_loss 22.165
09/21 10:20:21 AM | Train: [ 26/180] Step 200/312 Loss 3.514 Prec@(1,3) (73.1%, 98.0%), ce_loss 1.017, lat_loss 22.165
09/21 10:20:41 AM | Train: [ 26/180] Step 250/312 Loss 3.491 Prec@(1,3) (73.3%, 98.0%), ce_loss 1.017, lat_loss 22.165
09/21 10:21:00 AM | Train: [ 26/180] Step 300/312 Loss 3.492 Prec@(1,3) (73.4%, 98.0%), ce_loss 1.016, lat_loss 22.165
09/21 10:21:04 AM | Train: [ 26/180] Step 312/312 Loss 3.475 Prec@(1,3) (73.5%, 98.0%), ce_loss 1.016, lat_loss 22.165
09/21 10:21:04 AM | _theta_step_train: [ 26/180] Final Prec@1 73.4900% Time 120.06
09/21 10:21:09 AM | Valid: [ 26/180] Step 050/312 Loss 3.626 Prec@(1,3) (71.0%, 98.2%), ce_loss 1.016, lat_loss 22.165
09/21 10:21:14 AM | Valid: [ 26/180] Step 100/312 Loss 3.732 Prec@(1,3) (71.6%, 97.8%), ce_loss 1.016, lat_loss 22.165
09/21 10:21:19 AM | Valid: [ 26/180] Step 150/312 Loss 3.728 Prec@(1,3) (71.8%, 97.6%), ce_loss 1.016, lat_loss 22.165
09/21 10:21:24 AM | Valid: [ 26/180] Step 200/312 Loss 3.796 Prec@(1,3) (71.2%, 97.6%), ce_loss 1.015, lat_loss 22.165
09/21 10:21:28 AM | Valid: [ 26/180] Step 250/312 Loss 3.786 Prec@(1,3) (71.4%, 97.7%), ce_loss 1.015, lat_loss 22.164
09/21 10:21:33 AM | Valid: [ 26/180] Step 300/312 Loss 3.782 Prec@(1,3) (71.3%, 97.7%), ce_loss 1.015, lat_loss 22.164
09/21 10:21:34 AM | Valid: [ 26/180] Step 312/312 Loss 3.786 Prec@(1,3) (71.2%, 97.7%), ce_loss 1.015, lat_loss 22.164
09/21 10:21:34 AM | val: [ 26/180] Final Prec@1 71.1600% Time 30.01
09/21 10:21:34 AM | Start to train weights for epoch 26
09/21 10:21:59 AM | Train: [ 27/180] Step 050/1249 Loss 3.326 Prec@(1,3) (75.3%, 98.5%), ce_loss 1.015, lat_loss 22.164
09/21 10:22:22 AM | Train: [ 27/180] Step 100/1249 Loss 3.252 Prec@(1,3) (76.2%, 98.2%), ce_loss 1.014, lat_loss 22.164
09/21 10:22:47 AM | Train: [ 27/180] Step 150/1249 Loss 3.186 Prec@(1,3) (75.9%, 98.5%), ce_loss 1.014, lat_loss 22.164
09/21 10:23:10 AM | Train: [ 27/180] Step 200/1249 Loss 3.199 Prec@(1,3) (75.7%, 98.3%), ce_loss 1.014, lat_loss 22.164
09/21 10:23:33 AM | Train: [ 27/180] Step 250/1249 Loss 3.197 Prec@(1,3) (75.7%, 98.4%), ce_loss 1.013, lat_loss 22.164
09/21 10:23:56 AM | Train: [ 27/180] Step 300/1249 Loss 3.229 Prec@(1,3) (75.4%, 98.4%), ce_loss 1.013, lat_loss 22.164
09/21 10:24:19 AM | Train: [ 27/180] Step 350/1249 Loss 3.223 Prec@(1,3) (75.4%, 98.4%), ce_loss 1.013, lat_loss 22.164
09/21 10:24:42 AM | Train: [ 27/180] Step 400/1249 Loss 3.246 Prec@(1,3) (75.1%, 98.4%), ce_loss 1.012, lat_loss 22.164
09/21 10:25:03 AM | Train: [ 27/180] Step 450/1249 Loss 3.276 Prec@(1,3) (74.8%, 98.4%), ce_loss 1.012, lat_loss 22.164
09/21 10:25:25 AM | Train: [ 27/180] Step 500/1249 Loss 3.268 Prec@(1,3) (74.9%, 98.3%), ce_loss 1.012, lat_loss 22.164
09/21 10:25:47 AM | Train: [ 27/180] Step 550/1249 Loss 3.264 Prec@(1,3) (75.0%, 98.3%), ce_loss 1.011, lat_loss 22.163
09/21 10:26:09 AM | Train: [ 27/180] Step 600/1249 Loss 3.250 Prec@(1,3) (75.1%, 98.3%), ce_loss 1.011, lat_loss 22.163
09/21 10:26:30 AM | Train: [ 27/180] Step 650/1249 Loss 3.229 Prec@(1,3) (75.2%, 98.3%), ce_loss 1.011, lat_loss 22.163
09/21 10:26:53 AM | Train: [ 27/180] Step 700/1249 Loss 3.238 Prec@(1,3) (75.1%, 98.3%), ce_loss 1.010, lat_loss 22.163
09/21 10:27:17 AM | Train: [ 27/180] Step 750/1249 Loss 3.219 Prec@(1,3) (75.3%, 98.3%), ce_loss 1.010, lat_loss 22.163
09/21 10:27:37 AM | Train: [ 27/180] Step 800/1249 Loss 3.203 Prec@(1,3) (75.3%, 98.3%), ce_loss 1.010, lat_loss 22.163
09/21 10:27:56 AM | Train: [ 27/180] Step 850/1249 Loss 3.198 Prec@(1,3) (75.4%, 98.3%), ce_loss 1.009, lat_loss 22.163
09/21 10:28:16 AM | Train: [ 27/180] Step 900/1249 Loss 3.192 Prec@(1,3) (75.5%, 98.3%), ce_loss 1.009, lat_loss 22.163
09/21 10:28:38 AM | Train: [ 27/180] Step 950/1249 Loss 3.200 Prec@(1,3) (75.4%, 98.3%), ce_loss 1.009, lat_loss 22.163
09/21 10:29:01 AM | Train: [ 27/180] Step 1000/1249 Loss 3.188 Prec@(1,3) (75.5%, 98.3%), ce_loss 1.008, lat_loss 22.163
09/21 10:29:24 AM | Train: [ 27/180] Step 1050/1249 Loss 3.190 Prec@(1,3) (75.5%, 98.3%), ce_loss 1.008, lat_loss 22.163
09/21 10:29:47 AM | Train: [ 27/180] Step 1100/1249 Loss 3.181 Prec@(1,3) (75.6%, 98.3%), ce_loss 1.008, lat_loss 22.163
09/21 10:30:09 AM | Train: [ 27/180] Step 1150/1249 Loss 3.184 Prec@(1,3) (75.6%, 98.3%), ce_loss 1.007, lat_loss 22.162
09/21 10:30:32 AM | Train: [ 27/180] Step 1200/1249 Loss 3.186 Prec@(1,3) (75.6%, 98.3%), ce_loss 1.007, lat_loss 22.162
09/21 10:30:55 AM | Train: [ 27/180] Step 1249/1249 Loss 3.193 Prec@(1,3) (75.6%, 98.3%), ce_loss 1.007, lat_loss 22.162
09/21 10:30:55 AM | _w_step_train: [ 27/180] Final Prec@1 75.5800% Time 560.87
09/21 10:30:55 AM | Start to train theta for epoch 26
09/21 10:31:13 AM | Train: [ 27/180] Step 050/312 Loss 3.421 Prec@(1,3) (75.2%, 97.9%), ce_loss 1.006, lat_loss 22.162
09/21 10:31:29 AM | Train: [ 27/180] Step 100/312 Loss 3.299 Prec@(1,3) (75.7%, 98.4%), ce_loss 1.006, lat_loss 22.162
09/21 10:31:44 AM | Train: [ 27/180] Step 150/312 Loss 3.371 Prec@(1,3) (75.0%, 98.3%), ce_loss 1.006, lat_loss 22.162
09/21 10:32:00 AM | Train: [ 27/180] Step 200/312 Loss 3.326 Prec@(1,3) (75.1%, 98.3%), ce_loss 1.005, lat_loss 22.162
09/21 10:32:19 AM | Train: [ 27/180] Step 250/312 Loss 3.319 Prec@(1,3) (75.0%, 98.3%), ce_loss 1.005, lat_loss 22.162
09/21 10:32:38 AM | Train: [ 27/180] Step 300/312 Loss 3.341 Prec@(1,3) (74.7%, 98.3%), ce_loss 1.005, lat_loss 22.162
09/21 10:32:43 AM | Train: [ 27/180] Step 312/312 Loss 3.349 Prec@(1,3) (74.7%, 98.2%), ce_loss 1.005, lat_loss 22.162
09/21 10:32:43 AM | _theta_step_train: [ 27/180] Final Prec@1 74.7100% Time 107.99
09/21 10:32:48 AM | Valid: [ 27/180] Step 050/312 Loss 4.112 Prec@(1,3) (69.2%, 98.0%), ce_loss 1.005, lat_loss 22.162
09/21 10:32:53 AM | Valid: [ 27/180] Step 100/312 Loss 3.934 Prec@(1,3) (70.6%, 97.9%), ce_loss 1.005, lat_loss 22.162
09/21 10:32:58 AM | Valid: [ 27/180] Step 150/312 Loss 3.792 Prec@(1,3) (72.0%, 97.7%), ce_loss 1.004, lat_loss 22.162
09/21 10:33:02 AM | Valid: [ 27/180] Step 200/312 Loss 3.708 Prec@(1,3) (72.4%, 97.8%), ce_loss 1.004, lat_loss 22.161
09/21 10:33:07 AM | Valid: [ 27/180] Step 250/312 Loss 3.698 Prec@(1,3) (72.1%, 97.9%), ce_loss 1.004, lat_loss 22.161
09/21 10:33:12 AM | Valid: [ 27/180] Step 300/312 Loss 3.719 Prec@(1,3) (71.9%, 97.9%), ce_loss 1.004, lat_loss 22.161
09/21 10:33:13 AM | Valid: [ 27/180] Step 312/312 Loss 3.726 Prec@(1,3) (71.8%, 97.9%), ce_loss 1.004, lat_loss 22.161
09/21 10:33:13 AM | val: [ 27/180] Final Prec@1 71.8000% Time 29.77
09/21 10:33:13 AM | Start to train weights for epoch 27
09/21 10:33:38 AM | Train: [ 28/180] Step 050/1249 Loss 3.119 Prec@(1,3) (76.5%, 98.1%), ce_loss 1.003, lat_loss 22.161
09/21 10:34:04 AM | Train: [ 28/180] Step 100/1249 Loss 3.234 Prec@(1,3) (75.7%, 98.1%), ce_loss 1.003, lat_loss 22.161
09/21 10:34:27 AM | Train: [ 28/180] Step 150/1249 Loss 3.249 Prec@(1,3) (75.3%, 98.0%), ce_loss 1.003, lat_loss 22.161
09/21 10:34:51 AM | Train: [ 28/180] Step 200/1249 Loss 3.200 Prec@(1,3) (75.3%, 98.2%), ce_loss 1.002, lat_loss 22.161
09/21 10:35:16 AM | Train: [ 28/180] Step 250/1249 Loss 3.222 Prec@(1,3) (75.0%, 98.2%), ce_loss 1.002, lat_loss 22.161
09/21 10:35:41 AM | Train: [ 28/180] Step 300/1249 Loss 3.202 Prec@(1,3) (75.1%, 98.3%), ce_loss 1.002, lat_loss 22.161
09/21 10:36:06 AM | Train: [ 28/180] Step 350/1249 Loss 3.211 Prec@(1,3) (74.9%, 98.3%), ce_loss 1.002, lat_loss 22.161
09/21 10:36:31 AM | Train: [ 28/180] Step 400/1249 Loss 3.195 Prec@(1,3) (75.2%, 98.3%), ce_loss 1.001, lat_loss 22.161
09/21 10:36:56 AM | Train: [ 28/180] Step 450/1249 Loss 3.198 Prec@(1,3) (75.3%, 98.3%), ce_loss 1.001, lat_loss 22.160
09/21 10:37:19 AM | Train: [ 28/180] Step 500/1249 Loss 3.201 Prec@(1,3) (75.2%, 98.3%), ce_loss 1.001, lat_loss 22.160
09/21 10:37:42 AM | Train: [ 28/180] Step 550/1249 Loss 3.194 Prec@(1,3) (75.3%, 98.3%), ce_loss 1.000, lat_loss 22.160
09/21 10:38:05 AM | Train: [ 28/180] Step 600/1249 Loss 3.206 Prec@(1,3) (75.2%, 98.3%), ce_loss 1.000, lat_loss 22.160
09/21 10:38:29 AM | Train: [ 28/180] Step 650/1249 Loss 3.189 Prec@(1,3) (75.4%, 98.3%), ce_loss 1.000, lat_loss 22.160
09/21 10:38:54 AM | Train: [ 28/180] Step 700/1249 Loss 3.197 Prec@(1,3) (75.3%, 98.3%), ce_loss 0.999, lat_loss 22.160
09/21 10:39:15 AM | Train: [ 28/180] Step 750/1249 Loss 3.203 Prec@(1,3) (75.2%, 98.2%), ce_loss 0.999, lat_loss 22.160
09/21 10:39:36 AM | Train: [ 28/180] Step 800/1249 Loss 3.190 Prec@(1,3) (75.4%, 98.3%), ce_loss 0.999, lat_loss 22.160
09/21 10:39:57 AM | Train: [ 28/180] Step 850/1249 Loss 3.187 Prec@(1,3) (75.4%, 98.3%), ce_loss 0.998, lat_loss 22.160
09/21 10:40:19 AM | Train: [ 28/180] Step 900/1249 Loss 3.192 Prec@(1,3) (75.4%, 98.3%), ce_loss 0.998, lat_loss 22.160
09/21 10:40:40 AM | Train: [ 28/180] Step 950/1249 Loss 3.191 Prec@(1,3) (75.4%, 98.3%), ce_loss 0.998, lat_loss 22.160
09/21 10:41:01 AM | Train: [ 28/180] Step 1000/1249 Loss 3.187 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.998, lat_loss 22.160
09/21 10:41:23 AM | Train: [ 28/180] Step 1050/1249 Loss 3.186 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.997, lat_loss 22.159
09/21 10:41:44 AM | Train: [ 28/180] Step 1100/1249 Loss 3.192 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.997, lat_loss 22.159
09/21 10:42:05 AM | Train: [ 28/180] Step 1150/1249 Loss 3.193 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.997, lat_loss 22.159
09/21 10:42:26 AM | Train: [ 28/180] Step 1200/1249 Loss 3.194 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.996, lat_loss 22.159
09/21 10:42:50 AM | Train: [ 28/180] Step 1249/1249 Loss 3.197 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.996, lat_loss 22.159
09/21 10:42:51 AM | _w_step_train: [ 28/180] Final Prec@1 75.4925% Time 577.71
09/21 10:42:51 AM | Start to train theta for epoch 27
09/21 10:43:11 AM | Train: [ 28/180] Step 050/312 Loss 3.565 Prec@(1,3) (71.8%, 97.9%), ce_loss 0.996, lat_loss 22.159
09/21 10:43:31 AM | Train: [ 28/180] Step 100/312 Loss 3.448 Prec@(1,3) (73.4%, 97.6%), ce_loss 0.996, lat_loss 22.159
09/21 10:43:51 AM | Train: [ 28/180] Step 150/312 Loss 3.356 Prec@(1,3) (74.4%, 97.9%), ce_loss 0.995, lat_loss 22.159
09/21 10:44:11 AM | Train: [ 28/180] Step 200/312 Loss 3.323 Prec@(1,3) (74.8%, 97.9%), ce_loss 0.995, lat_loss 22.159
09/21 10:44:30 AM | Train: [ 28/180] Step 250/312 Loss 3.333 Prec@(1,3) (74.6%, 98.0%), ce_loss 0.995, lat_loss 22.159
09/21 10:44:50 AM | Train: [ 28/180] Step 300/312 Loss 3.361 Prec@(1,3) (74.4%, 97.9%), ce_loss 0.995, lat_loss 22.159
09/21 10:44:55 AM | Train: [ 28/180] Step 312/312 Loss 3.381 Prec@(1,3) (74.2%, 97.9%), ce_loss 0.995, lat_loss 22.159
09/21 10:44:55 AM | _theta_step_train: [ 28/180] Final Prec@1 74.2300% Time 124.45
09/21 10:45:00 AM | Valid: [ 28/180] Step 050/312 Loss 3.583 Prec@(1,3) (73.7%, 98.1%), ce_loss 0.994, lat_loss 22.159
09/21 10:45:05 AM | Valid: [ 28/180] Step 100/312 Loss 3.723 Prec@(1,3) (72.2%, 97.6%), ce_loss 0.994, lat_loss 22.159
09/21 10:45:10 AM | Valid: [ 28/180] Step 150/312 Loss 3.725 Prec@(1,3) (72.1%, 97.4%), ce_loss 0.994, lat_loss 22.159
09/21 10:45:14 AM | Valid: [ 28/180] Step 200/312 Loss 3.762 Prec@(1,3) (71.6%, 97.5%), ce_loss 0.994, lat_loss 22.159
09/21 10:45:19 AM | Valid: [ 28/180] Step 250/312 Loss 3.804 Prec@(1,3) (71.4%, 97.4%), ce_loss 0.994, lat_loss 22.158
09/21 10:45:24 AM | Valid: [ 28/180] Step 300/312 Loss 3.791 Prec@(1,3) (71.4%, 97.4%), ce_loss 0.994, lat_loss 22.158
09/21 10:45:25 AM | Valid: [ 28/180] Step 312/312 Loss 3.800 Prec@(1,3) (71.2%, 97.4%), ce_loss 0.994, lat_loss 22.158
09/21 10:45:25 AM | val: [ 28/180] Final Prec@1 71.1900% Time 29.76
09/21 10:45:25 AM | Start to train weights for epoch 28
09/21 10:45:49 AM | Train: [ 29/180] Step 050/1249 Loss 3.315 Prec@(1,3) (75.2%, 98.0%), ce_loss 0.993, lat_loss 22.158
09/21 10:46:12 AM | Train: [ 29/180] Step 100/1249 Loss 3.206 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.993, lat_loss 22.158
09/21 10:46:35 AM | Train: [ 29/180] Step 150/1249 Loss 3.225 Prec@(1,3) (75.2%, 98.2%), ce_loss 0.993, lat_loss 22.158
09/21 10:47:00 AM | Train: [ 29/180] Step 200/1249 Loss 3.302 Prec@(1,3) (75.1%, 98.2%), ce_loss 0.993, lat_loss 22.158
09/21 10:47:25 AM | Train: [ 29/180] Step 250/1249 Loss 3.260 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.992, lat_loss 22.158
09/21 10:47:50 AM | Train: [ 29/180] Step 300/1249 Loss 3.235 Prec@(1,3) (75.6%, 98.2%), ce_loss 0.992, lat_loss 22.158
09/21 10:48:14 AM | Train: [ 29/180] Step 350/1249 Loss 3.241 Prec@(1,3) (75.6%, 98.2%), ce_loss 0.992, lat_loss 22.158
09/21 10:48:39 AM | Train: [ 29/180] Step 400/1249 Loss 3.254 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.991, lat_loss 22.158
09/21 10:49:03 AM | Train: [ 29/180] Step 450/1249 Loss 3.251 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.991, lat_loss 22.158
09/21 10:49:28 AM | Train: [ 29/180] Step 500/1249 Loss 3.259 Prec@(1,3) (75.3%, 98.3%), ce_loss 0.991, lat_loss 22.158
09/21 10:49:52 AM | Train: [ 29/180] Step 550/1249 Loss 3.240 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.991, lat_loss 22.158
09/21 10:50:17 AM | Train: [ 29/180] Step 600/1249 Loss 3.241 Prec@(1,3) (75.4%, 98.3%), ce_loss 0.990, lat_loss 22.158
09/21 10:50:41 AM | Train: [ 29/180] Step 650/1249 Loss 3.243 Prec@(1,3) (75.4%, 98.3%), ce_loss 0.990, lat_loss 22.158
09/21 10:51:05 AM | Train: [ 29/180] Step 700/1249 Loss 3.239 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.990, lat_loss 22.158
09/21 10:51:29 AM | Train: [ 29/180] Step 750/1249 Loss 3.236 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.989, lat_loss 22.158
09/21 10:51:53 AM | Train: [ 29/180] Step 800/1249 Loss 3.251 Prec@(1,3) (75.4%, 98.3%), ce_loss 0.989, lat_loss 22.158
09/21 10:52:18 AM | Train: [ 29/180] Step 850/1249 Loss 3.252 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.989, lat_loss 22.158
09/21 10:52:42 AM | Train: [ 29/180] Step 900/1249 Loss 3.256 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.989, lat_loss 22.157
09/21 10:53:06 AM | Train: [ 29/180] Step 950/1249 Loss 3.245 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.988, lat_loss 22.157
09/21 10:53:30 AM | Train: [ 29/180] Step 1000/1249 Loss 3.251 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.988, lat_loss 22.157
09/21 10:53:53 AM | Train: [ 29/180] Step 1050/1249 Loss 3.244 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.988, lat_loss 22.157
09/21 10:54:18 AM | Train: [ 29/180] Step 1100/1249 Loss 3.239 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.988, lat_loss 22.157
09/21 10:54:41 AM | Train: [ 29/180] Step 1150/1249 Loss 3.245 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.987, lat_loss 22.157
09/21 10:55:06 AM | Train: [ 29/180] Step 1200/1249 Loss 3.247 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.987, lat_loss 22.157
09/21 10:55:30 AM | Train: [ 29/180] Step 1249/1249 Loss 3.238 Prec@(1,3) (75.6%, 98.2%), ce_loss 0.987, lat_loss 22.157
09/21 10:55:30 AM | _w_step_train: [ 29/180] Final Prec@1 75.5825% Time 605.10
09/21 10:55:30 AM | Start to train theta for epoch 28
09/21 10:55:47 AM | Train: [ 29/180] Step 050/312 Loss 3.412 Prec@(1,3) (74.6%, 97.9%), ce_loss 0.986, lat_loss 22.157
09/21 10:56:07 AM | Train: [ 29/180] Step 100/312 Loss 3.393 Prec@(1,3) (73.8%, 97.9%), ce_loss 0.986, lat_loss 22.157
09/21 10:56:27 AM | Train: [ 29/180] Step 150/312 Loss 3.402 Prec@(1,3) (74.1%, 97.8%), ce_loss 0.986, lat_loss 22.157
09/21 10:56:46 AM | Train: [ 29/180] Step 200/312 Loss 3.385 Prec@(1,3) (74.1%, 97.9%), ce_loss 0.986, lat_loss 22.157
09/21 10:57:05 AM | Train: [ 29/180] Step 250/312 Loss 3.375 Prec@(1,3) (74.1%, 98.1%), ce_loss 0.986, lat_loss 22.157
09/21 10:57:25 AM | Train: [ 29/180] Step 300/312 Loss 3.328 Prec@(1,3) (74.4%, 98.1%), ce_loss 0.985, lat_loss 22.157
09/21 10:57:30 AM | Train: [ 29/180] Step 312/312 Loss 3.321 Prec@(1,3) (74.5%, 98.1%), ce_loss 0.985, lat_loss 22.157
09/21 10:57:30 AM | _theta_step_train: [ 29/180] Final Prec@1 74.5300% Time 120.21
09/21 10:57:35 AM | Valid: [ 29/180] Step 050/312 Loss 3.528 Prec@(1,3) (72.4%, 97.7%), ce_loss 0.985, lat_loss 22.157
09/21 10:57:40 AM | Valid: [ 29/180] Step 100/312 Loss 3.731 Prec@(1,3) (71.8%, 97.2%), ce_loss 0.985, lat_loss 22.157
09/21 10:57:45 AM | Valid: [ 29/180] Step 150/312 Loss 3.693 Prec@(1,3) (72.0%, 97.3%), ce_loss 0.985, lat_loss 22.156
09/21 10:57:49 AM | Valid: [ 29/180] Step 200/312 Loss 3.737 Prec@(1,3) (71.6%, 97.4%), ce_loss 0.985, lat_loss 22.156
09/21 10:57:54 AM | Valid: [ 29/180] Step 250/312 Loss 3.796 Prec@(1,3) (71.3%, 97.4%), ce_loss 0.985, lat_loss 22.156
09/21 10:57:59 AM | Valid: [ 29/180] Step 300/312 Loss 3.793 Prec@(1,3) (71.3%, 97.4%), ce_loss 0.984, lat_loss 22.156
09/21 10:58:00 AM | Valid: [ 29/180] Step 312/312 Loss 3.810 Prec@(1,3) (71.1%, 97.4%), ce_loss 0.984, lat_loss 22.156
09/21 10:58:00 AM | val: [ 29/180] Final Prec@1 71.1400% Time 29.55
09/21 10:58:00 AM | Start to train weights for epoch 29
09/21 10:58:17 AM | Train: [ 30/180] Step 050/1249 Loss 3.188 Prec@(1,3) (76.0%, 98.3%), ce_loss 0.984, lat_loss 22.156
09/21 10:58:33 AM | Train: [ 30/180] Step 100/1249 Loss 3.117 Prec@(1,3) (76.1%, 98.3%), ce_loss 0.984, lat_loss 22.156
09/21 10:58:49 AM | Train: [ 30/180] Step 150/1249 Loss 3.170 Prec@(1,3) (75.8%, 98.3%), ce_loss 0.984, lat_loss 22.156
09/21 10:59:05 AM | Train: [ 30/180] Step 200/1249 Loss 3.165 Prec@(1,3) (75.7%, 98.4%), ce_loss 0.983, lat_loss 22.156
09/21 10:59:21 AM | Train: [ 30/180] Step 250/1249 Loss 3.173 Prec@(1,3) (75.7%, 98.3%), ce_loss 0.983, lat_loss 22.156
09/21 10:59:37 AM | Train: [ 30/180] Step 300/1249 Loss 3.196 Prec@(1,3) (75.5%, 98.4%), ce_loss 0.983, lat_loss 22.156
09/21 10:59:53 AM | Train: [ 30/180] Step 350/1249 Loss 3.228 Prec@(1,3) (75.3%, 98.4%), ce_loss 0.983, lat_loss 22.156
09/21 11:00:09 AM | Train: [ 30/180] Step 400/1249 Loss 3.207 Prec@(1,3) (75.6%, 98.4%), ce_loss 0.982, lat_loss 22.156
09/21 11:00:33 AM | Train: [ 30/180] Step 450/1249 Loss 3.194 Prec@(1,3) (75.7%, 98.4%), ce_loss 0.982, lat_loss 22.156
09/21 11:00:58 AM | Train: [ 30/180] Step 500/1249 Loss 3.195 Prec@(1,3) (75.7%, 98.4%), ce_loss 0.982, lat_loss 22.155
09/21 11:01:23 AM | Train: [ 30/180] Step 550/1249 Loss 3.181 Prec@(1,3) (75.8%, 98.3%), ce_loss 0.981, lat_loss 22.155
09/21 11:01:48 AM | Train: [ 30/180] Step 600/1249 Loss 3.185 Prec@(1,3) (75.8%, 98.3%), ce_loss 0.981, lat_loss 22.155
09/21 11:02:13 AM | Train: [ 30/180] Step 650/1249 Loss 3.193 Prec@(1,3) (75.8%, 98.3%), ce_loss 0.981, lat_loss 22.155
09/21 11:02:38 AM | Train: [ 30/180] Step 700/1249 Loss 3.209 Prec@(1,3) (75.7%, 98.3%), ce_loss 0.981, lat_loss 22.155
09/21 11:03:03 AM | Train: [ 30/180] Step 750/1249 Loss 3.213 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.980, lat_loss 22.155
09/21 11:03:28 AM | Train: [ 30/180] Step 800/1249 Loss 3.203 Prec@(1,3) (75.7%, 98.3%), ce_loss 0.980, lat_loss 22.155
09/21 11:03:52 AM | Train: [ 30/180] Step 850/1249 Loss 3.220 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.980, lat_loss 22.155
09/21 11:04:17 AM | Train: [ 30/180] Step 900/1249 Loss 3.219 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.980, lat_loss 22.155
09/21 11:04:41 AM | Train: [ 30/180] Step 950/1249 Loss 3.212 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.979, lat_loss 22.155
09/21 11:05:04 AM | Train: [ 30/180] Step 1000/1249 Loss 3.216 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.979, lat_loss 22.155
09/21 11:05:28 AM | Train: [ 30/180] Step 1050/1249 Loss 3.207 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.979, lat_loss 22.155
09/21 11:05:51 AM | Train: [ 30/180] Step 1100/1249 Loss 3.211 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.979, lat_loss 22.155
09/21 11:06:16 AM | Train: [ 30/180] Step 1150/1249 Loss 3.204 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.978, lat_loss 22.155
09/21 11:06:40 AM | Train: [ 30/180] Step 1200/1249 Loss 3.201 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.978, lat_loss 22.154
09/21 11:07:05 AM | Train: [ 30/180] Step 1249/1249 Loss 3.198 Prec@(1,3) (75.7%, 98.3%), ce_loss 0.978, lat_loss 22.154
09/21 11:07:05 AM | _w_step_train: [ 30/180] Final Prec@1 75.6625% Time 544.97
09/21 11:07:05 AM | Start to train theta for epoch 29
09/21 11:07:26 AM | Train: [ 30/180] Step 050/312 Loss 3.411 Prec@(1,3) (73.2%, 98.5%), ce_loss 0.978, lat_loss 22.154
09/21 11:07:47 AM | Train: [ 30/180] Step 100/312 Loss 3.417 Prec@(1,3) (74.2%, 98.2%), ce_loss 0.977, lat_loss 22.154
09/21 11:08:08 AM | Train: [ 30/180] Step 150/312 Loss 3.432 Prec@(1,3) (74.3%, 98.1%), ce_loss 0.977, lat_loss 22.154
09/21 11:08:29 AM | Train: [ 30/180] Step 200/312 Loss 3.435 Prec@(1,3) (74.3%, 98.1%), ce_loss 0.977, lat_loss 22.154
09/21 11:08:50 AM | Train: [ 30/180] Step 250/312 Loss 3.434 Prec@(1,3) (74.3%, 98.1%), ce_loss 0.977, lat_loss 22.154
09/21 11:09:11 AM | Train: [ 30/180] Step 300/312 Loss 3.432 Prec@(1,3) (74.2%, 98.1%), ce_loss 0.977, lat_loss 22.154
09/21 11:09:15 AM | Train: [ 30/180] Step 312/312 Loss 3.423 Prec@(1,3) (74.2%, 98.1%), ce_loss 0.977, lat_loss 22.154
09/21 11:09:16 AM | _theta_step_train: [ 30/180] Final Prec@1 74.2200% Time 130.90
09/21 11:09:21 AM | Valid: [ 30/180] Step 050/312 Loss 3.670 Prec@(1,3) (73.8%, 97.6%), ce_loss 0.976, lat_loss 22.154
09/21 11:09:26 AM | Valid: [ 30/180] Step 100/312 Loss 3.805 Prec@(1,3) (72.5%, 97.6%), ce_loss 0.976, lat_loss 22.154
09/21 11:09:30 AM | Valid: [ 30/180] Step 150/312 Loss 3.746 Prec@(1,3) (72.7%, 97.4%), ce_loss 0.976, lat_loss 22.154
09/21 11:09:35 AM | Valid: [ 30/180] Step 200/312 Loss 3.729 Prec@(1,3) (72.4%, 97.5%), ce_loss 0.976, lat_loss 22.154
09/21 11:09:39 AM | Valid: [ 30/180] Step 250/312 Loss 3.776 Prec@(1,3) (72.1%, 97.5%), ce_loss 0.976, lat_loss 22.153
09/21 11:09:44 AM | Valid: [ 30/180] Step 300/312 Loss 3.792 Prec@(1,3) (71.9%, 97.4%), ce_loss 0.976, lat_loss 22.153
09/21 11:09:45 AM | Valid: [ 30/180] Step 312/312 Loss 3.780 Prec@(1,3) (72.0%, 97.5%), ce_loss 0.976, lat_loss 22.153
09/21 11:09:45 AM | val: [ 30/180] Final Prec@1 71.9700% Time 29.69
09/21 11:09:45 AM | Start to train weights for epoch 30
09/21 11:10:01 AM | Train: [ 31/180] Step 050/1249 Loss 3.423 Prec@(1,3) (73.8%, 98.2%), ce_loss 0.976, lat_loss 22.153
09/21 11:10:16 AM | Train: [ 31/180] Step 100/1249 Loss 3.571 Prec@(1,3) (73.0%, 97.9%), ce_loss 0.975, lat_loss 22.153
09/21 11:10:30 AM | Train: [ 31/180] Step 150/1249 Loss 3.373 Prec@(1,3) (74.5%, 98.0%), ce_loss 0.975, lat_loss 22.153
09/21 11:10:45 AM | Train: [ 31/180] Step 200/1249 Loss 3.372 Prec@(1,3) (74.9%, 98.0%), ce_loss 0.975, lat_loss 22.153
09/21 11:10:59 AM | Train: [ 31/180] Step 250/1249 Loss 3.331 Prec@(1,3) (75.2%, 98.2%), ce_loss 0.975, lat_loss 22.153
09/21 11:11:14 AM | Train: [ 31/180] Step 300/1249 Loss 3.307 Prec@(1,3) (75.4%, 98.3%), ce_loss 0.974, lat_loss 22.153
09/21 11:11:28 AM | Train: [ 31/180] Step 350/1249 Loss 3.315 Prec@(1,3) (75.1%, 98.2%), ce_loss 0.974, lat_loss 22.153
09/21 11:11:43 AM | Train: [ 31/180] Step 400/1249 Loss 3.290 Prec@(1,3) (75.2%, 98.2%), ce_loss 0.974, lat_loss 22.153
09/21 11:11:58 AM | Train: [ 31/180] Step 450/1249 Loss 3.285 Prec@(1,3) (75.2%, 98.1%), ce_loss 0.974, lat_loss 22.152
09/21 11:12:12 AM | Train: [ 31/180] Step 500/1249 Loss 3.276 Prec@(1,3) (75.2%, 98.1%), ce_loss 0.973, lat_loss 22.152
09/21 11:12:27 AM | Train: [ 31/180] Step 550/1249 Loss 3.282 Prec@(1,3) (75.1%, 98.1%), ce_loss 0.973, lat_loss 22.152
09/21 11:12:41 AM | Train: [ 31/180] Step 600/1249 Loss 3.274 Prec@(1,3) (75.2%, 98.1%), ce_loss 0.973, lat_loss 22.152
09/21 11:12:56 AM | Train: [ 31/180] Step 650/1249 Loss 3.270 Prec@(1,3) (75.3%, 98.1%), ce_loss 0.973, lat_loss 22.152
09/21 11:13:10 AM | Train: [ 31/180] Step 700/1249 Loss 3.315 Prec@(1,3) (75.2%, 98.2%), ce_loss 0.973, lat_loss 22.152
09/21 11:13:25 AM | Train: [ 31/180] Step 750/1249 Loss 3.341 Prec@(1,3) (75.1%, 98.1%), ce_loss 0.973, lat_loss 22.152
09/21 11:13:40 AM | Train: [ 31/180] Step 800/1249 Loss 3.341 Prec@(1,3) (75.1%, 98.1%), ce_loss 0.972, lat_loss 22.152
09/21 11:13:55 AM | Train: [ 31/180] Step 850/1249 Loss 3.352 Prec@(1,3) (75.0%, 98.0%), ce_loss 0.972, lat_loss 22.152
09/21 11:14:09 AM | Train: [ 31/180] Step 900/1249 Loss 3.340 Prec@(1,3) (75.1%, 98.1%), ce_loss 0.972, lat_loss 22.152
09/21 11:14:24 AM | Train: [ 31/180] Step 950/1249 Loss 3.344 Prec@(1,3) (75.1%, 98.1%), ce_loss 0.972, lat_loss 22.152
09/21 11:14:38 AM | Train: [ 31/180] Step 1000/1249 Loss 3.355 Prec@(1,3) (74.9%, 98.0%), ce_loss 0.972, lat_loss 22.151
09/21 11:14:53 AM | Train: [ 31/180] Step 1050/1249 Loss 3.359 Prec@(1,3) (74.9%, 98.0%), ce_loss 0.971, lat_loss 22.151
09/21 11:15:07 AM | Train: [ 31/180] Step 1100/1249 Loss 3.351 Prec@(1,3) (75.0%, 98.0%), ce_loss 0.971, lat_loss 22.151
09/21 11:15:22 AM | Train: [ 31/180] Step 1150/1249 Loss 3.364 Prec@(1,3) (74.9%, 98.0%), ce_loss 0.971, lat_loss 22.151
09/21 11:15:36 AM | Train: [ 31/180] Step 1200/1249 Loss 3.377 Prec@(1,3) (74.8%, 98.0%), ce_loss 0.971, lat_loss 22.151
09/21 11:15:50 AM | Train: [ 31/180] Step 1249/1249 Loss 3.376 Prec@(1,3) (74.7%, 98.0%), ce_loss 0.971, lat_loss 22.151
09/21 11:15:51 AM | _w_step_train: [ 31/180] Final Prec@1 74.7150% Time 365.27
09/21 11:15:51 AM | Start to train theta for epoch 30
09/21 11:16:02 AM | Train: [ 31/180] Step 050/312 Loss 3.517 Prec@(1,3) (72.5%, 97.7%), ce_loss 0.970, lat_loss 22.151
09/21 11:16:14 AM | Train: [ 31/180] Step 100/312 Loss 3.454 Prec@(1,3) (72.8%, 97.7%), ce_loss 0.970, lat_loss 22.151
09/21 11:16:25 AM | Train: [ 31/180] Step 150/312 Loss 3.443 Prec@(1,3) (72.8%, 97.9%), ce_loss 0.970, lat_loss 22.151
09/21 11:16:36 AM | Train: [ 31/180] Step 200/312 Loss 3.468 Prec@(1,3) (73.1%, 97.8%), ce_loss 0.970, lat_loss 22.151
09/21 11:16:48 AM | Train: [ 31/180] Step 250/312 Loss 3.436 Prec@(1,3) (73.1%, 97.9%), ce_loss 0.970, lat_loss 22.151
09/21 11:16:59 AM | Train: [ 31/180] Step 300/312 Loss 3.430 Prec@(1,3) (73.2%, 97.9%), ce_loss 0.970, lat_loss 22.150
09/21 11:17:02 AM | Train: [ 31/180] Step 312/312 Loss 3.423 Prec@(1,3) (73.3%, 98.0%), ce_loss 0.969, lat_loss 22.150
09/21 11:17:02 AM | _theta_step_train: [ 31/180] Final Prec@1 73.3000% Time 71.41
09/21 11:17:07 AM | Valid: [ 31/180] Step 050/312 Loss 3.865 Prec@(1,3) (70.0%, 98.0%), ce_loss 0.969, lat_loss 22.150
09/21 11:17:12 AM | Valid: [ 31/180] Step 100/312 Loss 4.046 Prec@(1,3) (69.6%, 97.5%), ce_loss 0.969, lat_loss 22.150
09/21 11:17:17 AM | Valid: [ 31/180] Step 150/312 Loss 3.983 Prec@(1,3) (70.2%, 97.4%), ce_loss 0.969, lat_loss 22.150
09/21 11:17:21 AM | Valid: [ 31/180] Step 200/312 Loss 4.030 Prec@(1,3) (70.3%, 97.4%), ce_loss 0.969, lat_loss 22.150
09/21 11:17:26 AM | Valid: [ 31/180] Step 250/312 Loss 4.021 Prec@(1,3) (69.8%, 97.3%), ce_loss 0.969, lat_loss 22.150
09/21 11:17:31 AM | Valid: [ 31/180] Step 300/312 Loss 3.957 Prec@(1,3) (70.1%, 97.4%), ce_loss 0.969, lat_loss 22.150
09/21 11:17:32 AM | Valid: [ 31/180] Step 312/312 Loss 3.972 Prec@(1,3) (69.9%, 97.5%), ce_loss 0.969, lat_loss 22.150
09/21 11:17:32 AM | val: [ 31/180] Final Prec@1 69.8600% Time 30.06
09/21 11:17:32 AM | Start to train weights for epoch 31
09/21 11:17:57 AM | Train: [ 32/180] Step 050/1249 Loss 3.573 Prec@(1,3) (73.4%, 97.8%), ce_loss 0.969, lat_loss 22.150
09/21 11:18:20 AM | Train: [ 32/180] Step 100/1249 Loss 3.431 Prec@(1,3) (74.5%, 97.9%), ce_loss 0.969, lat_loss 22.150
09/21 11:18:42 AM | Train: [ 32/180] Step 150/1249 Loss 3.394 Prec@(1,3) (74.5%, 98.1%), ce_loss 0.968, lat_loss 22.149
09/21 11:19:05 AM | Train: [ 32/180] Step 200/1249 Loss 3.402 Prec@(1,3) (74.5%, 98.1%), ce_loss 0.968, lat_loss 22.149
09/21 11:19:29 AM | Train: [ 32/180] Step 250/1249 Loss 3.353 Prec@(1,3) (75.0%, 98.2%), ce_loss 0.968, lat_loss 22.149
09/21 11:19:51 AM | Train: [ 32/180] Step 300/1249 Loss 3.373 Prec@(1,3) (74.6%, 98.1%), ce_loss 0.968, lat_loss 22.149
09/21 11:20:13 AM | Train: [ 32/180] Step 350/1249 Loss 3.368 Prec@(1,3) (74.5%, 98.0%), ce_loss 0.968, lat_loss 22.149
09/21 11:20:36 AM | Train: [ 32/180] Step 400/1249 Loss 3.383 Prec@(1,3) (74.5%, 98.0%), ce_loss 0.968, lat_loss 22.149
09/21 11:20:58 AM | Train: [ 32/180] Step 450/1249 Loss 3.377 Prec@(1,3) (74.4%, 98.1%), ce_loss 0.967, lat_loss 22.149
09/21 11:21:20 AM | Train: [ 32/180] Step 500/1249 Loss 3.366 Prec@(1,3) (74.5%, 98.1%), ce_loss 0.967, lat_loss 22.149
09/21 11:21:43 AM | Train: [ 32/180] Step 550/1249 Loss 3.361 Prec@(1,3) (74.5%, 98.1%), ce_loss 0.967, lat_loss 22.149
09/21 11:22:05 AM | Train: [ 32/180] Step 600/1249 Loss 3.354 Prec@(1,3) (74.5%, 98.1%), ce_loss 0.967, lat_loss 22.148
09/21 11:22:26 AM | Train: [ 32/180] Step 650/1249 Loss 3.343 Prec@(1,3) (74.6%, 98.0%), ce_loss 0.966, lat_loss 22.148
09/21 11:22:49 AM | Train: [ 32/180] Step 700/1249 Loss 3.341 Prec@(1,3) (74.5%, 98.0%), ce_loss 0.966, lat_loss 22.148
09/21 11:23:12 AM | Train: [ 32/180] Step 750/1249 Loss 3.341 Prec@(1,3) (74.5%, 98.1%), ce_loss 0.966, lat_loss 22.148
09/21 11:23:35 AM | Train: [ 32/180] Step 800/1249 Loss 3.337 Prec@(1,3) (74.5%, 98.1%), ce_loss 0.966, lat_loss 22.148
09/21 11:23:57 AM | Train: [ 32/180] Step 850/1249 Loss 3.341 Prec@(1,3) (74.6%, 98.1%), ce_loss 0.966, lat_loss 22.148
09/21 11:24:20 AM | Train: [ 32/180] Step 900/1249 Loss 3.336 Prec@(1,3) (74.6%, 98.1%), ce_loss 0.965, lat_loss 22.148
09/21 11:24:42 AM | Train: [ 32/180] Step 950/1249 Loss 3.319 Prec@(1,3) (74.7%, 98.1%), ce_loss 0.965, lat_loss 22.148
09/21 11:25:03 AM | Train: [ 32/180] Step 1000/1249 Loss 3.326 Prec@(1,3) (74.7%, 98.1%), ce_loss 0.965, lat_loss 22.148
09/21 11:25:26 AM | Train: [ 32/180] Step 1050/1249 Loss 3.320 Prec@(1,3) (74.8%, 98.1%), ce_loss 0.965, lat_loss 22.147
09/21 11:25:48 AM | Train: [ 32/180] Step 1100/1249 Loss 3.319 Prec@(1,3) (74.8%, 98.1%), ce_loss 0.965, lat_loss 22.147
09/21 11:26:11 AM | Train: [ 32/180] Step 1150/1249 Loss 3.319 Prec@(1,3) (74.8%, 98.1%), ce_loss 0.964, lat_loss 22.147
09/21 11:26:33 AM | Train: [ 32/180] Step 1200/1249 Loss 3.318 Prec@(1,3) (74.8%, 98.1%), ce_loss 0.964, lat_loss 22.147
09/21 11:26:57 AM | Train: [ 32/180] Step 1249/1249 Loss 3.310 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.964, lat_loss 22.147
09/21 11:26:57 AM | _w_step_train: [ 32/180] Final Prec@1 74.8800% Time 564.97
09/21 11:26:57 AM | Start to train theta for epoch 31
09/21 11:27:18 AM | Train: [ 32/180] Step 050/312 Loss 3.707 Prec@(1,3) (71.8%, 97.8%), ce_loss 0.964, lat_loss 22.147
09/21 11:27:39 AM | Train: [ 32/180] Step 100/312 Loss 3.568 Prec@(1,3) (73.1%, 97.9%), ce_loss 0.964, lat_loss 22.147
09/21 11:28:00 AM | Train: [ 32/180] Step 150/312 Loss 3.505 Prec@(1,3) (73.9%, 98.0%), ce_loss 0.963, lat_loss 22.147
09/21 11:28:20 AM | Train: [ 32/180] Step 200/312 Loss 3.438 Prec@(1,3) (74.4%, 98.1%), ce_loss 0.963, lat_loss 22.147
09/21 11:28:40 AM | Train: [ 32/180] Step 250/312 Loss 3.423 Prec@(1,3) (74.4%, 98.2%), ce_loss 0.963, lat_loss 22.146
09/21 11:29:01 AM | Train: [ 32/180] Step 300/312 Loss 3.407 Prec@(1,3) (74.6%, 98.2%), ce_loss 0.963, lat_loss 22.146
09/21 11:29:06 AM | Train: [ 32/180] Step 312/312 Loss 3.395 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.963, lat_loss 22.146
09/21 11:29:07 AM | _theta_step_train: [ 32/180] Final Prec@1 74.6700% Time 129.44
09/21 11:29:12 AM | Valid: [ 32/180] Step 050/312 Loss 3.942 Prec@(1,3) (69.9%, 96.9%), ce_loss 0.963, lat_loss 22.146
09/21 11:29:16 AM | Valid: [ 32/180] Step 100/312 Loss 4.045 Prec@(1,3) (70.3%, 97.0%), ce_loss 0.963, lat_loss 22.146
09/21 11:29:21 AM | Valid: [ 32/180] Step 150/312 Loss 4.104 Prec@(1,3) (70.0%, 97.1%), ce_loss 0.963, lat_loss 22.146
09/21 11:29:26 AM | Valid: [ 32/180] Step 200/312 Loss 3.997 Prec@(1,3) (70.7%, 97.4%), ce_loss 0.963, lat_loss 22.146
09/21 11:29:30 AM | Valid: [ 32/180] Step 250/312 Loss 3.988 Prec@(1,3) (70.7%, 97.6%), ce_loss 0.963, lat_loss 22.146
09/21 11:29:35 AM | Valid: [ 32/180] Step 300/312 Loss 4.005 Prec@(1,3) (70.7%, 97.6%), ce_loss 0.962, lat_loss 22.146
09/21 11:29:36 AM | Valid: [ 32/180] Step 312/312 Loss 4.011 Prec@(1,3) (70.6%, 97.6%), ce_loss 0.962, lat_loss 22.146
09/21 11:29:36 AM | val: [ 32/180] Final Prec@1 70.6400% Time 29.97
09/21 11:29:36 AM | Start to train weights for epoch 32
09/21 11:30:01 AM | Train: [ 33/180] Step 050/1249 Loss 3.347 Prec@(1,3) (74.1%, 98.1%), ce_loss 0.962, lat_loss 22.145
09/21 11:30:24 AM | Train: [ 33/180] Step 100/1249 Loss 3.184 Prec@(1,3) (75.8%, 98.1%), ce_loss 0.962, lat_loss 22.145
09/21 11:30:48 AM | Train: [ 33/180] Step 150/1249 Loss 3.210 Prec@(1,3) (75.6%, 98.2%), ce_loss 0.962, lat_loss 22.145
09/21 11:31:12 AM | Train: [ 33/180] Step 200/1249 Loss 3.234 Prec@(1,3) (75.4%, 98.1%), ce_loss 0.962, lat_loss 22.145
09/21 11:31:36 AM | Train: [ 33/180] Step 250/1249 Loss 3.219 Prec@(1,3) (75.3%, 98.3%), ce_loss 0.961, lat_loss 22.145
09/21 11:31:59 AM | Train: [ 33/180] Step 300/1249 Loss 3.215 Prec@(1,3) (75.4%, 98.2%), ce_loss 0.961, lat_loss 22.145
09/21 11:32:22 AM | Train: [ 33/180] Step 350/1249 Loss 3.200 Prec@(1,3) (75.6%, 98.2%), ce_loss 0.961, lat_loss 22.145
09/21 11:32:45 AM | Train: [ 33/180] Step 400/1249 Loss 3.200 Prec@(1,3) (75.7%, 98.3%), ce_loss 0.961, lat_loss 22.145
09/21 11:33:06 AM | Train: [ 33/180] Step 450/1249 Loss 3.192 Prec@(1,3) (75.8%, 98.3%), ce_loss 0.961, lat_loss 22.144
09/21 11:33:30 AM | Train: [ 33/180] Step 500/1249 Loss 3.238 Prec@(1,3) (75.6%, 98.1%), ce_loss 0.960, lat_loss 22.144
09/21 11:33:54 AM | Train: [ 33/180] Step 550/1249 Loss 3.245 Prec@(1,3) (75.5%, 98.1%), ce_loss 0.960, lat_loss 22.144
09/21 11:34:17 AM | Train: [ 33/180] Step 600/1249 Loss 3.235 Prec@(1,3) (75.6%, 98.1%), ce_loss 0.960, lat_loss 22.144
09/21 11:34:40 AM | Train: [ 33/180] Step 650/1249 Loss 3.253 Prec@(1,3) (75.5%, 98.1%), ce_loss 0.960, lat_loss 22.144
09/21 11:35:05 AM | Train: [ 33/180] Step 700/1249 Loss 3.250 Prec@(1,3) (75.6%, 98.1%), ce_loss 0.960, lat_loss 22.144
09/21 11:35:29 AM | Train: [ 33/180] Step 750/1249 Loss 3.240 Prec@(1,3) (75.6%, 98.1%), ce_loss 0.959, lat_loss 22.144
09/21 11:35:53 AM | Train: [ 33/180] Step 800/1249 Loss 3.230 Prec@(1,3) (75.7%, 98.1%), ce_loss 0.959, lat_loss 22.144
09/21 11:36:15 AM | Train: [ 33/180] Step 850/1249 Loss 3.226 Prec@(1,3) (75.7%, 98.1%), ce_loss 0.959, lat_loss 22.143
09/21 11:36:37 AM | Train: [ 33/180] Step 900/1249 Loss 3.225 Prec@(1,3) (75.8%, 98.2%), ce_loss 0.959, lat_loss 22.143
09/21 11:37:01 AM | Train: [ 33/180] Step 950/1249 Loss 3.225 Prec@(1,3) (75.8%, 98.2%), ce_loss 0.958, lat_loss 22.143
09/21 11:37:24 AM | Train: [ 33/180] Step 1000/1249 Loss 3.212 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.958, lat_loss 22.143
09/21 11:37:48 AM | Train: [ 33/180] Step 1050/1249 Loss 3.218 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.958, lat_loss 22.143
09/21 11:38:10 AM | Train: [ 33/180] Step 1100/1249 Loss 3.233 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.958, lat_loss 22.143
09/21 11:38:32 AM | Train: [ 33/180] Step 1150/1249 Loss 3.232 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.958, lat_loss 22.143
09/21 11:38:56 AM | Train: [ 33/180] Step 1200/1249 Loss 3.228 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.957, lat_loss 22.143
09/21 11:39:20 AM | Train: [ 33/180] Step 1249/1249 Loss 3.214 Prec@(1,3) (75.8%, 98.2%), ce_loss 0.957, lat_loss 22.142
09/21 11:39:20 AM | _w_step_train: [ 33/180] Final Prec@1 75.7725% Time 583.75
09/21 11:39:20 AM | Start to train theta for epoch 32
09/21 11:39:41 AM | Train: [ 33/180] Step 050/312 Loss 3.153 Prec@(1,3) (75.2%, 98.7%), ce_loss 0.957, lat_loss 22.142
09/21 11:40:00 AM | Train: [ 33/180] Step 100/312 Loss 3.213 Prec@(1,3) (75.9%, 98.3%), ce_loss 0.957, lat_loss 22.142
09/21 11:40:21 AM | Train: [ 33/180] Step 150/312 Loss 3.229 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.957, lat_loss 22.142
09/21 11:40:41 AM | Train: [ 33/180] Step 200/312 Loss 3.214 Prec@(1,3) (75.4%, 98.2%), ce_loss 0.956, lat_loss 22.142
09/21 11:41:02 AM | Train: [ 33/180] Step 250/312 Loss 3.243 Prec@(1,3) (75.4%, 98.2%), ce_loss 0.956, lat_loss 22.142
09/21 11:41:23 AM | Train: [ 33/180] Step 300/312 Loss 3.221 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.956, lat_loss 22.142
09/21 11:41:28 AM | Train: [ 33/180] Step 312/312 Loss 3.221 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.956, lat_loss 22.142
09/21 11:41:28 AM | _theta_step_train: [ 33/180] Final Prec@1 75.6600% Time 127.52
09/21 11:41:33 AM | Valid: [ 33/180] Step 050/312 Loss 3.819 Prec@(1,3) (71.0%, 97.4%), ce_loss 0.956, lat_loss 22.142
09/21 11:41:38 AM | Valid: [ 33/180] Step 100/312 Loss 3.840 Prec@(1,3) (70.4%, 97.7%), ce_loss 0.956, lat_loss 22.141
09/21 11:41:42 AM | Valid: [ 33/180] Step 150/312 Loss 3.774 Prec@(1,3) (71.3%, 97.7%), ce_loss 0.956, lat_loss 22.141
09/21 11:41:47 AM | Valid: [ 33/180] Step 200/312 Loss 3.905 Prec@(1,3) (70.1%, 97.6%), ce_loss 0.956, lat_loss 22.141
09/21 11:41:51 AM | Valid: [ 33/180] Step 250/312 Loss 3.883 Prec@(1,3) (70.3%, 97.6%), ce_loss 0.956, lat_loss 22.141
09/21 11:41:56 AM | Valid: [ 33/180] Step 300/312 Loss 3.910 Prec@(1,3) (70.3%, 97.5%), ce_loss 0.956, lat_loss 22.141
09/21 11:41:57 AM | Valid: [ 33/180] Step 312/312 Loss 3.910 Prec@(1,3) (70.3%, 97.5%), ce_loss 0.956, lat_loss 22.141
09/21 11:41:57 AM | val: [ 33/180] Final Prec@1 70.2700% Time 29.37
09/21 11:41:57 AM | Start to train weights for epoch 33
09/21 11:42:23 AM | Train: [ 34/180] Step 050/1249 Loss 2.830 Prec@(1,3) (78.1%, 98.7%), ce_loss 0.955, lat_loss 22.141
09/21 11:42:46 AM | Train: [ 34/180] Step 100/1249 Loss 2.904 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.955, lat_loss 22.141
09/21 11:43:09 AM | Train: [ 34/180] Step 150/1249 Loss 3.044 Prec@(1,3) (76.6%, 98.5%), ce_loss 0.955, lat_loss 22.140
09/21 11:43:32 AM | Train: [ 34/180] Step 200/1249 Loss 3.069 Prec@(1,3) (76.5%, 98.5%), ce_loss 0.955, lat_loss 22.140
09/21 11:43:55 AM | Train: [ 34/180] Step 250/1249 Loss 3.112 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.954, lat_loss 22.140
09/21 11:44:19 AM | Train: [ 34/180] Step 300/1249 Loss 3.137 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.954, lat_loss 22.140
09/21 11:44:44 AM | Train: [ 34/180] Step 350/1249 Loss 3.155 Prec@(1,3) (75.7%, 98.3%), ce_loss 0.954, lat_loss 22.140
09/21 11:45:09 AM | Train: [ 34/180] Step 400/1249 Loss 3.151 Prec@(1,3) (75.7%, 98.3%), ce_loss 0.954, lat_loss 22.140
09/21 11:45:34 AM | Train: [ 34/180] Step 450/1249 Loss 3.155 Prec@(1,3) (75.8%, 98.3%), ce_loss 0.954, lat_loss 22.140
09/21 11:45:58 AM | Train: [ 34/180] Step 500/1249 Loss 3.150 Prec@(1,3) (75.8%, 98.3%), ce_loss 0.953, lat_loss 22.140
09/21 11:46:22 AM | Train: [ 34/180] Step 550/1249 Loss 3.175 Prec@(1,3) (75.8%, 98.2%), ce_loss 0.953, lat_loss 22.139
09/21 11:46:45 AM | Train: [ 34/180] Step 600/1249 Loss 3.198 Prec@(1,3) (75.6%, 98.2%), ce_loss 0.953, lat_loss 22.139
09/21 11:47:09 AM | Train: [ 34/180] Step 650/1249 Loss 3.199 Prec@(1,3) (75.6%, 98.2%), ce_loss 0.953, lat_loss 22.139
09/21 11:47:34 AM | Train: [ 34/180] Step 700/1249 Loss 3.199 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.953, lat_loss 22.139
09/21 11:47:58 AM | Train: [ 34/180] Step 750/1249 Loss 3.204 Prec@(1,3) (75.6%, 98.2%), ce_loss 0.953, lat_loss 22.139
09/21 11:48:23 AM | Train: [ 34/180] Step 800/1249 Loss 3.205 Prec@(1,3) (75.6%, 98.2%), ce_loss 0.952, lat_loss 22.139
09/21 11:48:47 AM | Train: [ 34/180] Step 850/1249 Loss 3.207 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.952, lat_loss 22.139
09/21 11:49:11 AM | Train: [ 34/180] Step 900/1249 Loss 3.216 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.952, lat_loss 22.139
09/21 11:49:36 AM | Train: [ 34/180] Step 950/1249 Loss 3.211 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.952, lat_loss 22.138
09/21 11:50:00 AM | Train: [ 34/180] Step 1000/1249 Loss 3.213 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.952, lat_loss 22.138
09/21 11:50:25 AM | Train: [ 34/180] Step 1050/1249 Loss 3.208 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.951, lat_loss 22.138
09/21 11:50:49 AM | Train: [ 34/180] Step 1100/1249 Loss 3.202 Prec@(1,3) (75.6%, 98.2%), ce_loss 0.951, lat_loss 22.138
09/21 11:51:13 AM | Train: [ 34/180] Step 1150/1249 Loss 3.211 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.951, lat_loss 22.138
09/21 11:51:36 AM | Train: [ 34/180] Step 1200/1249 Loss 3.214 Prec@(1,3) (75.5%, 98.1%), ce_loss 0.951, lat_loss 22.138
09/21 11:52:00 AM | Train: [ 34/180] Step 1249/1249 Loss 3.211 Prec@(1,3) (75.4%, 98.2%), ce_loss 0.951, lat_loss 22.138
09/21 11:52:00 AM | _w_step_train: [ 34/180] Final Prec@1 75.4300% Time 602.67
09/21 11:52:00 AM | Start to train theta for epoch 33
09/21 11:52:20 AM | Train: [ 34/180] Step 050/312 Loss 3.444 Prec@(1,3) (74.4%, 97.5%), ce_loss 0.950, lat_loss 22.138
09/21 11:52:39 AM | Train: [ 34/180] Step 100/312 Loss 3.412 Prec@(1,3) (73.9%, 97.6%), ce_loss 0.950, lat_loss 22.138
09/21 11:52:59 AM | Train: [ 34/180] Step 150/312 Loss 3.461 Prec@(1,3) (74.0%, 97.6%), ce_loss 0.950, lat_loss 22.137
09/21 11:53:17 AM | Train: [ 34/180] Step 200/312 Loss 3.416 Prec@(1,3) (74.4%, 97.7%), ce_loss 0.950, lat_loss 22.137
09/21 11:53:37 AM | Train: [ 34/180] Step 250/312 Loss 3.404 Prec@(1,3) (74.3%, 97.8%), ce_loss 0.950, lat_loss 22.137
09/21 11:53:57 AM | Train: [ 34/180] Step 300/312 Loss 3.393 Prec@(1,3) (74.3%, 97.8%), ce_loss 0.950, lat_loss 22.137
09/21 11:54:02 AM | Train: [ 34/180] Step 312/312 Loss 3.406 Prec@(1,3) (74.1%, 97.9%), ce_loss 0.950, lat_loss 22.137
09/21 11:54:03 AM | _theta_step_train: [ 34/180] Final Prec@1 74.1400% Time 122.67
09/21 11:54:08 AM | Valid: [ 34/180] Step 050/312 Loss 3.898 Prec@(1,3) (69.8%, 98.0%), ce_loss 0.950, lat_loss 22.137
09/21 11:54:12 AM | Valid: [ 34/180] Step 100/312 Loss 4.146 Prec@(1,3) (70.1%, 97.6%), ce_loss 0.950, lat_loss 22.137
09/21 11:54:17 AM | Valid: [ 34/180] Step 150/312 Loss 4.137 Prec@(1,3) (70.2%, 97.7%), ce_loss 0.950, lat_loss 22.137
09/21 11:54:22 AM | Valid: [ 34/180] Step 200/312 Loss 4.097 Prec@(1,3) (70.1%, 97.6%), ce_loss 0.950, lat_loss 22.137
09/21 11:54:26 AM | Valid: [ 34/180] Step 250/312 Loss 4.218 Prec@(1,3) (69.9%, 97.6%), ce_loss 0.950, lat_loss 22.137
09/21 11:54:31 AM | Valid: [ 34/180] Step 300/312 Loss 4.237 Prec@(1,3) (69.8%, 97.5%), ce_loss 0.950, lat_loss 22.136
09/21 11:54:32 AM | Valid: [ 34/180] Step 312/312 Loss 4.230 Prec@(1,3) (69.7%, 97.6%), ce_loss 0.950, lat_loss 22.136
09/21 11:54:32 AM | val: [ 34/180] Final Prec@1 69.7400% Time 29.69
09/21 11:54:32 AM | Start to train weights for epoch 34
09/21 11:54:55 AM | Train: [ 35/180] Step 050/1249 Loss 3.299 Prec@(1,3) (76.0%, 97.7%), ce_loss 0.950, lat_loss 22.136
09/21 11:55:16 AM | Train: [ 35/180] Step 100/1249 Loss 3.372 Prec@(1,3) (74.8%, 97.7%), ce_loss 0.949, lat_loss 22.136
09/21 11:55:38 AM | Train: [ 35/180] Step 150/1249 Loss 3.305 Prec@(1,3) (75.3%, 98.1%), ce_loss 0.949, lat_loss 22.136
09/21 11:56:03 AM | Train: [ 35/180] Step 200/1249 Loss 3.223 Prec@(1,3) (75.6%, 98.1%), ce_loss 0.949, lat_loss 22.136
09/21 11:56:29 AM | Train: [ 35/180] Step 250/1249 Loss 3.293 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.949, lat_loss 22.136
09/21 11:56:54 AM | Train: [ 35/180] Step 300/1249 Loss 3.253 Prec@(1,3) (75.2%, 98.2%), ce_loss 0.949, lat_loss 22.136
09/21 11:57:19 AM | Train: [ 35/180] Step 350/1249 Loss 3.290 Prec@(1,3) (75.0%, 98.2%), ce_loss 0.948, lat_loss 22.136
09/21 11:57:44 AM | Train: [ 35/180] Step 400/1249 Loss 3.259 Prec@(1,3) (75.4%, 98.2%), ce_loss 0.948, lat_loss 22.136
09/21 11:58:09 AM | Train: [ 35/180] Step 450/1249 Loss 3.268 Prec@(1,3) (75.3%, 98.2%), ce_loss 0.948, lat_loss 22.136
09/21 11:58:34 AM | Train: [ 35/180] Step 500/1249 Loss 3.280 Prec@(1,3) (75.1%, 98.2%), ce_loss 0.948, lat_loss 22.135
09/21 11:59:00 AM | Train: [ 35/180] Step 550/1249 Loss 3.295 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.948, lat_loss 22.135
09/21 11:59:25 AM | Train: [ 35/180] Step 600/1249 Loss 3.292 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.948, lat_loss 22.135
09/21 11:59:50 AM | Train: [ 35/180] Step 650/1249 Loss 3.290 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.947, lat_loss 22.135
09/21 12:00:15 PM | Train: [ 35/180] Step 700/1249 Loss 3.271 Prec@(1,3) (75.1%, 98.1%), ce_loss 0.947, lat_loss 22.135
09/21 12:00:40 PM | Train: [ 35/180] Step 750/1249 Loss 3.276 Prec@(1,3) (75.1%, 98.1%), ce_loss 0.947, lat_loss 22.135
09/21 12:01:05 PM | Train: [ 35/180] Step 800/1249 Loss 3.270 Prec@(1,3) (75.1%, 98.1%), ce_loss 0.947, lat_loss 22.135
09/21 12:01:30 PM | Train: [ 35/180] Step 850/1249 Loss 3.263 Prec@(1,3) (75.1%, 98.1%), ce_loss 0.947, lat_loss 22.135
09/21 12:01:55 PM | Train: [ 35/180] Step 900/1249 Loss 3.249 Prec@(1,3) (75.2%, 98.1%), ce_loss 0.946, lat_loss 22.135
09/21 12:02:20 PM | Train: [ 35/180] Step 950/1249 Loss 3.240 Prec@(1,3) (75.3%, 98.1%), ce_loss 0.946, lat_loss 22.134
09/21 12:02:44 PM | Train: [ 35/180] Step 1000/1249 Loss 3.226 Prec@(1,3) (75.5%, 98.1%), ce_loss 0.946, lat_loss 22.134
09/21 12:03:09 PM | Train: [ 35/180] Step 1050/1249 Loss 3.232 Prec@(1,3) (75.5%, 98.1%), ce_loss 0.946, lat_loss 22.134
09/21 12:03:35 PM | Train: [ 35/180] Step 1100/1249 Loss 3.229 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.946, lat_loss 22.134
09/21 12:04:00 PM | Train: [ 35/180] Step 1150/1249 Loss 3.220 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.945, lat_loss 22.134
09/21 12:04:25 PM | Train: [ 35/180] Step 1200/1249 Loss 3.214 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.945, lat_loss 22.134
09/21 12:04:49 PM | Train: [ 35/180] Step 1249/1249 Loss 3.216 Prec@(1,3) (75.4%, 98.2%), ce_loss 0.945, lat_loss 22.134
09/21 12:04:49 PM | _w_step_train: [ 35/180] Final Prec@1 75.4425% Time 616.96
09/21 12:04:49 PM | Start to train theta for epoch 34
09/21 12:05:02 PM | Train: [ 35/180] Step 050/312 Loss 3.338 Prec@(1,3) (75.2%, 97.7%), ce_loss 0.945, lat_loss 22.134
09/21 12:05:15 PM | Train: [ 35/180] Step 100/312 Loss 3.358 Prec@(1,3) (75.0%, 97.6%), ce_loss 0.945, lat_loss 22.134
09/21 12:05:27 PM | Train: [ 35/180] Step 150/312 Loss 3.297 Prec@(1,3) (74.9%, 97.8%), ce_loss 0.945, lat_loss 22.134
09/21 12:05:41 PM | Train: [ 35/180] Step 200/312 Loss 3.265 Prec@(1,3) (75.1%, 97.9%), ce_loss 0.944, lat_loss 22.133
09/21 12:05:53 PM | Train: [ 35/180] Step 250/312 Loss 3.250 Prec@(1,3) (75.2%, 98.0%), ce_loss 0.944, lat_loss 22.133
09/21 12:06:05 PM | Train: [ 35/180] Step 300/312 Loss 3.230 Prec@(1,3) (75.2%, 98.0%), ce_loss 0.944, lat_loss 22.133
09/21 12:06:08 PM | Train: [ 35/180] Step 312/312 Loss 3.228 Prec@(1,3) (75.2%, 98.0%), ce_loss 0.944, lat_loss 22.133
09/21 12:06:08 PM | _theta_step_train: [ 35/180] Final Prec@1 75.2100% Time 79.06
09/21 12:06:13 PM | Valid: [ 35/180] Step 050/312 Loss 3.898 Prec@(1,3) (70.3%, 97.4%), ce_loss 0.944, lat_loss 22.133
09/21 12:06:17 PM | Valid: [ 35/180] Step 100/312 Loss 3.935 Prec@(1,3) (70.1%, 97.4%), ce_loss 0.944, lat_loss 22.133
09/21 12:06:22 PM | Valid: [ 35/180] Step 150/312 Loss 4.073 Prec@(1,3) (69.1%, 97.2%), ce_loss 0.944, lat_loss 22.133
09/21 12:06:26 PM | Valid: [ 35/180] Step 200/312 Loss 4.149 Prec@(1,3) (68.7%, 96.9%), ce_loss 0.944, lat_loss 22.133
09/21 12:06:30 PM | Valid: [ 35/180] Step 250/312 Loss 4.125 Prec@(1,3) (68.6%, 97.0%), ce_loss 0.944, lat_loss 22.133
09/21 12:06:34 PM | Valid: [ 35/180] Step 300/312 Loss 4.110 Prec@(1,3) (68.8%, 97.0%), ce_loss 0.944, lat_loss 22.133
09/21 12:06:35 PM | Valid: [ 35/180] Step 312/312 Loss 4.099 Prec@(1,3) (68.8%, 97.1%), ce_loss 0.944, lat_loss 22.133
09/21 12:06:35 PM | val: [ 35/180] Final Prec@1 68.8200% Time 27.12
09/21 12:06:35 PM | Start to train weights for epoch 35
09/21 12:07:00 PM | Train: [ 36/180] Step 050/1249 Loss 3.083 Prec@(1,3) (76.9%, 98.0%), ce_loss 0.944, lat_loss 22.133
09/21 12:07:23 PM | Train: [ 36/180] Step 100/1249 Loss 3.129 Prec@(1,3) (76.6%, 98.2%), ce_loss 0.943, lat_loss 22.132
09/21 12:07:46 PM | Train: [ 36/180] Step 150/1249 Loss 3.079 Prec@(1,3) (76.8%, 98.3%), ce_loss 0.943, lat_loss 22.132
09/21 12:08:10 PM | Train: [ 36/180] Step 200/1249 Loss 3.105 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.943, lat_loss 22.132
09/21 12:08:33 PM | Train: [ 36/180] Step 250/1249 Loss 3.102 Prec@(1,3) (76.4%, 98.3%), ce_loss 0.943, lat_loss 22.132
09/21 12:08:56 PM | Train: [ 36/180] Step 300/1249 Loss 3.126 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.943, lat_loss 22.132
09/21 12:09:20 PM | Train: [ 36/180] Step 350/1249 Loss 3.103 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.942, lat_loss 22.132
09/21 12:09:43 PM | Train: [ 36/180] Step 400/1249 Loss 3.093 Prec@(1,3) (76.3%, 98.4%), ce_loss 0.942, lat_loss 22.132
09/21 12:10:06 PM | Train: [ 36/180] Step 450/1249 Loss 3.107 Prec@(1,3) (76.2%, 98.4%), ce_loss 0.942, lat_loss 22.132
09/21 12:10:30 PM | Train: [ 36/180] Step 500/1249 Loss 3.088 Prec@(1,3) (76.4%, 98.4%), ce_loss 0.942, lat_loss 22.132
09/21 12:10:54 PM | Train: [ 36/180] Step 550/1249 Loss 3.088 Prec@(1,3) (76.3%, 98.4%), ce_loss 0.942, lat_loss 22.132
09/21 12:11:17 PM | Train: [ 36/180] Step 600/1249 Loss 3.081 Prec@(1,3) (76.4%, 98.4%), ce_loss 0.941, lat_loss 22.132
09/21 12:11:40 PM | Train: [ 36/180] Step 650/1249 Loss 3.093 Prec@(1,3) (76.3%, 98.4%), ce_loss 0.941, lat_loss 22.131
09/21 12:12:03 PM | Train: [ 36/180] Step 700/1249 Loss 3.115 Prec@(1,3) (76.3%, 98.3%), ce_loss 0.941, lat_loss 22.131
09/21 12:12:25 PM | Train: [ 36/180] Step 750/1249 Loss 3.139 Prec@(1,3) (76.1%, 98.3%), ce_loss 0.941, lat_loss 22.131
09/21 12:12:49 PM | Train: [ 36/180] Step 800/1249 Loss 3.127 Prec@(1,3) (76.1%, 98.3%), ce_loss 0.941, lat_loss 22.131
09/21 12:13:12 PM | Train: [ 36/180] Step 850/1249 Loss 3.138 Prec@(1,3) (76.1%, 98.3%), ce_loss 0.941, lat_loss 22.131
09/21 12:13:35 PM | Train: [ 36/180] Step 900/1249 Loss 3.156 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.940, lat_loss 22.131
09/21 12:13:59 PM | Train: [ 36/180] Step 950/1249 Loss 3.162 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.940, lat_loss 22.131
09/21 12:14:21 PM | Train: [ 36/180] Step 1000/1249 Loss 3.153 Prec@(1,3) (76.0%, 98.2%), ce_loss 0.940, lat_loss 22.131
09/21 12:14:44 PM | Train: [ 36/180] Step 1050/1249 Loss 3.153 Prec@(1,3) (76.0%, 98.2%), ce_loss 0.940, lat_loss 22.131
09/21 12:15:08 PM | Train: [ 36/180] Step 1100/1249 Loss 3.144 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.940, lat_loss 22.131
09/21 12:15:31 PM | Train: [ 36/180] Step 1150/1249 Loss 3.143 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.939, lat_loss 22.130
09/21 12:15:54 PM | Train: [ 36/180] Step 1200/1249 Loss 3.145 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.939, lat_loss 22.130
09/21 12:16:19 PM | Train: [ 36/180] Step 1249/1249 Loss 3.142 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.939, lat_loss 22.130
09/21 12:16:19 PM | _w_step_train: [ 36/180] Final Prec@1 76.0750% Time 583.51
09/21 12:16:19 PM | Start to train theta for epoch 35
09/21 12:16:39 PM | Train: [ 36/180] Step 050/312 Loss 3.267 Prec@(1,3) (74.9%, 97.7%), ce_loss 0.939, lat_loss 22.130
09/21 12:16:59 PM | Train: [ 36/180] Step 100/312 Loss 3.316 Prec@(1,3) (74.1%, 97.8%), ce_loss 0.939, lat_loss 22.130
09/21 12:17:19 PM | Train: [ 36/180] Step 150/312 Loss 3.319 Prec@(1,3) (74.2%, 98.0%), ce_loss 0.939, lat_loss 22.130
09/21 12:17:39 PM | Train: [ 36/180] Step 200/312 Loss 3.251 Prec@(1,3) (74.6%, 98.0%), ce_loss 0.938, lat_loss 22.130
09/21 12:17:59 PM | Train: [ 36/180] Step 250/312 Loss 3.253 Prec@(1,3) (74.8%, 97.9%), ce_loss 0.938, lat_loss 22.130
09/21 12:18:19 PM | Train: [ 36/180] Step 300/312 Loss 3.209 Prec@(1,3) (75.2%, 97.9%), ce_loss 0.938, lat_loss 22.130
09/21 12:18:24 PM | Train: [ 36/180] Step 312/312 Loss 3.198 Prec@(1,3) (75.4%, 97.9%), ce_loss 0.938, lat_loss 22.130
09/21 12:18:24 PM | _theta_step_train: [ 36/180] Final Prec@1 75.4400% Time 125.49
09/21 12:18:30 PM | Valid: [ 36/180] Step 050/312 Loss 3.709 Prec@(1,3) (72.7%, 97.4%), ce_loss 0.938, lat_loss 22.130
09/21 12:18:34 PM | Valid: [ 36/180] Step 100/312 Loss 4.010 Prec@(1,3) (71.2%, 97.3%), ce_loss 0.938, lat_loss 22.130
09/21 12:18:39 PM | Valid: [ 36/180] Step 150/312 Loss 3.999 Prec@(1,3) (70.7%, 97.1%), ce_loss 0.938, lat_loss 22.130
09/21 12:18:44 PM | Valid: [ 36/180] Step 200/312 Loss 4.034 Prec@(1,3) (70.6%, 96.9%), ce_loss 0.938, lat_loss 22.129
09/21 12:18:48 PM | Valid: [ 36/180] Step 250/312 Loss 4.104 Prec@(1,3) (70.1%, 96.8%), ce_loss 0.938, lat_loss 22.129
09/21 12:18:53 PM | Valid: [ 36/180] Step 300/312 Loss 4.055 Prec@(1,3) (70.4%, 96.9%), ce_loss 0.938, lat_loss 22.129
09/21 12:18:54 PM | Valid: [ 36/180] Step 312/312 Loss 4.057 Prec@(1,3) (70.3%, 96.9%), ce_loss 0.938, lat_loss 22.129
09/21 12:18:54 PM | val: [ 36/180] Final Prec@1 70.3200% Time 29.68
09/21 12:18:54 PM | Start to train weights for epoch 36
09/21 12:19:20 PM | Train: [ 37/180] Step 050/1249 Loss 2.891 Prec@(1,3) (78.9%, 98.3%), ce_loss 0.938, lat_loss 22.129
09/21 12:19:45 PM | Train: [ 37/180] Step 100/1249 Loss 2.972 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.937, lat_loss 22.129
09/21 12:20:10 PM | Train: [ 37/180] Step 150/1249 Loss 3.049 Prec@(1,3) (76.4%, 98.4%), ce_loss 0.937, lat_loss 22.129
09/21 12:20:35 PM | Train: [ 37/180] Step 200/1249 Loss 3.087 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.937, lat_loss 22.129
09/21 12:21:00 PM | Train: [ 37/180] Step 250/1249 Loss 3.052 Prec@(1,3) (76.4%, 98.4%), ce_loss 0.937, lat_loss 22.129
09/21 12:21:25 PM | Train: [ 37/180] Step 300/1249 Loss 3.091 Prec@(1,3) (76.3%, 98.3%), ce_loss 0.937, lat_loss 22.129
09/21 12:21:51 PM | Train: [ 37/180] Step 350/1249 Loss 3.076 Prec@(1,3) (76.4%, 98.3%), ce_loss 0.937, lat_loss 22.129
09/21 12:22:16 PM | Train: [ 37/180] Step 400/1249 Loss 3.051 Prec@(1,3) (76.6%, 98.4%), ce_loss 0.936, lat_loss 22.129
09/21 12:22:41 PM | Train: [ 37/180] Step 450/1249 Loss 3.058 Prec@(1,3) (76.6%, 98.3%), ce_loss 0.936, lat_loss 22.129
09/21 12:23:06 PM | Train: [ 37/180] Step 500/1249 Loss 3.062 Prec@(1,3) (76.5%, 98.3%), ce_loss 0.936, lat_loss 22.128
09/21 12:23:31 PM | Train: [ 37/180] Step 550/1249 Loss 3.079 Prec@(1,3) (76.4%, 98.3%), ce_loss 0.936, lat_loss 22.128
09/21 12:23:56 PM | Train: [ 37/180] Step 600/1249 Loss 3.088 Prec@(1,3) (76.3%, 98.3%), ce_loss 0.936, lat_loss 22.128
09/21 12:24:21 PM | Train: [ 37/180] Step 650/1249 Loss 3.085 Prec@(1,3) (76.3%, 98.3%), ce_loss 0.935, lat_loss 22.128
09/21 12:24:45 PM | Train: [ 37/180] Step 700/1249 Loss 3.099 Prec@(1,3) (76.3%, 98.3%), ce_loss 0.935, lat_loss 22.128
09/21 12:25:09 PM | Train: [ 37/180] Step 750/1249 Loss 3.095 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.935, lat_loss 22.128
09/21 12:25:34 PM | Train: [ 37/180] Step 800/1249 Loss 3.105 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.935, lat_loss 22.128
09/21 12:25:59 PM | Train: [ 37/180] Step 850/1249 Loss 3.099 Prec@(1,3) (76.3%, 98.3%), ce_loss 0.935, lat_loss 22.128
09/21 12:26:24 PM | Train: [ 37/180] Step 900/1249 Loss 3.110 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.935, lat_loss 22.128
09/21 12:26:47 PM | Train: [ 37/180] Step 950/1249 Loss 3.120 Prec@(1,3) (76.0%, 98.3%), ce_loss 0.934, lat_loss 22.128
09/21 12:27:09 PM | Train: [ 37/180] Step 1000/1249 Loss 3.127 Prec@(1,3) (76.0%, 98.2%), ce_loss 0.934, lat_loss 22.128
09/21 12:27:32 PM | Train: [ 37/180] Step 1050/1249 Loss 3.122 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.934, lat_loss 22.128
09/21 12:27:57 PM | Train: [ 37/180] Step 1100/1249 Loss 3.118 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.934, lat_loss 22.128
09/21 12:28:20 PM | Train: [ 37/180] Step 1150/1249 Loss 3.113 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.934, lat_loss 22.127
09/21 12:28:44 PM | Train: [ 37/180] Step 1200/1249 Loss 3.122 Prec@(1,3) (76.0%, 98.3%), ce_loss 0.933, lat_loss 22.127
09/21 12:29:09 PM | Train: [ 37/180] Step 1249/1249 Loss 3.120 Prec@(1,3) (76.1%, 98.3%), ce_loss 0.933, lat_loss 22.127
09/21 12:29:09 PM | _w_step_train: [ 37/180] Final Prec@1 76.1025% Time 614.53
09/21 12:29:09 PM | Start to train theta for epoch 36
09/21 12:29:30 PM | Train: [ 37/180] Step 050/312 Loss 3.036 Prec@(1,3) (77.0%, 98.2%), ce_loss 0.933, lat_loss 22.127
09/21 12:29:52 PM | Train: [ 37/180] Step 100/312 Loss 3.110 Prec@(1,3) (76.4%, 97.9%), ce_loss 0.933, lat_loss 22.127
09/21 12:30:14 PM | Train: [ 37/180] Step 150/312 Loss 3.195 Prec@(1,3) (75.4%, 98.0%), ce_loss 0.933, lat_loss 22.127
09/21 12:30:36 PM | Train: [ 37/180] Step 200/312 Loss 3.178 Prec@(1,3) (75.5%, 98.0%), ce_loss 0.933, lat_loss 22.127
09/21 12:30:58 PM | Train: [ 37/180] Step 250/312 Loss 3.175 Prec@(1,3) (75.9%, 98.0%), ce_loss 0.932, lat_loss 22.127
09/21 12:31:20 PM | Train: [ 37/180] Step 300/312 Loss 3.205 Prec@(1,3) (75.6%, 98.0%), ce_loss 0.932, lat_loss 22.127
09/21 12:31:25 PM | Train: [ 37/180] Step 312/312 Loss 3.215 Prec@(1,3) (75.4%, 98.0%), ce_loss 0.932, lat_loss 22.127
09/21 12:31:25 PM | _theta_step_train: [ 37/180] Final Prec@1 75.4200% Time 136.20
09/21 12:31:30 PM | Valid: [ 37/180] Step 050/312 Loss 4.145 Prec@(1,3) (70.4%, 97.0%), ce_loss 0.932, lat_loss 22.127
09/21 12:31:35 PM | Valid: [ 37/180] Step 100/312 Loss 4.077 Prec@(1,3) (71.2%, 97.0%), ce_loss 0.932, lat_loss 22.127
09/21 12:31:40 PM | Valid: [ 37/180] Step 150/312 Loss 3.987 Prec@(1,3) (71.1%, 97.1%), ce_loss 0.932, lat_loss 22.127
09/21 12:31:44 PM | Valid: [ 37/180] Step 200/312 Loss 3.998 Prec@(1,3) (70.8%, 97.0%), ce_loss 0.932, lat_loss 22.126
09/21 12:31:49 PM | Valid: [ 37/180] Step 250/312 Loss 3.965 Prec@(1,3) (71.1%, 97.2%), ce_loss 0.932, lat_loss 22.126
09/21 12:31:54 PM | Valid: [ 37/180] Step 300/312 Loss 3.871 Prec@(1,3) (71.5%, 97.4%), ce_loss 0.932, lat_loss 22.126
09/21 12:31:55 PM | Valid: [ 37/180] Step 312/312 Loss 3.875 Prec@(1,3) (71.4%, 97.4%), ce_loss 0.932, lat_loss 22.126
09/21 12:31:55 PM | val: [ 37/180] Final Prec@1 71.4100% Time 29.94
09/21 12:31:55 PM | Start to train weights for epoch 37
09/21 12:32:21 PM | Train: [ 38/180] Step 050/1249 Loss 3.107 Prec@(1,3) (76.2%, 98.4%), ce_loss 0.932, lat_loss 22.126
09/21 12:32:46 PM | Train: [ 38/180] Step 100/1249 Loss 3.041 Prec@(1,3) (77.0%, 98.4%), ce_loss 0.932, lat_loss 22.126
09/21 12:33:11 PM | Train: [ 38/180] Step 150/1249 Loss 3.063 Prec@(1,3) (77.0%, 98.4%), ce_loss 0.931, lat_loss 22.126
09/21 12:33:36 PM | Train: [ 38/180] Step 200/1249 Loss 3.130 Prec@(1,3) (76.4%, 98.3%), ce_loss 0.931, lat_loss 22.126
09/21 12:34:00 PM | Train: [ 38/180] Step 250/1249 Loss 3.181 Prec@(1,3) (76.3%, 98.2%), ce_loss 0.931, lat_loss 22.126
09/21 12:34:25 PM | Train: [ 38/180] Step 300/1249 Loss 3.184 Prec@(1,3) (76.3%, 98.1%), ce_loss 0.931, lat_loss 22.126
09/21 12:34:49 PM | Train: [ 38/180] Step 350/1249 Loss 3.139 Prec@(1,3) (76.6%, 98.2%), ce_loss 0.931, lat_loss 22.126
09/21 12:35:14 PM | Train: [ 38/180] Step 400/1249 Loss 3.136 Prec@(1,3) (76.6%, 98.2%), ce_loss 0.931, lat_loss 22.126
09/21 12:35:39 PM | Train: [ 38/180] Step 450/1249 Loss 3.137 Prec@(1,3) (76.5%, 98.2%), ce_loss 0.930, lat_loss 22.126
09/21 12:36:04 PM | Train: [ 38/180] Step 500/1249 Loss 3.128 Prec@(1,3) (76.6%, 98.2%), ce_loss 0.930, lat_loss 22.125
09/21 12:36:29 PM | Train: [ 38/180] Step 550/1249 Loss 3.127 Prec@(1,3) (76.5%, 98.2%), ce_loss 0.930, lat_loss 22.125
09/21 12:36:54 PM | Train: [ 38/180] Step 600/1249 Loss 3.105 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.930, lat_loss 22.125
09/21 12:37:19 PM | Train: [ 38/180] Step 650/1249 Loss 3.099 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.930, lat_loss 22.125
09/21 12:37:43 PM | Train: [ 38/180] Step 700/1249 Loss 3.092 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.930, lat_loss 22.125
09/21 12:38:08 PM | Train: [ 38/180] Step 750/1249 Loss 3.097 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.929, lat_loss 22.125
09/21 12:38:32 PM | Train: [ 38/180] Step 800/1249 Loss 3.102 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.929, lat_loss 22.125
09/21 12:38:57 PM | Train: [ 38/180] Step 850/1249 Loss 3.107 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.929, lat_loss 22.125
09/21 12:39:22 PM | Train: [ 38/180] Step 900/1249 Loss 3.101 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.929, lat_loss 22.125
09/21 12:39:47 PM | Train: [ 38/180] Step 950/1249 Loss 3.103 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.929, lat_loss 22.125
09/21 12:40:13 PM | Train: [ 38/180] Step 1000/1249 Loss 3.106 Prec@(1,3) (76.6%, 98.2%), ce_loss 0.928, lat_loss 22.125
09/21 12:40:39 PM | Train: [ 38/180] Step 1050/1249 Loss 3.109 Prec@(1,3) (76.6%, 98.2%), ce_loss 0.928, lat_loss 22.125
09/21 12:41:06 PM | Train: [ 38/180] Step 1100/1249 Loss 3.112 Prec@(1,3) (76.6%, 98.2%), ce_loss 0.928, lat_loss 22.125
09/21 12:41:33 PM | Train: [ 38/180] Step 1150/1249 Loss 3.111 Prec@(1,3) (76.6%, 98.2%), ce_loss 0.928, lat_loss 22.124
09/21 12:41:59 PM | Train: [ 38/180] Step 1200/1249 Loss 3.119 Prec@(1,3) (76.5%, 98.2%), ce_loss 0.928, lat_loss 22.124
09/21 12:42:23 PM | Train: [ 38/180] Step 1249/1249 Loss 3.122 Prec@(1,3) (76.4%, 98.2%), ce_loss 0.928, lat_loss 22.124
09/21 12:42:23 PM | _w_step_train: [ 38/180] Final Prec@1 76.4450% Time 628.60
09/21 12:42:23 PM | Start to train theta for epoch 37
09/21 12:42:43 PM | Train: [ 38/180] Step 050/312 Loss 3.205 Prec@(1,3) (75.2%, 98.0%), ce_loss 0.928, lat_loss 22.124
09/21 12:42:59 PM | Train: [ 38/180] Step 100/312 Loss 3.154 Prec@(1,3) (76.0%, 97.9%), ce_loss 0.927, lat_loss 22.124
09/21 12:43:17 PM | Train: [ 38/180] Step 150/312 Loss 3.154 Prec@(1,3) (75.8%, 98.0%), ce_loss 0.927, lat_loss 22.124
09/21 12:43:33 PM | Train: [ 38/180] Step 200/312 Loss 3.137 Prec@(1,3) (76.0%, 97.9%), ce_loss 0.927, lat_loss 22.124
09/21 12:43:50 PM | Train: [ 38/180] Step 250/312 Loss 3.140 Prec@(1,3) (76.1%, 97.9%), ce_loss 0.927, lat_loss 22.124
09/21 12:44:09 PM | Train: [ 38/180] Step 300/312 Loss 3.110 Prec@(1,3) (76.2%, 98.0%), ce_loss 0.927, lat_loss 22.124
09/21 12:44:14 PM | Train: [ 38/180] Step 312/312 Loss 3.128 Prec@(1,3) (76.2%, 98.0%), ce_loss 0.927, lat_loss 22.124
09/21 12:44:14 PM | _theta_step_train: [ 38/180] Final Prec@1 76.1700% Time 110.36
09/21 12:44:19 PM | Valid: [ 38/180] Step 050/312 Loss 3.377 Prec@(1,3) (73.9%, 98.4%), ce_loss 0.927, lat_loss 22.124
09/21 12:44:24 PM | Valid: [ 38/180] Step 100/312 Loss 3.582 Prec@(1,3) (72.6%, 97.5%), ce_loss 0.926, lat_loss 22.124
09/21 12:44:29 PM | Valid: [ 38/180] Step 150/312 Loss 3.691 Prec@(1,3) (72.6%, 97.1%), ce_loss 0.926, lat_loss 22.124
09/21 12:44:33 PM | Valid: [ 38/180] Step 200/312 Loss 3.682 Prec@(1,3) (72.8%, 97.2%), ce_loss 0.926, lat_loss 22.123
09/21 12:44:38 PM | Valid: [ 38/180] Step 250/312 Loss 3.752 Prec@(1,3) (72.4%, 97.1%), ce_loss 0.926, lat_loss 22.123
09/21 12:44:43 PM | Valid: [ 38/180] Step 300/312 Loss 3.793 Prec@(1,3) (72.0%, 97.1%), ce_loss 0.926, lat_loss 22.123
09/21 12:44:44 PM | Valid: [ 38/180] Step 312/312 Loss 3.781 Prec@(1,3) (72.1%, 97.1%), ce_loss 0.926, lat_loss 22.123
09/21 12:44:44 PM | val: [ 38/180] Final Prec@1 72.1000% Time 29.96
09/21 12:44:44 PM | Start to train weights for epoch 38
09/21 12:45:08 PM | Train: [ 39/180] Step 050/1249 Loss 3.138 Prec@(1,3) (76.6%, 98.2%), ce_loss 0.926, lat_loss 22.123
09/21 12:45:31 PM | Train: [ 39/180] Step 100/1249 Loss 3.126 Prec@(1,3) (76.5%, 98.3%), ce_loss 0.926, lat_loss 22.123
09/21 12:45:54 PM | Train: [ 39/180] Step 150/1249 Loss 3.165 Prec@(1,3) (76.2%, 98.2%), ce_loss 0.926, lat_loss 22.123
09/21 12:46:15 PM | Train: [ 39/180] Step 200/1249 Loss 3.131 Prec@(1,3) (76.2%, 98.2%), ce_loss 0.926, lat_loss 22.123
09/21 12:46:38 PM | Train: [ 39/180] Step 250/1249 Loss 3.117 Prec@(1,3) (76.4%, 98.3%), ce_loss 0.925, lat_loss 22.123
09/21 12:47:00 PM | Train: [ 39/180] Step 300/1249 Loss 3.130 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.925, lat_loss 22.123
09/21 12:47:23 PM | Train: [ 39/180] Step 350/1249 Loss 3.115 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.925, lat_loss 22.123
09/21 12:47:45 PM | Train: [ 39/180] Step 400/1249 Loss 3.090 Prec@(1,3) (76.4%, 98.3%), ce_loss 0.925, lat_loss 22.122
09/21 12:48:07 PM | Train: [ 39/180] Step 450/1249 Loss 3.092 Prec@(1,3) (76.3%, 98.3%), ce_loss 0.925, lat_loss 22.122
09/21 12:48:29 PM | Train: [ 39/180] Step 500/1249 Loss 3.108 Prec@(1,3) (76.2%, 98.2%), ce_loss 0.925, lat_loss 22.122
09/21 12:48:52 PM | Train: [ 39/180] Step 550/1249 Loss 3.106 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.924, lat_loss 22.122
09/21 12:49:16 PM | Train: [ 39/180] Step 600/1249 Loss 3.132 Prec@(1,3) (76.0%, 98.2%), ce_loss 0.924, lat_loss 22.122
09/21 12:49:38 PM | Train: [ 39/180] Step 650/1249 Loss 3.121 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.924, lat_loss 22.122
09/21 12:50:01 PM | Train: [ 39/180] Step 700/1249 Loss 3.116 Prec@(1,3) (76.2%, 98.2%), ce_loss 0.924, lat_loss 22.122
09/21 12:50:23 PM | Train: [ 39/180] Step 750/1249 Loss 3.121 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.924, lat_loss 22.122
09/21 12:50:45 PM | Train: [ 39/180] Step 800/1249 Loss 3.131 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.924, lat_loss 22.122
09/21 12:51:06 PM | Train: [ 39/180] Step 850/1249 Loss 3.125 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.924, lat_loss 22.122
09/21 12:51:28 PM | Train: [ 39/180] Step 900/1249 Loss 3.126 Prec@(1,3) (76.2%, 98.2%), ce_loss 0.923, lat_loss 22.122
09/21 12:51:49 PM | Train: [ 39/180] Step 950/1249 Loss 3.124 Prec@(1,3) (76.2%, 98.2%), ce_loss 0.923, lat_loss 22.121
09/21 12:52:12 PM | Train: [ 39/180] Step 1000/1249 Loss 3.122 Prec@(1,3) (76.2%, 98.2%), ce_loss 0.923, lat_loss 22.121
09/21 12:52:34 PM | Train: [ 39/180] Step 1050/1249 Loss 3.128 Prec@(1,3) (76.2%, 98.2%), ce_loss 0.923, lat_loss 22.121
09/21 12:52:58 PM | Train: [ 39/180] Step 1100/1249 Loss 3.134 Prec@(1,3) (76.2%, 98.2%), ce_loss 0.923, lat_loss 22.121
09/21 12:53:21 PM | Train: [ 39/180] Step 1150/1249 Loss 3.134 Prec@(1,3) (76.2%, 98.2%), ce_loss 0.923, lat_loss 22.121
09/21 12:53:43 PM | Train: [ 39/180] Step 1200/1249 Loss 3.136 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.922, lat_loss 22.121
09/21 12:54:08 PM | Train: [ 39/180] Step 1249/1249 Loss 3.131 Prec@(1,3) (76.2%, 98.2%), ce_loss 0.922, lat_loss 22.121
09/21 12:54:08 PM | _w_step_train: [ 39/180] Final Prec@1 76.2175% Time 564.14
09/21 12:54:08 PM | Start to train theta for epoch 38
09/21 12:54:30 PM | Train: [ 39/180] Step 050/312 Loss 3.184 Prec@(1,3) (75.3%, 97.9%), ce_loss 0.922, lat_loss 22.121
09/21 12:54:51 PM | Train: [ 39/180] Step 100/312 Loss 3.125 Prec@(1,3) (76.2%, 98.1%), ce_loss 0.922, lat_loss 22.121
09/21 12:55:05 PM | Train: [ 39/180] Step 150/312 Loss 3.240 Prec@(1,3) (75.6%, 98.0%), ce_loss 0.922, lat_loss 22.121
09/21 12:55:18 PM | Train: [ 39/180] Step 200/312 Loss 3.239 Prec@(1,3) (75.7%, 98.0%), ce_loss 0.922, lat_loss 22.120
09/21 12:55:34 PM | Train: [ 39/180] Step 250/312 Loss 3.191 Prec@(1,3) (75.9%, 98.1%), ce_loss 0.922, lat_loss 22.120
09/21 12:55:54 PM | Train: [ 39/180] Step 300/312 Loss 3.165 Prec@(1,3) (76.0%, 98.1%), ce_loss 0.921, lat_loss 22.120
09/21 12:55:59 PM | Train: [ 39/180] Step 312/312 Loss 3.161 Prec@(1,3) (76.0%, 98.2%), ce_loss 0.921, lat_loss 22.120
09/21 12:56:00 PM | _theta_step_train: [ 39/180] Final Prec@1 75.9700% Time 111.89
09/21 12:56:05 PM | Valid: [ 39/180] Step 050/312 Loss 3.576 Prec@(1,3) (73.6%, 97.3%), ce_loss 0.921, lat_loss 22.120
09/21 12:56:10 PM | Valid: [ 39/180] Step 100/312 Loss 3.835 Prec@(1,3) (70.9%, 97.1%), ce_loss 0.921, lat_loss 22.120
09/21 12:56:14 PM | Valid: [ 39/180] Step 150/312 Loss 3.994 Prec@(1,3) (70.2%, 96.6%), ce_loss 0.921, lat_loss 22.120
09/21 12:56:19 PM | Valid: [ 39/180] Step 200/312 Loss 3.990 Prec@(1,3) (70.0%, 96.7%), ce_loss 0.921, lat_loss 22.120
09/21 12:56:24 PM | Valid: [ 39/180] Step 250/312 Loss 4.076 Prec@(1,3) (69.5%, 96.6%), ce_loss 0.921, lat_loss 22.120
09/21 12:56:29 PM | Valid: [ 39/180] Step 300/312 Loss 4.026 Prec@(1,3) (69.8%, 96.8%), ce_loss 0.921, lat_loss 22.120
09/21 12:56:30 PM | Valid: [ 39/180] Step 312/312 Loss 4.022 Prec@(1,3) (69.8%, 96.9%), ce_loss 0.921, lat_loss 22.120
09/21 12:56:30 PM | val: [ 39/180] Final Prec@1 69.8200% Time 30.40
09/21 12:56:30 PM | Start to train weights for epoch 39
09/21 12:56:57 PM | Train: [ 40/180] Step 050/1249 Loss 2.889 Prec@(1,3) (77.1%, 98.8%), ce_loss 0.921, lat_loss 22.119
09/21 12:57:22 PM | Train: [ 40/180] Step 100/1249 Loss 3.022 Prec@(1,3) (76.8%, 98.5%), ce_loss 0.921, lat_loss 22.119
09/21 12:57:47 PM | Train: [ 40/180] Step 150/1249 Loss 3.097 Prec@(1,3) (76.1%, 98.6%), ce_loss 0.921, lat_loss 22.119
09/21 12:58:10 PM | Train: [ 40/180] Step 200/1249 Loss 3.079 Prec@(1,3) (76.1%, 98.5%), ce_loss 0.921, lat_loss 22.119
09/21 12:58:34 PM | Train: [ 40/180] Step 250/1249 Loss 3.080 Prec@(1,3) (76.2%, 98.5%), ce_loss 0.920, lat_loss 22.119
09/21 12:58:58 PM | Train: [ 40/180] Step 300/1249 Loss 3.079 Prec@(1,3) (76.1%, 98.5%), ce_loss 0.920, lat_loss 22.119
09/21 12:59:22 PM | Train: [ 40/180] Step 350/1249 Loss 3.078 Prec@(1,3) (76.1%, 98.5%), ce_loss 0.920, lat_loss 22.119
09/21 12:59:47 PM | Train: [ 40/180] Step 400/1249 Loss 3.085 Prec@(1,3) (76.0%, 98.5%), ce_loss 0.920, lat_loss 22.119
09/21 01:00:09 PM | Train: [ 40/180] Step 450/1249 Loss 3.102 Prec@(1,3) (76.1%, 98.4%), ce_loss 0.920, lat_loss 22.119
09/21 01:00:33 PM | Train: [ 40/180] Step 500/1249 Loss 3.093 Prec@(1,3) (76.2%, 98.4%), ce_loss 0.920, lat_loss 22.119
09/21 01:00:57 PM | Train: [ 40/180] Step 550/1249 Loss 3.079 Prec@(1,3) (76.2%, 98.4%), ce_loss 0.919, lat_loss 22.118
09/21 01:01:21 PM | Train: [ 40/180] Step 600/1249 Loss 3.065 Prec@(1,3) (76.4%, 98.4%), ce_loss 0.919, lat_loss 22.118
09/21 01:01:44 PM | Train: [ 40/180] Step 650/1249 Loss 3.074 Prec@(1,3) (76.4%, 98.4%), ce_loss 0.919, lat_loss 22.118
09/21 01:02:08 PM | Train: [ 40/180] Step 700/1249 Loss 3.078 Prec@(1,3) (76.3%, 98.4%), ce_loss 0.919, lat_loss 22.118
09/21 01:02:31 PM | Train: [ 40/180] Step 750/1249 Loss 3.085 Prec@(1,3) (76.4%, 98.4%), ce_loss 0.919, lat_loss 22.118
09/21 01:02:55 PM | Train: [ 40/180] Step 800/1249 Loss 3.078 Prec@(1,3) (76.5%, 98.4%), ce_loss 0.919, lat_loss 22.118
09/21 01:03:19 PM | Train: [ 40/180] Step 850/1249 Loss 3.067 Prec@(1,3) (76.6%, 98.4%), ce_loss 0.918, lat_loss 22.118
09/21 01:03:44 PM | Train: [ 40/180] Step 900/1249 Loss 3.054 Prec@(1,3) (76.7%, 98.4%), ce_loss 0.918, lat_loss 22.118
09/21 01:04:09 PM | Train: [ 40/180] Step 950/1249 Loss 3.055 Prec@(1,3) (76.7%, 98.4%), ce_loss 0.918, lat_loss 22.118
09/21 01:04:34 PM | Train: [ 40/180] Step 1000/1249 Loss 3.064 Prec@(1,3) (76.6%, 98.4%), ce_loss 0.918, lat_loss 22.118
09/21 01:04:58 PM | Train: [ 40/180] Step 1050/1249 Loss 3.073 Prec@(1,3) (76.5%, 98.4%), ce_loss 0.918, lat_loss 22.117
09/21 01:05:23 PM | Train: [ 40/180] Step 1100/1249 Loss 3.073 Prec@(1,3) (76.5%, 98.4%), ce_loss 0.918, lat_loss 22.117
09/21 01:05:47 PM | Train: [ 40/180] Step 1150/1249 Loss 3.069 Prec@(1,3) (76.5%, 98.4%), ce_loss 0.918, lat_loss 22.117
09/21 01:06:12 PM | Train: [ 40/180] Step 1200/1249 Loss 3.066 Prec@(1,3) (76.5%, 98.4%), ce_loss 0.917, lat_loss 22.117
09/21 01:06:36 PM | Train: [ 40/180] Step 1249/1249 Loss 3.064 Prec@(1,3) (76.5%, 98.4%), ce_loss 0.917, lat_loss 22.117
09/21 01:06:36 PM | _w_step_train: [ 40/180] Final Prec@1 76.5150% Time 605.94
09/21 01:06:36 PM | Start to train theta for epoch 39
09/21 01:06:57 PM | Train: [ 40/180] Step 050/312 Loss 3.578 Prec@(1,3) (73.7%, 97.8%), ce_loss 0.917, lat_loss 22.117
09/21 01:07:17 PM | Train: [ 40/180] Step 100/312 Loss 3.435 Prec@(1,3) (74.1%, 98.0%), ce_loss 0.917, lat_loss 22.117
09/21 01:07:31 PM | Train: [ 40/180] Step 150/312 Loss 3.311 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.917, lat_loss 22.117
09/21 01:07:43 PM | Train: [ 40/180] Step 200/312 Loss 3.280 Prec@(1,3) (75.3%, 98.1%), ce_loss 0.917, lat_loss 22.117
09/21 01:08:01 PM | Train: [ 40/180] Step 250/312 Loss 3.282 Prec@(1,3) (75.3%, 98.0%), ce_loss 0.917, lat_loss 22.117
09/21 01:08:21 PM | Train: [ 40/180] Step 300/312 Loss 3.288 Prec@(1,3) (75.0%, 98.0%), ce_loss 0.916, lat_loss 22.117
09/21 01:08:26 PM | Train: [ 40/180] Step 312/312 Loss 3.278 Prec@(1,3) (75.1%, 97.9%), ce_loss 0.916, lat_loss 22.117
09/21 01:08:26 PM | _theta_step_train: [ 40/180] Final Prec@1 75.1100% Time 110.04
09/21 01:08:32 PM | Valid: [ 40/180] Step 050/312 Loss 4.224 Prec@(1,3) (71.1%, 96.9%), ce_loss 0.916, lat_loss 22.117
09/21 01:08:36 PM | Valid: [ 40/180] Step 100/312 Loss 4.416 Prec@(1,3) (70.0%, 96.5%), ce_loss 0.917, lat_loss 22.117
09/21 01:08:41 PM | Valid: [ 40/180] Step 150/312 Loss 4.261 Prec@(1,3) (70.4%, 96.5%), ce_loss 0.916, lat_loss 22.117
09/21 01:08:46 PM | Valid: [ 40/180] Step 200/312 Loss 4.190 Prec@(1,3) (70.4%, 96.7%), ce_loss 0.916, lat_loss 22.117
09/21 01:08:50 PM | Valid: [ 40/180] Step 250/312 Loss 4.154 Prec@(1,3) (70.3%, 96.8%), ce_loss 0.916, lat_loss 22.116
09/21 01:08:55 PM | Valid: [ 40/180] Step 300/312 Loss 4.138 Prec@(1,3) (70.4%, 96.8%), ce_loss 0.916, lat_loss 22.116
09/21 01:08:56 PM | Valid: [ 40/180] Step 312/312 Loss 4.111 Prec@(1,3) (70.4%, 96.9%), ce_loss 0.916, lat_loss 22.116
09/21 01:08:56 PM | val: [ 40/180] Final Prec@1 70.4100% Time 29.70
09/21 01:08:56 PM | Start to train weights for epoch 40
09/21 01:09:19 PM | Train: [ 41/180] Step 050/1249 Loss 3.036 Prec@(1,3) (76.0%, 98.5%), ce_loss 0.916, lat_loss 22.116
09/21 01:09:41 PM | Train: [ 41/180] Step 100/1249 Loss 2.968 Prec@(1,3) (76.8%, 98.5%), ce_loss 0.916, lat_loss 22.116
09/21 01:10:05 PM | Train: [ 41/180] Step 150/1249 Loss 2.994 Prec@(1,3) (77.1%, 98.6%), ce_loss 0.916, lat_loss 22.116
09/21 01:10:29 PM | Train: [ 41/180] Step 200/1249 Loss 3.024 Prec@(1,3) (76.9%, 98.6%), ce_loss 0.916, lat_loss 22.116
09/21 01:10:52 PM | Train: [ 41/180] Step 250/1249 Loss 3.034 Prec@(1,3) (77.0%, 98.5%), ce_loss 0.916, lat_loss 22.116
09/21 01:11:15 PM | Train: [ 41/180] Step 300/1249 Loss 3.080 Prec@(1,3) (76.4%, 98.4%), ce_loss 0.916, lat_loss 22.116
09/21 01:11:38 PM | Train: [ 41/180] Step 350/1249 Loss 3.069 Prec@(1,3) (76.4%, 98.5%), ce_loss 0.915, lat_loss 22.116
09/21 01:12:01 PM | Train: [ 41/180] Step 400/1249 Loss 3.082 Prec@(1,3) (76.4%, 98.5%), ce_loss 0.915, lat_loss 22.116
09/21 01:12:24 PM | Train: [ 41/180] Step 450/1249 Loss 3.066 Prec@(1,3) (76.6%, 98.4%), ce_loss 0.915, lat_loss 22.116
09/21 01:12:48 PM | Train: [ 41/180] Step 500/1249 Loss 3.067 Prec@(1,3) (76.5%, 98.5%), ce_loss 0.915, lat_loss 22.116
09/21 01:13:11 PM | Train: [ 41/180] Step 550/1249 Loss 3.076 Prec@(1,3) (76.4%, 98.5%), ce_loss 0.915, lat_loss 22.116
09/21 01:13:34 PM | Train: [ 41/180] Step 600/1249 Loss 3.098 Prec@(1,3) (76.3%, 98.4%), ce_loss 0.915, lat_loss 22.116
09/21 01:13:57 PM | Train: [ 41/180] Step 650/1249 Loss 3.107 Prec@(1,3) (76.3%, 98.4%), ce_loss 0.914, lat_loss 22.116
09/21 01:14:20 PM | Train: [ 41/180] Step 700/1249 Loss 3.111 Prec@(1,3) (76.3%, 98.4%), ce_loss 0.914, lat_loss 22.116
09/21 01:14:45 PM | Train: [ 41/180] Step 750/1249 Loss 3.133 Prec@(1,3) (76.1%, 98.4%), ce_loss 0.914, lat_loss 22.116
09/21 01:15:10 PM | Train: [ 41/180] Step 800/1249 Loss 3.127 Prec@(1,3) (76.1%, 98.4%), ce_loss 0.914, lat_loss 22.116
09/21 01:15:35 PM | Train: [ 41/180] Step 850/1249 Loss 3.122 Prec@(1,3) (76.1%, 98.4%), ce_loss 0.914, lat_loss 22.116
09/21 01:15:59 PM | Train: [ 41/180] Step 900/1249 Loss 3.112 Prec@(1,3) (76.3%, 98.3%), ce_loss 0.914, lat_loss 22.116
09/21 01:16:23 PM | Train: [ 41/180] Step 950/1249 Loss 3.124 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.914, lat_loss 22.116
09/21 01:16:46 PM | Train: [ 41/180] Step 1000/1249 Loss 3.127 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.913, lat_loss 22.116
09/21 01:17:09 PM | Train: [ 41/180] Step 1050/1249 Loss 3.134 Prec@(1,3) (76.1%, 98.3%), ce_loss 0.913, lat_loss 22.116
09/21 01:17:31 PM | Train: [ 41/180] Step 1100/1249 Loss 3.132 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.913, lat_loss 22.116
09/21 01:17:56 PM | Train: [ 41/180] Step 1150/1249 Loss 3.130 Prec@(1,3) (76.1%, 98.3%), ce_loss 0.913, lat_loss 22.116
09/21 01:18:21 PM | Train: [ 41/180] Step 1200/1249 Loss 3.120 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.913, lat_loss 22.115
09/21 01:18:45 PM | Train: [ 41/180] Step 1249/1249 Loss 3.117 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.913, lat_loss 22.115
09/21 01:18:45 PM | _w_step_train: [ 41/180] Final Prec@1 76.1725% Time 589.23
09/21 01:18:45 PM | Start to train theta for epoch 40
09/21 01:19:06 PM | Train: [ 41/180] Step 050/312 Loss 3.205 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.913, lat_loss 22.115
09/21 01:19:27 PM | Train: [ 41/180] Step 100/312 Loss 3.238 Prec@(1,3) (75.4%, 98.0%), ce_loss 0.912, lat_loss 22.115
09/21 01:19:47 PM | Train: [ 41/180] Step 150/312 Loss 3.236 Prec@(1,3) (75.2%, 98.0%), ce_loss 0.912, lat_loss 22.115
09/21 01:20:09 PM | Train: [ 41/180] Step 200/312 Loss 3.261 Prec@(1,3) (74.6%, 98.2%), ce_loss 0.912, lat_loss 22.115
09/21 01:20:30 PM | Train: [ 41/180] Step 250/312 Loss 3.280 Prec@(1,3) (74.6%, 98.2%), ce_loss 0.912, lat_loss 22.115
09/21 01:20:49 PM | Train: [ 41/180] Step 300/312 Loss 3.273 Prec@(1,3) (74.9%, 98.3%), ce_loss 0.912, lat_loss 22.115
09/21 01:20:54 PM | Train: [ 41/180] Step 312/312 Loss 3.280 Prec@(1,3) (74.8%, 98.3%), ce_loss 0.912, lat_loss 22.115
09/21 01:20:54 PM | _theta_step_train: [ 41/180] Final Prec@1 74.7900% Time 128.67
09/21 01:20:59 PM | Valid: [ 41/180] Step 050/312 Loss 3.873 Prec@(1,3) (70.0%, 97.2%), ce_loss 0.912, lat_loss 22.115
09/21 01:21:04 PM | Valid: [ 41/180] Step 100/312 Loss 3.928 Prec@(1,3) (69.8%, 97.0%), ce_loss 0.912, lat_loss 22.115
09/21 01:21:09 PM | Valid: [ 41/180] Step 150/312 Loss 4.057 Prec@(1,3) (68.9%, 96.7%), ce_loss 0.912, lat_loss 22.115
09/21 01:21:13 PM | Valid: [ 41/180] Step 200/312 Loss 4.097 Prec@(1,3) (68.8%, 96.6%), ce_loss 0.912, lat_loss 22.115
09/21 01:21:18 PM | Valid: [ 41/180] Step 250/312 Loss 4.093 Prec@(1,3) (68.8%, 96.7%), ce_loss 0.912, lat_loss 22.115
09/21 01:21:23 PM | Valid: [ 41/180] Step 300/312 Loss 4.018 Prec@(1,3) (69.4%, 96.9%), ce_loss 0.912, lat_loss 22.115
09/21 01:21:24 PM | Valid: [ 41/180] Step 312/312 Loss 4.007 Prec@(1,3) (69.4%, 96.9%), ce_loss 0.912, lat_loss 22.115
09/21 01:21:24 PM | val: [ 41/180] Final Prec@1 69.3700% Time 30.12
09/21 01:21:24 PM | Start to train weights for epoch 41
09/21 01:21:50 PM | Train: [ 42/180] Step 050/1249 Loss 3.063 Prec@(1,3) (76.8%, 98.3%), ce_loss 0.912, lat_loss 22.115
09/21 01:22:12 PM | Train: [ 42/180] Step 100/1249 Loss 3.074 Prec@(1,3) (77.1%, 98.2%), ce_loss 0.912, lat_loss 22.114
09/21 01:22:36 PM | Train: [ 42/180] Step 150/1249 Loss 3.114 Prec@(1,3) (76.7%, 98.1%), ce_loss 0.912, lat_loss 22.114
09/21 01:22:59 PM | Train: [ 42/180] Step 200/1249 Loss 3.080 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.911, lat_loss 22.114
09/21 01:23:22 PM | Train: [ 42/180] Step 250/1249 Loss 3.062 Prec@(1,3) (76.8%, 98.3%), ce_loss 0.911, lat_loss 22.114
09/21 01:23:44 PM | Train: [ 42/180] Step 300/1249 Loss 3.113 Prec@(1,3) (76.4%, 98.1%), ce_loss 0.911, lat_loss 22.114
09/21 01:24:06 PM | Train: [ 42/180] Step 350/1249 Loss 3.146 Prec@(1,3) (76.2%, 98.0%), ce_loss 0.911, lat_loss 22.114
09/21 01:24:28 PM | Train: [ 42/180] Step 400/1249 Loss 3.139 Prec@(1,3) (76.3%, 98.1%), ce_loss 0.911, lat_loss 22.114
09/21 01:24:49 PM | Train: [ 42/180] Step 450/1249 Loss 3.109 Prec@(1,3) (76.5%, 98.1%), ce_loss 0.911, lat_loss 22.114
09/21 01:25:09 PM | Train: [ 42/180] Step 500/1249 Loss 3.109 Prec@(1,3) (76.4%, 98.1%), ce_loss 0.911, lat_loss 22.114
09/21 01:25:31 PM | Train: [ 42/180] Step 550/1249 Loss 3.086 Prec@(1,3) (76.6%, 98.2%), ce_loss 0.910, lat_loss 22.114
09/21 01:25:54 PM | Train: [ 42/180] Step 600/1249 Loss 3.059 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.910, lat_loss 22.114
09/21 01:26:15 PM | Train: [ 42/180] Step 650/1249 Loss 3.063 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.910, lat_loss 22.114
09/21 01:26:38 PM | Train: [ 42/180] Step 700/1249 Loss 3.041 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.910, lat_loss 22.114
09/21 01:27:01 PM | Train: [ 42/180] Step 750/1249 Loss 3.038 Prec@(1,3) (76.8%, 98.2%), ce_loss 0.910, lat_loss 22.114
09/21 01:27:23 PM | Train: [ 42/180] Step 800/1249 Loss 3.054 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.910, lat_loss 22.113
09/21 01:27:44 PM | Train: [ 42/180] Step 850/1249 Loss 3.063 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.909, lat_loss 22.113
09/21 01:28:06 PM | Train: [ 42/180] Step 900/1249 Loss 3.071 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.909, lat_loss 22.113
09/21 01:28:26 PM | Train: [ 42/180] Step 950/1249 Loss 3.084 Prec@(1,3) (76.6%, 98.2%), ce_loss 0.909, lat_loss 22.113
09/21 01:28:49 PM | Train: [ 42/180] Step 1000/1249 Loss 3.070 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.909, lat_loss 22.113
09/21 01:29:10 PM | Train: [ 42/180] Step 1050/1249 Loss 3.084 Prec@(1,3) (76.5%, 98.2%), ce_loss 0.909, lat_loss 22.113
09/21 01:29:32 PM | Train: [ 42/180] Step 1100/1249 Loss 3.087 Prec@(1,3) (76.5%, 98.2%), ce_loss 0.909, lat_loss 22.113
09/21 01:29:53 PM | Train: [ 42/180] Step 1150/1249 Loss 3.084 Prec@(1,3) (76.5%, 98.2%), ce_loss 0.909, lat_loss 22.113
09/21 01:30:16 PM | Train: [ 42/180] Step 1200/1249 Loss 3.083 Prec@(1,3) (76.6%, 98.2%), ce_loss 0.908, lat_loss 22.113
09/21 01:30:39 PM | Train: [ 42/180] Step 1249/1249 Loss 3.077 Prec@(1,3) (76.6%, 98.2%), ce_loss 0.908, lat_loss 22.113
09/21 01:30:39 PM | _w_step_train: [ 42/180] Final Prec@1 76.6000% Time 555.05
09/21 01:30:39 PM | Start to train theta for epoch 41
09/21 01:31:00 PM | Train: [ 42/180] Step 050/312 Loss 3.094 Prec@(1,3) (76.5%, 98.3%), ce_loss 0.908, lat_loss 22.113
09/21 01:31:19 PM | Train: [ 42/180] Step 100/312 Loss 3.116 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.908, lat_loss 22.113
09/21 01:31:40 PM | Train: [ 42/180] Step 150/312 Loss 3.125 Prec@(1,3) (76.4%, 98.3%), ce_loss 0.908, lat_loss 22.113
09/21 01:31:59 PM | Train: [ 42/180] Step 200/312 Loss 3.164 Prec@(1,3) (76.0%, 98.3%), ce_loss 0.908, lat_loss 22.112
09/21 01:32:19 PM | Train: [ 42/180] Step 250/312 Loss 3.150 Prec@(1,3) (76.1%, 98.3%), ce_loss 0.908, lat_loss 22.112
09/21 01:32:38 PM | Train: [ 42/180] Step 300/312 Loss 3.137 Prec@(1,3) (76.3%, 98.2%), ce_loss 0.907, lat_loss 22.112
09/21 01:32:43 PM | Train: [ 42/180] Step 312/312 Loss 3.133 Prec@(1,3) (76.2%, 98.2%), ce_loss 0.907, lat_loss 22.112
09/21 01:32:43 PM | _theta_step_train: [ 42/180] Final Prec@1 76.2100% Time 124.26
09/21 01:32:49 PM | Valid: [ 42/180] Step 050/312 Loss 5.286 Prec@(1,3) (69.1%, 96.2%), ce_loss 0.908, lat_loss 22.112
09/21 01:32:53 PM | Valid: [ 42/180] Step 100/312 Loss 4.739 Prec@(1,3) (68.8%, 96.7%), ce_loss 0.908, lat_loss 22.112
09/21 01:32:58 PM | Valid: [ 42/180] Step 150/312 Loss 4.628 Prec@(1,3) (69.3%, 96.7%), ce_loss 0.908, lat_loss 22.112
09/21 01:33:03 PM | Valid: [ 42/180] Step 200/312 Loss 4.481 Prec@(1,3) (69.7%, 97.0%), ce_loss 0.908, lat_loss 22.112
09/21 01:33:08 PM | Valid: [ 42/180] Step 250/312 Loss 4.492 Prec@(1,3) (69.7%, 97.1%), ce_loss 0.908, lat_loss 22.112
09/21 01:33:12 PM | Valid: [ 42/180] Step 300/312 Loss 4.498 Prec@(1,3) (69.6%, 96.9%), ce_loss 0.908, lat_loss 22.112
09/21 01:33:13 PM | Valid: [ 42/180] Step 312/312 Loss 4.456 Prec@(1,3) (69.8%, 97.0%), ce_loss 0.908, lat_loss 22.112
09/21 01:33:13 PM | val: [ 42/180] Final Prec@1 69.7500% Time 29.95
09/21 01:33:13 PM | Start to train weights for epoch 42
09/21 01:33:38 PM | Train: [ 43/180] Step 050/1249 Loss 2.936 Prec@(1,3) (77.6%, 98.7%), ce_loss 0.908, lat_loss 22.112
09/21 01:34:01 PM | Train: [ 43/180] Step 100/1249 Loss 2.961 Prec@(1,3) (77.5%, 98.6%), ce_loss 0.908, lat_loss 22.112
09/21 01:34:23 PM | Train: [ 43/180] Step 150/1249 Loss 3.038 Prec@(1,3) (76.4%, 98.6%), ce_loss 0.907, lat_loss 22.111
09/21 01:34:46 PM | Train: [ 43/180] Step 200/1249 Loss 3.052 Prec@(1,3) (76.6%, 98.4%), ce_loss 0.907, lat_loss 22.111
09/21 01:35:08 PM | Train: [ 43/180] Step 250/1249 Loss 3.036 Prec@(1,3) (76.8%, 98.5%), ce_loss 0.907, lat_loss 22.111
09/21 01:35:29 PM | Train: [ 43/180] Step 300/1249 Loss 3.073 Prec@(1,3) (76.4%, 98.3%), ce_loss 0.907, lat_loss 22.111
09/21 01:35:50 PM | Train: [ 43/180] Step 350/1249 Loss 3.074 Prec@(1,3) (76.4%, 98.2%), ce_loss 0.907, lat_loss 22.111
09/21 01:36:13 PM | Train: [ 43/180] Step 400/1249 Loss 3.075 Prec@(1,3) (76.4%, 98.3%), ce_loss 0.907, lat_loss 22.111
09/21 01:36:34 PM | Train: [ 43/180] Step 450/1249 Loss 3.084 Prec@(1,3) (76.3%, 98.3%), ce_loss 0.907, lat_loss 22.111
09/21 01:36:57 PM | Train: [ 43/180] Step 500/1249 Loss 3.104 Prec@(1,3) (76.2%, 98.2%), ce_loss 0.906, lat_loss 22.111
09/21 01:37:18 PM | Train: [ 43/180] Step 550/1249 Loss 3.083 Prec@(1,3) (76.4%, 98.2%), ce_loss 0.906, lat_loss 22.111
09/21 01:37:39 PM | Train: [ 43/180] Step 600/1249 Loss 3.078 Prec@(1,3) (76.5%, 98.3%), ce_loss 0.906, lat_loss 22.111
09/21 01:37:59 PM | Train: [ 43/180] Step 650/1249 Loss 3.068 Prec@(1,3) (76.5%, 98.3%), ce_loss 0.906, lat_loss 22.111
09/21 01:38:21 PM | Train: [ 43/180] Step 700/1249 Loss 3.058 Prec@(1,3) (76.6%, 98.3%), ce_loss 0.906, lat_loss 22.111
09/21 01:38:43 PM | Train: [ 43/180] Step 750/1249 Loss 3.054 Prec@(1,3) (76.7%, 98.3%), ce_loss 0.906, lat_loss 22.110
09/21 01:39:05 PM | Train: [ 43/180] Step 800/1249 Loss 3.055 Prec@(1,3) (76.7%, 98.3%), ce_loss 0.906, lat_loss 22.110
09/21 01:39:27 PM | Train: [ 43/180] Step 850/1249 Loss 3.048 Prec@(1,3) (76.8%, 98.3%), ce_loss 0.905, lat_loss 22.110
09/21 01:39:48 PM | Train: [ 43/180] Step 900/1249 Loss 3.052 Prec@(1,3) (76.7%, 98.3%), ce_loss 0.905, lat_loss 22.110
09/21 01:40:11 PM | Train: [ 43/180] Step 950/1249 Loss 3.047 Prec@(1,3) (76.7%, 98.3%), ce_loss 0.905, lat_loss 22.110
09/21 01:40:36 PM | Train: [ 43/180] Step 1000/1249 Loss 3.046 Prec@(1,3) (76.8%, 98.3%), ce_loss 0.905, lat_loss 22.110
09/21 01:41:00 PM | Train: [ 43/180] Step 1050/1249 Loss 3.047 Prec@(1,3) (76.8%, 98.3%), ce_loss 0.905, lat_loss 22.110
09/21 01:41:25 PM | Train: [ 43/180] Step 1100/1249 Loss 3.059 Prec@(1,3) (76.7%, 98.3%), ce_loss 0.905, lat_loss 22.110
09/21 01:41:50 PM | Train: [ 43/180] Step 1150/1249 Loss 3.052 Prec@(1,3) (76.8%, 98.3%), ce_loss 0.905, lat_loss 22.110
09/21 01:42:15 PM | Train: [ 43/180] Step 1200/1249 Loss 3.043 Prec@(1,3) (76.9%, 98.4%), ce_loss 0.904, lat_loss 22.110
09/21 01:42:39 PM | Train: [ 43/180] Step 1249/1249 Loss 3.041 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.904, lat_loss 22.110
09/21 01:42:40 PM | _w_step_train: [ 43/180] Final Prec@1 76.9025% Time 566.18
09/21 01:42:40 PM | Start to train theta for epoch 42
09/21 01:43:01 PM | Train: [ 43/180] Step 050/312 Loss 3.267 Prec@(1,3) (76.0%, 98.2%), ce_loss 0.904, lat_loss 22.109
09/21 01:43:21 PM | Train: [ 43/180] Step 100/312 Loss 3.337 Prec@(1,3) (75.6%, 98.1%), ce_loss 0.904, lat_loss 22.109
09/21 01:43:42 PM | Train: [ 43/180] Step 150/312 Loss 3.339 Prec@(1,3) (75.6%, 97.9%), ce_loss 0.904, lat_loss 22.109
09/21 01:44:02 PM | Train: [ 43/180] Step 200/312 Loss 3.260 Prec@(1,3) (76.2%, 98.1%), ce_loss 0.904, lat_loss 22.109
09/21 01:44:22 PM | Train: [ 43/180] Step 250/312 Loss 3.277 Prec@(1,3) (76.1%, 98.1%), ce_loss 0.904, lat_loss 22.109
09/21 01:44:41 PM | Train: [ 43/180] Step 300/312 Loss 3.242 Prec@(1,3) (76.2%, 98.1%), ce_loss 0.904, lat_loss 22.109
09/21 01:44:46 PM | Train: [ 43/180] Step 312/312 Loss 3.230 Prec@(1,3) (76.2%, 98.1%), ce_loss 0.903, lat_loss 22.109
09/21 01:44:46 PM | _theta_step_train: [ 43/180] Final Prec@1 76.2400% Time 126.44
09/21 01:44:52 PM | Valid: [ 43/180] Step 050/312 Loss 3.527 Prec@(1,3) (72.7%, 97.9%), ce_loss 0.903, lat_loss 22.109
09/21 01:44:56 PM | Valid: [ 43/180] Step 100/312 Loss 3.708 Prec@(1,3) (71.9%, 97.4%), ce_loss 0.903, lat_loss 22.109
09/21 01:45:00 PM | Valid: [ 43/180] Step 150/312 Loss 3.741 Prec@(1,3) (72.3%, 97.2%), ce_loss 0.903, lat_loss 22.109
09/21 01:45:05 PM | Valid: [ 43/180] Step 200/312 Loss 3.717 Prec@(1,3) (72.3%, 97.5%), ce_loss 0.903, lat_loss 22.109
09/21 01:45:09 PM | Valid: [ 43/180] Step 250/312 Loss 3.706 Prec@(1,3) (72.6%, 97.5%), ce_loss 0.903, lat_loss 22.109
09/21 01:45:14 PM | Valid: [ 43/180] Step 300/312 Loss 3.816 Prec@(1,3) (71.9%, 97.2%), ce_loss 0.903, lat_loss 22.109
09/21 01:45:15 PM | Valid: [ 43/180] Step 312/312 Loss 3.816 Prec@(1,3) (72.0%, 97.2%), ce_loss 0.903, lat_loss 22.109
09/21 01:45:15 PM | val: [ 43/180] Final Prec@1 71.9500% Time 29.24
09/21 01:45:15 PM | Start to train weights for epoch 43
09/21 01:45:40 PM | Train: [ 44/180] Step 050/1249 Loss 3.021 Prec@(1,3) (77.8%, 98.5%), ce_loss 0.903, lat_loss 22.109
09/21 01:46:04 PM | Train: [ 44/180] Step 100/1249 Loss 3.005 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.903, lat_loss 22.109
09/21 01:46:29 PM | Train: [ 44/180] Step 150/1249 Loss 2.999 Prec@(1,3) (77.9%, 98.5%), ce_loss 0.903, lat_loss 22.109
09/21 01:46:54 PM | Train: [ 44/180] Step 200/1249 Loss 3.009 Prec@(1,3) (77.9%, 98.4%), ce_loss 0.903, lat_loss 22.109
09/21 01:47:17 PM | Train: [ 44/180] Step 250/1249 Loss 2.988 Prec@(1,3) (77.8%, 98.6%), ce_loss 0.903, lat_loss 22.108
09/21 01:47:40 PM | Train: [ 44/180] Step 300/1249 Loss 3.043 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.902, lat_loss 22.108
09/21 01:48:04 PM | Train: [ 44/180] Step 350/1249 Loss 3.023 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.902, lat_loss 22.108
09/21 01:48:27 PM | Train: [ 44/180] Step 400/1249 Loss 3.006 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.902, lat_loss 22.108
09/21 01:48:49 PM | Train: [ 44/180] Step 450/1249 Loss 3.005 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.902, lat_loss 22.108
09/21 01:49:12 PM | Train: [ 44/180] Step 500/1249 Loss 3.032 Prec@(1,3) (77.3%, 98.4%), ce_loss 0.902, lat_loss 22.108
09/21 01:49:35 PM | Train: [ 44/180] Step 550/1249 Loss 3.025 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.902, lat_loss 22.108
09/21 01:49:58 PM | Train: [ 44/180] Step 600/1249 Loss 3.011 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.902, lat_loss 22.108
09/21 01:50:22 PM | Train: [ 44/180] Step 650/1249 Loss 3.011 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.901, lat_loss 22.108
09/21 01:50:45 PM | Train: [ 44/180] Step 700/1249 Loss 3.009 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.901, lat_loss 22.108
09/21 01:51:07 PM | Train: [ 44/180] Step 750/1249 Loss 3.005 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.901, lat_loss 22.108
09/21 01:51:29 PM | Train: [ 44/180] Step 800/1249 Loss 3.008 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.901, lat_loss 22.108
09/21 01:51:50 PM | Train: [ 44/180] Step 850/1249 Loss 3.008 Prec@(1,3) (77.2%, 98.5%), ce_loss 0.901, lat_loss 22.108
09/21 01:52:13 PM | Train: [ 44/180] Step 900/1249 Loss 2.999 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.901, lat_loss 22.108
09/21 01:52:37 PM | Train: [ 44/180] Step 950/1249 Loss 3.014 Prec@(1,3) (77.2%, 98.4%), ce_loss 0.901, lat_loss 22.108
09/21 01:53:00 PM | Train: [ 44/180] Step 1000/1249 Loss 3.015 Prec@(1,3) (77.2%, 98.4%), ce_loss 0.900, lat_loss 22.107
09/21 01:53:23 PM | Train: [ 44/180] Step 1050/1249 Loss 3.026 Prec@(1,3) (77.1%, 98.4%), ce_loss 0.900, lat_loss 22.107
09/21 01:53:46 PM | Train: [ 44/180] Step 1100/1249 Loss 3.035 Prec@(1,3) (77.0%, 98.4%), ce_loss 0.900, lat_loss 22.107
09/21 01:54:09 PM | Train: [ 44/180] Step 1150/1249 Loss 3.040 Prec@(1,3) (77.0%, 98.4%), ce_loss 0.900, lat_loss 22.107
09/21 01:54:33 PM | Train: [ 44/180] Step 1200/1249 Loss 3.044 Prec@(1,3) (77.0%, 98.4%), ce_loss 0.900, lat_loss 22.107
09/21 01:54:58 PM | Train: [ 44/180] Step 1249/1249 Loss 3.054 Prec@(1,3) (76.9%, 98.4%), ce_loss 0.900, lat_loss 22.107
09/21 01:54:58 PM | _w_step_train: [ 44/180] Final Prec@1 76.9400% Time 582.95
09/21 01:54:58 PM | Start to train theta for epoch 43
09/21 01:55:20 PM | Train: [ 44/180] Step 050/312 Loss 3.184 Prec@(1,3) (76.5%, 98.3%), ce_loss 0.900, lat_loss 22.107
09/21 01:55:41 PM | Train: [ 44/180] Step 100/312 Loss 3.247 Prec@(1,3) (75.5%, 98.0%), ce_loss 0.900, lat_loss 22.107
09/21 01:56:01 PM | Train: [ 44/180] Step 150/312 Loss 3.220 Prec@(1,3) (75.3%, 98.0%), ce_loss 0.900, lat_loss 22.107
09/21 01:56:17 PM | Train: [ 44/180] Step 200/312 Loss 3.211 Prec@(1,3) (75.3%, 98.0%), ce_loss 0.899, lat_loss 22.107
09/21 01:56:29 PM | Train: [ 44/180] Step 250/312 Loss 3.200 Prec@(1,3) (75.7%, 98.0%), ce_loss 0.899, lat_loss 22.107
09/21 01:56:42 PM | Train: [ 44/180] Step 300/312 Loss 3.216 Prec@(1,3) (75.4%, 97.9%), ce_loss 0.899, lat_loss 22.107
09/21 01:56:45 PM | Train: [ 44/180] Step 312/312 Loss 3.211 Prec@(1,3) (75.5%, 97.9%), ce_loss 0.899, lat_loss 22.107
09/21 01:56:45 PM | _theta_step_train: [ 44/180] Final Prec@1 75.4800% Time 106.60
09/21 01:56:50 PM | Valid: [ 44/180] Step 050/312 Loss 3.884 Prec@(1,3) (70.2%, 97.2%), ce_loss 0.899, lat_loss 22.107
09/21 01:56:54 PM | Valid: [ 44/180] Step 100/312 Loss 4.046 Prec@(1,3) (69.0%, 96.5%), ce_loss 0.899, lat_loss 22.107
09/21 01:56:59 PM | Valid: [ 44/180] Step 150/312 Loss 4.122 Prec@(1,3) (68.5%, 96.6%), ce_loss 0.899, lat_loss 22.107
09/21 01:57:03 PM | Valid: [ 44/180] Step 200/312 Loss 4.071 Prec@(1,3) (68.9%, 96.8%), ce_loss 0.899, lat_loss 22.106
09/21 01:57:08 PM | Valid: [ 44/180] Step 250/312 Loss 4.058 Prec@(1,3) (69.4%, 96.9%), ce_loss 0.899, lat_loss 22.106
09/21 01:57:12 PM | Valid: [ 44/180] Step 300/312 Loss 4.020 Prec@(1,3) (69.6%, 97.0%), ce_loss 0.899, lat_loss 22.106
09/21 01:57:14 PM | Valid: [ 44/180] Step 312/312 Loss 4.032 Prec@(1,3) (69.5%, 97.0%), ce_loss 0.899, lat_loss 22.106
09/21 01:57:14 PM | val: [ 44/180] Final Prec@1 69.4800% Time 28.72
09/21 01:57:14 PM | Start to train weights for epoch 44
09/21 01:57:40 PM | Train: [ 45/180] Step 050/1249 Loss 3.174 Prec@(1,3) (76.4%, 97.4%), ce_loss 0.899, lat_loss 22.106
09/21 01:58:04 PM | Train: [ 45/180] Step 100/1249 Loss 3.148 Prec@(1,3) (76.6%, 97.6%), ce_loss 0.899, lat_loss 22.106
09/21 01:58:28 PM | Train: [ 45/180] Step 150/1249 Loss 3.204 Prec@(1,3) (76.0%, 97.8%), ce_loss 0.899, lat_loss 22.106
09/21 01:58:51 PM | Train: [ 45/180] Step 200/1249 Loss 3.167 Prec@(1,3) (76.1%, 98.0%), ce_loss 0.899, lat_loss 22.106
09/21 01:59:17 PM | Train: [ 45/180] Step 250/1249 Loss 3.101 Prec@(1,3) (76.7%, 98.0%), ce_loss 0.899, lat_loss 22.106
09/21 01:59:42 PM | Train: [ 45/180] Step 300/1249 Loss 3.056 Prec@(1,3) (77.0%, 98.1%), ce_loss 0.898, lat_loss 22.106
09/21 02:00:07 PM | Train: [ 45/180] Step 350/1249 Loss 3.050 Prec@(1,3) (77.0%, 98.2%), ce_loss 0.898, lat_loss 22.106
09/21 02:00:31 PM | Train: [ 45/180] Step 400/1249 Loss 3.026 Prec@(1,3) (77.0%, 98.3%), ce_loss 0.898, lat_loss 22.106
09/21 02:00:54 PM | Train: [ 45/180] Step 450/1249 Loss 3.042 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.898, lat_loss 22.106
09/21 02:01:18 PM | Train: [ 45/180] Step 500/1249 Loss 3.051 Prec@(1,3) (76.7%, 98.3%), ce_loss 0.898, lat_loss 22.106
09/21 02:01:43 PM | Train: [ 45/180] Step 550/1249 Loss 3.054 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.898, lat_loss 22.106
09/21 02:02:08 PM | Train: [ 45/180] Step 600/1249 Loss 3.063 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.898, lat_loss 22.105
09/21 02:02:33 PM | Train: [ 45/180] Step 650/1249 Loss 3.045 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.897, lat_loss 22.105
09/21 02:02:58 PM | Train: [ 45/180] Step 700/1249 Loss 3.050 Prec@(1,3) (76.8%, 98.3%), ce_loss 0.897, lat_loss 22.105
09/21 02:03:23 PM | Train: [ 45/180] Step 750/1249 Loss 3.041 Prec@(1,3) (76.9%, 98.2%), ce_loss 0.897, lat_loss 22.105
09/21 02:03:46 PM | Train: [ 45/180] Step 800/1249 Loss 3.045 Prec@(1,3) (76.9%, 98.2%), ce_loss 0.897, lat_loss 22.105
09/21 02:04:10 PM | Train: [ 45/180] Step 850/1249 Loss 3.035 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.897, lat_loss 22.105
09/21 02:04:32 PM | Train: [ 45/180] Step 900/1249 Loss 3.028 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.897, lat_loss 22.105
09/21 02:04:57 PM | Train: [ 45/180] Step 950/1249 Loss 3.030 Prec@(1,3) (77.0%, 98.3%), ce_loss 0.897, lat_loss 22.105
09/21 02:05:21 PM | Train: [ 45/180] Step 1000/1249 Loss 3.043 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.897, lat_loss 22.105
09/21 02:05:46 PM | Train: [ 45/180] Step 1050/1249 Loss 3.034 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.896, lat_loss 22.105
09/21 02:06:10 PM | Train: [ 45/180] Step 1100/1249 Loss 3.034 Prec@(1,3) (77.0%, 98.3%), ce_loss 0.896, lat_loss 22.105
09/21 02:06:33 PM | Train: [ 45/180] Step 1150/1249 Loss 3.042 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.896, lat_loss 22.105
09/21 02:06:58 PM | Train: [ 45/180] Step 1200/1249 Loss 3.043 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.896, lat_loss 22.105
09/21 02:07:22 PM | Train: [ 45/180] Step 1249/1249 Loss 3.042 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.896, lat_loss 22.105
09/21 02:07:22 PM | _w_step_train: [ 45/180] Final Prec@1 76.8675% Time 608.74
09/21 02:07:22 PM | Start to train theta for epoch 44
09/21 02:07:44 PM | Train: [ 45/180] Step 050/312 Loss 3.011 Prec@(1,3) (76.7%, 98.6%), ce_loss 0.896, lat_loss 22.104
09/21 02:08:04 PM | Train: [ 45/180] Step 100/312 Loss 2.998 Prec@(1,3) (76.4%, 98.5%), ce_loss 0.896, lat_loss 22.104
09/21 02:08:24 PM | Train: [ 45/180] Step 150/312 Loss 3.121 Prec@(1,3) (76.1%, 98.0%), ce_loss 0.896, lat_loss 22.104
09/21 02:08:44 PM | Train: [ 45/180] Step 200/312 Loss 3.098 Prec@(1,3) (76.5%, 97.9%), ce_loss 0.895, lat_loss 22.104
09/21 02:09:01 PM | Train: [ 45/180] Step 250/312 Loss 3.157 Prec@(1,3) (76.3%, 97.9%), ce_loss 0.895, lat_loss 22.104
09/21 02:09:20 PM | Train: [ 45/180] Step 300/312 Loss 3.168 Prec@(1,3) (76.1%, 98.0%), ce_loss 0.895, lat_loss 22.104
09/21 02:09:25 PM | Train: [ 45/180] Step 312/312 Loss 3.150 Prec@(1,3) (76.2%, 98.0%), ce_loss 0.895, lat_loss 22.104
09/21 02:09:25 PM | _theta_step_train: [ 45/180] Final Prec@1 76.2400% Time 122.52
09/21 02:09:30 PM | Valid: [ 45/180] Step 050/312 Loss 3.531 Prec@(1,3) (74.0%, 98.3%), ce_loss 0.895, lat_loss 22.104
09/21 02:09:35 PM | Valid: [ 45/180] Step 100/312 Loss 3.757 Prec@(1,3) (72.4%, 97.6%), ce_loss 0.895, lat_loss 22.104
09/21 02:09:40 PM | Valid: [ 45/180] Step 150/312 Loss 3.694 Prec@(1,3) (72.9%, 97.6%), ce_loss 0.895, lat_loss 22.104
09/21 02:09:44 PM | Valid: [ 45/180] Step 200/312 Loss 3.739 Prec@(1,3) (72.3%, 97.5%), ce_loss 0.895, lat_loss 22.104
09/21 02:09:49 PM | Valid: [ 45/180] Step 250/312 Loss 3.763 Prec@(1,3) (72.2%, 97.5%), ce_loss 0.895, lat_loss 22.104
09/21 02:09:54 PM | Valid: [ 45/180] Step 300/312 Loss 3.715 Prec@(1,3) (72.5%, 97.6%), ce_loss 0.895, lat_loss 22.104
09/21 02:09:55 PM | Valid: [ 45/180] Step 312/312 Loss 3.714 Prec@(1,3) (72.5%, 97.6%), ce_loss 0.895, lat_loss 22.104
09/21 02:09:55 PM | val: [ 45/180] Final Prec@1 72.5500% Time 29.97
09/21 02:09:55 PM | Start to train weights for epoch 45
09/21 02:10:20 PM | Train: [ 46/180] Step 050/1249 Loss 2.944 Prec@(1,3) (76.8%, 98.2%), ce_loss 0.895, lat_loss 22.104
09/21 02:10:42 PM | Train: [ 46/180] Step 100/1249 Loss 2.985 Prec@(1,3) (77.1%, 98.6%), ce_loss 0.895, lat_loss 22.104
09/21 02:11:05 PM | Train: [ 46/180] Step 150/1249 Loss 3.011 Prec@(1,3) (76.9%, 98.6%), ce_loss 0.895, lat_loss 22.104
09/21 02:11:28 PM | Train: [ 46/180] Step 200/1249 Loss 3.016 Prec@(1,3) (76.8%, 98.6%), ce_loss 0.894, lat_loss 22.104
09/21 02:11:50 PM | Train: [ 46/180] Step 250/1249 Loss 2.995 Prec@(1,3) (77.1%, 98.5%), ce_loss 0.894, lat_loss 22.103
09/21 02:12:13 PM | Train: [ 46/180] Step 300/1249 Loss 2.940 Prec@(1,3) (77.5%, 98.6%), ce_loss 0.894, lat_loss 22.103
09/21 02:12:36 PM | Train: [ 46/180] Step 350/1249 Loss 2.960 Prec@(1,3) (77.3%, 98.6%), ce_loss 0.894, lat_loss 22.103
09/21 02:12:59 PM | Train: [ 46/180] Step 400/1249 Loss 2.955 Prec@(1,3) (77.4%, 98.6%), ce_loss 0.894, lat_loss 22.103
09/21 02:13:22 PM | Train: [ 46/180] Step 450/1249 Loss 2.961 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.894, lat_loss 22.103
09/21 02:13:45 PM | Train: [ 46/180] Step 500/1249 Loss 2.971 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.894, lat_loss 22.103
09/21 02:14:09 PM | Train: [ 46/180] Step 550/1249 Loss 2.989 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.893, lat_loss 22.103
09/21 02:14:33 PM | Train: [ 46/180] Step 600/1249 Loss 2.981 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.893, lat_loss 22.103
09/21 02:14:57 PM | Train: [ 46/180] Step 650/1249 Loss 2.985 Prec@(1,3) (77.2%, 98.5%), ce_loss 0.893, lat_loss 22.103
09/21 02:15:22 PM | Train: [ 46/180] Step 700/1249 Loss 2.988 Prec@(1,3) (77.2%, 98.5%), ce_loss 0.893, lat_loss 22.103
09/21 02:15:47 PM | Train: [ 46/180] Step 750/1249 Loss 2.991 Prec@(1,3) (77.2%, 98.5%), ce_loss 0.893, lat_loss 22.103
09/21 02:16:11 PM | Train: [ 46/180] Step 800/1249 Loss 2.992 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.893, lat_loss 22.103
09/21 02:16:35 PM | Train: [ 46/180] Step 850/1249 Loss 2.994 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.893, lat_loss 22.103
09/21 02:17:00 PM | Train: [ 46/180] Step 900/1249 Loss 2.991 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.892, lat_loss 22.103
09/21 02:17:25 PM | Train: [ 46/180] Step 950/1249 Loss 2.989 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.892, lat_loss 22.103
09/21 02:17:48 PM | Train: [ 46/180] Step 1000/1249 Loss 2.996 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.892, lat_loss 22.103
09/21 02:18:09 PM | Train: [ 46/180] Step 1050/1249 Loss 2.997 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.892, lat_loss 22.102
09/21 02:18:33 PM | Train: [ 46/180] Step 1100/1249 Loss 2.993 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.892, lat_loss 22.102
09/21 02:18:58 PM | Train: [ 46/180] Step 1150/1249 Loss 3.011 Prec@(1,3) (77.3%, 98.4%), ce_loss 0.892, lat_loss 22.102
09/21 02:19:21 PM | Train: [ 46/180] Step 1200/1249 Loss 3.008 Prec@(1,3) (77.3%, 98.4%), ce_loss 0.892, lat_loss 22.102
09/21 02:19:45 PM | Train: [ 46/180] Step 1249/1249 Loss 3.008 Prec@(1,3) (77.3%, 98.4%), ce_loss 0.892, lat_loss 22.102
09/21 02:19:46 PM | _w_step_train: [ 46/180] Final Prec@1 77.3350% Time 590.69
09/21 02:19:46 PM | Start to train theta for epoch 45
09/21 02:20:02 PM | Train: [ 46/180] Step 050/312 Loss 3.218 Prec@(1,3) (74.4%, 98.5%), ce_loss 0.892, lat_loss 22.102
09/21 02:20:20 PM | Train: [ 46/180] Step 100/312 Loss 3.095 Prec@(1,3) (75.6%, 98.4%), ce_loss 0.891, lat_loss 22.102
09/21 02:20:39 PM | Train: [ 46/180] Step 150/312 Loss 3.053 Prec@(1,3) (76.1%, 98.4%), ce_loss 0.891, lat_loss 22.102
09/21 02:20:58 PM | Train: [ 46/180] Step 200/312 Loss 3.108 Prec@(1,3) (75.9%, 98.3%), ce_loss 0.891, lat_loss 22.102
09/21 02:21:17 PM | Train: [ 46/180] Step 250/312 Loss 3.092 Prec@(1,3) (76.1%, 98.3%), ce_loss 0.891, lat_loss 22.102
09/21 02:21:38 PM | Train: [ 46/180] Step 300/312 Loss 3.132 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.891, lat_loss 22.102
09/21 02:21:43 PM | Train: [ 46/180] Step 312/312 Loss 3.125 Prec@(1,3) (76.0%, 98.2%), ce_loss 0.891, lat_loss 22.102
09/21 02:21:43 PM | _theta_step_train: [ 46/180] Final Prec@1 76.0200% Time 117.84
09/21 02:21:49 PM | Valid: [ 46/180] Step 050/312 Loss 3.809 Prec@(1,3) (70.8%, 97.5%), ce_loss 0.891, lat_loss 22.102
09/21 02:21:54 PM | Valid: [ 46/180] Step 100/312 Loss 3.888 Prec@(1,3) (70.9%, 97.0%), ce_loss 0.891, lat_loss 22.102
09/21 02:21:58 PM | Valid: [ 46/180] Step 150/312 Loss 3.909 Prec@(1,3) (71.6%, 97.1%), ce_loss 0.891, lat_loss 22.102
09/21 02:22:03 PM | Valid: [ 46/180] Step 200/312 Loss 3.849 Prec@(1,3) (71.9%, 97.2%), ce_loss 0.891, lat_loss 22.101
09/21 02:22:08 PM | Valid: [ 46/180] Step 250/312 Loss 3.782 Prec@(1,3) (72.1%, 97.3%), ce_loss 0.891, lat_loss 22.101
09/21 02:22:12 PM | Valid: [ 46/180] Step 300/312 Loss 3.783 Prec@(1,3) (71.8%, 97.2%), ce_loss 0.891, lat_loss 22.101
09/21 02:22:13 PM | Valid: [ 46/180] Step 312/312 Loss 3.767 Prec@(1,3) (72.0%, 97.2%), ce_loss 0.891, lat_loss 22.101
09/21 02:22:13 PM | val: [ 46/180] Final Prec@1 71.9700% Time 29.88
09/21 02:22:13 PM | Start to train weights for epoch 46
09/21 02:22:40 PM | Train: [ 47/180] Step 050/1249 Loss 2.947 Prec@(1,3) (77.0%, 98.6%), ce_loss 0.891, lat_loss 22.101
09/21 02:23:03 PM | Train: [ 47/180] Step 100/1249 Loss 2.792 Prec@(1,3) (78.4%, 98.7%), ce_loss 0.890, lat_loss 22.101
09/21 02:23:28 PM | Train: [ 47/180] Step 150/1249 Loss 2.795 Prec@(1,3) (78.8%, 98.7%), ce_loss 0.890, lat_loss 22.101
09/21 02:23:52 PM | Train: [ 47/180] Step 200/1249 Loss 2.925 Prec@(1,3) (77.8%, 98.6%), ce_loss 0.890, lat_loss 22.101
09/21 02:24:16 PM | Train: [ 47/180] Step 250/1249 Loss 2.923 Prec@(1,3) (77.8%, 98.6%), ce_loss 0.890, lat_loss 22.101
09/21 02:24:39 PM | Train: [ 47/180] Step 300/1249 Loss 2.982 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.890, lat_loss 22.101
09/21 02:25:01 PM | Train: [ 47/180] Step 350/1249 Loss 2.969 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.890, lat_loss 22.101
09/21 02:25:23 PM | Train: [ 47/180] Step 400/1249 Loss 2.991 Prec@(1,3) (77.2%, 98.5%), ce_loss 0.890, lat_loss 22.101
09/21 02:25:45 PM | Train: [ 47/180] Step 450/1249 Loss 2.980 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.890, lat_loss 22.101
09/21 02:26:09 PM | Train: [ 47/180] Step 500/1249 Loss 2.968 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.889, lat_loss 22.101
09/21 02:26:32 PM | Train: [ 47/180] Step 550/1249 Loss 2.982 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.889, lat_loss 22.101
09/21 02:26:55 PM | Train: [ 47/180] Step 600/1249 Loss 2.974 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.889, lat_loss 22.100
09/21 02:27:18 PM | Train: [ 47/180] Step 650/1249 Loss 2.975 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.889, lat_loss 22.100
09/21 02:27:42 PM | Train: [ 47/180] Step 700/1249 Loss 2.967 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.889, lat_loss 22.100
09/21 02:28:03 PM | Train: [ 47/180] Step 750/1249 Loss 2.978 Prec@(1,3) (77.2%, 98.5%), ce_loss 0.889, lat_loss 22.100
09/21 02:28:24 PM | Train: [ 47/180] Step 800/1249 Loss 2.976 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.889, lat_loss 22.100
09/21 02:28:44 PM | Train: [ 47/180] Step 850/1249 Loss 2.975 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.889, lat_loss 22.100
09/21 02:29:05 PM | Train: [ 47/180] Step 900/1249 Loss 2.979 Prec@(1,3) (77.2%, 98.5%), ce_loss 0.888, lat_loss 22.100
09/21 02:29:25 PM | Train: [ 47/180] Step 950/1249 Loss 2.991 Prec@(1,3) (77.2%, 98.5%), ce_loss 0.888, lat_loss 22.100
09/21 02:29:48 PM | Train: [ 47/180] Step 1000/1249 Loss 2.998 Prec@(1,3) (77.1%, 98.4%), ce_loss 0.888, lat_loss 22.100
09/21 02:30:12 PM | Train: [ 47/180] Step 1050/1249 Loss 3.000 Prec@(1,3) (77.1%, 98.4%), ce_loss 0.888, lat_loss 22.100
09/21 02:30:34 PM | Train: [ 47/180] Step 1100/1249 Loss 2.986 Prec@(1,3) (77.2%, 98.4%), ce_loss 0.888, lat_loss 22.100
09/21 02:30:57 PM | Train: [ 47/180] Step 1150/1249 Loss 2.992 Prec@(1,3) (77.2%, 98.4%), ce_loss 0.888, lat_loss 22.100
09/21 02:31:19 PM | Train: [ 47/180] Step 1200/1249 Loss 2.997 Prec@(1,3) (77.1%, 98.4%), ce_loss 0.888, lat_loss 22.100
09/21 02:31:43 PM | Train: [ 47/180] Step 1249/1249 Loss 2.995 Prec@(1,3) (77.2%, 98.4%), ce_loss 0.888, lat_loss 22.100
09/21 02:31:43 PM | _w_step_train: [ 47/180] Final Prec@1 77.1550% Time 570.14
09/21 02:31:43 PM | Start to train theta for epoch 46
09/21 02:32:04 PM | Train: [ 47/180] Step 050/312 Loss 3.141 Prec@(1,3) (77.1%, 98.7%), ce_loss 0.887, lat_loss 22.100
09/21 02:32:22 PM | Train: [ 47/180] Step 100/312 Loss 3.200 Prec@(1,3) (76.3%, 98.5%), ce_loss 0.887, lat_loss 22.099
09/21 02:32:38 PM | Train: [ 47/180] Step 150/312 Loss 3.282 Prec@(1,3) (75.9%, 98.4%), ce_loss 0.887, lat_loss 22.099
09/21 02:32:57 PM | Train: [ 47/180] Step 200/312 Loss 3.250 Prec@(1,3) (75.6%, 98.4%), ce_loss 0.887, lat_loss 22.099
09/21 02:33:15 PM | Train: [ 47/180] Step 250/312 Loss 3.262 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.887, lat_loss 22.099
09/21 02:33:33 PM | Train: [ 47/180] Step 300/312 Loss 3.263 Prec@(1,3) (75.8%, 98.3%), ce_loss 0.887, lat_loss 22.099
09/21 02:33:38 PM | Train: [ 47/180] Step 312/312 Loss 3.247 Prec@(1,3) (75.9%, 98.3%), ce_loss 0.887, lat_loss 22.099
09/21 02:33:38 PM | _theta_step_train: [ 47/180] Final Prec@1 75.9100% Time 114.67
09/21 02:33:43 PM | Valid: [ 47/180] Step 050/312 Loss 3.967 Prec@(1,3) (69.6%, 97.4%), ce_loss 0.887, lat_loss 22.099
09/21 02:33:47 PM | Valid: [ 47/180] Step 100/312 Loss 4.028 Prec@(1,3) (70.6%, 96.7%), ce_loss 0.887, lat_loss 22.099
09/21 02:33:52 PM | Valid: [ 47/180] Step 150/312 Loss 3.951 Prec@(1,3) (71.3%, 97.0%), ce_loss 0.887, lat_loss 22.099
09/21 02:33:56 PM | Valid: [ 47/180] Step 200/312 Loss 3.931 Prec@(1,3) (71.7%, 97.2%), ce_loss 0.887, lat_loss 22.099
09/21 02:34:00 PM | Valid: [ 47/180] Step 250/312 Loss 3.984 Prec@(1,3) (70.8%, 97.0%), ce_loss 0.887, lat_loss 22.099
09/21 02:34:05 PM | Valid: [ 47/180] Step 300/312 Loss 3.926 Prec@(1,3) (71.3%, 97.0%), ce_loss 0.887, lat_loss 22.099
09/21 02:34:06 PM | Valid: [ 47/180] Step 312/312 Loss 3.937 Prec@(1,3) (71.1%, 97.0%), ce_loss 0.887, lat_loss 22.099
09/21 02:34:06 PM | val: [ 47/180] Final Prec@1 71.0700% Time 27.72
09/21 02:34:06 PM | Start to train weights for epoch 47
09/21 02:34:30 PM | Train: [ 48/180] Step 050/1249 Loss 3.121 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.887, lat_loss 22.099
09/21 02:34:50 PM | Train: [ 48/180] Step 100/1249 Loss 2.995 Prec@(1,3) (77.4%, 98.3%), ce_loss 0.887, lat_loss 22.099
09/21 02:35:11 PM | Train: [ 48/180] Step 150/1249 Loss 3.013 Prec@(1,3) (77.6%, 98.1%), ce_loss 0.887, lat_loss 22.099
09/21 02:35:32 PM | Train: [ 48/180] Step 200/1249 Loss 2.939 Prec@(1,3) (78.1%, 98.2%), ce_loss 0.886, lat_loss 22.099
09/21 02:35:55 PM | Train: [ 48/180] Step 250/1249 Loss 2.932 Prec@(1,3) (78.0%, 98.1%), ce_loss 0.886, lat_loss 22.098
09/21 02:36:18 PM | Train: [ 48/180] Step 300/1249 Loss 2.932 Prec@(1,3) (77.9%, 98.2%), ce_loss 0.886, lat_loss 22.098
09/21 02:36:42 PM | Train: [ 48/180] Step 350/1249 Loss 2.915 Prec@(1,3) (77.9%, 98.2%), ce_loss 0.886, lat_loss 22.098
09/21 02:37:06 PM | Train: [ 48/180] Step 400/1249 Loss 2.968 Prec@(1,3) (77.5%, 98.2%), ce_loss 0.886, lat_loss 22.098
09/21 02:37:31 PM | Train: [ 48/180] Step 450/1249 Loss 2.986 Prec@(1,3) (77.4%, 98.2%), ce_loss 0.886, lat_loss 22.098
09/21 02:37:55 PM | Train: [ 48/180] Step 500/1249 Loss 2.982 Prec@(1,3) (77.4%, 98.2%), ce_loss 0.886, lat_loss 22.098
09/21 02:38:19 PM | Train: [ 48/180] Step 550/1249 Loss 2.972 Prec@(1,3) (77.5%, 98.2%), ce_loss 0.886, lat_loss 22.098
09/21 02:38:42 PM | Train: [ 48/180] Step 600/1249 Loss 2.972 Prec@(1,3) (77.6%, 98.2%), ce_loss 0.885, lat_loss 22.098
09/21 02:39:06 PM | Train: [ 48/180] Step 650/1249 Loss 2.976 Prec@(1,3) (77.6%, 98.2%), ce_loss 0.885, lat_loss 22.098
09/21 02:39:30 PM | Train: [ 48/180] Step 700/1249 Loss 2.985 Prec@(1,3) (77.5%, 98.2%), ce_loss 0.885, lat_loss 22.098
09/21 02:39:54 PM | Train: [ 48/180] Step 750/1249 Loss 3.001 Prec@(1,3) (77.4%, 98.3%), ce_loss 0.885, lat_loss 22.098
09/21 02:40:18 PM | Train: [ 48/180] Step 800/1249 Loss 2.999 Prec@(1,3) (77.3%, 98.3%), ce_loss 0.885, lat_loss 22.098
09/21 02:40:43 PM | Train: [ 48/180] Step 850/1249 Loss 2.993 Prec@(1,3) (77.4%, 98.3%), ce_loss 0.885, lat_loss 22.098
09/21 02:41:06 PM | Train: [ 48/180] Step 900/1249 Loss 2.994 Prec@(1,3) (77.3%, 98.3%), ce_loss 0.885, lat_loss 22.098
09/21 02:41:28 PM | Train: [ 48/180] Step 950/1249 Loss 2.997 Prec@(1,3) (77.3%, 98.3%), ce_loss 0.885, lat_loss 22.098
09/21 02:41:50 PM | Train: [ 48/180] Step 1000/1249 Loss 2.991 Prec@(1,3) (77.3%, 98.3%), ce_loss 0.885, lat_loss 22.098
09/21 02:42:14 PM | Train: [ 48/180] Step 1050/1249 Loss 2.986 Prec@(1,3) (77.4%, 98.3%), ce_loss 0.884, lat_loss 22.097
09/21 02:42:39 PM | Train: [ 48/180] Step 1100/1249 Loss 2.993 Prec@(1,3) (77.3%, 98.3%), ce_loss 0.884, lat_loss 22.097
09/21 02:43:03 PM | Train: [ 48/180] Step 1150/1249 Loss 2.990 Prec@(1,3) (77.3%, 98.3%), ce_loss 0.884, lat_loss 22.097
09/21 02:43:27 PM | Train: [ 48/180] Step 1200/1249 Loss 3.001 Prec@(1,3) (77.2%, 98.3%), ce_loss 0.884, lat_loss 22.097
09/21 02:43:52 PM | Train: [ 48/180] Step 1249/1249 Loss 2.994 Prec@(1,3) (77.2%, 98.3%), ce_loss 0.884, lat_loss 22.097
09/21 02:43:52 PM | _w_step_train: [ 48/180] Final Prec@1 77.2150% Time 585.82
09/21 02:43:52 PM | Start to train theta for epoch 47
09/21 02:44:05 PM | Train: [ 48/180] Step 050/312 Loss 2.918 Prec@(1,3) (77.7%, 98.4%), ce_loss 0.884, lat_loss 22.097
09/21 02:44:19 PM | Train: [ 48/180] Step 100/312 Loss 3.096 Prec@(1,3) (76.4%, 98.3%), ce_loss 0.884, lat_loss 22.097
09/21 02:44:40 PM | Train: [ 48/180] Step 150/312 Loss 3.063 Prec@(1,3) (76.5%, 98.5%), ce_loss 0.884, lat_loss 22.097
09/21 02:45:01 PM | Train: [ 48/180] Step 200/312 Loss 3.079 Prec@(1,3) (76.2%, 98.6%), ce_loss 0.883, lat_loss 22.097
09/21 02:45:21 PM | Train: [ 48/180] Step 250/312 Loss 3.072 Prec@(1,3) (76.3%, 98.5%), ce_loss 0.883, lat_loss 22.097
09/21 02:45:41 PM | Train: [ 48/180] Step 300/312 Loss 3.072 Prec@(1,3) (76.4%, 98.4%), ce_loss 0.883, lat_loss 22.097
09/21 02:45:46 PM | Train: [ 48/180] Step 312/312 Loss 3.059 Prec@(1,3) (76.5%, 98.4%), ce_loss 0.883, lat_loss 22.097
09/21 02:45:47 PM | _theta_step_train: [ 48/180] Final Prec@1 76.5300% Time 114.74
09/21 02:45:52 PM | Valid: [ 48/180] Step 050/312 Loss 3.512 Prec@(1,3) (72.6%, 98.0%), ce_loss 0.883, lat_loss 22.097
09/21 02:45:56 PM | Valid: [ 48/180] Step 100/312 Loss 3.772 Prec@(1,3) (70.9%, 97.4%), ce_loss 0.883, lat_loss 22.097
09/21 02:46:01 PM | Valid: [ 48/180] Step 150/312 Loss 3.744 Prec@(1,3) (71.2%, 97.1%), ce_loss 0.883, lat_loss 22.096
09/21 02:46:06 PM | Valid: [ 48/180] Step 200/312 Loss 3.717 Prec@(1,3) (71.4%, 97.2%), ce_loss 0.883, lat_loss 22.096
09/21 02:46:11 PM | Valid: [ 48/180] Step 250/312 Loss 3.645 Prec@(1,3) (71.9%, 97.4%), ce_loss 0.883, lat_loss 22.096
09/21 02:46:15 PM | Valid: [ 48/180] Step 300/312 Loss 3.612 Prec@(1,3) (72.4%, 97.5%), ce_loss 0.883, lat_loss 22.096
09/21 02:46:16 PM | Valid: [ 48/180] Step 312/312 Loss 3.622 Prec@(1,3) (72.2%, 97.5%), ce_loss 0.883, lat_loss 22.096
09/21 02:46:16 PM | val: [ 48/180] Final Prec@1 72.1900% Time 29.88
09/21 02:46:16 PM | Start to train weights for epoch 48
09/21 02:46:42 PM | Train: [ 49/180] Step 050/1249 Loss 2.848 Prec@(1,3) (78.1%, 98.5%), ce_loss 0.883, lat_loss 22.096
09/21 02:47:04 PM | Train: [ 49/180] Step 100/1249 Loss 2.997 Prec@(1,3) (77.3%, 98.2%), ce_loss 0.883, lat_loss 22.096
09/21 02:47:26 PM | Train: [ 49/180] Step 150/1249 Loss 2.946 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.883, lat_loss 22.096
09/21 02:47:49 PM | Train: [ 49/180] Step 200/1249 Loss 2.953 Prec@(1,3) (77.5%, 98.6%), ce_loss 0.882, lat_loss 22.096
09/21 02:48:11 PM | Train: [ 49/180] Step 250/1249 Loss 2.970 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.882, lat_loss 22.096
09/21 02:48:32 PM | Train: [ 49/180] Step 300/1249 Loss 2.975 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.882, lat_loss 22.096
09/21 02:48:54 PM | Train: [ 49/180] Step 350/1249 Loss 2.981 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.882, lat_loss 22.096
09/21 02:49:18 PM | Train: [ 49/180] Step 400/1249 Loss 2.949 Prec@(1,3) (77.6%, 98.5%), ce_loss 0.882, lat_loss 22.096
09/21 02:49:40 PM | Train: [ 49/180] Step 450/1249 Loss 2.956 Prec@(1,3) (77.6%, 98.4%), ce_loss 0.882, lat_loss 22.096
09/21 02:50:03 PM | Train: [ 49/180] Step 500/1249 Loss 2.971 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.882, lat_loss 22.096
09/21 02:50:25 PM | Train: [ 49/180] Step 550/1249 Loss 2.999 Prec@(1,3) (77.3%, 98.4%), ce_loss 0.882, lat_loss 22.095
09/21 02:50:47 PM | Train: [ 49/180] Step 600/1249 Loss 3.010 Prec@(1,3) (77.2%, 98.4%), ce_loss 0.882, lat_loss 22.095
09/21 02:51:10 PM | Train: [ 49/180] Step 650/1249 Loss 2.997 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.881, lat_loss 22.095
09/21 02:51:31 PM | Train: [ 49/180] Step 700/1249 Loss 2.988 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.881, lat_loss 22.095
09/21 02:51:53 PM | Train: [ 49/180] Step 750/1249 Loss 2.989 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.881, lat_loss 22.095
09/21 02:52:16 PM | Train: [ 49/180] Step 800/1249 Loss 2.987 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.881, lat_loss 22.095
09/21 02:52:39 PM | Train: [ 49/180] Step 850/1249 Loss 2.977 Prec@(1,3) (77.6%, 98.4%), ce_loss 0.881, lat_loss 22.095
09/21 02:53:03 PM | Train: [ 49/180] Step 900/1249 Loss 2.967 Prec@(1,3) (77.8%, 98.4%), ce_loss 0.881, lat_loss 22.095
09/21 02:53:27 PM | Train: [ 49/180] Step 950/1249 Loss 2.961 Prec@(1,3) (77.8%, 98.4%), ce_loss 0.881, lat_loss 22.095
09/21 02:53:48 PM | Train: [ 49/180] Step 1000/1249 Loss 2.966 Prec@(1,3) (77.7%, 98.4%), ce_loss 0.881, lat_loss 22.095
09/21 02:54:10 PM | Train: [ 49/180] Step 1050/1249 Loss 2.967 Prec@(1,3) (77.7%, 98.4%), ce_loss 0.880, lat_loss 22.095
09/21 02:54:32 PM | Train: [ 49/180] Step 1100/1249 Loss 2.961 Prec@(1,3) (77.7%, 98.4%), ce_loss 0.880, lat_loss 22.095
09/21 02:54:54 PM | Train: [ 49/180] Step 1150/1249 Loss 2.965 Prec@(1,3) (77.6%, 98.4%), ce_loss 0.880, lat_loss 22.095
09/21 02:55:17 PM | Train: [ 49/180] Step 1200/1249 Loss 2.960 Prec@(1,3) (77.6%, 98.4%), ce_loss 0.880, lat_loss 22.095
09/21 02:55:42 PM | Train: [ 49/180] Step 1249/1249 Loss 2.952 Prec@(1,3) (77.6%, 98.4%), ce_loss 0.880, lat_loss 22.094
09/21 02:55:42 PM | _w_step_train: [ 49/180] Final Prec@1 77.6450% Time 565.52
09/21 02:55:42 PM | Start to train theta for epoch 48
09/21 02:56:01 PM | Train: [ 49/180] Step 050/312 Loss 3.304 Prec@(1,3) (74.6%, 97.7%), ce_loss 0.880, lat_loss 22.094
09/21 02:56:20 PM | Train: [ 49/180] Step 100/312 Loss 3.371 Prec@(1,3) (74.4%, 97.7%), ce_loss 0.880, lat_loss 22.094
09/21 02:56:41 PM | Train: [ 49/180] Step 150/312 Loss 3.370 Prec@(1,3) (74.4%, 97.7%), ce_loss 0.880, lat_loss 22.094
09/21 02:57:02 PM | Train: [ 49/180] Step 200/312 Loss 3.306 Prec@(1,3) (74.9%, 97.8%), ce_loss 0.880, lat_loss 22.094
09/21 02:57:23 PM | Train: [ 49/180] Step 250/312 Loss 3.256 Prec@(1,3) (75.4%, 98.0%), ce_loss 0.879, lat_loss 22.094
09/21 02:57:43 PM | Train: [ 49/180] Step 300/312 Loss 3.231 Prec@(1,3) (75.7%, 98.0%), ce_loss 0.879, lat_loss 22.094
09/21 02:57:48 PM | Train: [ 49/180] Step 312/312 Loss 3.223 Prec@(1,3) (75.7%, 98.0%), ce_loss 0.879, lat_loss 22.094
09/21 02:57:48 PM | _theta_step_train: [ 49/180] Final Prec@1 75.7200% Time 126.17
09/21 02:57:53 PM | Valid: [ 49/180] Step 050/312 Loss 3.912 Prec@(1,3) (71.6%, 96.4%), ce_loss 0.879, lat_loss 22.094
09/21 02:57:58 PM | Valid: [ 49/180] Step 100/312 Loss 3.826 Prec@(1,3) (72.2%, 96.5%), ce_loss 0.879, lat_loss 22.094
09/21 02:58:03 PM | Valid: [ 49/180] Step 150/312 Loss 3.815 Prec@(1,3) (72.2%, 96.5%), ce_loss 0.879, lat_loss 22.094
09/21 02:58:07 PM | Valid: [ 49/180] Step 200/312 Loss 3.858 Prec@(1,3) (72.0%, 96.5%), ce_loss 0.879, lat_loss 22.094
09/21 02:58:12 PM | Valid: [ 49/180] Step 250/312 Loss 3.836 Prec@(1,3) (72.2%, 96.6%), ce_loss 0.879, lat_loss 22.093
09/21 02:58:17 PM | Valid: [ 49/180] Step 300/312 Loss 3.779 Prec@(1,3) (72.6%, 96.8%), ce_loss 0.879, lat_loss 22.093
09/21 02:58:18 PM | Valid: [ 49/180] Step 312/312 Loss 3.777 Prec@(1,3) (72.6%, 96.8%), ce_loss 0.879, lat_loss 22.093
09/21 02:58:18 PM | val: [ 49/180] Final Prec@1 72.6300% Time 29.92
09/21 02:58:18 PM | Start to train weights for epoch 49
09/21 02:58:44 PM | Train: [ 50/180] Step 050/1249 Loss 3.051 Prec@(1,3) (76.5%, 98.2%), ce_loss 0.879, lat_loss 22.093
09/21 02:59:09 PM | Train: [ 50/180] Step 100/1249 Loss 3.022 Prec@(1,3) (77.0%, 98.1%), ce_loss 0.879, lat_loss 22.093
09/21 02:59:33 PM | Train: [ 50/180] Step 150/1249 Loss 2.961 Prec@(1,3) (77.4%, 98.3%), ce_loss 0.879, lat_loss 22.093
09/21 02:59:58 PM | Train: [ 50/180] Step 200/1249 Loss 2.954 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.879, lat_loss 22.093
09/21 03:00:22 PM | Train: [ 50/180] Step 250/1249 Loss 2.961 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.879, lat_loss 22.093
09/21 03:00:43 PM | Train: [ 50/180] Step 300/1249 Loss 2.982 Prec@(1,3) (77.3%, 98.4%), ce_loss 0.879, lat_loss 22.093
09/21 03:00:59 PM | Train: [ 50/180] Step 350/1249 Loss 2.994 Prec@(1,3) (77.2%, 98.4%), ce_loss 0.878, lat_loss 22.093
09/21 03:01:15 PM | Train: [ 50/180] Step 400/1249 Loss 2.992 Prec@(1,3) (77.3%, 98.3%), ce_loss 0.878, lat_loss 22.093
09/21 03:01:31 PM | Train: [ 50/180] Step 450/1249 Loss 2.972 Prec@(1,3) (77.4%, 98.3%), ce_loss 0.878, lat_loss 22.092
09/21 03:01:47 PM | Train: [ 50/180] Step 500/1249 Loss 2.970 Prec@(1,3) (77.3%, 98.3%), ce_loss 0.878, lat_loss 22.092
09/21 03:02:03 PM | Train: [ 50/180] Step 550/1249 Loss 2.979 Prec@(1,3) (77.3%, 98.3%), ce_loss 0.878, lat_loss 22.092
09/21 03:02:19 PM | Train: [ 50/180] Step 600/1249 Loss 2.975 Prec@(1,3) (77.3%, 98.2%), ce_loss 0.878, lat_loss 22.092
09/21 03:02:35 PM | Train: [ 50/180] Step 650/1249 Loss 2.974 Prec@(1,3) (77.3%, 98.3%), ce_loss 0.878, lat_loss 22.092
09/21 03:02:51 PM | Train: [ 50/180] Step 700/1249 Loss 2.971 Prec@(1,3) (77.4%, 98.2%), ce_loss 0.878, lat_loss 22.092
09/21 03:03:08 PM | Train: [ 50/180] Step 750/1249 Loss 2.961 Prec@(1,3) (77.5%, 98.2%), ce_loss 0.878, lat_loss 22.092
09/21 03:03:24 PM | Train: [ 50/180] Step 800/1249 Loss 2.949 Prec@(1,3) (77.7%, 98.3%), ce_loss 0.877, lat_loss 22.092
09/21 03:03:40 PM | Train: [ 50/180] Step 850/1249 Loss 2.950 Prec@(1,3) (77.6%, 98.3%), ce_loss 0.877, lat_loss 22.092
09/21 03:03:56 PM | Train: [ 50/180] Step 900/1249 Loss 2.957 Prec@(1,3) (77.6%, 98.3%), ce_loss 0.877, lat_loss 22.092
09/21 03:04:12 PM | Train: [ 50/180] Step 950/1249 Loss 2.951 Prec@(1,3) (77.6%, 98.3%), ce_loss 0.877, lat_loss 22.092
09/21 03:04:28 PM | Train: [ 50/180] Step 1000/1249 Loss 2.939 Prec@(1,3) (77.7%, 98.3%), ce_loss 0.877, lat_loss 22.092
09/21 03:04:44 PM | Train: [ 50/180] Step 1050/1249 Loss 2.950 Prec@(1,3) (77.7%, 98.3%), ce_loss 0.877, lat_loss 22.091
09/21 03:05:00 PM | Train: [ 50/180] Step 1100/1249 Loss 2.953 Prec@(1,3) (77.6%, 98.3%), ce_loss 0.877, lat_loss 22.091
09/21 03:05:17 PM | Train: [ 50/180] Step 1150/1249 Loss 2.953 Prec@(1,3) (77.6%, 98.3%), ce_loss 0.877, lat_loss 22.091
09/21 03:05:33 PM | Train: [ 50/180] Step 1200/1249 Loss 2.952 Prec@(1,3) (77.6%, 98.4%), ce_loss 0.876, lat_loss 22.091
09/21 03:05:49 PM | Train: [ 50/180] Step 1249/1249 Loss 2.956 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.876, lat_loss 22.091
09/21 03:05:49 PM | _w_step_train: [ 50/180] Final Prec@1 77.5425% Time 451.33
09/21 03:05:49 PM | Start to train theta for epoch 49
09/21 03:06:10 PM | Train: [ 50/180] Step 050/312 Loss 3.168 Prec@(1,3) (76.2%, 98.5%), ce_loss 0.876, lat_loss 22.091
09/21 03:06:29 PM | Train: [ 50/180] Step 100/312 Loss 3.090 Prec@(1,3) (77.2%, 98.3%), ce_loss 0.876, lat_loss 22.091
09/21 03:06:48 PM | Train: [ 50/180] Step 150/312 Loss 3.087 Prec@(1,3) (76.9%, 98.1%), ce_loss 0.876, lat_loss 22.091
09/21 03:07:05 PM | Train: [ 50/180] Step 200/312 Loss 3.127 Prec@(1,3) (76.7%, 98.0%), ce_loss 0.876, lat_loss 22.091
09/21 03:07:23 PM | Train: [ 50/180] Step 250/312 Loss 3.173 Prec@(1,3) (76.5%, 97.9%), ce_loss 0.876, lat_loss 22.091
09/21 03:07:41 PM | Train: [ 50/180] Step 300/312 Loss 3.148 Prec@(1,3) (76.7%, 98.0%), ce_loss 0.876, lat_loss 22.091
09/21 03:07:46 PM | Train: [ 50/180] Step 312/312 Loss 3.125 Prec@(1,3) (76.8%, 98.1%), ce_loss 0.876, lat_loss 22.091
09/21 03:07:47 PM | _theta_step_train: [ 50/180] Final Prec@1 76.8000% Time 117.47
09/21 03:07:52 PM | Valid: [ 50/180] Step 050/312 Loss 3.866 Prec@(1,3) (71.0%, 96.6%), ce_loss 0.876, lat_loss 22.090
09/21 03:07:57 PM | Valid: [ 50/180] Step 100/312 Loss 3.780 Prec@(1,3) (72.0%, 97.1%), ce_loss 0.876, lat_loss 22.090
09/21 03:08:02 PM | Valid: [ 50/180] Step 150/312 Loss 3.761 Prec@(1,3) (72.5%, 97.1%), ce_loss 0.876, lat_loss 22.090
09/21 03:08:06 PM | Valid: [ 50/180] Step 200/312 Loss 3.755 Prec@(1,3) (71.9%, 97.3%), ce_loss 0.876, lat_loss 22.090
09/21 03:08:11 PM | Valid: [ 50/180] Step 250/312 Loss 3.816 Prec@(1,3) (71.0%, 97.3%), ce_loss 0.876, lat_loss 22.090
09/21 03:08:16 PM | Valid: [ 50/180] Step 300/312 Loss 3.782 Prec@(1,3) (71.2%, 97.4%), ce_loss 0.876, lat_loss 22.090
09/21 03:08:17 PM | Valid: [ 50/180] Step 312/312 Loss 3.792 Prec@(1,3) (71.2%, 97.4%), ce_loss 0.876, lat_loss 22.090
09/21 03:08:17 PM | val: [ 50/180] Final Prec@1 71.2100% Time 30.01
09/21 03:08:17 PM | Start to train weights for epoch 50
09/21 03:08:42 PM | Train: [ 51/180] Step 050/1249 Loss 2.838 Prec@(1,3) (77.0%, 98.5%), ce_loss 0.876, lat_loss 22.090
09/21 03:09:06 PM | Train: [ 51/180] Step 100/1249 Loss 3.009 Prec@(1,3) (76.3%, 98.4%), ce_loss 0.875, lat_loss 22.090
09/21 03:09:30 PM | Train: [ 51/180] Step 150/1249 Loss 2.968 Prec@(1,3) (77.1%, 98.4%), ce_loss 0.875, lat_loss 22.090
09/21 03:09:53 PM | Train: [ 51/180] Step 200/1249 Loss 2.932 Prec@(1,3) (77.5%, 98.3%), ce_loss 0.875, lat_loss 22.090
09/21 03:10:16 PM | Train: [ 51/180] Step 250/1249 Loss 2.923 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.875, lat_loss 22.090
09/21 03:10:40 PM | Train: [ 51/180] Step 300/1249 Loss 2.923 Prec@(1,3) (77.6%, 98.4%), ce_loss 0.875, lat_loss 22.089
09/21 03:11:03 PM | Train: [ 51/180] Step 350/1249 Loss 2.879 Prec@(1,3) (78.0%, 98.5%), ce_loss 0.875, lat_loss 22.089
09/21 03:11:27 PM | Train: [ 51/180] Step 400/1249 Loss 2.906 Prec@(1,3) (77.8%, 98.5%), ce_loss 0.875, lat_loss 22.089
09/21 03:11:48 PM | Train: [ 51/180] Step 450/1249 Loss 2.939 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.875, lat_loss 22.089
09/21 03:12:09 PM | Train: [ 51/180] Step 500/1249 Loss 2.926 Prec@(1,3) (77.6%, 98.5%), ce_loss 0.875, lat_loss 22.089
09/21 03:12:31 PM | Train: [ 51/180] Step 550/1249 Loss 2.946 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.874, lat_loss 22.089
09/21 03:12:56 PM | Train: [ 51/180] Step 600/1249 Loss 2.945 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.874, lat_loss 22.089
09/21 03:13:20 PM | Train: [ 51/180] Step 650/1249 Loss 2.950 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.874, lat_loss 22.089
09/21 03:13:42 PM | Train: [ 51/180] Step 700/1249 Loss 2.952 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.874, lat_loss 22.089
09/21 03:14:06 PM | Train: [ 51/180] Step 750/1249 Loss 2.955 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.874, lat_loss 22.089
09/21 03:14:30 PM | Train: [ 51/180] Step 800/1249 Loss 2.958 Prec@(1,3) (77.3%, 98.4%), ce_loss 0.874, lat_loss 22.089
09/21 03:14:52 PM | Train: [ 51/180] Step 850/1249 Loss 2.961 Prec@(1,3) (77.3%, 98.4%), ce_loss 0.874, lat_loss 22.089
09/21 03:15:15 PM | Train: [ 51/180] Step 900/1249 Loss 2.953 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.874, lat_loss 22.088
09/21 03:15:39 PM | Train: [ 51/180] Step 950/1249 Loss 2.948 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.874, lat_loss 22.088
09/21 03:16:03 PM | Train: [ 51/180] Step 1000/1249 Loss 2.954 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.873, lat_loss 22.088
09/21 03:16:26 PM | Train: [ 51/180] Step 1050/1249 Loss 2.958 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.873, lat_loss 22.088
09/21 03:16:49 PM | Train: [ 51/180] Step 1100/1249 Loss 2.949 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.873, lat_loss 22.088
09/21 03:17:11 PM | Train: [ 51/180] Step 1150/1249 Loss 2.954 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.873, lat_loss 22.088
09/21 03:17:34 PM | Train: [ 51/180] Step 1200/1249 Loss 2.949 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.873, lat_loss 22.088
09/21 03:17:58 PM | Train: [ 51/180] Step 1249/1249 Loss 2.952 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.873, lat_loss 22.088
09/21 03:17:58 PM | _w_step_train: [ 51/180] Final Prec@1 77.4825% Time 581.58
09/21 03:17:58 PM | Start to train theta for epoch 50
09/21 03:18:19 PM | Train: [ 51/180] Step 050/312 Loss 3.060 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.873, lat_loss 22.088
09/21 03:18:38 PM | Train: [ 51/180] Step 100/312 Loss 3.101 Prec@(1,3) (76.5%, 98.2%), ce_loss 0.873, lat_loss 22.088
09/21 03:18:57 PM | Train: [ 51/180] Step 150/312 Loss 3.145 Prec@(1,3) (75.4%, 98.1%), ce_loss 0.873, lat_loss 22.088
09/21 03:19:17 PM | Train: [ 51/180] Step 200/312 Loss 3.135 Prec@(1,3) (75.6%, 98.0%), ce_loss 0.872, lat_loss 22.088
09/21 03:19:37 PM | Train: [ 51/180] Step 250/312 Loss 3.142 Prec@(1,3) (75.6%, 98.1%), ce_loss 0.872, lat_loss 22.087
09/21 03:19:57 PM | Train: [ 51/180] Step 300/312 Loss 3.142 Prec@(1,3) (75.8%, 98.0%), ce_loss 0.872, lat_loss 22.087
09/21 03:20:02 PM | Train: [ 51/180] Step 312/312 Loss 3.126 Prec@(1,3) (75.9%, 98.1%), ce_loss 0.872, lat_loss 22.087
09/21 03:20:02 PM | _theta_step_train: [ 51/180] Final Prec@1 75.9000% Time 123.64
09/21 03:20:07 PM | Valid: [ 51/180] Step 050/312 Loss 3.346 Prec@(1,3) (74.4%, 98.2%), ce_loss 0.872, lat_loss 22.087
09/21 03:20:12 PM | Valid: [ 51/180] Step 100/312 Loss 3.450 Prec@(1,3) (72.9%, 98.1%), ce_loss 0.872, lat_loss 22.087
09/21 03:20:17 PM | Valid: [ 51/180] Step 150/312 Loss 3.468 Prec@(1,3) (73.2%, 98.0%), ce_loss 0.872, lat_loss 22.087
09/21 03:20:21 PM | Valid: [ 51/180] Step 200/312 Loss 3.527 Prec@(1,3) (73.0%, 97.9%), ce_loss 0.872, lat_loss 22.087
09/21 03:20:26 PM | Valid: [ 51/180] Step 250/312 Loss 3.602 Prec@(1,3) (72.7%, 97.9%), ce_loss 0.872, lat_loss 22.087
09/21 03:20:31 PM | Valid: [ 51/180] Step 300/312 Loss 3.571 Prec@(1,3) (72.8%, 97.9%), ce_loss 0.872, lat_loss 22.087
09/21 03:20:32 PM | Valid: [ 51/180] Step 312/312 Loss 3.556 Prec@(1,3) (72.9%, 98.0%), ce_loss 0.872, lat_loss 22.087
09/21 03:20:32 PM | val: [ 51/180] Final Prec@1 72.8800% Time 29.54
09/21 03:20:32 PM | Start to train weights for epoch 51
09/21 03:20:58 PM | Train: [ 52/180] Step 050/1249 Loss 2.851 Prec@(1,3) (78.7%, 98.3%), ce_loss 0.872, lat_loss 22.087
09/21 03:21:23 PM | Train: [ 52/180] Step 100/1249 Loss 2.809 Prec@(1,3) (78.7%, 98.4%), ce_loss 0.872, lat_loss 22.087
09/21 03:21:48 PM | Train: [ 52/180] Step 150/1249 Loss 2.830 Prec@(1,3) (78.2%, 98.5%), ce_loss 0.872, lat_loss 22.087
09/21 03:22:13 PM | Train: [ 52/180] Step 200/1249 Loss 2.845 Prec@(1,3) (77.8%, 98.5%), ce_loss 0.872, lat_loss 22.086
09/21 03:22:39 PM | Train: [ 52/180] Step 250/1249 Loss 2.870 Prec@(1,3) (77.7%, 98.5%), ce_loss 0.871, lat_loss 22.086
09/21 03:23:03 PM | Train: [ 52/180] Step 300/1249 Loss 2.873 Prec@(1,3) (77.8%, 98.5%), ce_loss 0.871, lat_loss 22.086
09/21 03:23:26 PM | Train: [ 52/180] Step 350/1249 Loss 2.855 Prec@(1,3) (77.9%, 98.6%), ce_loss 0.871, lat_loss 22.086
09/21 03:23:49 PM | Train: [ 52/180] Step 400/1249 Loss 2.835 Prec@(1,3) (78.0%, 98.6%), ce_loss 0.871, lat_loss 22.086
09/21 03:24:12 PM | Train: [ 52/180] Step 450/1249 Loss 2.826 Prec@(1,3) (78.2%, 98.6%), ce_loss 0.871, lat_loss 22.086
09/21 03:24:34 PM | Train: [ 52/180] Step 500/1249 Loss 2.822 Prec@(1,3) (78.1%, 98.6%), ce_loss 0.871, lat_loss 22.086
09/21 03:24:57 PM | Train: [ 52/180] Step 550/1249 Loss 2.839 Prec@(1,3) (77.9%, 98.5%), ce_loss 0.871, lat_loss 22.086
09/21 03:25:21 PM | Train: [ 52/180] Step 600/1249 Loss 2.837 Prec@(1,3) (78.0%, 98.5%), ce_loss 0.871, lat_loss 22.086
09/21 03:25:43 PM | Train: [ 52/180] Step 650/1249 Loss 2.831 Prec@(1,3) (78.1%, 98.5%), ce_loss 0.870, lat_loss 22.086
09/21 03:26:06 PM | Train: [ 52/180] Step 700/1249 Loss 2.823 Prec@(1,3) (78.2%, 98.5%), ce_loss 0.870, lat_loss 22.086
09/21 03:26:28 PM | Train: [ 52/180] Step 750/1249 Loss 2.822 Prec@(1,3) (78.2%, 98.5%), ce_loss 0.870, lat_loss 22.085
09/21 03:26:53 PM | Train: [ 52/180] Step 800/1249 Loss 2.825 Prec@(1,3) (78.2%, 98.5%), ce_loss 0.870, lat_loss 22.085
09/21 03:27:17 PM | Train: [ 52/180] Step 850/1249 Loss 2.828 Prec@(1,3) (78.3%, 98.5%), ce_loss 0.870, lat_loss 22.085
09/21 03:27:42 PM | Train: [ 52/180] Step 900/1249 Loss 2.835 Prec@(1,3) (78.3%, 98.5%), ce_loss 0.870, lat_loss 22.085
09/21 03:28:07 PM | Train: [ 52/180] Step 950/1249 Loss 2.840 Prec@(1,3) (78.2%, 98.5%), ce_loss 0.870, lat_loss 22.085
09/21 03:28:32 PM | Train: [ 52/180] Step 1000/1249 Loss 2.839 Prec@(1,3) (78.3%, 98.5%), ce_loss 0.870, lat_loss 22.085
09/21 03:28:57 PM | Train: [ 52/180] Step 1050/1249 Loss 2.832 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.869, lat_loss 22.085
09/21 03:29:20 PM | Train: [ 52/180] Step 1100/1249 Loss 2.845 Prec@(1,3) (78.3%, 98.5%), ce_loss 0.869, lat_loss 22.085
09/21 03:29:44 PM | Train: [ 52/180] Step 1150/1249 Loss 2.844 Prec@(1,3) (78.3%, 98.5%), ce_loss 0.869, lat_loss 22.085
09/21 03:30:08 PM | Train: [ 52/180] Step 1200/1249 Loss 2.844 Prec@(1,3) (78.3%, 98.5%), ce_loss 0.869, lat_loss 22.085
09/21 03:30:32 PM | Train: [ 52/180] Step 1249/1249 Loss 2.845 Prec@(1,3) (78.3%, 98.5%), ce_loss 0.869, lat_loss 22.085
09/21 03:30:32 PM | _w_step_train: [ 52/180] Final Prec@1 78.3050% Time 600.53
09/21 03:30:32 PM | Start to train theta for epoch 51
09/21 03:30:54 PM | Train: [ 52/180] Step 050/312 Loss 3.346 Prec@(1,3) (74.5%, 97.9%), ce_loss 0.869, lat_loss 22.084
09/21 03:31:15 PM | Train: [ 52/180] Step 100/312 Loss 3.306 Prec@(1,3) (74.7%, 98.0%), ce_loss 0.869, lat_loss 22.084
09/21 03:31:35 PM | Train: [ 52/180] Step 150/312 Loss 3.172 Prec@(1,3) (75.7%, 97.9%), ce_loss 0.869, lat_loss 22.084
09/21 03:31:56 PM | Train: [ 52/180] Step 200/312 Loss 3.196 Prec@(1,3) (75.4%, 98.0%), ce_loss 0.869, lat_loss 22.084
09/21 03:32:17 PM | Train: [ 52/180] Step 250/312 Loss 3.148 Prec@(1,3) (75.8%, 98.0%), ce_loss 0.869, lat_loss 22.084
09/21 03:32:38 PM | Train: [ 52/180] Step 300/312 Loss 3.150 Prec@(1,3) (75.9%, 98.0%), ce_loss 0.868, lat_loss 22.084
09/21 03:32:43 PM | Train: [ 52/180] Step 312/312 Loss 3.152 Prec@(1,3) (75.9%, 98.0%), ce_loss 0.868, lat_loss 22.084
09/21 03:32:44 PM | _theta_step_train: [ 52/180] Final Prec@1 75.8700% Time 131.39
09/21 03:32:49 PM | Valid: [ 52/180] Step 050/312 Loss 3.372 Prec@(1,3) (75.6%, 98.2%), ce_loss 0.868, lat_loss 22.084
09/21 03:32:54 PM | Valid: [ 52/180] Step 100/312 Loss 3.421 Prec@(1,3) (75.2%, 98.1%), ce_loss 0.868, lat_loss 22.084
09/21 03:32:58 PM | Valid: [ 52/180] Step 150/312 Loss 3.422 Prec@(1,3) (74.6%, 97.9%), ce_loss 0.868, lat_loss 22.084
09/21 03:33:03 PM | Valid: [ 52/180] Step 200/312 Loss 3.416 Prec@(1,3) (74.7%, 97.9%), ce_loss 0.868, lat_loss 22.084
09/21 03:33:08 PM | Valid: [ 52/180] Step 250/312 Loss 3.467 Prec@(1,3) (74.4%, 97.9%), ce_loss 0.868, lat_loss 22.084
09/21 03:33:12 PM | Valid: [ 52/180] Step 300/312 Loss 3.437 Prec@(1,3) (74.7%, 97.9%), ce_loss 0.868, lat_loss 22.084
09/21 03:33:14 PM | Valid: [ 52/180] Step 312/312 Loss 3.459 Prec@(1,3) (74.7%, 97.9%), ce_loss 0.868, lat_loss 22.083
09/21 03:33:14 PM | val: [ 52/180] Final Prec@1 74.6900% Time 29.91
09/21 03:33:14 PM | Best top1 acc by now. Save model
09/21 03:33:14 PM | Start to train weights for epoch 52
09/21 03:33:40 PM | Train: [ 53/180] Step 050/1249 Loss 2.866 Prec@(1,3) (77.1%, 98.9%), ce_loss 0.868, lat_loss 22.083
09/21 03:34:05 PM | Train: [ 53/180] Step 100/1249 Loss 2.780 Prec@(1,3) (78.3%, 98.8%), ce_loss 0.868, lat_loss 22.083
09/21 03:34:30 PM | Train: [ 53/180] Step 150/1249 Loss 2.762 Prec@(1,3) (78.4%, 98.8%), ce_loss 0.868, lat_loss 22.083
09/21 03:34:54 PM | Train: [ 53/180] Step 200/1249 Loss 2.824 Prec@(1,3) (78.0%, 98.7%), ce_loss 0.868, lat_loss 22.083
09/21 03:35:19 PM | Train: [ 53/180] Step 250/1249 Loss 2.814 Prec@(1,3) (78.1%, 98.7%), ce_loss 0.868, lat_loss 22.083
09/21 03:35:44 PM | Train: [ 53/180] Step 300/1249 Loss 2.847 Prec@(1,3) (77.8%, 98.7%), ce_loss 0.867, lat_loss 22.083
09/21 03:36:09 PM | Train: [ 53/180] Step 350/1249 Loss 2.857 Prec@(1,3) (77.8%, 98.7%), ce_loss 0.867, lat_loss 22.083
09/21 03:36:34 PM | Train: [ 53/180] Step 400/1249 Loss 2.861 Prec@(1,3) (77.8%, 98.7%), ce_loss 0.867, lat_loss 22.083
09/21 03:36:58 PM | Train: [ 53/180] Step 450/1249 Loss 2.906 Prec@(1,3) (77.6%, 98.6%), ce_loss 0.867, lat_loss 22.083
09/21 03:37:23 PM | Train: [ 53/180] Step 500/1249 Loss 2.897 Prec@(1,3) (77.7%, 98.6%), ce_loss 0.867, lat_loss 22.083
09/21 03:37:47 PM | Train: [ 53/180] Step 550/1249 Loss 2.892 Prec@(1,3) (77.8%, 98.6%), ce_loss 0.867, lat_loss 22.083
09/21 03:38:12 PM | Train: [ 53/180] Step 600/1249 Loss 2.895 Prec@(1,3) (77.7%, 98.5%), ce_loss 0.867, lat_loss 22.082
09/21 03:38:37 PM | Train: [ 53/180] Step 650/1249 Loss 2.870 Prec@(1,3) (77.9%, 98.5%), ce_loss 0.867, lat_loss 22.082
09/21 03:39:02 PM | Train: [ 53/180] Step 700/1249 Loss 2.878 Prec@(1,3) (77.8%, 98.5%), ce_loss 0.867, lat_loss 22.082
09/21 03:39:27 PM | Train: [ 53/180] Step 750/1249 Loss 2.882 Prec@(1,3) (77.8%, 98.5%), ce_loss 0.866, lat_loss 22.082
09/21 03:39:52 PM | Train: [ 53/180] Step 800/1249 Loss 2.876 Prec@(1,3) (77.9%, 98.5%), ce_loss 0.866, lat_loss 22.082
09/21 03:40:16 PM | Train: [ 53/180] Step 850/1249 Loss 2.872 Prec@(1,3) (78.0%, 98.5%), ce_loss 0.866, lat_loss 22.082
09/21 03:40:41 PM | Train: [ 53/180] Step 900/1249 Loss 2.873 Prec@(1,3) (77.9%, 98.5%), ce_loss 0.866, lat_loss 22.082
09/21 03:41:06 PM | Train: [ 53/180] Step 950/1249 Loss 2.879 Prec@(1,3) (77.9%, 98.4%), ce_loss 0.866, lat_loss 22.082
09/21 03:41:30 PM | Train: [ 53/180] Step 1000/1249 Loss 2.873 Prec@(1,3) (78.0%, 98.4%), ce_loss 0.866, lat_loss 22.082
09/21 03:41:53 PM | Train: [ 53/180] Step 1050/1249 Loss 2.880 Prec@(1,3) (78.0%, 98.4%), ce_loss 0.866, lat_loss 22.082
09/21 03:42:16 PM | Train: [ 53/180] Step 1100/1249 Loss 2.875 Prec@(1,3) (78.1%, 98.4%), ce_loss 0.866, lat_loss 22.082
09/21 03:42:37 PM | Train: [ 53/180] Step 1150/1249 Loss 2.883 Prec@(1,3) (78.0%, 98.4%), ce_loss 0.866, lat_loss 22.082
09/21 03:43:00 PM | Train: [ 53/180] Step 1200/1249 Loss 2.885 Prec@(1,3) (78.1%, 98.4%), ce_loss 0.865, lat_loss 22.081
09/21 03:43:24 PM | Train: [ 53/180] Step 1249/1249 Loss 2.879 Prec@(1,3) (78.1%, 98.4%), ce_loss 0.865, lat_loss 22.081
09/21 03:43:24 PM | _w_step_train: [ 53/180] Final Prec@1 78.1075% Time 610.19
09/21 03:43:24 PM | Start to train theta for epoch 52
09/21 03:43:45 PM | Train: [ 53/180] Step 050/312 Loss 2.824 Prec@(1,3) (79.3%, 98.2%), ce_loss 0.865, lat_loss 22.081
09/21 03:44:01 PM | Train: [ 53/180] Step 100/312 Loss 2.830 Prec@(1,3) (79.1%, 98.2%), ce_loss 0.865, lat_loss 22.081
09/21 03:44:13 PM | Train: [ 53/180] Step 150/312 Loss 2.881 Prec@(1,3) (78.4%, 98.3%), ce_loss 0.865, lat_loss 22.081
09/21 03:44:26 PM | Train: [ 53/180] Step 200/312 Loss 2.913 Prec@(1,3) (78.1%, 98.3%), ce_loss 0.865, lat_loss 22.081
09/21 03:44:38 PM | Train: [ 53/180] Step 250/312 Loss 2.875 Prec@(1,3) (78.4%, 98.4%), ce_loss 0.865, lat_loss 22.081
09/21 03:44:50 PM | Train: [ 53/180] Step 300/312 Loss 2.891 Prec@(1,3) (78.3%, 98.4%), ce_loss 0.865, lat_loss 22.081
09/21 03:44:53 PM | Train: [ 53/180] Step 312/312 Loss 2.879 Prec@(1,3) (78.3%, 98.4%), ce_loss 0.865, lat_loss 22.081
09/21 03:44:53 PM | _theta_step_train: [ 53/180] Final Prec@1 78.3500% Time 89.26
09/21 03:44:58 PM | Valid: [ 53/180] Step 050/312 Loss 3.585 Prec@(1,3) (72.6%, 98.2%), ce_loss 0.865, lat_loss 22.081
09/21 03:45:03 PM | Valid: [ 53/180] Step 100/312 Loss 3.796 Prec@(1,3) (72.2%, 97.7%), ce_loss 0.865, lat_loss 22.081
09/21 03:45:08 PM | Valid: [ 53/180] Step 150/312 Loss 3.707 Prec@(1,3) (73.0%, 97.6%), ce_loss 0.865, lat_loss 22.081
09/21 03:45:13 PM | Valid: [ 53/180] Step 200/312 Loss 3.615 Prec@(1,3) (73.3%, 97.7%), ce_loss 0.865, lat_loss 22.081
09/21 03:45:17 PM | Valid: [ 53/180] Step 250/312 Loss 3.554 Prec@(1,3) (73.5%, 97.8%), ce_loss 0.864, lat_loss 22.080
09/21 03:45:22 PM | Valid: [ 53/180] Step 300/312 Loss 3.510 Prec@(1,3) (74.1%, 97.9%), ce_loss 0.864, lat_loss 22.080
09/21 03:45:23 PM | Valid: [ 53/180] Step 312/312 Loss 3.511 Prec@(1,3) (74.1%, 97.9%), ce_loss 0.864, lat_loss 22.080
09/21 03:45:23 PM | val: [ 53/180] Final Prec@1 74.1200% Time 29.78
09/21 03:45:23 PM | Start to train weights for epoch 53
09/21 03:45:49 PM | Train: [ 54/180] Step 050/1249 Loss 2.883 Prec@(1,3) (78.9%, 98.3%), ce_loss 0.864, lat_loss 22.080
09/21 03:46:13 PM | Train: [ 54/180] Step 100/1249 Loss 2.836 Prec@(1,3) (79.1%, 98.4%), ce_loss 0.864, lat_loss 22.080
09/21 03:46:38 PM | Train: [ 54/180] Step 150/1249 Loss 2.822 Prec@(1,3) (79.1%, 98.4%), ce_loss 0.864, lat_loss 22.080
09/21 03:47:02 PM | Train: [ 54/180] Step 200/1249 Loss 2.795 Prec@(1,3) (79.2%, 98.5%), ce_loss 0.864, lat_loss 22.080
09/21 03:47:27 PM | Train: [ 54/180] Step 250/1249 Loss 2.787 Prec@(1,3) (79.1%, 98.5%), ce_loss 0.864, lat_loss 22.080
09/21 03:47:52 PM | Train: [ 54/180] Step 300/1249 Loss 2.772 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.864, lat_loss 22.080
09/21 03:48:16 PM | Train: [ 54/180] Step 350/1249 Loss 2.806 Prec@(1,3) (78.9%, 98.5%), ce_loss 0.864, lat_loss 22.080
09/21 03:48:41 PM | Train: [ 54/180] Step 400/1249 Loss 2.815 Prec@(1,3) (78.8%, 98.5%), ce_loss 0.863, lat_loss 22.080
09/21 03:49:04 PM | Train: [ 54/180] Step 450/1249 Loss 2.828 Prec@(1,3) (78.8%, 98.5%), ce_loss 0.863, lat_loss 22.080
09/21 03:49:27 PM | Train: [ 54/180] Step 500/1249 Loss 2.821 Prec@(1,3) (78.8%, 98.5%), ce_loss 0.863, lat_loss 22.079
09/21 03:49:50 PM | Train: [ 54/180] Step 550/1249 Loss 2.830 Prec@(1,3) (78.7%, 98.5%), ce_loss 0.863, lat_loss 22.079
09/21 03:50:13 PM | Train: [ 54/180] Step 600/1249 Loss 2.816 Prec@(1,3) (78.7%, 98.4%), ce_loss 0.863, lat_loss 22.079
09/21 03:50:37 PM | Train: [ 54/180] Step 650/1249 Loss 2.805 Prec@(1,3) (78.7%, 98.5%), ce_loss 0.863, lat_loss 22.079
09/21 03:51:00 PM | Train: [ 54/180] Step 700/1249 Loss 2.813 Prec@(1,3) (78.6%, 98.5%), ce_loss 0.863, lat_loss 22.079
09/21 03:51:23 PM | Train: [ 54/180] Step 750/1249 Loss 2.812 Prec@(1,3) (78.6%, 98.5%), ce_loss 0.863, lat_loss 22.079
09/21 03:51:46 PM | Train: [ 54/180] Step 800/1249 Loss 2.818 Prec@(1,3) (78.6%, 98.5%), ce_loss 0.863, lat_loss 22.079
09/21 03:52:08 PM | Train: [ 54/180] Step 850/1249 Loss 2.822 Prec@(1,3) (78.5%, 98.5%), ce_loss 0.862, lat_loss 22.079
09/21 03:52:30 PM | Train: [ 54/180] Step 900/1249 Loss 2.823 Prec@(1,3) (78.5%, 98.5%), ce_loss 0.862, lat_loss 22.079
09/21 03:52:53 PM | Train: [ 54/180] Step 950/1249 Loss 2.826 Prec@(1,3) (78.5%, 98.5%), ce_loss 0.862, lat_loss 22.079
09/21 03:53:15 PM | Train: [ 54/180] Step 1000/1249 Loss 2.819 Prec@(1,3) (78.5%, 98.5%), ce_loss 0.862, lat_loss 22.079
09/21 03:53:35 PM | Train: [ 54/180] Step 1050/1249 Loss 2.820 Prec@(1,3) (78.5%, 98.5%), ce_loss 0.862, lat_loss 22.078
09/21 03:53:55 PM | Train: [ 54/180] Step 1100/1249 Loss 2.824 Prec@(1,3) (78.5%, 98.5%), ce_loss 0.862, lat_loss 22.078
09/21 03:54:19 PM | Train: [ 54/180] Step 1150/1249 Loss 2.829 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.862, lat_loss 22.078
09/21 03:54:43 PM | Train: [ 54/180] Step 1200/1249 Loss 2.830 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.862, lat_loss 22.078
09/21 03:55:07 PM | Train: [ 54/180] Step 1249/1249 Loss 2.827 Prec@(1,3) (78.5%, 98.5%), ce_loss 0.862, lat_loss 22.078
09/21 03:55:07 PM | _w_step_train: [ 54/180] Final Prec@1 78.4600% Time 584.23
09/21 03:55:07 PM | Start to train theta for epoch 53
09/21 03:55:29 PM | Train: [ 54/180] Step 050/312 Loss 2.897 Prec@(1,3) (77.5%, 98.8%), ce_loss 0.861, lat_loss 22.078
09/21 03:55:48 PM | Train: [ 54/180] Step 100/312 Loss 2.889 Prec@(1,3) (78.3%, 98.5%), ce_loss 0.861, lat_loss 22.078
09/21 03:56:08 PM | Train: [ 54/180] Step 150/312 Loss 2.951 Prec@(1,3) (78.0%, 98.5%), ce_loss 0.861, lat_loss 22.078
09/21 03:56:29 PM | Train: [ 54/180] Step 200/312 Loss 2.951 Prec@(1,3) (77.9%, 98.6%), ce_loss 0.861, lat_loss 22.078
09/21 03:56:50 PM | Train: [ 54/180] Step 250/312 Loss 2.973 Prec@(1,3) (77.6%, 98.5%), ce_loss 0.861, lat_loss 22.078
09/21 03:57:10 PM | Train: [ 54/180] Step 300/312 Loss 2.981 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.861, lat_loss 22.078
09/21 03:57:15 PM | Train: [ 54/180] Step 312/312 Loss 2.984 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.861, lat_loss 22.078
09/21 03:57:15 PM | _theta_step_train: [ 54/180] Final Prec@1 77.4800% Time 127.65
09/21 03:57:20 PM | Valid: [ 54/180] Step 050/312 Loss 3.384 Prec@(1,3) (75.8%, 97.1%), ce_loss 0.861, lat_loss 22.078
09/21 03:57:25 PM | Valid: [ 54/180] Step 100/312 Loss 3.457 Prec@(1,3) (75.8%, 97.4%), ce_loss 0.861, lat_loss 22.077
09/21 03:57:29 PM | Valid: [ 54/180] Step 150/312 Loss 3.832 Prec@(1,3) (76.0%, 97.5%), ce_loss 0.861, lat_loss 22.077
09/21 03:57:34 PM | Valid: [ 54/180] Step 200/312 Loss 3.645 Prec@(1,3) (76.4%, 97.8%), ce_loss 0.861, lat_loss 22.077
09/21 03:57:39 PM | Valid: [ 54/180] Step 250/312 Loss 3.615 Prec@(1,3) (76.0%, 97.8%), ce_loss 0.861, lat_loss 22.077
09/21 03:57:43 PM | Valid: [ 54/180] Step 300/312 Loss 3.717 Prec@(1,3) (75.4%, 97.4%), ce_loss 0.861, lat_loss 22.077
09/21 03:57:44 PM | Valid: [ 54/180] Step 312/312 Loss 3.726 Prec@(1,3) (75.3%, 97.5%), ce_loss 0.861, lat_loss 22.077
09/21 03:57:44 PM | val: [ 54/180] Final Prec@1 75.2600% Time 29.38
09/21 03:57:44 PM | Best top1 acc by now. Save model
09/21 03:57:45 PM | Start to train weights for epoch 54
09/21 03:58:11 PM | Train: [ 55/180] Step 050/1249 Loss 2.706 Prec@(1,3) (79.0%, 98.9%), ce_loss 0.861, lat_loss 22.077
09/21 03:58:35 PM | Train: [ 55/180] Step 100/1249 Loss 2.718 Prec@(1,3) (78.9%, 98.9%), ce_loss 0.861, lat_loss 22.077
09/21 03:58:55 PM | Train: [ 55/180] Step 150/1249 Loss 2.685 Prec@(1,3) (79.2%, 98.8%), ce_loss 0.860, lat_loss 22.077
09/21 03:59:19 PM | Train: [ 55/180] Step 200/1249 Loss 2.707 Prec@(1,3) (79.1%, 98.7%), ce_loss 0.860, lat_loss 22.077
09/21 03:59:43 PM | Train: [ 55/180] Step 250/1249 Loss 2.696 Prec@(1,3) (79.1%, 98.7%), ce_loss 0.860, lat_loss 22.077
09/21 04:00:04 PM | Train: [ 55/180] Step 300/1249 Loss 2.800 Prec@(1,3) (78.6%, 98.6%), ce_loss 0.860, lat_loss 22.077
09/21 04:00:28 PM | Train: [ 55/180] Step 350/1249 Loss 2.820 Prec@(1,3) (78.5%, 98.6%), ce_loss 0.860, lat_loss 22.077
09/21 04:00:50 PM | Train: [ 55/180] Step 400/1249 Loss 2.861 Prec@(1,3) (78.2%, 98.5%), ce_loss 0.860, lat_loss 22.076
09/21 04:01:12 PM | Train: [ 55/180] Step 450/1249 Loss 2.857 Prec@(1,3) (78.2%, 98.5%), ce_loss 0.860, lat_loss 22.076
09/21 04:01:35 PM | Train: [ 55/180] Step 500/1249 Loss 2.838 Prec@(1,3) (78.2%, 98.5%), ce_loss 0.860, lat_loss 22.076
09/21 04:01:58 PM | Train: [ 55/180] Step 550/1249 Loss 2.824 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.860, lat_loss 22.076
09/21 04:02:21 PM | Train: [ 55/180] Step 600/1249 Loss 2.820 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.860, lat_loss 22.076
09/21 04:02:45 PM | Train: [ 55/180] Step 650/1249 Loss 2.827 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.859, lat_loss 22.076
09/21 04:03:07 PM | Train: [ 55/180] Step 700/1249 Loss 2.833 Prec@(1,3) (78.3%, 98.5%), ce_loss 0.859, lat_loss 22.076
09/21 04:03:29 PM | Train: [ 55/180] Step 750/1249 Loss 2.822 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.859, lat_loss 22.076
09/21 04:03:52 PM | Train: [ 55/180] Step 800/1249 Loss 2.819 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.859, lat_loss 22.076
09/21 04:04:17 PM | Train: [ 55/180] Step 850/1249 Loss 2.822 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.859, lat_loss 22.076
09/21 04:04:42 PM | Train: [ 55/180] Step 900/1249 Loss 2.825 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.859, lat_loss 22.076
09/21 04:05:07 PM | Train: [ 55/180] Step 950/1249 Loss 2.830 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.859, lat_loss 22.076
09/21 04:05:30 PM | Train: [ 55/180] Step 1000/1249 Loss 2.827 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.859, lat_loss 22.075
09/21 04:05:53 PM | Train: [ 55/180] Step 1050/1249 Loss 2.823 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.858, lat_loss 22.075
09/21 04:06:17 PM | Train: [ 55/180] Step 1100/1249 Loss 2.821 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.858, lat_loss 22.075
09/21 04:06:40 PM | Train: [ 55/180] Step 1150/1249 Loss 2.823 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.858, lat_loss 22.075
09/21 04:07:04 PM | Train: [ 55/180] Step 1200/1249 Loss 2.818 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.858, lat_loss 22.075
09/21 04:07:28 PM | Train: [ 55/180] Step 1249/1249 Loss 2.811 Prec@(1,3) (78.5%, 98.5%), ce_loss 0.858, lat_loss 22.075
09/21 04:07:28 PM | _w_step_train: [ 55/180] Final Prec@1 78.4725% Time 583.69
09/21 04:07:28 PM | Start to train theta for epoch 54
09/21 04:07:49 PM | Train: [ 55/180] Step 050/312 Loss 3.085 Prec@(1,3) (76.9%, 98.4%), ce_loss 0.858, lat_loss 22.075
09/21 04:08:08 PM | Train: [ 55/180] Step 100/312 Loss 2.941 Prec@(1,3) (77.8%, 98.4%), ce_loss 0.858, lat_loss 22.075
09/21 04:08:26 PM | Train: [ 55/180] Step 150/312 Loss 2.949 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.858, lat_loss 22.075
09/21 04:08:44 PM | Train: [ 55/180] Step 200/312 Loss 2.905 Prec@(1,3) (77.9%, 98.4%), ce_loss 0.858, lat_loss 22.075
09/21 04:09:04 PM | Train: [ 55/180] Step 250/312 Loss 2.920 Prec@(1,3) (77.9%, 98.5%), ce_loss 0.858, lat_loss 22.075
09/21 04:09:25 PM | Train: [ 55/180] Step 300/312 Loss 2.923 Prec@(1,3) (77.8%, 98.5%), ce_loss 0.857, lat_loss 22.075
09/21 04:09:30 PM | Train: [ 55/180] Step 312/312 Loss 2.931 Prec@(1,3) (77.8%, 98.5%), ce_loss 0.857, lat_loss 22.075
09/21 04:09:30 PM | _theta_step_train: [ 55/180] Final Prec@1 77.7800% Time 121.46
09/21 04:09:35 PM | Valid: [ 55/180] Step 050/312 Loss 3.079 Prec@(1,3) (77.1%, 98.3%), ce_loss 0.857, lat_loss 22.075
09/21 04:09:40 PM | Valid: [ 55/180] Step 100/312 Loss 3.160 Prec@(1,3) (77.1%, 98.4%), ce_loss 0.857, lat_loss 22.075
09/21 04:09:45 PM | Valid: [ 55/180] Step 150/312 Loss 3.151 Prec@(1,3) (76.7%, 98.3%), ce_loss 0.857, lat_loss 22.074
09/21 04:09:49 PM | Valid: [ 55/180] Step 200/312 Loss 3.186 Prec@(1,3) (76.3%, 98.4%), ce_loss 0.857, lat_loss 22.074
09/21 04:09:54 PM | Valid: [ 55/180] Step 250/312 Loss 3.207 Prec@(1,3) (76.1%, 98.4%), ce_loss 0.857, lat_loss 22.074
09/21 04:09:59 PM | Valid: [ 55/180] Step 300/312 Loss 3.173 Prec@(1,3) (76.5%, 98.5%), ce_loss 0.857, lat_loss 22.074
09/21 04:10:00 PM | Valid: [ 55/180] Step 312/312 Loss 3.160 Prec@(1,3) (76.6%, 98.5%), ce_loss 0.857, lat_loss 22.074
09/21 04:10:00 PM | val: [ 55/180] Final Prec@1 76.5700% Time 30.49
09/21 04:10:00 PM | Best top1 acc by now. Save model
09/21 04:10:00 PM | Start to train weights for epoch 55
09/21 04:10:27 PM | Train: [ 56/180] Step 050/1249 Loss 2.792 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.857, lat_loss 22.074
09/21 04:10:50 PM | Train: [ 56/180] Step 100/1249 Loss 2.828 Prec@(1,3) (78.9%, 98.6%), ce_loss 0.857, lat_loss 22.074
09/21 04:11:13 PM | Train: [ 56/180] Step 150/1249 Loss 2.796 Prec@(1,3) (79.1%, 98.7%), ce_loss 0.857, lat_loss 22.074
09/21 04:11:36 PM | Train: [ 56/180] Step 200/1249 Loss 2.789 Prec@(1,3) (79.0%, 98.7%), ce_loss 0.857, lat_loss 22.074
09/21 04:11:57 PM | Train: [ 56/180] Step 250/1249 Loss 2.779 Prec@(1,3) (78.9%, 98.8%), ce_loss 0.856, lat_loss 22.074
09/21 04:12:20 PM | Train: [ 56/180] Step 300/1249 Loss 2.785 Prec@(1,3) (79.0%, 98.7%), ce_loss 0.856, lat_loss 22.074
09/21 04:12:44 PM | Train: [ 56/180] Step 350/1249 Loss 2.781 Prec@(1,3) (78.9%, 98.8%), ce_loss 0.856, lat_loss 22.074
09/21 04:13:08 PM | Train: [ 56/180] Step 400/1249 Loss 2.775 Prec@(1,3) (78.9%, 98.7%), ce_loss 0.856, lat_loss 22.074
09/21 04:13:32 PM | Train: [ 56/180] Step 450/1249 Loss 2.794 Prec@(1,3) (78.8%, 98.7%), ce_loss 0.856, lat_loss 22.074
09/21 04:13:55 PM | Train: [ 56/180] Step 500/1249 Loss 2.775 Prec@(1,3) (79.0%, 98.7%), ce_loss 0.856, lat_loss 22.074
09/21 04:14:19 PM | Train: [ 56/180] Step 550/1249 Loss 2.761 Prec@(1,3) (79.2%, 98.7%), ce_loss 0.856, lat_loss 22.074
09/21 04:14:42 PM | Train: [ 56/180] Step 600/1249 Loss 2.755 Prec@(1,3) (79.2%, 98.7%), ce_loss 0.856, lat_loss 22.074
09/21 04:15:05 PM | Train: [ 56/180] Step 650/1249 Loss 2.740 Prec@(1,3) (79.3%, 98.7%), ce_loss 0.855, lat_loss 22.073
09/21 04:15:29 PM | Train: [ 56/180] Step 700/1249 Loss 2.745 Prec@(1,3) (79.3%, 98.7%), ce_loss 0.855, lat_loss 22.073
09/21 04:15:52 PM | Train: [ 56/180] Step 750/1249 Loss 2.780 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.855, lat_loss 22.073
09/21 04:16:16 PM | Train: [ 56/180] Step 800/1249 Loss 2.781 Prec@(1,3) (79.0%, 98.6%), ce_loss 0.855, lat_loss 22.073
09/21 04:16:39 PM | Train: [ 56/180] Step 850/1249 Loss 2.774 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.855, lat_loss 22.073
09/21 04:17:03 PM | Train: [ 56/180] Step 900/1249 Loss 2.763 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.855, lat_loss 22.073
09/21 04:17:28 PM | Train: [ 56/180] Step 950/1249 Loss 2.763 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.855, lat_loss 22.073
09/21 04:17:52 PM | Train: [ 56/180] Step 1000/1249 Loss 2.759 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.855, lat_loss 22.073
09/21 04:18:16 PM | Train: [ 56/180] Step 1050/1249 Loss 2.765 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.855, lat_loss 22.073
09/21 04:18:37 PM | Train: [ 56/180] Step 1100/1249 Loss 2.759 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.854, lat_loss 22.073
09/21 04:18:58 PM | Train: [ 56/180] Step 1150/1249 Loss 2.771 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.854, lat_loss 22.073
09/21 04:19:20 PM | Train: [ 56/180] Step 1200/1249 Loss 2.764 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.854, lat_loss 22.073
09/21 04:19:45 PM | Train: [ 56/180] Step 1249/1249 Loss 2.764 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.854, lat_loss 22.073
09/21 04:19:45 PM | _w_step_train: [ 56/180] Final Prec@1 79.1025% Time 584.57
09/21 04:19:45 PM | Start to train theta for epoch 55
09/21 04:20:03 PM | Train: [ 56/180] Step 050/312 Loss 2.848 Prec@(1,3) (78.2%, 98.7%), ce_loss 0.854, lat_loss 22.073
09/21 04:20:20 PM | Train: [ 56/180] Step 100/312 Loss 3.044 Prec@(1,3) (77.4%, 98.0%), ce_loss 0.854, lat_loss 22.073
09/21 04:20:37 PM | Train: [ 56/180] Step 150/312 Loss 3.026 Prec@(1,3) (77.0%, 98.1%), ce_loss 0.854, lat_loss 22.073
09/21 04:20:55 PM | Train: [ 56/180] Step 200/312 Loss 2.986 Prec@(1,3) (77.1%, 98.3%), ce_loss 0.854, lat_loss 22.073
09/21 04:21:13 PM | Train: [ 56/180] Step 250/312 Loss 3.003 Prec@(1,3) (77.1%, 98.2%), ce_loss 0.854, lat_loss 22.072
09/21 04:21:31 PM | Train: [ 56/180] Step 300/312 Loss 3.017 Prec@(1,3) (77.0%, 98.3%), ce_loss 0.854, lat_loss 22.072
09/21 04:21:36 PM | Train: [ 56/180] Step 312/312 Loss 3.011 Prec@(1,3) (77.1%, 98.2%), ce_loss 0.854, lat_loss 22.072
09/21 04:21:36 PM | _theta_step_train: [ 56/180] Final Prec@1 77.0700% Time 111.06
09/21 04:21:41 PM | Valid: [ 56/180] Step 050/312 Loss 4.143 Prec@(1,3) (72.3%, 96.6%), ce_loss 0.854, lat_loss 22.072
09/21 04:21:46 PM | Valid: [ 56/180] Step 100/312 Loss 3.954 Prec@(1,3) (73.0%, 97.1%), ce_loss 0.854, lat_loss 22.072
09/21 04:21:51 PM | Valid: [ 56/180] Step 150/312 Loss 3.956 Prec@(1,3) (73.2%, 96.9%), ce_loss 0.854, lat_loss 22.072
09/21 04:21:55 PM | Valid: [ 56/180] Step 200/312 Loss 3.959 Prec@(1,3) (72.7%, 97.2%), ce_loss 0.854, lat_loss 22.072
09/21 04:22:00 PM | Valid: [ 56/180] Step 250/312 Loss 3.887 Prec@(1,3) (72.7%, 97.4%), ce_loss 0.854, lat_loss 22.072
09/21 04:22:05 PM | Valid: [ 56/180] Step 300/312 Loss 3.828 Prec@(1,3) (72.8%, 97.5%), ce_loss 0.854, lat_loss 22.072
09/21 04:22:06 PM | Valid: [ 56/180] Step 312/312 Loss 3.815 Prec@(1,3) (73.0%, 97.5%), ce_loss 0.854, lat_loss 22.072
09/21 04:22:06 PM | val: [ 56/180] Final Prec@1 73.0000% Time 29.80
09/21 04:22:06 PM | Start to train weights for epoch 56
09/21 04:22:23 PM | Train: [ 57/180] Step 050/1249 Loss 2.997 Prec@(1,3) (76.2%, 98.4%), ce_loss 0.853, lat_loss 22.072
09/21 04:22:44 PM | Train: [ 57/180] Step 100/1249 Loss 2.669 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.853, lat_loss 22.072
09/21 04:23:08 PM | Train: [ 57/180] Step 150/1249 Loss 2.690 Prec@(1,3) (79.7%, 98.6%), ce_loss 0.853, lat_loss 22.072
09/21 04:23:32 PM | Train: [ 57/180] Step 200/1249 Loss 2.642 Prec@(1,3) (80.2%, 98.6%), ce_loss 0.853, lat_loss 22.072
09/21 04:23:57 PM | Train: [ 57/180] Step 250/1249 Loss 2.650 Prec@(1,3) (80.0%, 98.6%), ce_loss 0.853, lat_loss 22.072
09/21 04:24:19 PM | Train: [ 57/180] Step 300/1249 Loss 2.666 Prec@(1,3) (79.8%, 98.6%), ce_loss 0.853, lat_loss 22.072
09/21 04:24:43 PM | Train: [ 57/180] Step 350/1249 Loss 2.673 Prec@(1,3) (79.7%, 98.7%), ce_loss 0.853, lat_loss 22.072
09/21 04:25:08 PM | Train: [ 57/180] Step 400/1249 Loss 2.696 Prec@(1,3) (79.5%, 98.6%), ce_loss 0.853, lat_loss 22.072
09/21 04:25:29 PM | Train: [ 57/180] Step 450/1249 Loss 2.712 Prec@(1,3) (79.4%, 98.6%), ce_loss 0.852, lat_loss 22.072
09/21 04:25:52 PM | Train: [ 57/180] Step 500/1249 Loss 2.698 Prec@(1,3) (79.5%, 98.6%), ce_loss 0.852, lat_loss 22.072
09/21 04:26:17 PM | Train: [ 57/180] Step 550/1249 Loss 2.711 Prec@(1,3) (79.5%, 98.6%), ce_loss 0.852, lat_loss 22.072
09/21 04:26:41 PM | Train: [ 57/180] Step 600/1249 Loss 2.714 Prec@(1,3) (79.5%, 98.6%), ce_loss 0.852, lat_loss 22.072
09/21 04:27:06 PM | Train: [ 57/180] Step 650/1249 Loss 2.728 Prec@(1,3) (79.5%, 98.6%), ce_loss 0.852, lat_loss 22.072
09/21 04:27:27 PM | Train: [ 57/180] Step 700/1249 Loss 2.734 Prec@(1,3) (79.4%, 98.5%), ce_loss 0.852, lat_loss 22.072
09/21 04:27:50 PM | Train: [ 57/180] Step 750/1249 Loss 2.724 Prec@(1,3) (79.5%, 98.6%), ce_loss 0.852, lat_loss 22.072
09/21 04:28:13 PM | Train: [ 57/180] Step 800/1249 Loss 2.720 Prec@(1,3) (79.5%, 98.6%), ce_loss 0.852, lat_loss 22.072
09/21 04:28:37 PM | Train: [ 57/180] Step 850/1249 Loss 2.720 Prec@(1,3) (79.5%, 98.6%), ce_loss 0.852, lat_loss 22.072
09/21 04:29:01 PM | Train: [ 57/180] Step 900/1249 Loss 2.716 Prec@(1,3) (79.6%, 98.6%), ce_loss 0.851, lat_loss 22.072
09/21 04:29:25 PM | Train: [ 57/180] Step 950/1249 Loss 2.723 Prec@(1,3) (79.5%, 98.6%), ce_loss 0.851, lat_loss 22.072
09/21 04:29:51 PM | Train: [ 57/180] Step 1000/1249 Loss 2.723 Prec@(1,3) (79.5%, 98.6%), ce_loss 0.851, lat_loss 22.072
09/21 04:30:13 PM | Train: [ 57/180] Step 1050/1249 Loss 2.723 Prec@(1,3) (79.5%, 98.6%), ce_loss 0.851, lat_loss 22.072
09/21 04:30:34 PM | Train: [ 57/180] Step 1100/1249 Loss 2.732 Prec@(1,3) (79.4%, 98.6%), ce_loss 0.851, lat_loss 22.072
09/21 04:30:56 PM | Train: [ 57/180] Step 1150/1249 Loss 2.733 Prec@(1,3) (79.3%, 98.6%), ce_loss 0.851, lat_loss 22.072
09/21 04:31:18 PM | Train: [ 57/180] Step 1200/1249 Loss 2.733 Prec@(1,3) (79.3%, 98.6%), ce_loss 0.851, lat_loss 22.072
09/21 04:31:40 PM | Train: [ 57/180] Step 1249/1249 Loss 2.729 Prec@(1,3) (79.4%, 98.6%), ce_loss 0.851, lat_loss 22.072
09/21 04:31:40 PM | _w_step_train: [ 57/180] Final Prec@1 79.3700% Time 574.61
09/21 04:31:40 PM | Start to train theta for epoch 56
09/21 04:32:01 PM | Train: [ 57/180] Step 050/312 Loss 2.898 Prec@(1,3) (76.5%, 98.3%), ce_loss 0.851, lat_loss 22.072
09/21 04:32:18 PM | Train: [ 57/180] Step 100/312 Loss 2.877 Prec@(1,3) (77.6%, 98.3%), ce_loss 0.850, lat_loss 22.071
09/21 04:32:38 PM | Train: [ 57/180] Step 150/312 Loss 2.910 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.850, lat_loss 22.071
09/21 04:32:57 PM | Train: [ 57/180] Step 200/312 Loss 2.912 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.850, lat_loss 22.071
09/21 04:33:17 PM | Train: [ 57/180] Step 250/312 Loss 2.939 Prec@(1,3) (77.3%, 98.3%), ce_loss 0.850, lat_loss 22.071
09/21 04:33:38 PM | Train: [ 57/180] Step 300/312 Loss 2.935 Prec@(1,3) (77.5%, 98.3%), ce_loss 0.850, lat_loss 22.071
09/21 04:33:43 PM | Train: [ 57/180] Step 312/312 Loss 2.931 Prec@(1,3) (77.7%, 98.3%), ce_loss 0.850, lat_loss 22.071
09/21 04:33:43 PM | _theta_step_train: [ 57/180] Final Prec@1 77.6600% Time 122.21
09/21 04:33:48 PM | Valid: [ 57/180] Step 050/312 Loss 2.815 Prec@(1,3) (78.1%, 98.7%), ce_loss 0.850, lat_loss 22.071
09/21 04:33:53 PM | Valid: [ 57/180] Step 100/312 Loss 2.978 Prec@(1,3) (77.8%, 98.3%), ce_loss 0.850, lat_loss 22.071
09/21 04:33:57 PM | Valid: [ 57/180] Step 150/312 Loss 2.989 Prec@(1,3) (77.9%, 98.3%), ce_loss 0.850, lat_loss 22.071
09/21 04:34:02 PM | Valid: [ 57/180] Step 200/312 Loss 2.972 Prec@(1,3) (78.3%, 98.3%), ce_loss 0.850, lat_loss 22.071
09/21 04:34:07 PM | Valid: [ 57/180] Step 250/312 Loss 2.959 Prec@(1,3) (78.3%, 98.4%), ce_loss 0.850, lat_loss 22.071
09/21 04:34:11 PM | Valid: [ 57/180] Step 300/312 Loss 2.980 Prec@(1,3) (78.1%, 98.3%), ce_loss 0.850, lat_loss 22.071
09/21 04:34:12 PM | Valid: [ 57/180] Step 312/312 Loss 2.987 Prec@(1,3) (78.0%, 98.3%), ce_loss 0.850, lat_loss 22.071
09/21 04:34:12 PM | val: [ 57/180] Final Prec@1 78.0200% Time 29.75
09/21 04:34:12 PM | Best top1 acc by now. Save model
09/21 04:34:13 PM | Start to train weights for epoch 57
09/21 04:34:38 PM | Train: [ 58/180] Step 050/1249 Loss 2.778 Prec@(1,3) (79.8%, 98.3%), ce_loss 0.849, lat_loss 22.071
09/21 04:35:01 PM | Train: [ 58/180] Step 100/1249 Loss 2.690 Prec@(1,3) (80.2%, 98.5%), ce_loss 0.849, lat_loss 22.071
09/21 04:35:25 PM | Train: [ 58/180] Step 150/1249 Loss 2.720 Prec@(1,3) (79.7%, 98.6%), ce_loss 0.849, lat_loss 22.071
09/21 04:35:50 PM | Train: [ 58/180] Step 200/1249 Loss 2.734 Prec@(1,3) (79.5%, 98.6%), ce_loss 0.849, lat_loss 22.071
09/21 04:36:14 PM | Train: [ 58/180] Step 250/1249 Loss 2.738 Prec@(1,3) (79.5%, 98.6%), ce_loss 0.849, lat_loss 22.071
09/21 04:36:39 PM | Train: [ 58/180] Step 300/1249 Loss 2.752 Prec@(1,3) (79.2%, 98.7%), ce_loss 0.849, lat_loss 22.071
09/21 04:37:01 PM | Train: [ 58/180] Step 350/1249 Loss 2.745 Prec@(1,3) (79.2%, 98.7%), ce_loss 0.849, lat_loss 22.071
09/21 04:37:24 PM | Train: [ 58/180] Step 400/1249 Loss 2.719 Prec@(1,3) (79.3%, 98.7%), ce_loss 0.849, lat_loss 22.071
09/21 04:37:45 PM | Train: [ 58/180] Step 450/1249 Loss 2.712 Prec@(1,3) (79.3%, 98.7%), ce_loss 0.848, lat_loss 22.071
09/21 04:38:07 PM | Train: [ 58/180] Step 500/1249 Loss 2.719 Prec@(1,3) (79.3%, 98.7%), ce_loss 0.848, lat_loss 22.071
09/21 04:38:32 PM | Train: [ 58/180] Step 550/1249 Loss 2.704 Prec@(1,3) (79.4%, 98.7%), ce_loss 0.848, lat_loss 22.071
09/21 04:38:55 PM | Train: [ 58/180] Step 600/1249 Loss 2.699 Prec@(1,3) (79.4%, 98.7%), ce_loss 0.848, lat_loss 22.071
09/21 04:39:21 PM | Train: [ 58/180] Step 650/1249 Loss 2.682 Prec@(1,3) (79.5%, 98.8%), ce_loss 0.848, lat_loss 22.071
09/21 04:39:46 PM | Train: [ 58/180] Step 700/1249 Loss 2.674 Prec@(1,3) (79.5%, 98.8%), ce_loss 0.848, lat_loss 22.071
09/21 04:40:10 PM | Train: [ 58/180] Step 750/1249 Loss 2.681 Prec@(1,3) (79.5%, 98.7%), ce_loss 0.848, lat_loss 22.071
09/21 04:40:35 PM | Train: [ 58/180] Step 800/1249 Loss 2.683 Prec@(1,3) (79.5%, 98.8%), ce_loss 0.848, lat_loss 22.071
09/21 04:41:01 PM | Train: [ 58/180] Step 850/1249 Loss 2.675 Prec@(1,3) (79.6%, 98.8%), ce_loss 0.848, lat_loss 22.071
09/21 04:41:22 PM | Train: [ 58/180] Step 900/1249 Loss 2.683 Prec@(1,3) (79.5%, 98.7%), ce_loss 0.847, lat_loss 22.071
09/21 04:41:46 PM | Train: [ 58/180] Step 950/1249 Loss 2.677 Prec@(1,3) (79.5%, 98.7%), ce_loss 0.847, lat_loss 22.070
09/21 04:42:08 PM | Train: [ 58/180] Step 1000/1249 Loss 2.686 Prec@(1,3) (79.5%, 98.7%), ce_loss 0.847, lat_loss 22.070
09/21 04:42:31 PM | Train: [ 58/180] Step 1050/1249 Loss 2.685 Prec@(1,3) (79.5%, 98.8%), ce_loss 0.847, lat_loss 22.070
09/21 04:42:54 PM | Train: [ 58/180] Step 1100/1249 Loss 2.684 Prec@(1,3) (79.5%, 98.7%), ce_loss 0.847, lat_loss 22.070
09/21 04:43:16 PM | Train: [ 58/180] Step 1150/1249 Loss 2.684 Prec@(1,3) (79.5%, 98.7%), ce_loss 0.847, lat_loss 22.070
09/21 04:43:39 PM | Train: [ 58/180] Step 1200/1249 Loss 2.693 Prec@(1,3) (79.5%, 98.7%), ce_loss 0.847, lat_loss 22.070
09/21 04:44:04 PM | Train: [ 58/180] Step 1249/1249 Loss 2.695 Prec@(1,3) (79.5%, 98.7%), ce_loss 0.847, lat_loss 22.070
09/21 04:44:04 PM | _w_step_train: [ 58/180] Final Prec@1 79.5025% Time 591.14
09/21 04:44:04 PM | Start to train theta for epoch 57
09/21 04:44:25 PM | Train: [ 58/180] Step 050/312 Loss 2.778 Prec@(1,3) (78.9%, 98.8%), ce_loss 0.847, lat_loss 22.070
09/21 04:44:46 PM | Train: [ 58/180] Step 100/312 Loss 2.785 Prec@(1,3) (79.5%, 98.4%), ce_loss 0.846, lat_loss 22.070
09/21 04:45:07 PM | Train: [ 58/180] Step 150/312 Loss 2.760 Prec@(1,3) (79.8%, 98.5%), ce_loss 0.846, lat_loss 22.070
09/21 04:45:27 PM | Train: [ 58/180] Step 200/312 Loss 2.728 Prec@(1,3) (79.9%, 98.5%), ce_loss 0.846, lat_loss 22.070
09/21 04:45:48 PM | Train: [ 58/180] Step 250/312 Loss 2.748 Prec@(1,3) (79.7%, 98.5%), ce_loss 0.846, lat_loss 22.070
09/21 04:46:08 PM | Train: [ 58/180] Step 300/312 Loss 2.767 Prec@(1,3) (79.4%, 98.5%), ce_loss 0.846, lat_loss 22.070
09/21 04:46:13 PM | Train: [ 58/180] Step 312/312 Loss 2.764 Prec@(1,3) (79.4%, 98.5%), ce_loss 0.846, lat_loss 22.070
09/21 04:46:13 PM | _theta_step_train: [ 58/180] Final Prec@1 79.3800% Time 129.35
09/21 04:46:18 PM | Valid: [ 58/180] Step 050/312 Loss 2.864 Prec@(1,3) (78.1%, 98.5%), ce_loss 0.846, lat_loss 22.070
09/21 04:46:23 PM | Valid: [ 58/180] Step 100/312 Loss 2.823 Prec@(1,3) (79.0%, 98.5%), ce_loss 0.846, lat_loss 22.070
09/21 04:46:28 PM | Valid: [ 58/180] Step 150/312 Loss 3.079 Prec@(1,3) (78.4%, 98.0%), ce_loss 0.846, lat_loss 22.070
09/21 04:46:32 PM | Valid: [ 58/180] Step 200/312 Loss 3.035 Prec@(1,3) (78.5%, 98.3%), ce_loss 0.846, lat_loss 22.070
09/21 04:46:37 PM | Valid: [ 58/180] Step 250/312 Loss 3.017 Prec@(1,3) (78.6%, 98.4%), ce_loss 0.846, lat_loss 22.070
09/21 04:46:42 PM | Valid: [ 58/180] Step 300/312 Loss 2.975 Prec@(1,3) (78.7%, 98.5%), ce_loss 0.845, lat_loss 22.070
09/21 04:46:43 PM | Valid: [ 58/180] Step 312/312 Loss 2.955 Prec@(1,3) (78.8%, 98.5%), ce_loss 0.845, lat_loss 22.070
09/21 04:46:43 PM | val: [ 58/180] Final Prec@1 78.7600% Time 29.57
09/21 04:46:43 PM | Best top1 acc by now. Save model
09/21 04:46:43 PM | Start to train weights for epoch 58
09/21 04:47:06 PM | Train: [ 59/180] Step 050/1249 Loss 2.733 Prec@(1,3) (79.2%, 98.7%), ce_loss 0.845, lat_loss 22.070
09/21 04:47:31 PM | Train: [ 59/180] Step 100/1249 Loss 2.703 Prec@(1,3) (79.3%, 98.7%), ce_loss 0.845, lat_loss 22.070
09/21 04:47:56 PM | Train: [ 59/180] Step 150/1249 Loss 2.644 Prec@(1,3) (79.9%, 98.9%), ce_loss 0.845, lat_loss 22.070
09/21 04:48:20 PM | Train: [ 59/180] Step 200/1249 Loss 2.641 Prec@(1,3) (79.4%, 98.9%), ce_loss 0.845, lat_loss 22.070
09/21 04:48:45 PM | Train: [ 59/180] Step 250/1249 Loss 2.616 Prec@(1,3) (79.8%, 98.9%), ce_loss 0.845, lat_loss 22.070
09/21 04:49:10 PM | Train: [ 59/180] Step 300/1249 Loss 2.612 Prec@(1,3) (79.7%, 98.9%), ce_loss 0.845, lat_loss 22.069
09/21 04:49:35 PM | Train: [ 59/180] Step 350/1249 Loss 2.622 Prec@(1,3) (79.7%, 98.8%), ce_loss 0.845, lat_loss 22.069
09/21 04:49:59 PM | Train: [ 59/180] Step 400/1249 Loss 2.594 Prec@(1,3) (79.9%, 98.8%), ce_loss 0.844, lat_loss 22.069
09/21 04:50:24 PM | Train: [ 59/180] Step 450/1249 Loss 2.600 Prec@(1,3) (79.9%, 98.8%), ce_loss 0.844, lat_loss 22.069
09/21 04:50:49 PM | Train: [ 59/180] Step 500/1249 Loss 2.599 Prec@(1,3) (80.0%, 98.8%), ce_loss 0.844, lat_loss 22.069
09/21 04:51:13 PM | Train: [ 59/180] Step 550/1249 Loss 2.597 Prec@(1,3) (80.0%, 98.8%), ce_loss 0.844, lat_loss 22.069
09/21 04:51:38 PM | Train: [ 59/180] Step 600/1249 Loss 2.602 Prec@(1,3) (80.0%, 98.8%), ce_loss 0.844, lat_loss 22.069
09/21 04:52:03 PM | Train: [ 59/180] Step 650/1249 Loss 2.613 Prec@(1,3) (79.9%, 98.8%), ce_loss 0.844, lat_loss 22.069
09/21 04:52:28 PM | Train: [ 59/180] Step 700/1249 Loss 2.613 Prec@(1,3) (79.9%, 98.8%), ce_loss 0.844, lat_loss 22.069
09/21 04:52:53 PM | Train: [ 59/180] Step 750/1249 Loss 2.608 Prec@(1,3) (80.0%, 98.8%), ce_loss 0.844, lat_loss 22.069
09/21 04:53:16 PM | Train: [ 59/180] Step 800/1249 Loss 2.614 Prec@(1,3) (80.0%, 98.8%), ce_loss 0.843, lat_loss 22.069
09/21 04:53:40 PM | Train: [ 59/180] Step 850/1249 Loss 2.611 Prec@(1,3) (80.0%, 98.7%), ce_loss 0.843, lat_loss 22.069
09/21 04:54:03 PM | Train: [ 59/180] Step 900/1249 Loss 2.618 Prec@(1,3) (80.1%, 98.7%), ce_loss 0.843, lat_loss 22.069
09/21 04:54:26 PM | Train: [ 59/180] Step 950/1249 Loss 2.633 Prec@(1,3) (79.9%, 98.7%), ce_loss 0.843, lat_loss 22.069
09/21 04:54:50 PM | Train: [ 59/180] Step 1000/1249 Loss 2.628 Prec@(1,3) (80.0%, 98.7%), ce_loss 0.843, lat_loss 22.069
09/21 04:55:15 PM | Train: [ 59/180] Step 1050/1249 Loss 2.631 Prec@(1,3) (80.0%, 98.7%), ce_loss 0.843, lat_loss 22.069
09/21 04:55:39 PM | Train: [ 59/180] Step 1100/1249 Loss 2.630 Prec@(1,3) (80.0%, 98.7%), ce_loss 0.843, lat_loss 22.069
09/21 04:56:03 PM | Train: [ 59/180] Step 1150/1249 Loss 2.634 Prec@(1,3) (80.0%, 98.7%), ce_loss 0.843, lat_loss 22.069
09/21 04:56:28 PM | Train: [ 59/180] Step 1200/1249 Loss 2.631 Prec@(1,3) (80.0%, 98.7%), ce_loss 0.843, lat_loss 22.069
09/21 04:56:53 PM | Train: [ 59/180] Step 1249/1249 Loss 2.627 Prec@(1,3) (80.0%, 98.7%), ce_loss 0.842, lat_loss 22.069
09/21 04:56:53 PM | _w_step_train: [ 59/180] Final Prec@1 80.0375% Time 609.75
09/21 04:56:53 PM | Start to train theta for epoch 58
09/21 04:57:14 PM | Train: [ 59/180] Step 050/312 Loss 3.141 Prec@(1,3) (77.2%, 98.7%), ce_loss 0.842, lat_loss 22.069
09/21 04:57:36 PM | Train: [ 59/180] Step 100/312 Loss 3.211 Prec@(1,3) (76.5%, 98.6%), ce_loss 0.842, lat_loss 22.069
09/21 04:57:56 PM | Train: [ 59/180] Step 150/312 Loss 3.148 Prec@(1,3) (77.1%, 98.5%), ce_loss 0.842, lat_loss 22.068
09/21 04:58:18 PM | Train: [ 59/180] Step 200/312 Loss 3.070 Prec@(1,3) (77.5%, 98.6%), ce_loss 0.842, lat_loss 22.068
09/21 04:58:39 PM | Train: [ 59/180] Step 250/312 Loss 3.090 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.842, lat_loss 22.068
09/21 04:59:00 PM | Train: [ 59/180] Step 300/312 Loss 3.075 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.842, lat_loss 22.068
09/21 04:59:05 PM | Train: [ 59/180] Step 312/312 Loss 3.085 Prec@(1,3) (77.3%, 98.5%), ce_loss 0.842, lat_loss 22.068
09/21 04:59:05 PM | _theta_step_train: [ 59/180] Final Prec@1 77.2800% Time 132.17
09/21 04:59:10 PM | Valid: [ 59/180] Step 050/312 Loss 3.144 Prec@(1,3) (76.2%, 98.7%), ce_loss 0.842, lat_loss 22.068
09/21 04:59:15 PM | Valid: [ 59/180] Step 100/312 Loss 3.175 Prec@(1,3) (76.2%, 98.5%), ce_loss 0.842, lat_loss 22.068
09/21 04:59:20 PM | Valid: [ 59/180] Step 150/312 Loss 3.246 Prec@(1,3) (76.4%, 98.1%), ce_loss 0.842, lat_loss 22.068
09/21 04:59:24 PM | Valid: [ 59/180] Step 200/312 Loss 3.216 Prec@(1,3) (76.3%, 98.2%), ce_loss 0.842, lat_loss 22.068
09/21 04:59:29 PM | Valid: [ 59/180] Step 250/312 Loss 3.263 Prec@(1,3) (75.8%, 98.3%), ce_loss 0.842, lat_loss 22.068
09/21 04:59:34 PM | Valid: [ 59/180] Step 300/312 Loss 3.215 Prec@(1,3) (76.2%, 98.4%), ce_loss 0.842, lat_loss 22.068
09/21 04:59:35 PM | Valid: [ 59/180] Step 312/312 Loss 3.223 Prec@(1,3) (76.2%, 98.4%), ce_loss 0.842, lat_loss 22.068
09/21 04:59:35 PM | val: [ 59/180] Final Prec@1 76.1700% Time 29.84
09/21 04:59:35 PM | Start to train weights for epoch 59
09/21 05:00:01 PM | Train: [ 60/180] Step 050/1249 Loss 2.512 Prec@(1,3) (81.2%, 99.0%), ce_loss 0.842, lat_loss 22.068
09/21 05:00:24 PM | Train: [ 60/180] Step 100/1249 Loss 2.482 Prec@(1,3) (81.4%, 99.0%), ce_loss 0.841, lat_loss 22.068
09/21 05:00:47 PM | Train: [ 60/180] Step 150/1249 Loss 2.585 Prec@(1,3) (80.7%, 98.8%), ce_loss 0.841, lat_loss 22.068
09/21 05:01:10 PM | Train: [ 60/180] Step 200/1249 Loss 2.643 Prec@(1,3) (80.5%, 98.6%), ce_loss 0.841, lat_loss 22.068
09/21 05:01:33 PM | Train: [ 60/180] Step 250/1249 Loss 2.674 Prec@(1,3) (80.3%, 98.6%), ce_loss 0.841, lat_loss 22.068
09/21 05:01:54 PM | Train: [ 60/180] Step 300/1249 Loss 2.653 Prec@(1,3) (80.4%, 98.6%), ce_loss 0.841, lat_loss 22.068
09/21 05:02:17 PM | Train: [ 60/180] Step 350/1249 Loss 2.617 Prec@(1,3) (80.6%, 98.6%), ce_loss 0.841, lat_loss 22.068
09/21 05:02:38 PM | Train: [ 60/180] Step 400/1249 Loss 2.603 Prec@(1,3) (80.7%, 98.7%), ce_loss 0.841, lat_loss 22.068
09/21 05:03:01 PM | Train: [ 60/180] Step 450/1249 Loss 2.580 Prec@(1,3) (80.7%, 98.7%), ce_loss 0.841, lat_loss 22.068
09/21 05:03:23 PM | Train: [ 60/180] Step 500/1249 Loss 2.600 Prec@(1,3) (80.5%, 98.7%), ce_loss 0.841, lat_loss 22.068
09/21 05:03:45 PM | Train: [ 60/180] Step 550/1249 Loss 2.599 Prec@(1,3) (80.5%, 98.7%), ce_loss 0.840, lat_loss 22.068
09/21 05:04:06 PM | Train: [ 60/180] Step 600/1249 Loss 2.598 Prec@(1,3) (80.5%, 98.7%), ce_loss 0.840, lat_loss 22.068
09/21 05:04:28 PM | Train: [ 60/180] Step 650/1249 Loss 2.602 Prec@(1,3) (80.4%, 98.6%), ce_loss 0.840, lat_loss 22.068
09/21 05:04:50 PM | Train: [ 60/180] Step 700/1249 Loss 2.614 Prec@(1,3) (80.4%, 98.6%), ce_loss 0.840, lat_loss 22.068
09/21 05:05:11 PM | Train: [ 60/180] Step 750/1249 Loss 2.627 Prec@(1,3) (80.2%, 98.6%), ce_loss 0.840, lat_loss 22.068
09/21 05:05:34 PM | Train: [ 60/180] Step 800/1249 Loss 2.623 Prec@(1,3) (80.3%, 98.6%), ce_loss 0.840, lat_loss 22.068
09/21 05:05:58 PM | Train: [ 60/180] Step 850/1249 Loss 2.629 Prec@(1,3) (80.2%, 98.6%), ce_loss 0.840, lat_loss 22.068
09/21 05:06:22 PM | Train: [ 60/180] Step 900/1249 Loss 2.627 Prec@(1,3) (80.2%, 98.6%), ce_loss 0.840, lat_loss 22.067
09/21 05:06:46 PM | Train: [ 60/180] Step 950/1249 Loss 2.620 Prec@(1,3) (80.3%, 98.6%), ce_loss 0.839, lat_loss 22.067
09/21 05:07:10 PM | Train: [ 60/180] Step 1000/1249 Loss 2.620 Prec@(1,3) (80.2%, 98.7%), ce_loss 0.839, lat_loss 22.067
09/21 05:07:35 PM | Train: [ 60/180] Step 1050/1249 Loss 2.629 Prec@(1,3) (80.1%, 98.6%), ce_loss 0.839, lat_loss 22.067
09/21 05:07:59 PM | Train: [ 60/180] Step 1100/1249 Loss 2.625 Prec@(1,3) (80.1%, 98.7%), ce_loss 0.839, lat_loss 22.067
09/21 05:08:24 PM | Train: [ 60/180] Step 1150/1249 Loss 2.628 Prec@(1,3) (80.0%, 98.7%), ce_loss 0.839, lat_loss 22.067
09/21 05:08:49 PM | Train: [ 60/180] Step 1200/1249 Loss 2.624 Prec@(1,3) (80.0%, 98.7%), ce_loss 0.839, lat_loss 22.067
09/21 05:09:13 PM | Train: [ 60/180] Step 1249/1249 Loss 2.628 Prec@(1,3) (80.0%, 98.7%), ce_loss 0.839, lat_loss 22.067
09/21 05:09:14 PM | _w_step_train: [ 60/180] Final Prec@1 80.0075% Time 578.84
09/21 05:09:14 PM | Start to train theta for epoch 59
09/21 05:09:35 PM | Train: [ 60/180] Step 050/312 Loss 2.797 Prec@(1,3) (78.1%, 98.3%), ce_loss 0.839, lat_loss 22.067
09/21 05:09:51 PM | Train: [ 60/180] Step 100/312 Loss 2.846 Prec@(1,3) (78.3%, 98.2%), ce_loss 0.839, lat_loss 22.067
09/21 05:10:04 PM | Train: [ 60/180] Step 150/312 Loss 2.829 Prec@(1,3) (78.4%, 98.2%), ce_loss 0.839, lat_loss 22.067
09/21 05:10:16 PM | Train: [ 60/180] Step 200/312 Loss 2.779 Prec@(1,3) (78.8%, 98.4%), ce_loss 0.838, lat_loss 22.067
09/21 05:10:28 PM | Train: [ 60/180] Step 250/312 Loss 2.783 Prec@(1,3) (78.8%, 98.4%), ce_loss 0.838, lat_loss 22.067
09/21 05:10:40 PM | Train: [ 60/180] Step 300/312 Loss 2.812 Prec@(1,3) (78.6%, 98.3%), ce_loss 0.838, lat_loss 22.067
09/21 05:10:43 PM | Train: [ 60/180] Step 312/312 Loss 2.809 Prec@(1,3) (78.5%, 98.3%), ce_loss 0.838, lat_loss 22.067
09/21 05:10:43 PM | _theta_step_train: [ 60/180] Final Prec@1 78.5200% Time 89.89
09/21 05:10:49 PM | Valid: [ 60/180] Step 050/312 Loss 2.767 Prec@(1,3) (78.9%, 98.7%), ce_loss 0.838, lat_loss 22.067
09/21 05:10:53 PM | Valid: [ 60/180] Step 100/312 Loss 2.854 Prec@(1,3) (78.2%, 98.6%), ce_loss 0.838, lat_loss 22.067
09/21 05:10:58 PM | Valid: [ 60/180] Step 150/312 Loss 2.944 Prec@(1,3) (77.8%, 98.3%), ce_loss 0.838, lat_loss 22.067
09/21 05:11:03 PM | Valid: [ 60/180] Step 200/312 Loss 2.929 Prec@(1,3) (78.0%, 98.4%), ce_loss 0.838, lat_loss 22.067
09/21 05:11:07 PM | Valid: [ 60/180] Step 250/312 Loss 2.927 Prec@(1,3) (77.9%, 98.5%), ce_loss 0.838, lat_loss 22.067
09/21 05:11:12 PM | Valid: [ 60/180] Step 300/312 Loss 2.967 Prec@(1,3) (77.7%, 98.5%), ce_loss 0.838, lat_loss 22.067
09/21 05:11:13 PM | Valid: [ 60/180] Step 312/312 Loss 2.970 Prec@(1,3) (77.6%, 98.5%), ce_loss 0.838, lat_loss 22.067
09/21 05:11:13 PM | val: [ 60/180] Final Prec@1 77.6200% Time 29.74
09/21 05:11:13 PM | Start to train weights for epoch 60
09/21 05:11:38 PM | Train: [ 61/180] Step 050/1249 Loss 2.590 Prec@(1,3) (80.1%, 98.8%), ce_loss 0.838, lat_loss 22.067
09/21 05:12:00 PM | Train: [ 61/180] Step 100/1249 Loss 2.459 Prec@(1,3) (81.1%, 99.0%), ce_loss 0.837, lat_loss 22.067
09/21 05:12:25 PM | Train: [ 61/180] Step 150/1249 Loss 2.450 Prec@(1,3) (81.2%, 99.0%), ce_loss 0.837, lat_loss 22.067
09/21 05:12:50 PM | Train: [ 61/180] Step 200/1249 Loss 2.495 Prec@(1,3) (80.8%, 98.9%), ce_loss 0.837, lat_loss 22.067
09/21 05:13:15 PM | Train: [ 61/180] Step 250/1249 Loss 2.496 Prec@(1,3) (80.8%, 98.9%), ce_loss 0.837, lat_loss 22.066
09/21 05:13:40 PM | Train: [ 61/180] Step 300/1249 Loss 2.542 Prec@(1,3) (80.5%, 98.7%), ce_loss 0.837, lat_loss 22.066
09/21 05:14:05 PM | Train: [ 61/180] Step 350/1249 Loss 2.596 Prec@(1,3) (80.4%, 98.7%), ce_loss 0.837, lat_loss 22.066
09/21 05:14:30 PM | Train: [ 61/180] Step 400/1249 Loss 2.607 Prec@(1,3) (80.3%, 98.7%), ce_loss 0.837, lat_loss 22.066
09/21 05:14:55 PM | Train: [ 61/180] Step 450/1249 Loss 2.608 Prec@(1,3) (80.2%, 98.7%), ce_loss 0.837, lat_loss 22.066
09/21 05:15:19 PM | Train: [ 61/180] Step 500/1249 Loss 2.598 Prec@(1,3) (80.3%, 98.7%), ce_loss 0.837, lat_loss 22.066
09/21 05:15:42 PM | Train: [ 61/180] Step 550/1249 Loss 2.595 Prec@(1,3) (80.4%, 98.7%), ce_loss 0.836, lat_loss 22.066
09/21 05:16:07 PM | Train: [ 61/180] Step 600/1249 Loss 2.583 Prec@(1,3) (80.4%, 98.7%), ce_loss 0.836, lat_loss 22.066
09/21 05:16:32 PM | Train: [ 61/180] Step 650/1249 Loss 2.581 Prec@(1,3) (80.4%, 98.7%), ce_loss 0.836, lat_loss 22.066
09/21 05:16:57 PM | Train: [ 61/180] Step 700/1249 Loss 2.602 Prec@(1,3) (80.3%, 98.6%), ce_loss 0.836, lat_loss 22.066
09/21 05:17:22 PM | Train: [ 61/180] Step 750/1249 Loss 2.614 Prec@(1,3) (80.2%, 98.6%), ce_loss 0.836, lat_loss 22.066
09/21 05:17:47 PM | Train: [ 61/180] Step 800/1249 Loss 2.621 Prec@(1,3) (80.1%, 98.7%), ce_loss 0.836, lat_loss 22.066
09/21 05:18:12 PM | Train: [ 61/180] Step 850/1249 Loss 2.615 Prec@(1,3) (80.2%, 98.7%), ce_loss 0.836, lat_loss 22.066
09/21 05:18:36 PM | Train: [ 61/180] Step 900/1249 Loss 2.620 Prec@(1,3) (80.2%, 98.7%), ce_loss 0.836, lat_loss 22.066
09/21 05:19:01 PM | Train: [ 61/180] Step 950/1249 Loss 2.620 Prec@(1,3) (80.1%, 98.7%), ce_loss 0.836, lat_loss 22.066
09/21 05:19:26 PM | Train: [ 61/180] Step 1000/1249 Loss 2.610 Prec@(1,3) (80.2%, 98.7%), ce_loss 0.835, lat_loss 22.066
09/21 05:19:50 PM | Train: [ 61/180] Step 1050/1249 Loss 2.613 Prec@(1,3) (80.2%, 98.7%), ce_loss 0.835, lat_loss 22.066
09/21 05:20:15 PM | Train: [ 61/180] Step 1100/1249 Loss 2.610 Prec@(1,3) (80.2%, 98.7%), ce_loss 0.835, lat_loss 22.066
09/21 05:20:39 PM | Train: [ 61/180] Step 1150/1249 Loss 2.605 Prec@(1,3) (80.2%, 98.7%), ce_loss 0.835, lat_loss 22.066
09/21 05:21:00 PM | Train: [ 61/180] Step 1200/1249 Loss 2.592 Prec@(1,3) (80.3%, 98.7%), ce_loss 0.835, lat_loss 22.066
09/21 05:21:15 PM | Train: [ 61/180] Step 1249/1249 Loss 2.590 Prec@(1,3) (80.3%, 98.7%), ce_loss 0.835, lat_loss 22.066
09/21 05:21:15 PM | _w_step_train: [ 61/180] Final Prec@1 80.2900% Time 602.23
09/21 05:21:15 PM | Start to train theta for epoch 60
09/21 05:21:37 PM | Train: [ 61/180] Step 050/312 Loss 2.786 Prec@(1,3) (78.7%, 98.3%), ce_loss 0.835, lat_loss 22.065
09/21 05:21:58 PM | Train: [ 61/180] Step 100/312 Loss 2.746 Prec@(1,3) (79.1%, 98.4%), ce_loss 0.835, lat_loss 22.065
09/21 05:22:18 PM | Train: [ 61/180] Step 150/312 Loss 2.731 Prec@(1,3) (79.2%, 98.4%), ce_loss 0.835, lat_loss 22.065
09/21 05:22:38 PM | Train: [ 61/180] Step 200/312 Loss 2.727 Prec@(1,3) (79.4%, 98.5%), ce_loss 0.834, lat_loss 22.065
09/21 05:22:59 PM | Train: [ 61/180] Step 250/312 Loss 2.720 Prec@(1,3) (79.3%, 98.5%), ce_loss 0.834, lat_loss 22.065
09/21 05:23:19 PM | Train: [ 61/180] Step 300/312 Loss 2.695 Prec@(1,3) (79.5%, 98.5%), ce_loss 0.834, lat_loss 22.065
09/21 05:23:24 PM | Train: [ 61/180] Step 312/312 Loss 2.680 Prec@(1,3) (79.6%, 98.6%), ce_loss 0.834, lat_loss 22.065
09/21 05:23:24 PM | _theta_step_train: [ 61/180] Final Prec@1 79.6100% Time 128.94
09/21 05:23:30 PM | Valid: [ 61/180] Step 050/312 Loss 2.746 Prec@(1,3) (78.9%, 98.7%), ce_loss 0.834, lat_loss 22.065
09/21 05:23:34 PM | Valid: [ 61/180] Step 100/312 Loss 2.813 Prec@(1,3) (78.1%, 98.6%), ce_loss 0.834, lat_loss 22.065
09/21 05:23:39 PM | Valid: [ 61/180] Step 150/312 Loss 2.873 Prec@(1,3) (77.7%, 98.4%), ce_loss 0.834, lat_loss 22.065
09/21 05:23:44 PM | Valid: [ 61/180] Step 200/312 Loss 2.910 Prec@(1,3) (77.4%, 98.3%), ce_loss 0.834, lat_loss 22.065
09/21 05:23:49 PM | Valid: [ 61/180] Step 250/312 Loss 3.092 Prec@(1,3) (76.5%, 98.0%), ce_loss 0.834, lat_loss 22.065
09/21 05:23:53 PM | Valid: [ 61/180] Step 300/312 Loss 3.034 Prec@(1,3) (77.0%, 98.1%), ce_loss 0.834, lat_loss 22.065
09/21 05:23:54 PM | Valid: [ 61/180] Step 312/312 Loss 3.061 Prec@(1,3) (76.6%, 98.1%), ce_loss 0.834, lat_loss 22.065
09/21 05:23:55 PM | val: [ 61/180] Final Prec@1 76.6500% Time 30.13
09/21 05:23:55 PM | Start to train weights for epoch 61
09/21 05:24:21 PM | Train: [ 62/180] Step 050/1249 Loss 2.480 Prec@(1,3) (80.1%, 99.1%), ce_loss 0.834, lat_loss 22.065
09/21 05:24:46 PM | Train: [ 62/180] Step 100/1249 Loss 2.528 Prec@(1,3) (80.0%, 98.9%), ce_loss 0.834, lat_loss 22.065
09/21 05:25:11 PM | Train: [ 62/180] Step 150/1249 Loss 2.477 Prec@(1,3) (80.5%, 98.9%), ce_loss 0.833, lat_loss 22.065
09/21 05:25:36 PM | Train: [ 62/180] Step 200/1249 Loss 2.481 Prec@(1,3) (80.5%, 98.8%), ce_loss 0.833, lat_loss 22.065
09/21 05:26:00 PM | Train: [ 62/180] Step 250/1249 Loss 2.489 Prec@(1,3) (80.7%, 98.7%), ce_loss 0.833, lat_loss 22.065
09/21 05:26:25 PM | Train: [ 62/180] Step 300/1249 Loss 2.484 Prec@(1,3) (80.7%, 98.7%), ce_loss 0.833, lat_loss 22.064
09/21 05:26:50 PM | Train: [ 62/180] Step 350/1249 Loss 2.500 Prec@(1,3) (80.6%, 98.8%), ce_loss 0.833, lat_loss 22.064
09/21 05:27:15 PM | Train: [ 62/180] Step 400/1249 Loss 2.519 Prec@(1,3) (80.5%, 98.7%), ce_loss 0.833, lat_loss 22.064
09/21 05:27:40 PM | Train: [ 62/180] Step 450/1249 Loss 2.529 Prec@(1,3) (80.4%, 98.7%), ce_loss 0.833, lat_loss 22.064
09/21 05:28:05 PM | Train: [ 62/180] Step 500/1249 Loss 2.530 Prec@(1,3) (80.4%, 98.7%), ce_loss 0.833, lat_loss 22.064
09/21 05:28:30 PM | Train: [ 62/180] Step 550/1249 Loss 2.529 Prec@(1,3) (80.4%, 98.7%), ce_loss 0.833, lat_loss 22.064
09/21 05:28:55 PM | Train: [ 62/180] Step 600/1249 Loss 2.554 Prec@(1,3) (80.4%, 98.7%), ce_loss 0.832, lat_loss 22.064
09/21 05:29:20 PM | Train: [ 62/180] Step 650/1249 Loss 2.557 Prec@(1,3) (80.4%, 98.7%), ce_loss 0.832, lat_loss 22.064
09/21 05:29:45 PM | Train: [ 62/180] Step 700/1249 Loss 2.582 Prec@(1,3) (80.3%, 98.7%), ce_loss 0.832, lat_loss 22.064
09/21 05:30:10 PM | Train: [ 62/180] Step 750/1249 Loss 2.588 Prec@(1,3) (80.3%, 98.7%), ce_loss 0.832, lat_loss 22.064
09/21 05:30:34 PM | Train: [ 62/180] Step 800/1249 Loss 2.589 Prec@(1,3) (80.3%, 98.7%), ce_loss 0.832, lat_loss 22.064
09/21 05:30:59 PM | Train: [ 62/180] Step 850/1249 Loss 2.583 Prec@(1,3) (80.3%, 98.7%), ce_loss 0.832, lat_loss 22.064
09/21 05:31:25 PM | Train: [ 62/180] Step 900/1249 Loss 2.573 Prec@(1,3) (80.4%, 98.8%), ce_loss 0.832, lat_loss 22.064
09/21 05:31:48 PM | Train: [ 62/180] Step 950/1249 Loss 2.569 Prec@(1,3) (80.4%, 98.8%), ce_loss 0.832, lat_loss 22.064
09/21 05:32:13 PM | Train: [ 62/180] Step 1000/1249 Loss 2.563 Prec@(1,3) (80.5%, 98.8%), ce_loss 0.832, lat_loss 22.064
09/21 05:32:37 PM | Train: [ 62/180] Step 1050/1249 Loss 2.560 Prec@(1,3) (80.5%, 98.8%), ce_loss 0.831, lat_loss 22.064
09/21 05:33:03 PM | Train: [ 62/180] Step 1100/1249 Loss 2.551 Prec@(1,3) (80.5%, 98.8%), ce_loss 0.831, lat_loss 22.064
09/21 05:33:27 PM | Train: [ 62/180] Step 1150/1249 Loss 2.552 Prec@(1,3) (80.5%, 98.8%), ce_loss 0.831, lat_loss 22.064
09/21 05:33:52 PM | Train: [ 62/180] Step 1200/1249 Loss 2.552 Prec@(1,3) (80.5%, 98.8%), ce_loss 0.831, lat_loss 22.063
09/21 05:34:16 PM | Train: [ 62/180] Step 1249/1249 Loss 2.545 Prec@(1,3) (80.5%, 98.8%), ce_loss 0.831, lat_loss 22.063
09/21 05:34:16 PM | _w_step_train: [ 62/180] Final Prec@1 80.5000% Time 621.89
09/21 05:34:16 PM | Start to train theta for epoch 61
09/21 05:34:38 PM | Train: [ 62/180] Step 050/312 Loss 2.898 Prec@(1,3) (77.5%, 99.0%), ce_loss 0.831, lat_loss 22.063
09/21 05:34:59 PM | Train: [ 62/180] Step 100/312 Loss 2.845 Prec@(1,3) (78.6%, 98.9%), ce_loss 0.831, lat_loss 22.063
09/21 05:35:19 PM | Train: [ 62/180] Step 150/312 Loss 2.852 Prec@(1,3) (78.2%, 98.8%), ce_loss 0.831, lat_loss 22.063
09/21 05:35:40 PM | Train: [ 62/180] Step 200/312 Loss 2.850 Prec@(1,3) (78.4%, 98.8%), ce_loss 0.831, lat_loss 22.063
09/21 05:36:00 PM | Train: [ 62/180] Step 250/312 Loss 2.873 Prec@(1,3) (78.3%, 98.7%), ce_loss 0.831, lat_loss 22.063
09/21 05:36:21 PM | Train: [ 62/180] Step 300/312 Loss 2.858 Prec@(1,3) (78.4%, 98.7%), ce_loss 0.830, lat_loss 22.063
09/21 05:36:26 PM | Train: [ 62/180] Step 312/312 Loss 2.863 Prec@(1,3) (78.4%, 98.7%), ce_loss 0.830, lat_loss 22.063
09/21 05:36:26 PM | _theta_step_train: [ 62/180] Final Prec@1 78.4000% Time 129.45
09/21 05:36:32 PM | Valid: [ 62/180] Step 050/312 Loss 3.043 Prec@(1,3) (76.6%, 98.8%), ce_loss 0.830, lat_loss 22.063
09/21 05:36:36 PM | Valid: [ 62/180] Step 100/312 Loss 3.088 Prec@(1,3) (76.9%, 98.5%), ce_loss 0.830, lat_loss 22.063
09/21 05:36:41 PM | Valid: [ 62/180] Step 150/312 Loss 3.013 Prec@(1,3) (78.0%, 98.5%), ce_loss 0.830, lat_loss 22.063
09/21 05:36:46 PM | Valid: [ 62/180] Step 200/312 Loss 3.004 Prec@(1,3) (77.8%, 98.5%), ce_loss 0.830, lat_loss 22.063
09/21 05:36:50 PM | Valid: [ 62/180] Step 250/312 Loss 3.122 Prec@(1,3) (76.4%, 98.2%), ce_loss 0.830, lat_loss 22.063
09/21 05:36:55 PM | Valid: [ 62/180] Step 300/312 Loss 3.098 Prec@(1,3) (76.5%, 98.3%), ce_loss 0.830, lat_loss 22.063
09/21 05:36:56 PM | Valid: [ 62/180] Step 312/312 Loss 3.098 Prec@(1,3) (76.5%, 98.4%), ce_loss 0.830, lat_loss 22.063
09/21 05:36:56 PM | val: [ 62/180] Final Prec@1 76.4800% Time 29.86
09/21 05:36:56 PM | Start to train weights for epoch 62
09/21 05:37:23 PM | Train: [ 63/180] Step 050/1249 Loss 2.413 Prec@(1,3) (82.8%, 99.0%), ce_loss 0.830, lat_loss 22.063
09/21 05:37:48 PM | Train: [ 63/180] Step 100/1249 Loss 2.343 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.830, lat_loss 22.063
09/21 05:38:13 PM | Train: [ 63/180] Step 150/1249 Loss 2.385 Prec@(1,3) (82.6%, 98.9%), ce_loss 0.830, lat_loss 22.063
09/21 05:38:38 PM | Train: [ 63/180] Step 200/1249 Loss 2.387 Prec@(1,3) (82.1%, 98.9%), ce_loss 0.830, lat_loss 22.063
09/21 05:38:58 PM | Train: [ 63/180] Step 250/1249 Loss 2.398 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.829, lat_loss 22.063
09/21 05:39:18 PM | Train: [ 63/180] Step 300/1249 Loss 2.434 Prec@(1,3) (81.4%, 98.9%), ce_loss 0.829, lat_loss 22.062
09/21 05:39:38 PM | Train: [ 63/180] Step 350/1249 Loss 2.456 Prec@(1,3) (81.3%, 98.8%), ce_loss 0.829, lat_loss 22.062
09/21 05:40:04 PM | Train: [ 63/180] Step 400/1249 Loss 2.450 Prec@(1,3) (81.4%, 98.8%), ce_loss 0.829, lat_loss 22.062
09/21 05:40:29 PM | Train: [ 63/180] Step 450/1249 Loss 2.445 Prec@(1,3) (81.4%, 98.9%), ce_loss 0.829, lat_loss 22.062
09/21 05:40:54 PM | Train: [ 63/180] Step 500/1249 Loss 2.469 Prec@(1,3) (81.1%, 98.8%), ce_loss 0.829, lat_loss 22.062
09/21 05:41:19 PM | Train: [ 63/180] Step 550/1249 Loss 2.466 Prec@(1,3) (81.2%, 98.9%), ce_loss 0.829, lat_loss 22.062
09/21 05:41:44 PM | Train: [ 63/180] Step 600/1249 Loss 2.465 Prec@(1,3) (81.2%, 98.9%), ce_loss 0.829, lat_loss 22.062
09/21 05:42:10 PM | Train: [ 63/180] Step 650/1249 Loss 2.469 Prec@(1,3) (81.2%, 98.9%), ce_loss 0.828, lat_loss 22.062
09/21 05:42:35 PM | Train: [ 63/180] Step 700/1249 Loss 2.465 Prec@(1,3) (81.3%, 98.9%), ce_loss 0.828, lat_loss 22.062
09/21 05:43:00 PM | Train: [ 63/180] Step 750/1249 Loss 2.488 Prec@(1,3) (81.1%, 98.9%), ce_loss 0.828, lat_loss 22.062
09/21 05:43:25 PM | Train: [ 63/180] Step 800/1249 Loss 2.487 Prec@(1,3) (81.1%, 98.9%), ce_loss 0.828, lat_loss 22.062
09/21 05:43:51 PM | Train: [ 63/180] Step 850/1249 Loss 2.493 Prec@(1,3) (81.1%, 98.9%), ce_loss 0.828, lat_loss 22.062
09/21 05:44:17 PM | Train: [ 63/180] Step 900/1249 Loss 2.492 Prec@(1,3) (81.1%, 98.8%), ce_loss 0.828, lat_loss 22.062
09/21 05:44:42 PM | Train: [ 63/180] Step 950/1249 Loss 2.499 Prec@(1,3) (81.0%, 98.8%), ce_loss 0.828, lat_loss 22.062
09/21 05:45:08 PM | Train: [ 63/180] Step 1000/1249 Loss 2.498 Prec@(1,3) (81.0%, 98.8%), ce_loss 0.828, lat_loss 22.062
09/21 05:45:34 PM | Train: [ 63/180] Step 1050/1249 Loss 2.489 Prec@(1,3) (81.1%, 98.9%), ce_loss 0.828, lat_loss 22.062
09/21 05:45:59 PM | Train: [ 63/180] Step 1100/1249 Loss 2.491 Prec@(1,3) (81.1%, 98.9%), ce_loss 0.827, lat_loss 22.062
09/21 05:46:24 PM | Train: [ 63/180] Step 1150/1249 Loss 2.498 Prec@(1,3) (81.0%, 98.9%), ce_loss 0.827, lat_loss 22.062
09/21 05:46:50 PM | Train: [ 63/180] Step 1200/1249 Loss 2.489 Prec@(1,3) (81.1%, 98.9%), ce_loss 0.827, lat_loss 22.062
09/21 05:47:14 PM | Train: [ 63/180] Step 1249/1249 Loss 2.486 Prec@(1,3) (81.0%, 98.9%), ce_loss 0.827, lat_loss 22.062
09/21 05:47:14 PM | _w_step_train: [ 63/180] Final Prec@1 81.0400% Time 618.11
09/21 05:47:14 PM | Start to train theta for epoch 62
09/21 05:47:35 PM | Train: [ 63/180] Step 050/312 Loss 2.811 Prec@(1,3) (79.0%, 98.5%), ce_loss 0.827, lat_loss 22.061
09/21 05:47:55 PM | Train: [ 63/180] Step 100/312 Loss 2.819 Prec@(1,3) (78.8%, 98.4%), ce_loss 0.827, lat_loss 22.061
09/21 05:48:15 PM | Train: [ 63/180] Step 150/312 Loss 2.774 Prec@(1,3) (79.4%, 98.4%), ce_loss 0.827, lat_loss 22.061
09/21 05:48:35 PM | Train: [ 63/180] Step 200/312 Loss 2.757 Prec@(1,3) (79.5%, 98.4%), ce_loss 0.827, lat_loss 22.061
09/21 05:48:54 PM | Train: [ 63/180] Step 250/312 Loss 2.780 Prec@(1,3) (79.4%, 98.4%), ce_loss 0.827, lat_loss 22.061
09/21 05:49:14 PM | Train: [ 63/180] Step 300/312 Loss 2.782 Prec@(1,3) (79.3%, 98.5%), ce_loss 0.827, lat_loss 22.061
09/21 05:49:19 PM | Train: [ 63/180] Step 312/312 Loss 2.776 Prec@(1,3) (79.3%, 98.5%), ce_loss 0.827, lat_loss 22.061
09/21 05:49:20 PM | _theta_step_train: [ 63/180] Final Prec@1 79.3200% Time 125.64
09/21 05:49:25 PM | Valid: [ 63/180] Step 050/312 Loss 2.714 Prec@(1,3) (80.8%, 98.6%), ce_loss 0.826, lat_loss 22.061
09/21 05:49:30 PM | Valid: [ 63/180] Step 100/312 Loss 2.811 Prec@(1,3) (79.3%, 98.3%), ce_loss 0.826, lat_loss 22.061
09/21 05:49:34 PM | Valid: [ 63/180] Step 150/312 Loss 2.867 Prec@(1,3) (78.7%, 98.1%), ce_loss 0.826, lat_loss 22.061
09/21 05:49:39 PM | Valid: [ 63/180] Step 200/312 Loss 2.874 Prec@(1,3) (78.2%, 98.1%), ce_loss 0.826, lat_loss 22.061
09/21 05:49:44 PM | Valid: [ 63/180] Step 250/312 Loss 2.850 Prec@(1,3) (78.2%, 98.3%), ce_loss 0.826, lat_loss 22.061
09/21 05:49:48 PM | Valid: [ 63/180] Step 300/312 Loss 2.840 Prec@(1,3) (78.2%, 98.4%), ce_loss 0.826, lat_loss 22.061
09/21 05:49:49 PM | Valid: [ 63/180] Step 312/312 Loss 2.834 Prec@(1,3) (78.2%, 98.4%), ce_loss 0.826, lat_loss 22.061
09/21 05:49:50 PM | val: [ 63/180] Final Prec@1 78.2500% Time 29.51
09/21 05:49:50 PM | Start to train weights for epoch 63
09/21 05:50:15 PM | Train: [ 64/180] Step 050/1249 Loss 2.280 Prec@(1,3) (82.1%, 99.4%), ce_loss 0.826, lat_loss 22.061
09/21 05:50:39 PM | Train: [ 64/180] Step 100/1249 Loss 2.258 Prec@(1,3) (82.7%, 99.3%), ce_loss 0.826, lat_loss 22.061
09/21 05:51:03 PM | Train: [ 64/180] Step 150/1249 Loss 2.288 Prec@(1,3) (82.8%, 99.2%), ce_loss 0.826, lat_loss 22.061
09/21 05:51:26 PM | Train: [ 64/180] Step 200/1249 Loss 2.275 Prec@(1,3) (82.8%, 99.2%), ce_loss 0.825, lat_loss 22.061
09/21 05:51:50 PM | Train: [ 64/180] Step 250/1249 Loss 2.364 Prec@(1,3) (82.2%, 99.1%), ce_loss 0.825, lat_loss 22.061
09/21 05:52:13 PM | Train: [ 64/180] Step 300/1249 Loss 2.343 Prec@(1,3) (82.5%, 99.0%), ce_loss 0.825, lat_loss 22.061
09/21 05:52:38 PM | Train: [ 64/180] Step 350/1249 Loss 2.373 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.825, lat_loss 22.061
09/21 05:53:01 PM | Train: [ 64/180] Step 400/1249 Loss 2.386 Prec@(1,3) (81.9%, 99.0%), ce_loss 0.825, lat_loss 22.061
09/21 05:53:25 PM | Train: [ 64/180] Step 450/1249 Loss 2.419 Prec@(1,3) (81.6%, 99.0%), ce_loss 0.825, lat_loss 22.061
09/21 05:53:49 PM | Train: [ 64/180] Step 500/1249 Loss 2.408 Prec@(1,3) (81.6%, 99.0%), ce_loss 0.825, lat_loss 22.061
09/21 05:54:14 PM | Train: [ 64/180] Step 550/1249 Loss 2.418 Prec@(1,3) (81.5%, 98.9%), ce_loss 0.825, lat_loss 22.060
09/21 05:54:38 PM | Train: [ 64/180] Step 600/1249 Loss 2.415 Prec@(1,3) (81.6%, 99.0%), ce_loss 0.825, lat_loss 22.060
09/21 05:55:03 PM | Train: [ 64/180] Step 650/1249 Loss 2.406 Prec@(1,3) (81.6%, 99.0%), ce_loss 0.824, lat_loss 22.060
09/21 05:55:27 PM | Train: [ 64/180] Step 700/1249 Loss 2.408 Prec@(1,3) (81.6%, 99.0%), ce_loss 0.824, lat_loss 22.060
09/21 05:55:50 PM | Train: [ 64/180] Step 750/1249 Loss 2.426 Prec@(1,3) (81.5%, 99.0%), ce_loss 0.824, lat_loss 22.060
09/21 05:56:14 PM | Train: [ 64/180] Step 800/1249 Loss 2.436 Prec@(1,3) (81.4%, 99.0%), ce_loss 0.824, lat_loss 22.060
09/21 05:56:37 PM | Train: [ 64/180] Step 850/1249 Loss 2.437 Prec@(1,3) (81.4%, 98.9%), ce_loss 0.824, lat_loss 22.060
09/21 05:57:02 PM | Train: [ 64/180] Step 900/1249 Loss 2.441 Prec@(1,3) (81.4%, 98.9%), ce_loss 0.824, lat_loss 22.060
09/21 05:57:27 PM | Train: [ 64/180] Step 950/1249 Loss 2.441 Prec@(1,3) (81.4%, 98.9%), ce_loss 0.824, lat_loss 22.060
09/21 05:57:51 PM | Train: [ 64/180] Step 1000/1249 Loss 2.442 Prec@(1,3) (81.4%, 98.9%), ce_loss 0.824, lat_loss 22.060
09/21 05:58:16 PM | Train: [ 64/180] Step 1050/1249 Loss 2.450 Prec@(1,3) (81.3%, 98.9%), ce_loss 0.824, lat_loss 22.060
09/21 05:58:40 PM | Train: [ 64/180] Step 1100/1249 Loss 2.444 Prec@(1,3) (81.4%, 98.9%), ce_loss 0.823, lat_loss 22.060
09/21 05:59:05 PM | Train: [ 64/180] Step 1150/1249 Loss 2.432 Prec@(1,3) (81.5%, 98.9%), ce_loss 0.823, lat_loss 22.060
09/21 05:59:29 PM | Train: [ 64/180] Step 1200/1249 Loss 2.422 Prec@(1,3) (81.5%, 98.9%), ce_loss 0.823, lat_loss 22.060
09/21 05:59:54 PM | Train: [ 64/180] Step 1249/1249 Loss 2.435 Prec@(1,3) (81.4%, 98.9%), ce_loss 0.823, lat_loss 22.060
09/21 05:59:54 PM | _w_step_train: [ 64/180] Final Prec@1 81.4475% Time 604.47
09/21 05:59:54 PM | Start to train theta for epoch 63
09/21 06:00:15 PM | Train: [ 64/180] Step 050/312 Loss 2.428 Prec@(1,3) (80.7%, 98.5%), ce_loss 0.823, lat_loss 22.060
09/21 06:00:35 PM | Train: [ 64/180] Step 100/312 Loss 2.610 Prec@(1,3) (79.8%, 98.2%), ce_loss 0.823, lat_loss 22.060
09/21 06:00:55 PM | Train: [ 64/180] Step 150/312 Loss 2.683 Prec@(1,3) (79.5%, 98.4%), ce_loss 0.823, lat_loss 22.060
09/21 06:01:15 PM | Train: [ 64/180] Step 200/312 Loss 2.747 Prec@(1,3) (79.1%, 98.4%), ce_loss 0.823, lat_loss 22.060
09/21 06:01:35 PM | Train: [ 64/180] Step 250/312 Loss 2.774 Prec@(1,3) (78.9%, 98.4%), ce_loss 0.823, lat_loss 22.060
09/21 06:01:56 PM | Train: [ 64/180] Step 300/312 Loss 2.803 Prec@(1,3) (78.8%, 98.4%), ce_loss 0.823, lat_loss 22.060
09/21 06:02:01 PM | Train: [ 64/180] Step 312/312 Loss 2.792 Prec@(1,3) (78.8%, 98.4%), ce_loss 0.823, lat_loss 22.060
09/21 06:02:02 PM | _theta_step_train: [ 64/180] Final Prec@1 78.8500% Time 127.58
09/21 06:02:07 PM | Valid: [ 64/180] Step 050/312 Loss 2.604 Prec@(1,3) (79.6%, 98.9%), ce_loss 0.822, lat_loss 22.060
09/21 06:02:11 PM | Valid: [ 64/180] Step 100/312 Loss 2.813 Prec@(1,3) (78.1%, 98.8%), ce_loss 0.822, lat_loss 22.060
09/21 06:02:16 PM | Valid: [ 64/180] Step 150/312 Loss 2.929 Prec@(1,3) (77.6%, 98.6%), ce_loss 0.822, lat_loss 22.059
09/21 06:02:21 PM | Valid: [ 64/180] Step 200/312 Loss 2.935 Prec@(1,3) (77.9%, 98.6%), ce_loss 0.822, lat_loss 22.059
09/21 06:02:25 PM | Valid: [ 64/180] Step 250/312 Loss 2.966 Prec@(1,3) (77.4%, 98.7%), ce_loss 0.822, lat_loss 22.059
09/21 06:02:30 PM | Valid: [ 64/180] Step 300/312 Loss 2.915 Prec@(1,3) (77.9%, 98.7%), ce_loss 0.822, lat_loss 22.059
09/21 06:02:31 PM | Valid: [ 64/180] Step 312/312 Loss 2.924 Prec@(1,3) (77.8%, 98.8%), ce_loss 0.822, lat_loss 22.059
09/21 06:02:31 PM | val: [ 64/180] Final Prec@1 77.8300% Time 29.58
09/21 06:02:31 PM | Start to train weights for epoch 64
09/21 06:02:55 PM | Train: [ 65/180] Step 050/1249 Loss 2.322 Prec@(1,3) (81.9%, 99.0%), ce_loss 0.822, lat_loss 22.059
09/21 06:03:19 PM | Train: [ 65/180] Step 100/1249 Loss 2.427 Prec@(1,3) (81.9%, 98.9%), ce_loss 0.822, lat_loss 22.059
09/21 06:03:41 PM | Train: [ 65/180] Step 150/1249 Loss 2.330 Prec@(1,3) (82.6%, 98.9%), ce_loss 0.822, lat_loss 22.059
09/21 06:04:05 PM | Train: [ 65/180] Step 200/1249 Loss 2.332 Prec@(1,3) (82.7%, 98.9%), ce_loss 0.822, lat_loss 22.059
09/21 06:04:27 PM | Train: [ 65/180] Step 250/1249 Loss 2.303 Prec@(1,3) (82.9%, 99.0%), ce_loss 0.821, lat_loss 22.059
09/21 06:04:50 PM | Train: [ 65/180] Step 300/1249 Loss 2.323 Prec@(1,3) (82.5%, 99.0%), ce_loss 0.821, lat_loss 22.059
09/21 06:05:12 PM | Train: [ 65/180] Step 350/1249 Loss 2.353 Prec@(1,3) (82.3%, 99.1%), ce_loss 0.821, lat_loss 22.059
09/21 06:05:32 PM | Train: [ 65/180] Step 400/1249 Loss 2.353 Prec@(1,3) (82.4%, 99.0%), ce_loss 0.821, lat_loss 22.059
09/21 06:05:54 PM | Train: [ 65/180] Step 450/1249 Loss 2.347 Prec@(1,3) (82.5%, 99.0%), ce_loss 0.821, lat_loss 22.059
09/21 06:06:15 PM | Train: [ 65/180] Step 500/1249 Loss 2.333 Prec@(1,3) (82.6%, 99.0%), ce_loss 0.821, lat_loss 22.059
09/21 06:06:36 PM | Train: [ 65/180] Step 550/1249 Loss 2.335 Prec@(1,3) (82.7%, 99.0%), ce_loss 0.821, lat_loss 22.059
09/21 06:06:59 PM | Train: [ 65/180] Step 600/1249 Loss 2.340 Prec@(1,3) (82.6%, 99.0%), ce_loss 0.821, lat_loss 22.059
09/21 06:07:20 PM | Train: [ 65/180] Step 650/1249 Loss 2.325 Prec@(1,3) (82.7%, 99.0%), ce_loss 0.820, lat_loss 22.059
09/21 06:07:45 PM | Train: [ 65/180] Step 700/1249 Loss 2.317 Prec@(1,3) (82.6%, 99.0%), ce_loss 0.820, lat_loss 22.059
09/21 06:08:10 PM | Train: [ 65/180] Step 750/1249 Loss 2.314 Prec@(1,3) (82.6%, 99.0%), ce_loss 0.820, lat_loss 22.059
09/21 06:08:35 PM | Train: [ 65/180] Step 800/1249 Loss 2.327 Prec@(1,3) (82.5%, 99.0%), ce_loss 0.820, lat_loss 22.059
09/21 06:09:00 PM | Train: [ 65/180] Step 850/1249 Loss 2.333 Prec@(1,3) (82.5%, 99.0%), ce_loss 0.820, lat_loss 22.059
09/21 06:09:25 PM | Train: [ 65/180] Step 900/1249 Loss 2.339 Prec@(1,3) (82.4%, 99.0%), ce_loss 0.820, lat_loss 22.059
09/21 06:09:50 PM | Train: [ 65/180] Step 950/1249 Loss 2.347 Prec@(1,3) (82.3%, 98.9%), ce_loss 0.820, lat_loss 22.058
09/21 06:10:15 PM | Train: [ 65/180] Step 1000/1249 Loss 2.346 Prec@(1,3) (82.3%, 98.9%), ce_loss 0.820, lat_loss 22.058
09/21 06:10:40 PM | Train: [ 65/180] Step 1050/1249 Loss 2.350 Prec@(1,3) (82.2%, 98.9%), ce_loss 0.819, lat_loss 22.058
09/21 06:11:05 PM | Train: [ 65/180] Step 1100/1249 Loss 2.365 Prec@(1,3) (82.1%, 98.9%), ce_loss 0.819, lat_loss 22.058
09/21 06:11:30 PM | Train: [ 65/180] Step 1150/1249 Loss 2.367 Prec@(1,3) (82.1%, 98.9%), ce_loss 0.819, lat_loss 22.058
09/21 06:11:55 PM | Train: [ 65/180] Step 1200/1249 Loss 2.374 Prec@(1,3) (82.0%, 98.9%), ce_loss 0.819, lat_loss 22.058
09/21 06:12:19 PM | Train: [ 65/180] Step 1249/1249 Loss 2.371 Prec@(1,3) (82.0%, 98.9%), ce_loss 0.819, lat_loss 22.058
09/21 06:12:19 PM | _w_step_train: [ 65/180] Final Prec@1 82.0025% Time 588.14
09/21 06:12:19 PM | Start to train theta for epoch 64
09/21 06:12:40 PM | Train: [ 65/180] Step 050/312 Loss 2.624 Prec@(1,3) (80.9%, 97.9%), ce_loss 0.819, lat_loss 22.058
09/21 06:13:01 PM | Train: [ 65/180] Step 100/312 Loss 2.632 Prec@(1,3) (80.3%, 98.2%), ce_loss 0.819, lat_loss 22.058
09/21 06:13:22 PM | Train: [ 65/180] Step 150/312 Loss 2.673 Prec@(1,3) (79.7%, 98.3%), ce_loss 0.819, lat_loss 22.058
09/21 06:13:42 PM | Train: [ 65/180] Step 200/312 Loss 2.680 Prec@(1,3) (79.8%, 98.4%), ce_loss 0.819, lat_loss 22.058
09/21 06:14:02 PM | Train: [ 65/180] Step 250/312 Loss 2.678 Prec@(1,3) (79.9%, 98.5%), ce_loss 0.819, lat_loss 22.058
09/21 06:14:23 PM | Train: [ 65/180] Step 300/312 Loss 2.651 Prec@(1,3) (80.1%, 98.5%), ce_loss 0.818, lat_loss 22.058
09/21 06:14:28 PM | Train: [ 65/180] Step 312/312 Loss 2.654 Prec@(1,3) (80.0%, 98.5%), ce_loss 0.818, lat_loss 22.058
09/21 06:14:29 PM | _theta_step_train: [ 65/180] Final Prec@1 80.0200% Time 129.35
09/21 06:14:34 PM | Valid: [ 65/180] Step 050/312 Loss 2.540 Prec@(1,3) (79.7%, 98.9%), ce_loss 0.818, lat_loss 22.058
09/21 06:14:39 PM | Valid: [ 65/180] Step 100/312 Loss 2.688 Prec@(1,3) (79.1%, 98.8%), ce_loss 0.818, lat_loss 22.058
09/21 06:14:43 PM | Valid: [ 65/180] Step 150/312 Loss 2.741 Prec@(1,3) (78.8%, 98.8%), ce_loss 0.818, lat_loss 22.058
09/21 06:14:48 PM | Valid: [ 65/180] Step 200/312 Loss 2.685 Prec@(1,3) (79.5%, 98.8%), ce_loss 0.818, lat_loss 22.058
09/21 06:14:53 PM | Valid: [ 65/180] Step 250/312 Loss 2.685 Prec@(1,3) (79.3%, 98.8%), ce_loss 0.818, lat_loss 22.058
09/21 06:14:57 PM | Valid: [ 65/180] Step 300/312 Loss 2.675 Prec@(1,3) (79.2%, 98.9%), ce_loss 0.818, lat_loss 22.058
09/21 06:14:58 PM | Valid: [ 65/180] Step 312/312 Loss 2.690 Prec@(1,3) (79.0%, 98.9%), ce_loss 0.818, lat_loss 22.058
09/21 06:14:59 PM | val: [ 65/180] Final Prec@1 79.0200% Time 29.78
09/21 06:14:59 PM | Best top1 acc by now. Save model
09/21 06:14:59 PM | Start to train weights for epoch 65
09/21 06:15:25 PM | Train: [ 66/180] Step 050/1249 Loss 2.241 Prec@(1,3) (82.4%, 99.0%), ce_loss 0.818, lat_loss 22.058
09/21 06:15:50 PM | Train: [ 66/180] Step 100/1249 Loss 2.213 Prec@(1,3) (83.0%, 98.9%), ce_loss 0.818, lat_loss 22.058
09/21 06:16:15 PM | Train: [ 66/180] Step 150/1249 Loss 2.244 Prec@(1,3) (82.6%, 99.0%), ce_loss 0.817, lat_loss 22.057
09/21 06:16:40 PM | Train: [ 66/180] Step 200/1249 Loss 2.259 Prec@(1,3) (82.6%, 99.0%), ce_loss 0.817, lat_loss 22.057
09/21 06:17:05 PM | Train: [ 66/180] Step 250/1249 Loss 2.256 Prec@(1,3) (82.5%, 99.1%), ce_loss 0.817, lat_loss 22.057
09/21 06:17:30 PM | Train: [ 66/180] Step 300/1249 Loss 2.297 Prec@(1,3) (82.3%, 99.1%), ce_loss 0.817, lat_loss 22.057
09/21 06:17:55 PM | Train: [ 66/180] Step 350/1249 Loss 2.344 Prec@(1,3) (82.0%, 99.1%), ce_loss 0.817, lat_loss 22.057
09/21 06:18:20 PM | Train: [ 66/180] Step 400/1249 Loss 2.352 Prec@(1,3) (82.0%, 99.1%), ce_loss 0.817, lat_loss 22.057
09/21 06:18:45 PM | Train: [ 66/180] Step 450/1249 Loss 2.346 Prec@(1,3) (82.0%, 99.1%), ce_loss 0.817, lat_loss 22.057
09/21 06:19:10 PM | Train: [ 66/180] Step 500/1249 Loss 2.353 Prec@(1,3) (81.9%, 99.1%), ce_loss 0.817, lat_loss 22.057
09/21 06:19:35 PM | Train: [ 66/180] Step 550/1249 Loss 2.355 Prec@(1,3) (81.9%, 99.0%), ce_loss 0.817, lat_loss 22.057
09/21 06:20:00 PM | Train: [ 66/180] Step 600/1249 Loss 2.356 Prec@(1,3) (82.0%, 99.0%), ce_loss 0.816, lat_loss 22.057
09/21 06:20:25 PM | Train: [ 66/180] Step 650/1249 Loss 2.351 Prec@(1,3) (82.0%, 99.0%), ce_loss 0.816, lat_loss 22.057
09/21 06:20:50 PM | Train: [ 66/180] Step 700/1249 Loss 2.355 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.816, lat_loss 22.057
09/21 06:21:15 PM | Train: [ 66/180] Step 750/1249 Loss 2.360 Prec@(1,3) (82.0%, 99.0%), ce_loss 0.816, lat_loss 22.057
09/21 06:21:40 PM | Train: [ 66/180] Step 800/1249 Loss 2.357 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.816, lat_loss 22.057
09/21 06:22:05 PM | Train: [ 66/180] Step 850/1249 Loss 2.356 Prec@(1,3) (82.0%, 99.0%), ce_loss 0.816, lat_loss 22.057
09/21 06:22:30 PM | Train: [ 66/180] Step 900/1249 Loss 2.357 Prec@(1,3) (82.0%, 99.0%), ce_loss 0.816, lat_loss 22.057
09/21 06:22:55 PM | Train: [ 66/180] Step 950/1249 Loss 2.355 Prec@(1,3) (82.0%, 99.0%), ce_loss 0.816, lat_loss 22.057
09/21 06:23:20 PM | Train: [ 66/180] Step 1000/1249 Loss 2.346 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.815, lat_loss 22.057
09/21 06:23:45 PM | Train: [ 66/180] Step 1050/1249 Loss 2.351 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.815, lat_loss 22.057
09/21 06:24:10 PM | Train: [ 66/180] Step 1100/1249 Loss 2.346 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.815, lat_loss 22.057
09/21 06:24:36 PM | Train: [ 66/180] Step 1150/1249 Loss 2.341 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.815, lat_loss 22.057
09/21 06:25:01 PM | Train: [ 66/180] Step 1200/1249 Loss 2.334 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.815, lat_loss 22.057
09/21 06:25:25 PM | Train: [ 66/180] Step 1249/1249 Loss 2.335 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.815, lat_loss 22.057
09/21 06:25:25 PM | _w_step_train: [ 66/180] Final Prec@1 82.2125% Time 626.37
09/21 06:25:25 PM | Start to train theta for epoch 65
09/21 06:25:44 PM | Train: [ 66/180] Step 050/312 Loss 2.781 Prec@(1,3) (78.9%, 98.5%), ce_loss 0.815, lat_loss 22.056
09/21 06:26:04 PM | Train: [ 66/180] Step 100/312 Loss 2.791 Prec@(1,3) (78.6%, 98.5%), ce_loss 0.815, lat_loss 22.056
09/21 06:26:25 PM | Train: [ 66/180] Step 150/312 Loss 2.751 Prec@(1,3) (78.9%, 98.6%), ce_loss 0.815, lat_loss 22.056
09/21 06:26:46 PM | Train: [ 66/180] Step 200/312 Loss 2.689 Prec@(1,3) (79.8%, 98.5%), ce_loss 0.814, lat_loss 22.056
09/21 06:27:07 PM | Train: [ 66/180] Step 250/312 Loss 2.680 Prec@(1,3) (79.8%, 98.6%), ce_loss 0.814, lat_loss 22.056
09/21 06:27:28 PM | Train: [ 66/180] Step 300/312 Loss 2.664 Prec@(1,3) (79.9%, 98.6%), ce_loss 0.814, lat_loss 22.056
09/21 06:27:32 PM | Train: [ 66/180] Step 312/312 Loss 2.656 Prec@(1,3) (80.0%, 98.6%), ce_loss 0.814, lat_loss 22.056
09/21 06:27:33 PM | _theta_step_train: [ 66/180] Final Prec@1 79.9500% Time 127.51
09/21 06:27:38 PM | Valid: [ 66/180] Step 050/312 Loss 2.418 Prec@(1,3) (82.8%, 98.9%), ce_loss 0.814, lat_loss 22.056
09/21 06:27:43 PM | Valid: [ 66/180] Step 100/312 Loss 2.724 Prec@(1,3) (79.5%, 98.4%), ce_loss 0.814, lat_loss 22.056
09/21 06:27:47 PM | Valid: [ 66/180] Step 150/312 Loss 2.734 Prec@(1,3) (79.4%, 98.4%), ce_loss 0.814, lat_loss 22.056
09/21 06:27:52 PM | Valid: [ 66/180] Step 200/312 Loss 2.821 Prec@(1,3) (79.0%, 98.2%), ce_loss 0.814, lat_loss 22.056
09/21 06:27:57 PM | Valid: [ 66/180] Step 250/312 Loss 2.859 Prec@(1,3) (78.5%, 98.3%), ce_loss 0.814, lat_loss 22.056
09/21 06:28:01 PM | Valid: [ 66/180] Step 300/312 Loss 2.834 Prec@(1,3) (78.7%, 98.4%), ce_loss 0.814, lat_loss 22.056
09/21 06:28:03 PM | Valid: [ 66/180] Step 312/312 Loss 2.831 Prec@(1,3) (78.7%, 98.4%), ce_loss 0.814, lat_loss 22.056
09/21 06:28:03 PM | val: [ 66/180] Final Prec@1 78.7200% Time 30.09
09/21 06:28:03 PM | Start to train weights for epoch 66
09/21 06:28:18 PM | Train: [ 67/180] Step 050/1249 Loss 2.234 Prec@(1,3) (82.0%, 99.3%), ce_loss 0.814, lat_loss 22.056
09/21 06:28:33 PM | Train: [ 67/180] Step 100/1249 Loss 2.203 Prec@(1,3) (82.6%, 99.0%), ce_loss 0.814, lat_loss 22.056
09/21 06:28:48 PM | Train: [ 67/180] Step 150/1249 Loss 2.217 Prec@(1,3) (82.7%, 99.0%), ce_loss 0.813, lat_loss 22.056
09/21 06:29:02 PM | Train: [ 67/180] Step 200/1249 Loss 2.181 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.813, lat_loss 22.056
09/21 06:29:17 PM | Train: [ 67/180] Step 250/1249 Loss 2.267 Prec@(1,3) (82.6%, 99.0%), ce_loss 0.813, lat_loss 22.056
09/21 06:29:31 PM | Train: [ 67/180] Step 300/1249 Loss 2.278 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.813, lat_loss 22.055
09/21 06:29:46 PM | Train: [ 67/180] Step 350/1249 Loss 2.297 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.813, lat_loss 22.055
09/21 06:30:00 PM | Train: [ 67/180] Step 400/1249 Loss 2.297 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.813, lat_loss 22.055
09/21 06:30:15 PM | Train: [ 67/180] Step 450/1249 Loss 2.321 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.813, lat_loss 22.055
09/21 06:30:29 PM | Train: [ 67/180] Step 500/1249 Loss 2.330 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.813, lat_loss 22.055
09/21 06:30:44 PM | Train: [ 67/180] Step 550/1249 Loss 2.317 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.812, lat_loss 22.055
09/21 06:30:58 PM | Train: [ 67/180] Step 600/1249 Loss 2.308 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.812, lat_loss 22.055
09/21 06:31:13 PM | Train: [ 67/180] Step 650/1249 Loss 2.306 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.812, lat_loss 22.055
09/21 06:31:28 PM | Train: [ 67/180] Step 700/1249 Loss 2.309 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.812, lat_loss 22.055
09/21 06:31:42 PM | Train: [ 67/180] Step 750/1249 Loss 2.319 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.812, lat_loss 22.055
09/21 06:31:57 PM | Train: [ 67/180] Step 800/1249 Loss 2.335 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.812, lat_loss 22.055
09/21 06:32:11 PM | Train: [ 67/180] Step 850/1249 Loss 2.333 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.812, lat_loss 22.055
09/21 06:32:26 PM | Train: [ 67/180] Step 900/1249 Loss 2.338 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.812, lat_loss 22.055
09/21 06:32:40 PM | Train: [ 67/180] Step 950/1249 Loss 2.340 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.812, lat_loss 22.055
09/21 06:32:55 PM | Train: [ 67/180] Step 1000/1249 Loss 2.342 Prec@(1,3) (82.2%, 98.9%), ce_loss 0.811, lat_loss 22.055
09/21 06:33:09 PM | Train: [ 67/180] Step 1050/1249 Loss 2.349 Prec@(1,3) (82.1%, 98.9%), ce_loss 0.811, lat_loss 22.055
09/21 06:33:24 PM | Train: [ 67/180] Step 1100/1249 Loss 2.353 Prec@(1,3) (82.1%, 98.9%), ce_loss 0.811, lat_loss 22.055
09/21 06:33:38 PM | Train: [ 67/180] Step 1150/1249 Loss 2.357 Prec@(1,3) (82.1%, 98.9%), ce_loss 0.811, lat_loss 22.054
09/21 06:33:53 PM | Train: [ 67/180] Step 1200/1249 Loss 2.361 Prec@(1,3) (82.1%, 98.9%), ce_loss 0.811, lat_loss 22.054
09/21 06:34:07 PM | Train: [ 67/180] Step 1249/1249 Loss 2.366 Prec@(1,3) (82.0%, 98.9%), ce_loss 0.811, lat_loss 22.054
09/21 06:34:07 PM | _w_step_train: [ 67/180] Final Prec@1 82.0125% Time 364.57
09/21 06:34:07 PM | Start to train theta for epoch 66
09/21 06:34:28 PM | Train: [ 67/180] Step 050/312 Loss 2.862 Prec@(1,3) (79.9%, 97.7%), ce_loss 0.811, lat_loss 22.054
09/21 06:34:47 PM | Train: [ 67/180] Step 100/312 Loss 2.614 Prec@(1,3) (81.1%, 98.2%), ce_loss 0.811, lat_loss 22.054
09/21 06:35:06 PM | Train: [ 67/180] Step 150/312 Loss 2.542 Prec@(1,3) (81.4%, 98.3%), ce_loss 0.811, lat_loss 22.054
09/21 06:35:27 PM | Train: [ 67/180] Step 200/312 Loss 2.553 Prec@(1,3) (81.1%, 98.4%), ce_loss 0.811, lat_loss 22.054
09/21 06:35:46 PM | Train: [ 67/180] Step 250/312 Loss 2.524 Prec@(1,3) (81.1%, 98.5%), ce_loss 0.810, lat_loss 22.054
09/21 06:36:06 PM | Train: [ 67/180] Step 300/312 Loss 2.535 Prec@(1,3) (81.0%, 98.5%), ce_loss 0.810, lat_loss 22.054
09/21 06:36:11 PM | Train: [ 67/180] Step 312/312 Loss 2.518 Prec@(1,3) (81.2%, 98.6%), ce_loss 0.810, lat_loss 22.054
09/21 06:36:11 PM | _theta_step_train: [ 67/180] Final Prec@1 81.1800% Time 123.55
09/21 06:36:16 PM | Valid: [ 67/180] Step 050/312 Loss 2.264 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.810, lat_loss 22.054
09/21 06:36:20 PM | Valid: [ 67/180] Step 100/312 Loss 2.431 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.810, lat_loss 22.054
09/21 06:36:24 PM | Valid: [ 67/180] Step 150/312 Loss 2.562 Prec@(1,3) (81.5%, 98.6%), ce_loss 0.810, lat_loss 22.054
09/21 06:36:28 PM | Valid: [ 67/180] Step 200/312 Loss 2.533 Prec@(1,3) (81.6%, 98.7%), ce_loss 0.810, lat_loss 22.054
09/21 06:36:33 PM | Valid: [ 67/180] Step 250/312 Loss 2.505 Prec@(1,3) (81.8%, 98.8%), ce_loss 0.810, lat_loss 22.054
09/21 06:36:37 PM | Valid: [ 67/180] Step 300/312 Loss 2.517 Prec@(1,3) (81.8%, 98.7%), ce_loss 0.810, lat_loss 22.054
09/21 06:36:38 PM | Valid: [ 67/180] Step 312/312 Loss 2.513 Prec@(1,3) (81.8%, 98.7%), ce_loss 0.810, lat_loss 22.054
09/21 06:36:38 PM | val: [ 67/180] Final Prec@1 81.8400% Time 26.99
09/21 06:36:38 PM | Best top1 acc by now. Save model
09/21 06:36:38 PM | Start to train weights for epoch 67
09/21 06:37:03 PM | Train: [ 68/180] Step 050/1249 Loss 2.220 Prec@(1,3) (82.7%, 99.0%), ce_loss 0.810, lat_loss 22.054
09/21 06:37:28 PM | Train: [ 68/180] Step 100/1249 Loss 2.225 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.809, lat_loss 22.054
09/21 06:37:53 PM | Train: [ 68/180] Step 150/1249 Loss 2.183 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.809, lat_loss 22.053
09/21 06:38:18 PM | Train: [ 68/180] Step 200/1249 Loss 2.214 Prec@(1,3) (83.1%, 99.2%), ce_loss 0.809, lat_loss 22.053
09/21 06:38:43 PM | Train: [ 68/180] Step 250/1249 Loss 2.236 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.809, lat_loss 22.053
09/21 06:39:08 PM | Train: [ 68/180] Step 300/1249 Loss 2.244 Prec@(1,3) (82.9%, 99.1%), ce_loss 0.809, lat_loss 22.053
09/21 06:39:33 PM | Train: [ 68/180] Step 350/1249 Loss 2.268 Prec@(1,3) (82.7%, 99.1%), ce_loss 0.809, lat_loss 22.053
09/21 06:39:57 PM | Train: [ 68/180] Step 400/1249 Loss 2.289 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.809, lat_loss 22.053
09/21 06:40:22 PM | Train: [ 68/180] Step 450/1249 Loss 2.297 Prec@(1,3) (82.4%, 99.1%), ce_loss 0.809, lat_loss 22.053
09/21 06:40:46 PM | Train: [ 68/180] Step 500/1249 Loss 2.269 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.808, lat_loss 22.053
09/21 06:41:11 PM | Train: [ 68/180] Step 550/1249 Loss 2.271 Prec@(1,3) (82.5%, 99.1%), ce_loss 0.808, lat_loss 22.053
09/21 06:41:36 PM | Train: [ 68/180] Step 600/1249 Loss 2.262 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.808, lat_loss 22.053
09/21 06:42:00 PM | Train: [ 68/180] Step 650/1249 Loss 2.271 Prec@(1,3) (82.5%, 99.0%), ce_loss 0.808, lat_loss 22.053
09/21 06:42:25 PM | Train: [ 68/180] Step 700/1249 Loss 2.272 Prec@(1,3) (82.5%, 99.1%), ce_loss 0.808, lat_loss 22.053
09/21 06:42:50 PM | Train: [ 68/180] Step 750/1249 Loss 2.280 Prec@(1,3) (82.4%, 99.1%), ce_loss 0.808, lat_loss 22.053
09/21 06:43:15 PM | Train: [ 68/180] Step 800/1249 Loss 2.264 Prec@(1,3) (82.5%, 99.1%), ce_loss 0.808, lat_loss 22.053
09/21 06:43:40 PM | Train: [ 68/180] Step 850/1249 Loss 2.260 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.808, lat_loss 22.053
09/21 06:44:04 PM | Train: [ 68/180] Step 900/1249 Loss 2.258 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.807, lat_loss 22.053
09/21 06:44:28 PM | Train: [ 68/180] Step 950/1249 Loss 2.252 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.807, lat_loss 22.053
09/21 06:44:53 PM | Train: [ 68/180] Step 1000/1249 Loss 2.247 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.807, lat_loss 22.053
09/21 06:45:17 PM | Train: [ 68/180] Step 1050/1249 Loss 2.244 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.807, lat_loss 22.053
09/21 06:45:40 PM | Train: [ 68/180] Step 1100/1249 Loss 2.239 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.807, lat_loss 22.052
09/21 06:46:05 PM | Train: [ 68/180] Step 1150/1249 Loss 2.242 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.807, lat_loss 22.052
09/21 06:46:29 PM | Train: [ 68/180] Step 1200/1249 Loss 2.251 Prec@(1,3) (82.5%, 99.1%), ce_loss 0.807, lat_loss 22.052
09/21 06:46:53 PM | Train: [ 68/180] Step 1249/1249 Loss 2.250 Prec@(1,3) (82.5%, 99.1%), ce_loss 0.807, lat_loss 22.052
09/21 06:46:53 PM | _w_step_train: [ 68/180] Final Prec@1 82.5500% Time 615.44
09/21 06:46:53 PM | Start to train theta for epoch 67
09/21 06:47:14 PM | Train: [ 68/180] Step 050/312 Loss 2.837 Prec@(1,3) (78.3%, 98.3%), ce_loss 0.807, lat_loss 22.052
09/21 06:47:34 PM | Train: [ 68/180] Step 100/312 Loss 2.674 Prec@(1,3) (79.4%, 98.5%), ce_loss 0.806, lat_loss 22.052
09/21 06:47:53 PM | Train: [ 68/180] Step 150/312 Loss 2.696 Prec@(1,3) (79.5%, 98.7%), ce_loss 0.806, lat_loss 22.052
09/21 06:48:14 PM | Train: [ 68/180] Step 200/312 Loss 2.692 Prec@(1,3) (79.5%, 98.6%), ce_loss 0.806, lat_loss 22.052
09/21 06:48:35 PM | Train: [ 68/180] Step 250/312 Loss 2.684 Prec@(1,3) (79.5%, 98.6%), ce_loss 0.806, lat_loss 22.052
09/21 06:48:55 PM | Train: [ 68/180] Step 300/312 Loss 2.646 Prec@(1,3) (79.7%, 98.6%), ce_loss 0.806, lat_loss 22.052
09/21 06:49:00 PM | Train: [ 68/180] Step 312/312 Loss 2.613 Prec@(1,3) (79.9%, 98.6%), ce_loss 0.806, lat_loss 22.052
09/21 06:49:00 PM | _theta_step_train: [ 68/180] Final Prec@1 79.9400% Time 126.95
09/21 06:49:06 PM | Valid: [ 68/180] Step 050/312 Loss 2.361 Prec@(1,3) (81.7%, 99.2%), ce_loss 0.806, lat_loss 22.052
09/21 06:49:10 PM | Valid: [ 68/180] Step 100/312 Loss 2.614 Prec@(1,3) (80.0%, 98.7%), ce_loss 0.806, lat_loss 22.052
09/21 06:49:15 PM | Valid: [ 68/180] Step 150/312 Loss 2.720 Prec@(1,3) (79.2%, 98.4%), ce_loss 0.806, lat_loss 22.052
09/21 06:49:20 PM | Valid: [ 68/180] Step 200/312 Loss 2.624 Prec@(1,3) (80.0%, 98.6%), ce_loss 0.806, lat_loss 22.052
09/21 06:49:24 PM | Valid: [ 68/180] Step 250/312 Loss 2.611 Prec@(1,3) (80.1%, 98.7%), ce_loss 0.806, lat_loss 22.052
09/21 06:49:29 PM | Valid: [ 68/180] Step 300/312 Loss 2.596 Prec@(1,3) (80.1%, 98.8%), ce_loss 0.806, lat_loss 22.052
09/21 06:49:30 PM | Valid: [ 68/180] Step 312/312 Loss 2.632 Prec@(1,3) (79.8%, 98.7%), ce_loss 0.806, lat_loss 22.052
09/21 06:49:30 PM | val: [ 68/180] Final Prec@1 79.8400% Time 29.66
09/21 06:49:30 PM | Start to train weights for epoch 68
09/21 06:49:46 PM | Train: [ 69/180] Step 050/1249 Loss 2.157 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.805, lat_loss 22.052
09/21 06:50:01 PM | Train: [ 69/180] Step 100/1249 Loss 2.220 Prec@(1,3) (83.2%, 99.0%), ce_loss 0.805, lat_loss 22.052
09/21 06:50:15 PM | Train: [ 69/180] Step 150/1249 Loss 2.212 Prec@(1,3) (83.1%, 99.2%), ce_loss 0.805, lat_loss 22.051
09/21 06:50:30 PM | Train: [ 69/180] Step 200/1249 Loss 2.207 Prec@(1,3) (83.0%, 99.2%), ce_loss 0.805, lat_loss 22.051
09/21 06:50:44 PM | Train: [ 69/180] Step 250/1249 Loss 2.162 Prec@(1,3) (83.4%, 99.2%), ce_loss 0.805, lat_loss 22.051
09/21 06:50:59 PM | Train: [ 69/180] Step 300/1249 Loss 2.227 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.805, lat_loss 22.051
09/21 06:51:13 PM | Train: [ 69/180] Step 350/1249 Loss 2.236 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.805, lat_loss 22.051
09/21 06:51:28 PM | Train: [ 69/180] Step 400/1249 Loss 2.223 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.805, lat_loss 22.051
09/21 06:51:42 PM | Train: [ 69/180] Step 450/1249 Loss 2.211 Prec@(1,3) (83.2%, 99.0%), ce_loss 0.804, lat_loss 22.051
09/21 06:51:57 PM | Train: [ 69/180] Step 500/1249 Loss 2.223 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.804, lat_loss 22.051
09/21 06:52:12 PM | Train: [ 69/180] Step 550/1249 Loss 2.227 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.804, lat_loss 22.051
09/21 06:52:26 PM | Train: [ 69/180] Step 600/1249 Loss 2.226 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.804, lat_loss 22.051
09/21 06:52:41 PM | Train: [ 69/180] Step 650/1249 Loss 2.226 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.804, lat_loss 22.051
09/21 06:52:55 PM | Train: [ 69/180] Step 700/1249 Loss 2.225 Prec@(1,3) (82.9%, 99.1%), ce_loss 0.804, lat_loss 22.051
09/21 06:53:10 PM | Train: [ 69/180] Step 750/1249 Loss 2.218 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.804, lat_loss 22.051
09/21 06:53:25 PM | Train: [ 69/180] Step 800/1249 Loss 2.215 Prec@(1,3) (83.1%, 99.1%), ce_loss 0.804, lat_loss 22.051
09/21 06:53:39 PM | Train: [ 69/180] Step 850/1249 Loss 2.217 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.803, lat_loss 22.051
09/21 06:53:54 PM | Train: [ 69/180] Step 900/1249 Loss 2.230 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.803, lat_loss 22.051
09/21 06:54:09 PM | Train: [ 69/180] Step 950/1249 Loss 2.221 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.803, lat_loss 22.051
09/21 06:54:23 PM | Train: [ 69/180] Step 1000/1249 Loss 2.217 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.803, lat_loss 22.051
09/21 06:54:38 PM | Train: [ 69/180] Step 1050/1249 Loss 2.220 Prec@(1,3) (82.9%, 99.1%), ce_loss 0.803, lat_loss 22.050
09/21 06:54:52 PM | Train: [ 69/180] Step 1100/1249 Loss 2.227 Prec@(1,3) (82.9%, 99.0%), ce_loss 0.803, lat_loss 22.050
09/21 06:55:07 PM | Train: [ 69/180] Step 1150/1249 Loss 2.224 Prec@(1,3) (82.9%, 99.1%), ce_loss 0.803, lat_loss 22.050
09/21 06:55:21 PM | Train: [ 69/180] Step 1200/1249 Loss 2.222 Prec@(1,3) (82.9%, 99.1%), ce_loss 0.803, lat_loss 22.050
09/21 06:55:35 PM | Train: [ 69/180] Step 1249/1249 Loss 2.224 Prec@(1,3) (82.9%, 99.0%), ce_loss 0.803, lat_loss 22.050
09/21 06:55:36 PM | _w_step_train: [ 69/180] Final Prec@1 82.8700% Time 365.47
09/21 06:55:36 PM | Start to train theta for epoch 68
09/21 06:55:57 PM | Train: [ 69/180] Step 050/312 Loss 2.667 Prec@(1,3) (80.6%, 98.1%), ce_loss 0.802, lat_loss 22.050
09/21 06:56:18 PM | Train: [ 69/180] Step 100/312 Loss 2.785 Prec@(1,3) (79.1%, 98.4%), ce_loss 0.802, lat_loss 22.050
09/21 06:56:39 PM | Train: [ 69/180] Step 150/312 Loss 2.810 Prec@(1,3) (79.0%, 98.4%), ce_loss 0.802, lat_loss 22.050
09/21 06:57:00 PM | Train: [ 69/180] Step 200/312 Loss 2.782 Prec@(1,3) (79.2%, 98.5%), ce_loss 0.802, lat_loss 22.050
09/21 06:57:20 PM | Train: [ 69/180] Step 250/312 Loss 2.778 Prec@(1,3) (79.4%, 98.5%), ce_loss 0.802, lat_loss 22.050
09/21 06:57:41 PM | Train: [ 69/180] Step 300/312 Loss 2.760 Prec@(1,3) (79.6%, 98.5%), ce_loss 0.802, lat_loss 22.050
09/21 06:57:46 PM | Train: [ 69/180] Step 312/312 Loss 2.762 Prec@(1,3) (79.6%, 98.5%), ce_loss 0.802, lat_loss 22.050
09/21 06:57:46 PM | _theta_step_train: [ 69/180] Final Prec@1 79.6100% Time 130.32
09/21 06:57:51 PM | Valid: [ 69/180] Step 050/312 Loss 2.600 Prec@(1,3) (80.6%, 99.0%), ce_loss 0.802, lat_loss 22.050
09/21 06:57:56 PM | Valid: [ 69/180] Step 100/312 Loss 2.737 Prec@(1,3) (79.8%, 98.8%), ce_loss 0.802, lat_loss 22.050
09/21 06:58:00 PM | Valid: [ 69/180] Step 150/312 Loss 2.901 Prec@(1,3) (79.7%, 98.4%), ce_loss 0.802, lat_loss 22.050
09/21 06:58:05 PM | Valid: [ 69/180] Step 200/312 Loss 2.900 Prec@(1,3) (79.9%, 98.3%), ce_loss 0.802, lat_loss 22.050
09/21 06:58:10 PM | Valid: [ 69/180] Step 250/312 Loss 2.858 Prec@(1,3) (79.9%, 98.4%), ce_loss 0.802, lat_loss 22.050
09/21 06:58:14 PM | Valid: [ 69/180] Step 300/312 Loss 2.813 Prec@(1,3) (80.2%, 98.5%), ce_loss 0.802, lat_loss 22.050
09/21 06:58:16 PM | Valid: [ 69/180] Step 312/312 Loss 2.835 Prec@(1,3) (80.0%, 98.5%), ce_loss 0.802, lat_loss 22.050
09/21 06:58:16 PM | val: [ 69/180] Final Prec@1 80.0500% Time 29.66
09/21 06:58:16 PM | Start to train weights for epoch 69
09/21 06:58:39 PM | Train: [ 70/180] Step 050/1249 Loss 2.067 Prec@(1,3) (84.2%, 99.3%), ce_loss 0.802, lat_loss 22.050
09/21 06:59:01 PM | Train: [ 70/180] Step 100/1249 Loss 2.188 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.801, lat_loss 22.050
09/21 06:59:26 PM | Train: [ 70/180] Step 150/1249 Loss 2.165 Prec@(1,3) (83.3%, 99.2%), ce_loss 0.801, lat_loss 22.049
09/21 06:59:51 PM | Train: [ 70/180] Step 200/1249 Loss 2.178 Prec@(1,3) (83.2%, 99.2%), ce_loss 0.801, lat_loss 22.049
09/21 07:00:15 PM | Train: [ 70/180] Step 250/1249 Loss 2.204 Prec@(1,3) (83.1%, 99.1%), ce_loss 0.801, lat_loss 22.049
09/21 07:00:40 PM | Train: [ 70/180] Step 300/1249 Loss 2.238 Prec@(1,3) (82.8%, 99.1%), ce_loss 0.801, lat_loss 22.049
09/21 07:01:04 PM | Train: [ 70/180] Step 350/1249 Loss 2.232 Prec@(1,3) (83.0%, 99.2%), ce_loss 0.801, lat_loss 22.049
09/21 07:01:26 PM | Train: [ 70/180] Step 400/1249 Loss 2.212 Prec@(1,3) (83.1%, 99.1%), ce_loss 0.801, lat_loss 22.049
09/21 07:01:49 PM | Train: [ 70/180] Step 450/1249 Loss 2.195 Prec@(1,3) (83.1%, 99.1%), ce_loss 0.801, lat_loss 22.049
09/21 07:02:12 PM | Train: [ 70/180] Step 500/1249 Loss 2.186 Prec@(1,3) (83.2%, 99.2%), ce_loss 0.800, lat_loss 22.049
09/21 07:02:36 PM | Train: [ 70/180] Step 550/1249 Loss 2.188 Prec@(1,3) (83.2%, 99.2%), ce_loss 0.800, lat_loss 22.049
09/21 07:02:59 PM | Train: [ 70/180] Step 600/1249 Loss 2.186 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.800, lat_loss 22.049
09/21 07:03:22 PM | Train: [ 70/180] Step 650/1249 Loss 2.187 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.800, lat_loss 22.049
09/21 07:03:44 PM | Train: [ 70/180] Step 700/1249 Loss 2.188 Prec@(1,3) (83.2%, 99.2%), ce_loss 0.800, lat_loss 22.049
09/21 07:04:05 PM | Train: [ 70/180] Step 750/1249 Loss 2.194 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.800, lat_loss 22.049
09/21 07:04:26 PM | Train: [ 70/180] Step 800/1249 Loss 2.186 Prec@(1,3) (83.3%, 99.2%), ce_loss 0.800, lat_loss 22.049
09/21 07:04:48 PM | Train: [ 70/180] Step 850/1249 Loss 2.196 Prec@(1,3) (83.3%, 99.2%), ce_loss 0.800, lat_loss 22.049
09/21 07:05:10 PM | Train: [ 70/180] Step 900/1249 Loss 2.182 Prec@(1,3) (83.3%, 99.2%), ce_loss 0.799, lat_loss 22.049
09/21 07:05:31 PM | Train: [ 70/180] Step 950/1249 Loss 2.191 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.799, lat_loss 22.049
09/21 07:05:52 PM | Train: [ 70/180] Step 1000/1249 Loss 2.190 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.799, lat_loss 22.049
09/21 07:06:13 PM | Train: [ 70/180] Step 1050/1249 Loss 2.193 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.799, lat_loss 22.049
09/21 07:06:34 PM | Train: [ 70/180] Step 1100/1249 Loss 2.192 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.799, lat_loss 22.048
09/21 07:06:58 PM | Train: [ 70/180] Step 1150/1249 Loss 2.189 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.799, lat_loss 22.048
09/21 07:07:20 PM | Train: [ 70/180] Step 1200/1249 Loss 2.198 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.799, lat_loss 22.048
09/21 07:07:44 PM | Train: [ 70/180] Step 1249/1249 Loss 2.197 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.799, lat_loss 22.048
09/21 07:07:44 PM | _w_step_train: [ 70/180] Final Prec@1 83.2175% Time 568.30
09/21 07:07:44 PM | Start to train theta for epoch 69
09/21 07:08:06 PM | Train: [ 70/180] Step 050/312 Loss 2.467 Prec@(1,3) (80.8%, 99.6%), ce_loss 0.799, lat_loss 22.048
09/21 07:08:26 PM | Train: [ 70/180] Step 100/312 Loss 2.534 Prec@(1,3) (81.1%, 99.1%), ce_loss 0.798, lat_loss 22.048
09/21 07:08:47 PM | Train: [ 70/180] Step 150/312 Loss 2.528 Prec@(1,3) (80.8%, 99.0%), ce_loss 0.798, lat_loss 22.048
09/21 07:09:07 PM | Train: [ 70/180] Step 200/312 Loss 2.524 Prec@(1,3) (81.3%, 98.9%), ce_loss 0.798, lat_loss 22.048
09/21 07:09:28 PM | Train: [ 70/180] Step 250/312 Loss 2.556 Prec@(1,3) (81.2%, 98.8%), ce_loss 0.798, lat_loss 22.048
09/21 07:09:49 PM | Train: [ 70/180] Step 300/312 Loss 2.553 Prec@(1,3) (81.1%, 98.8%), ce_loss 0.798, lat_loss 22.048
09/21 07:09:54 PM | Train: [ 70/180] Step 312/312 Loss 2.556 Prec@(1,3) (81.0%, 98.8%), ce_loss 0.798, lat_loss 22.048
09/21 07:09:55 PM | _theta_step_train: [ 70/180] Final Prec@1 81.0300% Time 130.25
09/21 07:10:00 PM | Valid: [ 70/180] Step 050/312 Loss 2.406 Prec@(1,3) (82.0%, 99.1%), ce_loss 0.798, lat_loss 22.048
09/21 07:10:04 PM | Valid: [ 70/180] Step 100/312 Loss 2.533 Prec@(1,3) (80.9%, 98.8%), ce_loss 0.798, lat_loss 22.048
09/21 07:10:09 PM | Valid: [ 70/180] Step 150/312 Loss 2.574 Prec@(1,3) (80.5%, 98.7%), ce_loss 0.798, lat_loss 22.048
09/21 07:10:14 PM | Valid: [ 70/180] Step 200/312 Loss 2.569 Prec@(1,3) (80.8%, 98.7%), ce_loss 0.798, lat_loss 22.048
09/21 07:10:18 PM | Valid: [ 70/180] Step 250/312 Loss 2.550 Prec@(1,3) (81.1%, 98.8%), ce_loss 0.798, lat_loss 22.048
09/21 07:10:23 PM | Valid: [ 70/180] Step 300/312 Loss 2.512 Prec@(1,3) (81.1%, 98.9%), ce_loss 0.798, lat_loss 22.048
09/21 07:10:24 PM | Valid: [ 70/180] Step 312/312 Loss 2.506 Prec@(1,3) (81.1%, 98.9%), ce_loss 0.798, lat_loss 22.048
09/21 07:10:24 PM | val: [ 70/180] Final Prec@1 81.1400% Time 29.58
09/21 07:10:24 PM | Start to train weights for epoch 70
09/21 07:10:50 PM | Train: [ 71/180] Step 050/1249 Loss 2.144 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.797, lat_loss 22.048
09/21 07:11:16 PM | Train: [ 71/180] Step 100/1249 Loss 2.070 Prec@(1,3) (84.0%, 99.3%), ce_loss 0.797, lat_loss 22.048
09/21 07:11:41 PM | Train: [ 71/180] Step 150/1249 Loss 2.043 Prec@(1,3) (84.2%, 99.3%), ce_loss 0.797, lat_loss 22.048
09/21 07:12:06 PM | Train: [ 71/180] Step 200/1249 Loss 2.022 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.797, lat_loss 22.048
09/21 07:12:31 PM | Train: [ 71/180] Step 250/1249 Loss 2.056 Prec@(1,3) (84.2%, 99.3%), ce_loss 0.797, lat_loss 22.048
09/21 07:12:56 PM | Train: [ 71/180] Step 300/1249 Loss 2.096 Prec@(1,3) (83.8%, 99.3%), ce_loss 0.797, lat_loss 22.047
09/21 07:13:21 PM | Train: [ 71/180] Step 350/1249 Loss 2.098 Prec@(1,3) (83.8%, 99.3%), ce_loss 0.797, lat_loss 22.047
09/21 07:13:46 PM | Train: [ 71/180] Step 400/1249 Loss 2.102 Prec@(1,3) (83.8%, 99.3%), ce_loss 0.797, lat_loss 22.047
09/21 07:14:11 PM | Train: [ 71/180] Step 450/1249 Loss 2.122 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.796, lat_loss 22.047
09/21 07:14:35 PM | Train: [ 71/180] Step 500/1249 Loss 2.119 Prec@(1,3) (83.7%, 99.2%), ce_loss 0.796, lat_loss 22.047
09/21 07:15:00 PM | Train: [ 71/180] Step 550/1249 Loss 2.125 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.796, lat_loss 22.047
09/21 07:15:25 PM | Train: [ 71/180] Step 600/1249 Loss 2.133 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.796, lat_loss 22.047
09/21 07:15:49 PM | Train: [ 71/180] Step 650/1249 Loss 2.128 Prec@(1,3) (83.7%, 99.2%), ce_loss 0.796, lat_loss 22.047
09/21 07:16:13 PM | Train: [ 71/180] Step 700/1249 Loss 2.129 Prec@(1,3) (83.7%, 99.2%), ce_loss 0.796, lat_loss 22.047
09/21 07:16:36 PM | Train: [ 71/180] Step 750/1249 Loss 2.139 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.796, lat_loss 22.047
09/21 07:17:00 PM | Train: [ 71/180] Step 800/1249 Loss 2.141 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.796, lat_loss 22.047
09/21 07:17:23 PM | Train: [ 71/180] Step 850/1249 Loss 2.136 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.795, lat_loss 22.047
09/21 07:17:48 PM | Train: [ 71/180] Step 900/1249 Loss 2.140 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.795, lat_loss 22.047
09/21 07:18:12 PM | Train: [ 71/180] Step 950/1249 Loss 2.150 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.795, lat_loss 22.047
09/21 07:18:35 PM | Train: [ 71/180] Step 1000/1249 Loss 2.156 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.795, lat_loss 22.047
09/21 07:18:59 PM | Train: [ 71/180] Step 1050/1249 Loss 2.162 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.795, lat_loss 22.047
09/21 07:19:24 PM | Train: [ 71/180] Step 1100/1249 Loss 2.161 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.795, lat_loss 22.047
09/21 07:19:47 PM | Train: [ 71/180] Step 1150/1249 Loss 2.166 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.795, lat_loss 22.047
09/21 07:20:11 PM | Train: [ 71/180] Step 1200/1249 Loss 2.157 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.795, lat_loss 22.047
09/21 07:20:36 PM | Train: [ 71/180] Step 1249/1249 Loss 2.152 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.795, lat_loss 22.047
09/21 07:20:36 PM | _w_step_train: [ 71/180] Final Prec@1 83.4850% Time 611.75
09/21 07:20:36 PM | Start to train theta for epoch 70
09/21 07:20:57 PM | Train: [ 71/180] Step 050/312 Loss 2.850 Prec@(1,3) (80.5%, 98.2%), ce_loss 0.794, lat_loss 22.047
09/21 07:21:17 PM | Train: [ 71/180] Step 100/312 Loss 2.683 Prec@(1,3) (80.8%, 98.5%), ce_loss 0.794, lat_loss 22.047
09/21 07:21:39 PM | Train: [ 71/180] Step 150/312 Loss 2.650 Prec@(1,3) (80.7%, 98.5%), ce_loss 0.794, lat_loss 22.046
09/21 07:21:59 PM | Train: [ 71/180] Step 200/312 Loss 2.579 Prec@(1,3) (81.1%, 98.7%), ce_loss 0.794, lat_loss 22.046
09/21 07:22:19 PM | Train: [ 71/180] Step 250/312 Loss 2.577 Prec@(1,3) (81.0%, 98.7%), ce_loss 0.794, lat_loss 22.046
09/21 07:22:40 PM | Train: [ 71/180] Step 300/312 Loss 2.542 Prec@(1,3) (81.1%, 98.6%), ce_loss 0.794, lat_loss 22.046
09/21 07:22:45 PM | Train: [ 71/180] Step 312/312 Loss 2.547 Prec@(1,3) (81.1%, 98.6%), ce_loss 0.794, lat_loss 22.046
09/21 07:22:45 PM | _theta_step_train: [ 71/180] Final Prec@1 81.0900% Time 129.48
09/21 07:22:50 PM | Valid: [ 71/180] Step 050/312 Loss 2.423 Prec@(1,3) (81.9%, 99.3%), ce_loss 0.794, lat_loss 22.046
09/21 07:22:55 PM | Valid: [ 71/180] Step 100/312 Loss 2.574 Prec@(1,3) (81.1%, 98.8%), ce_loss 0.794, lat_loss 22.046
09/21 07:22:59 PM | Valid: [ 71/180] Step 150/312 Loss 2.539 Prec@(1,3) (81.5%, 98.8%), ce_loss 0.794, lat_loss 22.046
09/21 07:23:03 PM | Valid: [ 71/180] Step 200/312 Loss 2.552 Prec@(1,3) (81.3%, 98.7%), ce_loss 0.794, lat_loss 22.046
09/21 07:23:07 PM | Valid: [ 71/180] Step 250/312 Loss 2.529 Prec@(1,3) (81.3%, 98.8%), ce_loss 0.794, lat_loss 22.046
09/21 07:23:12 PM | Valid: [ 71/180] Step 300/312 Loss 2.490 Prec@(1,3) (81.5%, 98.8%), ce_loss 0.793, lat_loss 22.046
09/21 07:23:13 PM | Valid: [ 71/180] Step 312/312 Loss 2.498 Prec@(1,3) (81.3%, 98.8%), ce_loss 0.793, lat_loss 22.046
09/21 07:23:13 PM | val: [ 71/180] Final Prec@1 81.3300% Time 27.18
09/21 07:23:13 PM | Start to train weights for epoch 71
09/21 07:23:38 PM | Train: [ 72/180] Step 050/1249 Loss 2.126 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.793, lat_loss 22.046
09/21 07:24:01 PM | Train: [ 72/180] Step 100/1249 Loss 2.112 Prec@(1,3) (84.3%, 99.1%), ce_loss 0.793, lat_loss 22.046
09/21 07:24:24 PM | Train: [ 72/180] Step 150/1249 Loss 2.099 Prec@(1,3) (84.1%, 99.1%), ce_loss 0.793, lat_loss 22.046
09/21 07:24:47 PM | Train: [ 72/180] Step 200/1249 Loss 2.131 Prec@(1,3) (84.0%, 99.2%), ce_loss 0.793, lat_loss 22.046
09/21 07:25:07 PM | Train: [ 72/180] Step 250/1249 Loss 2.137 Prec@(1,3) (83.8%, 99.2%), ce_loss 0.793, lat_loss 22.046
09/21 07:25:29 PM | Train: [ 72/180] Step 300/1249 Loss 2.104 Prec@(1,3) (84.1%, 99.2%), ce_loss 0.793, lat_loss 22.046
09/21 07:25:49 PM | Train: [ 72/180] Step 350/1249 Loss 2.110 Prec@(1,3) (84.0%, 99.2%), ce_loss 0.793, lat_loss 22.046
09/21 07:26:13 PM | Train: [ 72/180] Step 400/1249 Loss 2.106 Prec@(1,3) (84.0%, 99.2%), ce_loss 0.792, lat_loss 22.046
09/21 07:26:37 PM | Train: [ 72/180] Step 450/1249 Loss 2.094 Prec@(1,3) (84.1%, 99.3%), ce_loss 0.792, lat_loss 22.046
09/21 07:27:01 PM | Train: [ 72/180] Step 500/1249 Loss 2.134 Prec@(1,3) (83.7%, 99.2%), ce_loss 0.792, lat_loss 22.046
09/21 07:27:26 PM | Train: [ 72/180] Step 550/1249 Loss 2.133 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.792, lat_loss 22.046
09/21 07:27:51 PM | Train: [ 72/180] Step 600/1249 Loss 2.138 Prec@(1,3) (83.6%, 99.1%), ce_loss 0.792, lat_loss 22.046
09/21 07:28:15 PM | Train: [ 72/180] Step 650/1249 Loss 2.144 Prec@(1,3) (83.6%, 99.1%), ce_loss 0.792, lat_loss 22.046
09/21 07:28:40 PM | Train: [ 72/180] Step 700/1249 Loss 2.160 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.792, lat_loss 22.046
09/21 07:29:03 PM | Train: [ 72/180] Step 750/1249 Loss 2.152 Prec@(1,3) (83.6%, 99.1%), ce_loss 0.792, lat_loss 22.046
09/21 07:29:25 PM | Train: [ 72/180] Step 800/1249 Loss 2.151 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.792, lat_loss 22.046
09/21 07:29:49 PM | Train: [ 72/180] Step 850/1249 Loss 2.155 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.791, lat_loss 22.045
09/21 07:30:12 PM | Train: [ 72/180] Step 900/1249 Loss 2.178 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.791, lat_loss 22.045
09/21 07:30:35 PM | Train: [ 72/180] Step 950/1249 Loss 2.171 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.791, lat_loss 22.045
09/21 07:30:59 PM | Train: [ 72/180] Step 1000/1249 Loss 2.166 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.791, lat_loss 22.045
09/21 07:31:21 PM | Train: [ 72/180] Step 1050/1249 Loss 2.183 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.791, lat_loss 22.045
09/21 07:31:40 PM | Train: [ 72/180] Step 1100/1249 Loss 2.187 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.791, lat_loss 22.045
09/21 07:32:03 PM | Train: [ 72/180] Step 1150/1249 Loss 2.184 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.791, lat_loss 22.045
09/21 07:32:28 PM | Train: [ 72/180] Step 1200/1249 Loss 2.194 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.791, lat_loss 22.045
09/21 07:32:52 PM | Train: [ 72/180] Step 1249/1249 Loss 2.190 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.791, lat_loss 22.045
09/21 07:32:52 PM | _w_step_train: [ 72/180] Final Prec@1 83.3825% Time 579.86
09/21 07:32:52 PM | Start to train theta for epoch 71
09/21 07:33:06 PM | Train: [ 72/180] Step 050/312 Loss 2.390 Prec@(1,3) (81.2%, 99.3%), ce_loss 0.790, lat_loss 22.045
09/21 07:33:18 PM | Train: [ 72/180] Step 100/312 Loss 2.446 Prec@(1,3) (80.8%, 99.0%), ce_loss 0.790, lat_loss 22.045
09/21 07:33:30 PM | Train: [ 72/180] Step 150/312 Loss 2.505 Prec@(1,3) (80.6%, 98.9%), ce_loss 0.790, lat_loss 22.045
09/21 07:33:42 PM | Train: [ 72/180] Step 200/312 Loss 2.501 Prec@(1,3) (81.0%, 98.8%), ce_loss 0.790, lat_loss 22.045
09/21 07:33:55 PM | Train: [ 72/180] Step 250/312 Loss 2.552 Prec@(1,3) (80.7%, 98.6%), ce_loss 0.790, lat_loss 22.045
09/21 07:34:15 PM | Train: [ 72/180] Step 300/312 Loss 2.521 Prec@(1,3) (80.9%, 98.7%), ce_loss 0.790, lat_loss 22.045
09/21 07:34:20 PM | Train: [ 72/180] Step 312/312 Loss 2.525 Prec@(1,3) (80.9%, 98.8%), ce_loss 0.790, lat_loss 22.045
09/21 07:34:20 PM | _theta_step_train: [ 72/180] Final Prec@1 80.9000% Time 87.87
09/21 07:34:26 PM | Valid: [ 72/180] Step 050/312 Loss 2.374 Prec@(1,3) (82.4%, 99.0%), ce_loss 0.790, lat_loss 22.045
09/21 07:34:30 PM | Valid: [ 72/180] Step 100/312 Loss 2.610 Prec@(1,3) (80.8%, 98.4%), ce_loss 0.790, lat_loss 22.045
09/21 07:34:35 PM | Valid: [ 72/180] Step 150/312 Loss 2.591 Prec@(1,3) (80.9%, 98.5%), ce_loss 0.790, lat_loss 22.045
09/21 07:34:39 PM | Valid: [ 72/180] Step 200/312 Loss 2.572 Prec@(1,3) (80.9%, 98.6%), ce_loss 0.790, lat_loss 22.045
09/21 07:34:44 PM | Valid: [ 72/180] Step 250/312 Loss 2.509 Prec@(1,3) (81.3%, 98.8%), ce_loss 0.790, lat_loss 22.045
09/21 07:34:49 PM | Valid: [ 72/180] Step 300/312 Loss 2.489 Prec@(1,3) (81.4%, 98.8%), ce_loss 0.790, lat_loss 22.045
09/21 07:34:50 PM | Valid: [ 72/180] Step 312/312 Loss 2.484 Prec@(1,3) (81.5%, 98.8%), ce_loss 0.789, lat_loss 22.045
09/21 07:34:50 PM | val: [ 72/180] Final Prec@1 81.4600% Time 29.51
09/21 07:34:50 PM | Start to train weights for epoch 72
09/21 07:35:16 PM | Train: [ 73/180] Step 050/1249 Loss 2.054 Prec@(1,3) (84.3%, 99.5%), ce_loss 0.789, lat_loss 22.045
09/21 07:35:41 PM | Train: [ 73/180] Step 100/1249 Loss 2.121 Prec@(1,3) (83.8%, 99.3%), ce_loss 0.789, lat_loss 22.045
09/21 07:35:58 PM | Train: [ 73/180] Step 150/1249 Loss 2.156 Prec@(1,3) (83.5%, 99.3%), ce_loss 0.789, lat_loss 22.045
09/21 07:36:13 PM | Train: [ 73/180] Step 200/1249 Loss 2.125 Prec@(1,3) (83.4%, 99.3%), ce_loss 0.789, lat_loss 22.045
09/21 07:36:29 PM | Train: [ 73/180] Step 250/1249 Loss 2.137 Prec@(1,3) (83.5%, 99.3%), ce_loss 0.789, lat_loss 22.045
09/21 07:36:45 PM | Train: [ 73/180] Step 300/1249 Loss 2.181 Prec@(1,3) (83.2%, 99.3%), ce_loss 0.789, lat_loss 22.045
09/21 07:37:01 PM | Train: [ 73/180] Step 350/1249 Loss 2.180 Prec@(1,3) (83.1%, 99.3%), ce_loss 0.789, lat_loss 22.045
09/21 07:37:17 PM | Train: [ 73/180] Step 400/1249 Loss 2.195 Prec@(1,3) (82.9%, 99.2%), ce_loss 0.789, lat_loss 22.045
09/21 07:37:33 PM | Train: [ 73/180] Step 450/1249 Loss 2.193 Prec@(1,3) (83.0%, 99.2%), ce_loss 0.788, lat_loss 22.044
09/21 07:37:49 PM | Train: [ 73/180] Step 500/1249 Loss 2.197 Prec@(1,3) (83.0%, 99.2%), ce_loss 0.788, lat_loss 22.044
09/21 07:38:05 PM | Train: [ 73/180] Step 550/1249 Loss 2.191 Prec@(1,3) (83.1%, 99.2%), ce_loss 0.788, lat_loss 22.044
09/21 07:38:21 PM | Train: [ 73/180] Step 600/1249 Loss 2.180 Prec@(1,3) (83.3%, 99.2%), ce_loss 0.788, lat_loss 22.044
09/21 07:38:37 PM | Train: [ 73/180] Step 650/1249 Loss 2.170 Prec@(1,3) (83.3%, 99.2%), ce_loss 0.788, lat_loss 22.044
09/21 07:38:53 PM | Train: [ 73/180] Step 700/1249 Loss 2.160 Prec@(1,3) (83.3%, 99.2%), ce_loss 0.788, lat_loss 22.044
09/21 07:39:09 PM | Train: [ 73/180] Step 750/1249 Loss 2.165 Prec@(1,3) (83.3%, 99.2%), ce_loss 0.788, lat_loss 22.044
09/21 07:39:25 PM | Train: [ 73/180] Step 800/1249 Loss 2.160 Prec@(1,3) (83.2%, 99.2%), ce_loss 0.788, lat_loss 22.044
09/21 07:39:41 PM | Train: [ 73/180] Step 850/1249 Loss 2.146 Prec@(1,3) (83.4%, 99.2%), ce_loss 0.788, lat_loss 22.044
09/21 07:39:57 PM | Train: [ 73/180] Step 900/1249 Loss 2.147 Prec@(1,3) (83.4%, 99.2%), ce_loss 0.787, lat_loss 22.044
09/21 07:40:13 PM | Train: [ 73/180] Step 950/1249 Loss 2.155 Prec@(1,3) (83.4%, 99.2%), ce_loss 0.787, lat_loss 22.044
09/21 07:40:29 PM | Train: [ 73/180] Step 1000/1249 Loss 2.157 Prec@(1,3) (83.4%, 99.2%), ce_loss 0.787, lat_loss 22.044
09/21 07:40:45 PM | Train: [ 73/180] Step 1050/1249 Loss 2.177 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.787, lat_loss 22.044
09/21 07:41:01 PM | Train: [ 73/180] Step 1100/1249 Loss 2.181 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.787, lat_loss 22.044
09/21 07:41:17 PM | Train: [ 73/180] Step 1150/1249 Loss 2.168 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.787, lat_loss 22.044
09/21 07:41:33 PM | Train: [ 73/180] Step 1200/1249 Loss 2.189 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.787, lat_loss 22.044
09/21 07:41:49 PM | Train: [ 73/180] Step 1249/1249 Loss 2.192 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.787, lat_loss 22.044
09/21 07:41:49 PM | _w_step_train: [ 73/180] Final Prec@1 83.2500% Time 419.09
09/21 07:41:49 PM | Start to train theta for epoch 72
09/21 07:42:10 PM | Train: [ 73/180] Step 050/312 Loss 2.521 Prec@(1,3) (81.9%, 98.5%), ce_loss 0.787, lat_loss 22.044
09/21 07:42:31 PM | Train: [ 73/180] Step 100/312 Loss 2.466 Prec@(1,3) (81.7%, 98.8%), ce_loss 0.787, lat_loss 22.044
09/21 07:42:52 PM | Train: [ 73/180] Step 150/312 Loss 2.431 Prec@(1,3) (81.6%, 98.8%), ce_loss 0.786, lat_loss 22.044
09/21 07:43:13 PM | Train: [ 73/180] Step 200/312 Loss 2.444 Prec@(1,3) (81.5%, 98.8%), ce_loss 0.786, lat_loss 22.044
09/21 07:43:33 PM | Train: [ 73/180] Step 250/312 Loss 2.454 Prec@(1,3) (81.4%, 98.8%), ce_loss 0.786, lat_loss 22.044
09/21 07:43:54 PM | Train: [ 73/180] Step 300/312 Loss 2.435 Prec@(1,3) (81.4%, 98.8%), ce_loss 0.786, lat_loss 22.044
09/21 07:43:59 PM | Train: [ 73/180] Step 312/312 Loss 2.428 Prec@(1,3) (81.5%, 98.8%), ce_loss 0.786, lat_loss 22.044
09/21 07:43:59 PM | _theta_step_train: [ 73/180] Final Prec@1 81.4600% Time 129.93
09/21 07:44:04 PM | Valid: [ 73/180] Step 050/312 Loss 2.330 Prec@(1,3) (82.0%, 99.2%), ce_loss 0.786, lat_loss 22.044
09/21 07:44:09 PM | Valid: [ 73/180] Step 100/312 Loss 2.493 Prec@(1,3) (80.7%, 99.0%), ce_loss 0.786, lat_loss 22.044
09/21 07:44:13 PM | Valid: [ 73/180] Step 150/312 Loss 2.474 Prec@(1,3) (81.0%, 98.9%), ce_loss 0.786, lat_loss 22.044
09/21 07:44:18 PM | Valid: [ 73/180] Step 200/312 Loss 2.476 Prec@(1,3) (80.7%, 98.9%), ce_loss 0.786, lat_loss 22.044
09/21 07:44:23 PM | Valid: [ 73/180] Step 250/312 Loss 2.485 Prec@(1,3) (80.6%, 98.9%), ce_loss 0.786, lat_loss 22.044
09/21 07:44:27 PM | Valid: [ 73/180] Step 300/312 Loss 2.451 Prec@(1,3) (80.8%, 99.0%), ce_loss 0.786, lat_loss 22.044
09/21 07:44:29 PM | Valid: [ 73/180] Step 312/312 Loss 2.455 Prec@(1,3) (80.7%, 99.0%), ce_loss 0.786, lat_loss 22.044
09/21 07:44:29 PM | val: [ 73/180] Final Prec@1 80.7400% Time 29.74
09/21 07:44:29 PM | Start to train weights for epoch 73
09/21 07:44:54 PM | Train: [ 74/180] Step 050/1249 Loss 2.083 Prec@(1,3) (83.5%, 99.0%), ce_loss 0.785, lat_loss 22.043
09/21 07:45:20 PM | Train: [ 74/180] Step 100/1249 Loss 2.142 Prec@(1,3) (83.5%, 98.8%), ce_loss 0.785, lat_loss 22.043
09/21 07:45:42 PM | Train: [ 74/180] Step 150/1249 Loss 2.136 Prec@(1,3) (83.8%, 98.9%), ce_loss 0.785, lat_loss 22.043
09/21 07:45:58 PM | Train: [ 74/180] Step 200/1249 Loss 2.129 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.785, lat_loss 22.043
09/21 07:46:14 PM | Train: [ 74/180] Step 250/1249 Loss 2.103 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.785, lat_loss 22.043
09/21 07:46:30 PM | Train: [ 74/180] Step 300/1249 Loss 2.175 Prec@(1,3) (83.5%, 98.9%), ce_loss 0.785, lat_loss 22.043
09/21 07:46:52 PM | Train: [ 74/180] Step 350/1249 Loss 2.164 Prec@(1,3) (83.6%, 98.9%), ce_loss 0.785, lat_loss 22.043
09/21 07:47:17 PM | Train: [ 74/180] Step 400/1249 Loss 2.163 Prec@(1,3) (83.6%, 99.0%), ce_loss 0.785, lat_loss 22.043
09/21 07:47:34 PM | Train: [ 74/180] Step 450/1249 Loss 2.158 Prec@(1,3) (83.6%, 98.9%), ce_loss 0.785, lat_loss 22.043
09/21 07:47:49 PM | Train: [ 74/180] Step 500/1249 Loss 2.166 Prec@(1,3) (83.5%, 98.9%), ce_loss 0.784, lat_loss 22.043
09/21 07:48:05 PM | Train: [ 74/180] Step 550/1249 Loss 2.165 Prec@(1,3) (83.5%, 99.0%), ce_loss 0.784, lat_loss 22.043
09/21 07:48:21 PM | Train: [ 74/180] Step 600/1249 Loss 2.157 Prec@(1,3) (83.7%, 98.9%), ce_loss 0.784, lat_loss 22.043
09/21 07:48:37 PM | Train: [ 74/180] Step 650/1249 Loss 2.169 Prec@(1,3) (83.5%, 99.0%), ce_loss 0.784, lat_loss 22.043
09/21 07:48:53 PM | Train: [ 74/180] Step 700/1249 Loss 2.167 Prec@(1,3) (83.6%, 99.0%), ce_loss 0.784, lat_loss 22.043
09/21 07:49:09 PM | Train: [ 74/180] Step 750/1249 Loss 2.156 Prec@(1,3) (83.6%, 99.0%), ce_loss 0.784, lat_loss 22.043
09/21 07:49:25 PM | Train: [ 74/180] Step 800/1249 Loss 2.152 Prec@(1,3) (83.7%, 99.0%), ce_loss 0.784, lat_loss 22.043
09/21 07:49:41 PM | Train: [ 74/180] Step 850/1249 Loss 2.151 Prec@(1,3) (83.7%, 99.0%), ce_loss 0.784, lat_loss 22.043
09/21 07:49:57 PM | Train: [ 74/180] Step 900/1249 Loss 2.149 Prec@(1,3) (83.7%, 99.0%), ce_loss 0.784, lat_loss 22.043
09/21 07:50:13 PM | Train: [ 74/180] Step 950/1249 Loss 2.151 Prec@(1,3) (83.6%, 99.0%), ce_loss 0.783, lat_loss 22.043
09/21 07:50:29 PM | Train: [ 74/180] Step 1000/1249 Loss 2.146 Prec@(1,3) (83.7%, 99.0%), ce_loss 0.783, lat_loss 22.043
09/21 07:50:45 PM | Train: [ 74/180] Step 1050/1249 Loss 2.144 Prec@(1,3) (83.7%, 99.0%), ce_loss 0.783, lat_loss 22.043
09/21 07:51:01 PM | Train: [ 74/180] Step 1100/1249 Loss 2.138 Prec@(1,3) (83.7%, 99.0%), ce_loss 0.783, lat_loss 22.043
09/21 07:51:24 PM | Train: [ 74/180] Step 1150/1249 Loss 2.136 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.783, lat_loss 22.043
09/21 07:51:49 PM | Train: [ 74/180] Step 1200/1249 Loss 2.139 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.783, lat_loss 22.043
09/21 07:52:13 PM | Train: [ 74/180] Step 1249/1249 Loss 2.142 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.783, lat_loss 22.043
09/21 07:52:13 PM | _w_step_train: [ 74/180] Final Prec@1 83.7050% Time 464.24
09/21 07:52:13 PM | Start to train theta for epoch 73
09/21 07:52:35 PM | Train: [ 74/180] Step 050/312 Loss 2.748 Prec@(1,3) (80.0%, 99.0%), ce_loss 0.783, lat_loss 22.043
09/21 07:52:54 PM | Train: [ 74/180] Step 100/312 Loss 2.610 Prec@(1,3) (80.5%, 99.0%), ce_loss 0.783, lat_loss 22.043
09/21 07:53:13 PM | Train: [ 74/180] Step 150/312 Loss 2.590 Prec@(1,3) (80.4%, 99.0%), ce_loss 0.783, lat_loss 22.042
09/21 07:53:33 PM | Train: [ 74/180] Step 200/312 Loss 2.595 Prec@(1,3) (80.5%, 98.9%), ce_loss 0.782, lat_loss 22.042
09/21 07:53:52 PM | Train: [ 74/180] Step 250/312 Loss 2.612 Prec@(1,3) (80.4%, 98.8%), ce_loss 0.782, lat_loss 22.042
09/21 07:54:13 PM | Train: [ 74/180] Step 300/312 Loss 2.625 Prec@(1,3) (80.3%, 98.9%), ce_loss 0.782, lat_loss 22.042
09/21 07:54:18 PM | Train: [ 74/180] Step 312/312 Loss 2.635 Prec@(1,3) (80.2%, 98.9%), ce_loss 0.782, lat_loss 22.042
09/21 07:54:18 PM | _theta_step_train: [ 74/180] Final Prec@1 80.2400% Time 124.76
09/21 07:54:23 PM | Valid: [ 74/180] Step 050/312 Loss 2.321 Prec@(1,3) (82.5%, 99.0%), ce_loss 0.782, lat_loss 22.042
09/21 07:54:28 PM | Valid: [ 74/180] Step 100/312 Loss 2.463 Prec@(1,3) (81.7%, 98.8%), ce_loss 0.782, lat_loss 22.042
09/21 07:54:33 PM | Valid: [ 74/180] Step 150/312 Loss 2.507 Prec@(1,3) (81.3%, 98.8%), ce_loss 0.782, lat_loss 22.042
09/21 07:54:37 PM | Valid: [ 74/180] Step 200/312 Loss 2.456 Prec@(1,3) (81.8%, 98.9%), ce_loss 0.782, lat_loss 22.042
09/21 07:54:42 PM | Valid: [ 74/180] Step 250/312 Loss 2.416 Prec@(1,3) (81.9%, 99.0%), ce_loss 0.782, lat_loss 22.042
09/21 07:54:47 PM | Valid: [ 74/180] Step 300/312 Loss 2.424 Prec@(1,3) (81.9%, 99.1%), ce_loss 0.782, lat_loss 22.042
09/21 07:54:48 PM | Valid: [ 74/180] Step 312/312 Loss 2.430 Prec@(1,3) (81.8%, 99.1%), ce_loss 0.782, lat_loss 22.042
09/21 07:54:48 PM | val: [ 74/180] Final Prec@1 81.8200% Time 29.71
09/21 07:54:48 PM | Start to train weights for epoch 74
09/21 07:55:11 PM | Train: [ 75/180] Step 050/1249 Loss 2.206 Prec@(1,3) (84.0%, 98.8%), ce_loss 0.782, lat_loss 22.042
09/21 07:55:32 PM | Train: [ 75/180] Step 100/1249 Loss 2.084 Prec@(1,3) (84.5%, 98.9%), ce_loss 0.782, lat_loss 22.042
09/21 07:55:52 PM | Train: [ 75/180] Step 150/1249 Loss 2.030 Prec@(1,3) (84.7%, 99.0%), ce_loss 0.781, lat_loss 22.042
09/21 07:56:17 PM | Train: [ 75/180] Step 200/1249 Loss 2.004 Prec@(1,3) (84.8%, 99.1%), ce_loss 0.781, lat_loss 22.042
09/21 07:56:41 PM | Train: [ 75/180] Step 250/1249 Loss 2.002 Prec@(1,3) (84.8%, 99.1%), ce_loss 0.781, lat_loss 22.042
09/21 07:57:06 PM | Train: [ 75/180] Step 300/1249 Loss 2.042 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.781, lat_loss 22.042
09/21 07:57:32 PM | Train: [ 75/180] Step 350/1249 Loss 2.031 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.781, lat_loss 22.042
09/21 07:57:54 PM | Train: [ 75/180] Step 400/1249 Loss 2.033 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.781, lat_loss 22.042
09/21 07:58:17 PM | Train: [ 75/180] Step 450/1249 Loss 2.044 Prec@(1,3) (84.5%, 99.1%), ce_loss 0.781, lat_loss 22.042
09/21 07:58:42 PM | Train: [ 75/180] Step 500/1249 Loss 2.036 Prec@(1,3) (84.5%, 99.1%), ce_loss 0.781, lat_loss 22.042
09/21 07:59:07 PM | Train: [ 75/180] Step 550/1249 Loss 2.043 Prec@(1,3) (84.4%, 99.1%), ce_loss 0.780, lat_loss 22.042
09/21 07:59:32 PM | Train: [ 75/180] Step 600/1249 Loss 2.061 Prec@(1,3) (84.3%, 99.1%), ce_loss 0.780, lat_loss 22.042
09/21 07:59:58 PM | Train: [ 75/180] Step 650/1249 Loss 2.066 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.780, lat_loss 22.042
09/21 08:00:23 PM | Train: [ 75/180] Step 700/1249 Loss 2.073 Prec@(1,3) (84.1%, 99.2%), ce_loss 0.780, lat_loss 22.042
09/21 08:00:49 PM | Train: [ 75/180] Step 750/1249 Loss 2.062 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.780, lat_loss 22.042
09/21 08:01:15 PM | Train: [ 75/180] Step 800/1249 Loss 2.060 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.780, lat_loss 22.042
09/21 08:01:40 PM | Train: [ 75/180] Step 850/1249 Loss 2.052 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.780, lat_loss 22.042
09/21 08:02:06 PM | Train: [ 75/180] Step 900/1249 Loss 2.054 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.780, lat_loss 22.041
09/21 08:02:31 PM | Train: [ 75/180] Step 950/1249 Loss 2.049 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.780, lat_loss 22.041
09/21 08:02:57 PM | Train: [ 75/180] Step 1000/1249 Loss 2.062 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.779, lat_loss 22.041
09/21 08:03:22 PM | Train: [ 75/180] Step 1050/1249 Loss 2.057 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.779, lat_loss 22.041
09/21 08:03:47 PM | Train: [ 75/180] Step 1100/1249 Loss 2.072 Prec@(1,3) (84.1%, 99.2%), ce_loss 0.779, lat_loss 22.041
09/21 08:04:12 PM | Train: [ 75/180] Step 1150/1249 Loss 2.081 Prec@(1,3) (84.0%, 99.2%), ce_loss 0.779, lat_loss 22.041
09/21 08:04:38 PM | Train: [ 75/180] Step 1200/1249 Loss 2.083 Prec@(1,3) (84.1%, 99.1%), ce_loss 0.779, lat_loss 22.041
09/21 08:05:02 PM | Train: [ 75/180] Step 1249/1249 Loss 2.078 Prec@(1,3) (84.1%, 99.2%), ce_loss 0.779, lat_loss 22.041
09/21 08:05:03 PM | _w_step_train: [ 75/180] Final Prec@1 84.0875% Time 614.69
09/21 08:05:03 PM | Start to train theta for epoch 74
09/21 08:05:24 PM | Train: [ 75/180] Step 050/312 Loss 2.842 Prec@(1,3) (78.6%, 98.4%), ce_loss 0.779, lat_loss 22.041
09/21 08:05:45 PM | Train: [ 75/180] Step 100/312 Loss 2.611 Prec@(1,3) (80.1%, 98.5%), ce_loss 0.779, lat_loss 22.041
09/21 08:06:05 PM | Train: [ 75/180] Step 150/312 Loss 2.575 Prec@(1,3) (80.7%, 98.6%), ce_loss 0.779, lat_loss 22.041
09/21 08:06:25 PM | Train: [ 75/180] Step 200/312 Loss 2.492 Prec@(1,3) (81.3%, 98.7%), ce_loss 0.779, lat_loss 22.041
09/21 08:06:46 PM | Train: [ 75/180] Step 250/312 Loss 2.546 Prec@(1,3) (81.1%, 98.6%), ce_loss 0.779, lat_loss 22.041
09/21 08:06:59 PM | Train: [ 75/180] Step 300/312 Loss 2.545 Prec@(1,3) (81.1%, 98.6%), ce_loss 0.778, lat_loss 22.041
09/21 08:07:02 PM | Train: [ 75/180] Step 312/312 Loss 2.540 Prec@(1,3) (81.1%, 98.6%), ce_loss 0.778, lat_loss 22.041
09/21 08:07:02 PM | _theta_step_train: [ 75/180] Final Prec@1 81.1100% Time 119.47
09/21 08:07:07 PM | Valid: [ 75/180] Step 050/312 Loss 2.353 Prec@(1,3) (81.6%, 99.1%), ce_loss 0.778, lat_loss 22.041
09/21 08:07:11 PM | Valid: [ 75/180] Step 100/312 Loss 2.431 Prec@(1,3) (80.8%, 98.9%), ce_loss 0.778, lat_loss 22.041
09/21 08:07:15 PM | Valid: [ 75/180] Step 150/312 Loss 2.388 Prec@(1,3) (81.5%, 98.8%), ce_loss 0.778, lat_loss 22.041
09/21 08:07:19 PM | Valid: [ 75/180] Step 200/312 Loss 2.383 Prec@(1,3) (81.7%, 98.8%), ce_loss 0.778, lat_loss 22.041
09/21 08:07:24 PM | Valid: [ 75/180] Step 250/312 Loss 2.402 Prec@(1,3) (81.4%, 98.8%), ce_loss 0.778, lat_loss 22.041
09/21 08:07:28 PM | Valid: [ 75/180] Step 300/312 Loss 2.423 Prec@(1,3) (81.4%, 98.7%), ce_loss 0.778, lat_loss 22.041
09/21 08:07:29 PM | Valid: [ 75/180] Step 312/312 Loss 2.416 Prec@(1,3) (81.4%, 98.7%), ce_loss 0.778, lat_loss 22.041
09/21 08:07:29 PM | val: [ 75/180] Final Prec@1 81.4100% Time 26.91
09/21 08:07:29 PM | Start to train weights for epoch 75
09/21 08:07:54 PM | Train: [ 76/180] Step 050/1249 Loss 1.980 Prec@(1,3) (84.3%, 99.6%), ce_loss 0.778, lat_loss 22.041
09/21 08:08:19 PM | Train: [ 76/180] Step 100/1249 Loss 1.956 Prec@(1,3) (84.8%, 99.4%), ce_loss 0.778, lat_loss 22.041
09/21 08:08:44 PM | Train: [ 76/180] Step 150/1249 Loss 1.929 Prec@(1,3) (85.1%, 99.5%), ce_loss 0.778, lat_loss 22.041
09/21 08:09:09 PM | Train: [ 76/180] Step 200/1249 Loss 1.998 Prec@(1,3) (85.0%, 99.4%), ce_loss 0.777, lat_loss 22.041
09/21 08:09:35 PM | Train: [ 76/180] Step 250/1249 Loss 1.997 Prec@(1,3) (85.0%, 99.4%), ce_loss 0.777, lat_loss 22.040
09/21 08:10:00 PM | Train: [ 76/180] Step 300/1249 Loss 2.010 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.777, lat_loss 22.040
09/21 08:10:25 PM | Train: [ 76/180] Step 350/1249 Loss 1.992 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.777, lat_loss 22.040
09/21 08:10:50 PM | Train: [ 76/180] Step 400/1249 Loss 1.998 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.777, lat_loss 22.040
09/21 08:11:15 PM | Train: [ 76/180] Step 450/1249 Loss 2.001 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.777, lat_loss 22.040
09/21 08:11:40 PM | Train: [ 76/180] Step 500/1249 Loss 2.008 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.777, lat_loss 22.040
09/21 08:12:05 PM | Train: [ 76/180] Step 550/1249 Loss 2.034 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.777, lat_loss 22.040
09/21 08:12:29 PM | Train: [ 76/180] Step 600/1249 Loss 2.030 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.777, lat_loss 22.040
09/21 08:12:53 PM | Train: [ 76/180] Step 650/1249 Loss 2.049 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.776, lat_loss 22.040
09/21 08:13:17 PM | Train: [ 76/180] Step 700/1249 Loss 2.048 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.776, lat_loss 22.040
09/21 08:13:41 PM | Train: [ 76/180] Step 750/1249 Loss 2.045 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.776, lat_loss 22.040
09/21 08:14:06 PM | Train: [ 76/180] Step 800/1249 Loss 2.048 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.776, lat_loss 22.040
09/21 08:14:31 PM | Train: [ 76/180] Step 850/1249 Loss 2.048 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.776, lat_loss 22.040
09/21 08:14:55 PM | Train: [ 76/180] Step 900/1249 Loss 2.044 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.776, lat_loss 22.040
09/21 08:15:19 PM | Train: [ 76/180] Step 950/1249 Loss 2.034 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.776, lat_loss 22.040
09/21 08:15:43 PM | Train: [ 76/180] Step 1000/1249 Loss 2.027 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.776, lat_loss 22.040
09/21 08:16:07 PM | Train: [ 76/180] Step 1050/1249 Loss 2.031 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.775, lat_loss 22.040
09/21 08:16:31 PM | Train: [ 76/180] Step 1100/1249 Loss 2.033 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.775, lat_loss 22.040
09/21 08:16:56 PM | Train: [ 76/180] Step 1150/1249 Loss 2.042 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.775, lat_loss 22.040
09/21 08:17:20 PM | Train: [ 76/180] Step 1200/1249 Loss 2.045 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.775, lat_loss 22.040
09/21 08:17:44 PM | Train: [ 76/180] Step 1249/1249 Loss 2.041 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.775, lat_loss 22.040
09/21 08:17:44 PM | _w_step_train: [ 76/180] Final Prec@1 84.4425% Time 615.08
09/21 08:17:44 PM | Start to train theta for epoch 75
09/21 08:18:05 PM | Train: [ 76/180] Step 050/312 Loss 2.679 Prec@(1,3) (80.4%, 98.2%), ce_loss 0.775, lat_loss 22.040
09/21 08:18:26 PM | Train: [ 76/180] Step 100/312 Loss 2.562 Prec@(1,3) (81.0%, 98.6%), ce_loss 0.775, lat_loss 22.040
09/21 08:18:46 PM | Train: [ 76/180] Step 150/312 Loss 2.481 Prec@(1,3) (81.1%, 98.8%), ce_loss 0.775, lat_loss 22.040
09/21 08:19:06 PM | Train: [ 76/180] Step 200/312 Loss 2.505 Prec@(1,3) (81.4%, 98.8%), ce_loss 0.775, lat_loss 22.039
09/21 08:19:27 PM | Train: [ 76/180] Step 250/312 Loss 2.482 Prec@(1,3) (81.5%, 98.8%), ce_loss 0.775, lat_loss 22.039
09/21 08:19:47 PM | Train: [ 76/180] Step 300/312 Loss 2.410 Prec@(1,3) (82.2%, 98.9%), ce_loss 0.775, lat_loss 22.039
09/21 08:19:52 PM | Train: [ 76/180] Step 312/312 Loss 2.412 Prec@(1,3) (82.2%, 98.9%), ce_loss 0.775, lat_loss 22.039
09/21 08:19:53 PM | _theta_step_train: [ 76/180] Final Prec@1 82.1600% Time 128.82
09/21 08:19:58 PM | Valid: [ 76/180] Step 050/312 Loss 2.121 Prec@(1,3) (83.0%, 99.6%), ce_loss 0.774, lat_loss 22.039
09/21 08:20:03 PM | Valid: [ 76/180] Step 100/312 Loss 2.448 Prec@(1,3) (81.8%, 98.7%), ce_loss 0.774, lat_loss 22.039
09/21 08:20:07 PM | Valid: [ 76/180] Step 150/312 Loss 2.504 Prec@(1,3) (81.4%, 98.7%), ce_loss 0.774, lat_loss 22.039
09/21 08:20:12 PM | Valid: [ 76/180] Step 200/312 Loss 2.492 Prec@(1,3) (81.3%, 98.8%), ce_loss 0.774, lat_loss 22.039
09/21 08:20:17 PM | Valid: [ 76/180] Step 250/312 Loss 2.424 Prec@(1,3) (81.5%, 98.9%), ce_loss 0.774, lat_loss 22.039
09/21 08:20:21 PM | Valid: [ 76/180] Step 300/312 Loss 2.382 Prec@(1,3) (81.7%, 99.0%), ce_loss 0.774, lat_loss 22.039
09/21 08:20:22 PM | Valid: [ 76/180] Step 312/312 Loss 2.441 Prec@(1,3) (81.5%, 98.8%), ce_loss 0.774, lat_loss 22.039
09/21 08:20:23 PM | val: [ 76/180] Final Prec@1 81.4500% Time 29.68
09/21 08:20:23 PM | Start to train weights for epoch 76
09/21 08:20:49 PM | Train: [ 77/180] Step 050/1249 Loss 1.966 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.774, lat_loss 22.039
09/21 08:21:14 PM | Train: [ 77/180] Step 100/1249 Loss 1.865 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.774, lat_loss 22.039
09/21 08:21:39 PM | Train: [ 77/180] Step 150/1249 Loss 1.921 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.774, lat_loss 22.039
09/21 08:22:04 PM | Train: [ 77/180] Step 200/1249 Loss 1.912 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.774, lat_loss 22.039
09/21 08:22:29 PM | Train: [ 77/180] Step 250/1249 Loss 1.897 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.773, lat_loss 22.039
09/21 08:22:54 PM | Train: [ 77/180] Step 300/1249 Loss 1.913 Prec@(1,3) (85.3%, 99.4%), ce_loss 0.773, lat_loss 22.039
09/21 08:23:19 PM | Train: [ 77/180] Step 350/1249 Loss 1.924 Prec@(1,3) (85.3%, 99.4%), ce_loss 0.773, lat_loss 22.039
09/21 08:23:43 PM | Train: [ 77/180] Step 400/1249 Loss 1.923 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.773, lat_loss 22.039
09/21 08:24:08 PM | Train: [ 77/180] Step 450/1249 Loss 1.941 Prec@(1,3) (85.1%, 99.4%), ce_loss 0.773, lat_loss 22.039
09/21 08:24:33 PM | Train: [ 77/180] Step 500/1249 Loss 1.954 Prec@(1,3) (85.0%, 99.4%), ce_loss 0.773, lat_loss 22.039
09/21 08:24:57 PM | Train: [ 77/180] Step 550/1249 Loss 1.943 Prec@(1,3) (85.1%, 99.4%), ce_loss 0.773, lat_loss 22.039
09/21 08:25:21 PM | Train: [ 77/180] Step 600/1249 Loss 1.933 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.773, lat_loss 22.039
09/21 08:25:46 PM | Train: [ 77/180] Step 650/1249 Loss 1.943 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.772, lat_loss 22.039
09/21 08:26:10 PM | Train: [ 77/180] Step 700/1249 Loss 1.941 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.772, lat_loss 22.039
09/21 08:26:35 PM | Train: [ 77/180] Step 750/1249 Loss 1.943 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.772, lat_loss 22.039
09/21 08:27:00 PM | Train: [ 77/180] Step 800/1249 Loss 1.947 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.772, lat_loss 22.039
09/21 08:27:25 PM | Train: [ 77/180] Step 850/1249 Loss 1.958 Prec@(1,3) (85.1%, 99.4%), ce_loss 0.772, lat_loss 22.039
09/21 08:27:49 PM | Train: [ 77/180] Step 900/1249 Loss 1.958 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.772, lat_loss 22.038
09/21 08:28:13 PM | Train: [ 77/180] Step 950/1249 Loss 1.952 Prec@(1,3) (85.1%, 99.4%), ce_loss 0.772, lat_loss 22.038
09/21 08:28:37 PM | Train: [ 77/180] Step 1000/1249 Loss 1.952 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.772, lat_loss 22.038
09/21 08:29:02 PM | Train: [ 77/180] Step 1050/1249 Loss 1.957 Prec@(1,3) (85.2%, 99.3%), ce_loss 0.772, lat_loss 22.038
09/21 08:29:24 PM | Train: [ 77/180] Step 1100/1249 Loss 1.959 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.771, lat_loss 22.038
09/21 08:29:44 PM | Train: [ 77/180] Step 1150/1249 Loss 1.971 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.771, lat_loss 22.038
09/21 08:30:05 PM | Train: [ 77/180] Step 1200/1249 Loss 1.977 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.771, lat_loss 22.038
09/21 08:30:29 PM | Train: [ 77/180] Step 1249/1249 Loss 1.975 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.771, lat_loss 22.038
09/21 08:30:29 PM | _w_step_train: [ 77/180] Final Prec@1 84.9700% Time 606.19
09/21 08:30:29 PM | Start to train theta for epoch 76
09/21 08:30:42 PM | Train: [ 77/180] Step 050/312 Loss 2.399 Prec@(1,3) (82.5%, 98.7%), ce_loss 0.771, lat_loss 22.038
09/21 08:30:55 PM | Train: [ 77/180] Step 100/312 Loss 2.414 Prec@(1,3) (81.9%, 98.9%), ce_loss 0.771, lat_loss 22.038
09/21 08:31:07 PM | Train: [ 77/180] Step 150/312 Loss 2.468 Prec@(1,3) (81.5%, 98.8%), ce_loss 0.771, lat_loss 22.038
09/21 08:31:19 PM | Train: [ 77/180] Step 200/312 Loss 2.450 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.771, lat_loss 22.038
09/21 08:31:31 PM | Train: [ 77/180] Step 250/312 Loss 2.449 Prec@(1,3) (81.6%, 98.9%), ce_loss 0.771, lat_loss 22.038
09/21 08:31:44 PM | Train: [ 77/180] Step 300/312 Loss 2.416 Prec@(1,3) (81.9%, 98.9%), ce_loss 0.771, lat_loss 22.038
09/21 08:31:47 PM | Train: [ 77/180] Step 312/312 Loss 2.402 Prec@(1,3) (81.9%, 98.9%), ce_loss 0.771, lat_loss 22.038
09/21 08:31:47 PM | _theta_step_train: [ 77/180] Final Prec@1 81.9000% Time 77.43
09/21 08:31:52 PM | Valid: [ 77/180] Step 050/312 Loss 2.177 Prec@(1,3) (83.4%, 98.8%), ce_loss 0.770, lat_loss 22.038
09/21 08:31:57 PM | Valid: [ 77/180] Step 100/312 Loss 2.397 Prec@(1,3) (81.8%, 98.7%), ce_loss 0.770, lat_loss 22.038
09/21 08:32:01 PM | Valid: [ 77/180] Step 150/312 Loss 2.349 Prec@(1,3) (82.2%, 98.8%), ce_loss 0.770, lat_loss 22.038
09/21 08:32:06 PM | Valid: [ 77/180] Step 200/312 Loss 2.342 Prec@(1,3) (82.5%, 99.0%), ce_loss 0.770, lat_loss 22.038
09/21 08:32:11 PM | Valid: [ 77/180] Step 250/312 Loss 2.336 Prec@(1,3) (82.4%, 99.0%), ce_loss 0.770, lat_loss 22.038
09/21 08:32:15 PM | Valid: [ 77/180] Step 300/312 Loss 2.324 Prec@(1,3) (82.2%, 99.1%), ce_loss 0.770, lat_loss 22.038
09/21 08:32:16 PM | Valid: [ 77/180] Step 312/312 Loss 2.325 Prec@(1,3) (82.2%, 99.1%), ce_loss 0.770, lat_loss 22.038
09/21 08:32:17 PM | val: [ 77/180] Final Prec@1 82.2000% Time 29.89
09/21 08:32:17 PM | Best top1 acc by now. Save model
09/21 08:32:17 PM | Start to train weights for epoch 77
09/21 08:32:34 PM | Train: [ 78/180] Step 050/1249 Loss 1.749 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.770, lat_loss 22.038
09/21 08:32:50 PM | Train: [ 78/180] Step 100/1249 Loss 1.848 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.770, lat_loss 22.038
09/21 08:33:06 PM | Train: [ 78/180] Step 150/1249 Loss 1.849 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.770, lat_loss 22.038
09/21 08:33:22 PM | Train: [ 78/180] Step 200/1249 Loss 1.907 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.770, lat_loss 22.038
09/21 08:33:38 PM | Train: [ 78/180] Step 250/1249 Loss 1.896 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.769, lat_loss 22.038
09/21 08:33:54 PM | Train: [ 78/180] Step 300/1249 Loss 1.894 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.769, lat_loss 22.037
09/21 08:34:10 PM | Train: [ 78/180] Step 350/1249 Loss 1.911 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.769, lat_loss 22.037
09/21 08:34:26 PM | Train: [ 78/180] Step 400/1249 Loss 1.916 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.769, lat_loss 22.037
09/21 08:34:42 PM | Train: [ 78/180] Step 450/1249 Loss 1.904 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.769, lat_loss 22.037
09/21 08:34:58 PM | Train: [ 78/180] Step 500/1249 Loss 1.900 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.769, lat_loss 22.037
09/21 08:35:14 PM | Train: [ 78/180] Step 550/1249 Loss 1.905 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.769, lat_loss 22.037
09/21 08:35:30 PM | Train: [ 78/180] Step 600/1249 Loss 1.903 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.769, lat_loss 22.037
09/21 08:35:46 PM | Train: [ 78/180] Step 650/1249 Loss 1.904 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.768, lat_loss 22.037
09/21 08:36:02 PM | Train: [ 78/180] Step 700/1249 Loss 1.894 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.768, lat_loss 22.037
09/21 08:36:18 PM | Train: [ 78/180] Step 750/1249 Loss 1.892 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.768, lat_loss 22.037
09/21 08:36:34 PM | Train: [ 78/180] Step 800/1249 Loss 1.900 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.768, lat_loss 22.037
09/21 08:36:50 PM | Train: [ 78/180] Step 850/1249 Loss 1.901 Prec@(1,3) (85.4%, 99.3%), ce_loss 0.768, lat_loss 22.037
09/21 08:37:06 PM | Train: [ 78/180] Step 900/1249 Loss 1.902 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.768, lat_loss 22.037
09/21 08:37:22 PM | Train: [ 78/180] Step 950/1249 Loss 1.905 Prec@(1,3) (85.4%, 99.3%), ce_loss 0.768, lat_loss 22.037
09/21 08:37:38 PM | Train: [ 78/180] Step 1000/1249 Loss 1.913 Prec@(1,3) (85.4%, 99.3%), ce_loss 0.768, lat_loss 22.037
09/21 08:37:54 PM | Train: [ 78/180] Step 1050/1249 Loss 1.910 Prec@(1,3) (85.4%, 99.3%), ce_loss 0.768, lat_loss 22.037
09/21 08:38:10 PM | Train: [ 78/180] Step 1100/1249 Loss 1.913 Prec@(1,3) (85.4%, 99.3%), ce_loss 0.767, lat_loss 22.037
09/21 08:38:26 PM | Train: [ 78/180] Step 1150/1249 Loss 1.922 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.767, lat_loss 22.037
09/21 08:38:42 PM | Train: [ 78/180] Step 1200/1249 Loss 1.924 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.767, lat_loss 22.037
09/21 08:38:57 PM | Train: [ 78/180] Step 1249/1249 Loss 1.925 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.767, lat_loss 22.037
09/21 08:38:57 PM | _w_step_train: [ 78/180] Final Prec@1 85.2650% Time 400.70
09/21 08:38:57 PM | Start to train theta for epoch 77
09/21 08:39:19 PM | Train: [ 78/180] Step 050/312 Loss 2.385 Prec@(1,3) (82.9%, 98.7%), ce_loss 0.767, lat_loss 22.037
09/21 08:39:39 PM | Train: [ 78/180] Step 100/312 Loss 2.334 Prec@(1,3) (82.6%, 98.9%), ce_loss 0.767, lat_loss 22.037
09/21 08:39:57 PM | Train: [ 78/180] Step 150/312 Loss 2.323 Prec@(1,3) (82.3%, 98.9%), ce_loss 0.767, lat_loss 22.037
09/21 08:40:16 PM | Train: [ 78/180] Step 200/312 Loss 2.333 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.767, lat_loss 22.037
09/21 08:40:34 PM | Train: [ 78/180] Step 250/312 Loss 2.351 Prec@(1,3) (82.0%, 99.0%), ce_loss 0.767, lat_loss 22.037
09/21 08:40:54 PM | Train: [ 78/180] Step 300/312 Loss 2.348 Prec@(1,3) (82.0%, 99.0%), ce_loss 0.767, lat_loss 22.036
09/21 08:40:59 PM | Train: [ 78/180] Step 312/312 Loss 2.349 Prec@(1,3) (82.0%, 99.0%), ce_loss 0.767, lat_loss 22.036
09/21 08:40:59 PM | _theta_step_train: [ 78/180] Final Prec@1 81.9900% Time 121.98
09/21 08:41:05 PM | Valid: [ 78/180] Step 050/312 Loss 2.188 Prec@(1,3) (82.4%, 99.4%), ce_loss 0.766, lat_loss 22.036
09/21 08:41:10 PM | Valid: [ 78/180] Step 100/312 Loss 2.265 Prec@(1,3) (82.2%, 99.1%), ce_loss 0.766, lat_loss 22.036
09/21 08:41:14 PM | Valid: [ 78/180] Step 150/312 Loss 2.318 Prec@(1,3) (82.3%, 98.9%), ce_loss 0.766, lat_loss 22.036
09/21 08:41:19 PM | Valid: [ 78/180] Step 200/312 Loss 2.325 Prec@(1,3) (82.2%, 98.9%), ce_loss 0.766, lat_loss 22.036
09/21 08:41:24 PM | Valid: [ 78/180] Step 250/312 Loss 2.288 Prec@(1,3) (82.4%, 99.0%), ce_loss 0.766, lat_loss 22.036
09/21 08:41:28 PM | Valid: [ 78/180] Step 300/312 Loss 2.298 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.766, lat_loss 22.036
09/21 08:41:29 PM | Valid: [ 78/180] Step 312/312 Loss 2.298 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.766, lat_loss 22.036
09/21 08:41:30 PM | val: [ 78/180] Final Prec@1 82.0900% Time 30.09
09/21 08:41:30 PM | Start to train weights for epoch 78
09/21 08:41:47 PM | Train: [ 79/180] Step 050/1249 Loss 1.721 Prec@(1,3) (86.8%, 99.6%), ce_loss 0.766, lat_loss 22.036
09/21 08:42:03 PM | Train: [ 79/180] Step 100/1249 Loss 2.109 Prec@(1,3) (84.9%, 98.6%), ce_loss 0.766, lat_loss 22.036
09/21 08:42:19 PM | Train: [ 79/180] Step 150/1249 Loss 2.004 Prec@(1,3) (85.6%, 98.8%), ce_loss 0.766, lat_loss 22.036
09/21 08:42:35 PM | Train: [ 79/180] Step 200/1249 Loss 2.023 Prec@(1,3) (85.3%, 98.9%), ce_loss 0.766, lat_loss 22.036
09/21 08:42:51 PM | Train: [ 79/180] Step 250/1249 Loss 2.000 Prec@(1,3) (85.4%, 99.0%), ce_loss 0.765, lat_loss 22.036
09/21 08:43:08 PM | Train: [ 79/180] Step 300/1249 Loss 2.005 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.765, lat_loss 22.036
09/21 08:43:24 PM | Train: [ 79/180] Step 350/1249 Loss 2.021 Prec@(1,3) (85.0%, 99.1%), ce_loss 0.765, lat_loss 22.036
09/21 08:43:40 PM | Train: [ 79/180] Step 400/1249 Loss 2.000 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.765, lat_loss 22.036
09/21 08:43:56 PM | Train: [ 79/180] Step 450/1249 Loss 1.994 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.765, lat_loss 22.036
09/21 08:44:15 PM | Train: [ 79/180] Step 500/1249 Loss 1.971 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.765, lat_loss 22.036
09/21 08:44:40 PM | Train: [ 79/180] Step 550/1249 Loss 1.967 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.765, lat_loss 22.036
09/21 08:45:05 PM | Train: [ 79/180] Step 600/1249 Loss 1.954 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.765, lat_loss 22.036
09/21 08:45:30 PM | Train: [ 79/180] Step 650/1249 Loss 1.945 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.765, lat_loss 22.036
09/21 08:45:55 PM | Train: [ 79/180] Step 700/1249 Loss 1.943 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.764, lat_loss 22.036
09/21 08:46:20 PM | Train: [ 79/180] Step 750/1249 Loss 1.937 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.764, lat_loss 22.036
09/21 08:46:45 PM | Train: [ 79/180] Step 800/1249 Loss 1.944 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.764, lat_loss 22.036
09/21 08:47:10 PM | Train: [ 79/180] Step 850/1249 Loss 1.935 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.764, lat_loss 22.036
09/21 08:47:35 PM | Train: [ 79/180] Step 900/1249 Loss 1.955 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.764, lat_loss 22.036
09/21 08:47:59 PM | Train: [ 79/180] Step 950/1249 Loss 1.954 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.764, lat_loss 22.036
09/21 08:48:23 PM | Train: [ 79/180] Step 1000/1249 Loss 1.951 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.764, lat_loss 22.035
09/21 08:48:49 PM | Train: [ 79/180] Step 1050/1249 Loss 1.952 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.764, lat_loss 22.035
09/21 08:49:13 PM | Train: [ 79/180] Step 1100/1249 Loss 1.946 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.763, lat_loss 22.035
09/21 08:49:38 PM | Train: [ 79/180] Step 1150/1249 Loss 1.940 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.763, lat_loss 22.035
09/21 08:50:03 PM | Train: [ 79/180] Step 1200/1249 Loss 1.937 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.763, lat_loss 22.035
09/21 08:50:27 PM | Train: [ 79/180] Step 1249/1249 Loss 1.940 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.763, lat_loss 22.035
09/21 08:50:28 PM | _w_step_train: [ 79/180] Final Prec@1 85.2625% Time 538.03
09/21 08:50:28 PM | Start to train theta for epoch 78
09/21 08:50:48 PM | Train: [ 79/180] Step 050/312 Loss 2.333 Prec@(1,3) (81.8%, 99.4%), ce_loss 0.763, lat_loss 22.035
09/21 08:51:07 PM | Train: [ 79/180] Step 100/312 Loss 2.315 Prec@(1,3) (82.1%, 99.2%), ce_loss 0.763, lat_loss 22.035
09/21 08:51:27 PM | Train: [ 79/180] Step 150/312 Loss 2.355 Prec@(1,3) (82.1%, 99.1%), ce_loss 0.763, lat_loss 22.035
09/21 08:51:47 PM | Train: [ 79/180] Step 200/312 Loss 2.377 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.763, lat_loss 22.035
09/21 08:52:07 PM | Train: [ 79/180] Step 250/312 Loss 2.386 Prec@(1,3) (81.9%, 99.0%), ce_loss 0.763, lat_loss 22.035
09/21 08:52:26 PM | Train: [ 79/180] Step 300/312 Loss 2.415 Prec@(1,3) (81.8%, 98.8%), ce_loss 0.763, lat_loss 22.035
09/21 08:52:31 PM | Train: [ 79/180] Step 312/312 Loss 2.407 Prec@(1,3) (81.9%, 98.8%), ce_loss 0.763, lat_loss 22.035
09/21 08:52:31 PM | _theta_step_train: [ 79/180] Final Prec@1 81.9000% Time 123.56
09/21 08:52:36 PM | Valid: [ 79/180] Step 050/312 Loss 2.232 Prec@(1,3) (82.4%, 99.1%), ce_loss 0.763, lat_loss 22.035
09/21 08:52:41 PM | Valid: [ 79/180] Step 100/312 Loss 2.424 Prec@(1,3) (81.9%, 99.0%), ce_loss 0.763, lat_loss 22.035
09/21 08:52:46 PM | Valid: [ 79/180] Step 150/312 Loss 2.466 Prec@(1,3) (81.7%, 99.0%), ce_loss 0.762, lat_loss 22.035
09/21 08:52:51 PM | Valid: [ 79/180] Step 200/312 Loss 2.435 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.762, lat_loss 22.035
09/21 08:52:55 PM | Valid: [ 79/180] Step 250/312 Loss 2.406 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.762, lat_loss 22.035
09/21 08:53:00 PM | Valid: [ 79/180] Step 300/312 Loss 2.357 Prec@(1,3) (82.5%, 99.0%), ce_loss 0.762, lat_loss 22.035
09/21 08:53:01 PM | Valid: [ 79/180] Step 312/312 Loss 2.357 Prec@(1,3) (82.4%, 99.0%), ce_loss 0.762, lat_loss 22.035
09/21 08:53:01 PM | val: [ 79/180] Final Prec@1 82.4300% Time 30.02
09/21 08:53:01 PM | Best top1 acc by now. Save model
09/21 08:53:01 PM | Start to train weights for epoch 79
09/21 08:53:27 PM | Train: [ 80/180] Step 050/1249 Loss 1.898 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.762, lat_loss 22.035
09/21 08:53:49 PM | Train: [ 80/180] Step 100/1249 Loss 1.903 Prec@(1,3) (85.4%, 99.4%), ce_loss 0.762, lat_loss 22.035
09/21 08:54:11 PM | Train: [ 80/180] Step 150/1249 Loss 1.907 Prec@(1,3) (85.1%, 99.5%), ce_loss 0.762, lat_loss 22.035
09/21 08:54:32 PM | Train: [ 80/180] Step 200/1249 Loss 1.866 Prec@(1,3) (85.6%, 99.5%), ce_loss 0.762, lat_loss 22.035
09/21 08:54:53 PM | Train: [ 80/180] Step 250/1249 Loss 1.869 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.762, lat_loss 22.035
09/21 08:55:14 PM | Train: [ 80/180] Step 300/1249 Loss 1.839 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.761, lat_loss 22.035
09/21 08:55:35 PM | Train: [ 80/180] Step 350/1249 Loss 1.865 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.761, lat_loss 22.035
09/21 08:55:56 PM | Train: [ 80/180] Step 400/1249 Loss 1.876 Prec@(1,3) (85.4%, 99.4%), ce_loss 0.761, lat_loss 22.035
09/21 08:56:19 PM | Train: [ 80/180] Step 450/1249 Loss 1.881 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.761, lat_loss 22.034
09/21 08:56:41 PM | Train: [ 80/180] Step 500/1249 Loss 1.898 Prec@(1,3) (85.3%, 99.4%), ce_loss 0.761, lat_loss 22.034
09/21 08:57:03 PM | Train: [ 80/180] Step 550/1249 Loss 1.911 Prec@(1,3) (85.3%, 99.4%), ce_loss 0.761, lat_loss 22.034
09/21 08:57:25 PM | Train: [ 80/180] Step 600/1249 Loss 1.919 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.761, lat_loss 22.034
09/21 08:57:46 PM | Train: [ 80/180] Step 650/1249 Loss 1.911 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.761, lat_loss 22.034
09/21 08:58:08 PM | Train: [ 80/180] Step 700/1249 Loss 1.917 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.761, lat_loss 22.034
09/21 08:58:28 PM | Train: [ 80/180] Step 750/1249 Loss 1.910 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.760, lat_loss 22.034
09/21 08:58:50 PM | Train: [ 80/180] Step 800/1249 Loss 1.905 Prec@(1,3) (85.3%, 99.4%), ce_loss 0.760, lat_loss 22.034
09/21 08:59:11 PM | Train: [ 80/180] Step 850/1249 Loss 1.905 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.760, lat_loss 22.034
09/21 08:59:34 PM | Train: [ 80/180] Step 900/1249 Loss 1.920 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.760, lat_loss 22.034
09/21 08:59:57 PM | Train: [ 80/180] Step 950/1249 Loss 1.920 Prec@(1,3) (85.1%, 99.4%), ce_loss 0.760, lat_loss 22.034
09/21 09:00:17 PM | Train: [ 80/180] Step 1000/1249 Loss 1.924 Prec@(1,3) (85.1%, 99.4%), ce_loss 0.760, lat_loss 22.034
09/21 09:00:40 PM | Train: [ 80/180] Step 1050/1249 Loss 1.923 Prec@(1,3) (85.1%, 99.4%), ce_loss 0.760, lat_loss 22.034
09/21 09:01:04 PM | Train: [ 80/180] Step 1100/1249 Loss 1.926 Prec@(1,3) (85.1%, 99.4%), ce_loss 0.760, lat_loss 22.034
09/21 09:01:27 PM | Train: [ 80/180] Step 1150/1249 Loss 1.922 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.760, lat_loss 22.034
09/21 09:01:51 PM | Train: [ 80/180] Step 1200/1249 Loss 1.929 Prec@(1,3) (85.1%, 99.4%), ce_loss 0.759, lat_loss 22.034
09/21 09:02:15 PM | Train: [ 80/180] Step 1249/1249 Loss 1.930 Prec@(1,3) (85.1%, 99.4%), ce_loss 0.759, lat_loss 22.034
09/21 09:02:16 PM | _w_step_train: [ 80/180] Final Prec@1 85.1300% Time 554.21
09/21 09:02:16 PM | Start to train theta for epoch 79
09/21 09:02:35 PM | Train: [ 80/180] Step 050/312 Loss 2.302 Prec@(1,3) (82.0%, 99.0%), ce_loss 0.759, lat_loss 22.034
09/21 09:02:54 PM | Train: [ 80/180] Step 100/312 Loss 2.297 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.759, lat_loss 22.034
09/21 09:03:13 PM | Train: [ 80/180] Step 150/312 Loss 2.222 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.759, lat_loss 22.034
09/21 09:03:33 PM | Train: [ 80/180] Step 200/312 Loss 2.302 Prec@(1,3) (82.6%, 98.8%), ce_loss 0.759, lat_loss 22.034
09/21 09:03:53 PM | Train: [ 80/180] Step 250/312 Loss 2.300 Prec@(1,3) (82.5%, 98.9%), ce_loss 0.759, lat_loss 22.034
09/21 09:04:11 PM | Train: [ 80/180] Step 300/312 Loss 2.280 Prec@(1,3) (82.8%, 99.0%), ce_loss 0.759, lat_loss 22.034
09/21 09:04:16 PM | Train: [ 80/180] Step 312/312 Loss 2.292 Prec@(1,3) (82.7%, 99.0%), ce_loss 0.759, lat_loss 22.034
09/21 09:04:16 PM | _theta_step_train: [ 80/180] Final Prec@1 82.7300% Time 120.06
09/21 09:04:21 PM | Valid: [ 80/180] Step 050/312 Loss 2.392 Prec@(1,3) (81.3%, 98.0%), ce_loss 0.759, lat_loss 22.034
09/21 09:04:26 PM | Valid: [ 80/180] Step 100/312 Loss 2.483 Prec@(1,3) (81.2%, 98.3%), ce_loss 0.759, lat_loss 22.034
09/21 09:04:30 PM | Valid: [ 80/180] Step 150/312 Loss 2.440 Prec@(1,3) (81.7%, 98.4%), ce_loss 0.759, lat_loss 22.034
09/21 09:04:35 PM | Valid: [ 80/180] Step 200/312 Loss 2.372 Prec@(1,3) (82.5%, 98.6%), ce_loss 0.759, lat_loss 22.034
09/21 09:04:40 PM | Valid: [ 80/180] Step 250/312 Loss 2.360 Prec@(1,3) (82.4%, 98.6%), ce_loss 0.758, lat_loss 22.034
09/21 09:04:44 PM | Valid: [ 80/180] Step 300/312 Loss 2.341 Prec@(1,3) (82.4%, 98.7%), ce_loss 0.758, lat_loss 22.033
09/21 09:04:46 PM | Valid: [ 80/180] Step 312/312 Loss 2.346 Prec@(1,3) (82.3%, 98.7%), ce_loss 0.758, lat_loss 22.033
09/21 09:04:46 PM | val: [ 80/180] Final Prec@1 82.3200% Time 29.93
09/21 09:04:46 PM | Start to train weights for epoch 80
09/21 09:05:10 PM | Train: [ 81/180] Step 050/1249 Loss 1.814 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.758, lat_loss 22.033
09/21 09:05:30 PM | Train: [ 81/180] Step 100/1249 Loss 1.784 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.758, lat_loss 22.033
09/21 09:05:51 PM | Train: [ 81/180] Step 150/1249 Loss 1.808 Prec@(1,3) (86.7%, 99.3%), ce_loss 0.758, lat_loss 22.033
09/21 09:06:14 PM | Train: [ 81/180] Step 200/1249 Loss 1.804 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.758, lat_loss 22.033
09/21 09:06:39 PM | Train: [ 81/180] Step 250/1249 Loss 1.801 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.758, lat_loss 22.033
09/21 09:07:04 PM | Train: [ 81/180] Step 300/1249 Loss 1.816 Prec@(1,3) (86.4%, 99.3%), ce_loss 0.758, lat_loss 22.033
09/21 09:07:29 PM | Train: [ 81/180] Step 350/1249 Loss 1.827 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.758, lat_loss 22.033
09/21 09:07:55 PM | Train: [ 81/180] Step 400/1249 Loss 1.813 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.757, lat_loss 22.033
09/21 09:08:19 PM | Train: [ 81/180] Step 450/1249 Loss 1.821 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.757, lat_loss 22.033
09/21 09:08:44 PM | Train: [ 81/180] Step 500/1249 Loss 1.807 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.757, lat_loss 22.033
09/21 09:09:09 PM | Train: [ 81/180] Step 550/1249 Loss 1.797 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.757, lat_loss 22.033
09/21 09:09:34 PM | Train: [ 81/180] Step 600/1249 Loss 1.816 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.757, lat_loss 22.033
09/21 09:09:59 PM | Train: [ 81/180] Step 650/1249 Loss 1.818 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.757, lat_loss 22.033
09/21 09:10:21 PM | Train: [ 81/180] Step 700/1249 Loss 1.821 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.757, lat_loss 22.033
09/21 09:10:45 PM | Train: [ 81/180] Step 750/1249 Loss 1.821 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.757, lat_loss 22.033
09/21 09:11:11 PM | Train: [ 81/180] Step 800/1249 Loss 1.827 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.756, lat_loss 22.033
09/21 09:11:36 PM | Train: [ 81/180] Step 850/1249 Loss 1.825 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.756, lat_loss 22.033
09/21 09:12:02 PM | Train: [ 81/180] Step 900/1249 Loss 1.834 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.756, lat_loss 22.033
09/21 09:12:27 PM | Train: [ 81/180] Step 950/1249 Loss 1.835 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.756, lat_loss 22.033
09/21 09:12:53 PM | Train: [ 81/180] Step 1000/1249 Loss 1.846 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.756, lat_loss 22.033
09/21 09:13:18 PM | Train: [ 81/180] Step 1050/1249 Loss 1.845 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.756, lat_loss 22.033
09/21 09:13:44 PM | Train: [ 81/180] Step 1100/1249 Loss 1.845 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.756, lat_loss 22.033
09/21 09:14:05 PM | Train: [ 81/180] Step 1150/1249 Loss 1.849 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.756, lat_loss 22.033
09/21 09:14:26 PM | Train: [ 81/180] Step 1200/1249 Loss 1.860 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.756, lat_loss 22.033
09/21 09:14:49 PM | Train: [ 81/180] Step 1249/1249 Loss 1.858 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.755, lat_loss 22.033
09/21 09:14:49 PM | _w_step_train: [ 81/180] Final Prec@1 85.6100% Time 603.73
09/21 09:14:49 PM | Start to train theta for epoch 80
09/21 09:15:10 PM | Train: [ 81/180] Step 050/312 Loss 2.418 Prec@(1,3) (81.4%, 98.5%), ce_loss 0.755, lat_loss 22.033
09/21 09:15:30 PM | Train: [ 81/180] Step 100/312 Loss 2.408 Prec@(1,3) (81.5%, 98.5%), ce_loss 0.755, lat_loss 22.033
09/21 09:15:48 PM | Train: [ 81/180] Step 150/312 Loss 2.424 Prec@(1,3) (81.5%, 98.6%), ce_loss 0.755, lat_loss 22.033
09/21 09:16:08 PM | Train: [ 81/180] Step 200/312 Loss 2.361 Prec@(1,3) (82.2%, 98.6%), ce_loss 0.755, lat_loss 22.033
09/21 09:16:27 PM | Train: [ 81/180] Step 250/312 Loss 2.371 Prec@(1,3) (82.3%, 98.7%), ce_loss 0.755, lat_loss 22.032
09/21 09:16:47 PM | Train: [ 81/180] Step 300/312 Loss 2.456 Prec@(1,3) (81.9%, 98.7%), ce_loss 0.755, lat_loss 22.032
09/21 09:16:52 PM | Train: [ 81/180] Step 312/312 Loss 2.452 Prec@(1,3) (82.0%, 98.7%), ce_loss 0.755, lat_loss 22.032
09/21 09:16:52 PM | _theta_step_train: [ 81/180] Final Prec@1 81.9600% Time 123.00
09/21 09:16:58 PM | Valid: [ 81/180] Step 050/312 Loss 2.047 Prec@(1,3) (84.5%, 99.4%), ce_loss 0.755, lat_loss 22.032
09/21 09:17:02 PM | Valid: [ 81/180] Step 100/312 Loss 2.368 Prec@(1,3) (82.3%, 98.8%), ce_loss 0.755, lat_loss 22.032
09/21 09:17:07 PM | Valid: [ 81/180] Step 150/312 Loss 2.355 Prec@(1,3) (82.5%, 98.9%), ce_loss 0.755, lat_loss 22.032
09/21 09:17:12 PM | Valid: [ 81/180] Step 200/312 Loss 2.339 Prec@(1,3) (82.5%, 98.9%), ce_loss 0.755, lat_loss 22.032
09/21 09:17:16 PM | Valid: [ 81/180] Step 250/312 Loss 2.383 Prec@(1,3) (82.3%, 98.8%), ce_loss 0.755, lat_loss 22.032
09/21 09:17:21 PM | Valid: [ 81/180] Step 300/312 Loss 2.377 Prec@(1,3) (82.2%, 98.9%), ce_loss 0.755, lat_loss 22.032
09/21 09:17:22 PM | Valid: [ 81/180] Step 312/312 Loss 2.377 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.755, lat_loss 22.032
09/21 09:17:22 PM | val: [ 81/180] Final Prec@1 82.1900% Time 29.62
09/21 09:17:22 PM | Start to train weights for epoch 81
09/21 09:17:48 PM | Train: [ 82/180] Step 050/1249 Loss 1.763 Prec@(1,3) (85.9%, 99.5%), ce_loss 0.754, lat_loss 22.032
09/21 09:18:13 PM | Train: [ 82/180] Step 100/1249 Loss 1.787 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.754, lat_loss 22.032
09/21 09:18:37 PM | Train: [ 82/180] Step 150/1249 Loss 1.794 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.754, lat_loss 22.032
09/21 09:19:02 PM | Train: [ 82/180] Step 200/1249 Loss 1.792 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.754, lat_loss 22.032
09/21 09:19:27 PM | Train: [ 82/180] Step 250/1249 Loss 1.806 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.754, lat_loss 22.032
09/21 09:19:50 PM | Train: [ 82/180] Step 300/1249 Loss 1.791 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.754, lat_loss 22.032
09/21 09:20:15 PM | Train: [ 82/180] Step 350/1249 Loss 1.795 Prec@(1,3) (86.0%, 99.5%), ce_loss 0.754, lat_loss 22.032
09/21 09:20:39 PM | Train: [ 82/180] Step 400/1249 Loss 1.834 Prec@(1,3) (85.7%, 99.5%), ce_loss 0.754, lat_loss 22.032
09/21 09:21:04 PM | Train: [ 82/180] Step 450/1249 Loss 1.841 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.754, lat_loss 22.032
09/21 09:21:28 PM | Train: [ 82/180] Step 500/1249 Loss 1.850 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.753, lat_loss 22.032
09/21 09:21:53 PM | Train: [ 82/180] Step 550/1249 Loss 1.845 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.753, lat_loss 22.032
09/21 09:22:18 PM | Train: [ 82/180] Step 600/1249 Loss 1.882 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.753, lat_loss 22.032
09/21 09:22:42 PM | Train: [ 82/180] Step 650/1249 Loss 1.871 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.753, lat_loss 22.032
09/21 09:23:05 PM | Train: [ 82/180] Step 700/1249 Loss 1.863 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.753, lat_loss 22.032
09/21 09:23:29 PM | Train: [ 82/180] Step 750/1249 Loss 1.864 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.753, lat_loss 22.032
09/21 09:23:54 PM | Train: [ 82/180] Step 800/1249 Loss 1.850 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.753, lat_loss 22.032
09/21 09:24:19 PM | Train: [ 82/180] Step 850/1249 Loss 1.844 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.753, lat_loss 22.032
09/21 09:24:46 PM | Train: [ 82/180] Step 900/1249 Loss 1.832 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.753, lat_loss 22.032
09/21 09:25:12 PM | Train: [ 82/180] Step 950/1249 Loss 1.834 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.752, lat_loss 22.032
09/21 09:25:38 PM | Train: [ 82/180] Step 1000/1249 Loss 1.843 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.752, lat_loss 22.032
09/21 09:26:05 PM | Train: [ 82/180] Step 1050/1249 Loss 1.846 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.752, lat_loss 22.032
09/21 09:26:31 PM | Train: [ 82/180] Step 1100/1249 Loss 1.846 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.752, lat_loss 22.032
09/21 09:26:57 PM | Train: [ 82/180] Step 1150/1249 Loss 1.837 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.752, lat_loss 22.032
09/21 09:27:23 PM | Train: [ 82/180] Step 1200/1249 Loss 1.833 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.752, lat_loss 22.031
09/21 09:27:48 PM | Train: [ 82/180] Step 1249/1249 Loss 1.842 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.752, lat_loss 22.031
09/21 09:27:48 PM | _w_step_train: [ 82/180] Final Prec@1 85.7975% Time 625.84
09/21 09:27:48 PM | Start to train theta for epoch 81
09/21 09:28:09 PM | Train: [ 82/180] Step 050/312 Loss 2.468 Prec@(1,3) (82.2%, 98.7%), ce_loss 0.752, lat_loss 22.031
09/21 09:28:30 PM | Train: [ 82/180] Step 100/312 Loss 2.414 Prec@(1,3) (82.0%, 98.7%), ce_loss 0.752, lat_loss 22.031
09/21 09:28:50 PM | Train: [ 82/180] Step 150/312 Loss 2.346 Prec@(1,3) (82.3%, 98.9%), ce_loss 0.752, lat_loss 22.031
09/21 09:29:11 PM | Train: [ 82/180] Step 200/312 Loss 2.314 Prec@(1,3) (82.5%, 98.9%), ce_loss 0.751, lat_loss 22.031
09/21 09:29:31 PM | Train: [ 82/180] Step 250/312 Loss 2.302 Prec@(1,3) (82.5%, 99.0%), ce_loss 0.751, lat_loss 22.031
09/21 09:29:52 PM | Train: [ 82/180] Step 300/312 Loss 2.303 Prec@(1,3) (82.5%, 99.0%), ce_loss 0.751, lat_loss 22.031
09/21 09:29:57 PM | Train: [ 82/180] Step 312/312 Loss 2.364 Prec@(1,3) (82.3%, 98.8%), ce_loss 0.751, lat_loss 22.031
09/21 09:29:57 PM | _theta_step_train: [ 82/180] Final Prec@1 82.2700% Time 128.97
09/21 09:30:02 PM | Valid: [ 82/180] Step 050/312 Loss 2.361 Prec@(1,3) (81.4%, 99.1%), ce_loss 0.751, lat_loss 22.031
09/21 09:30:07 PM | Valid: [ 82/180] Step 100/312 Loss 2.414 Prec@(1,3) (81.2%, 99.0%), ce_loss 0.751, lat_loss 22.031
09/21 09:30:11 PM | Valid: [ 82/180] Step 150/312 Loss 2.395 Prec@(1,3) (81.8%, 99.1%), ce_loss 0.751, lat_loss 22.031
09/21 09:30:16 PM | Valid: [ 82/180] Step 200/312 Loss 2.418 Prec@(1,3) (81.8%, 99.0%), ce_loss 0.751, lat_loss 22.031
09/21 09:30:21 PM | Valid: [ 82/180] Step 250/312 Loss 2.398 Prec@(1,3) (81.9%, 99.0%), ce_loss 0.751, lat_loss 22.031
09/21 09:30:25 PM | Valid: [ 82/180] Step 300/312 Loss 2.389 Prec@(1,3) (82.1%, 99.1%), ce_loss 0.751, lat_loss 22.031
09/21 09:30:26 PM | Valid: [ 82/180] Step 312/312 Loss 2.407 Prec@(1,3) (81.8%, 99.1%), ce_loss 0.751, lat_loss 22.031
09/21 09:30:26 PM | val: [ 82/180] Final Prec@1 81.8500% Time 29.51
09/21 09:30:26 PM | Start to train weights for epoch 82
09/21 09:30:52 PM | Train: [ 83/180] Step 050/1249 Loss 1.753 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.751, lat_loss 22.031
09/21 09:31:17 PM | Train: [ 83/180] Step 100/1249 Loss 1.785 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.751, lat_loss 22.031
09/21 09:31:40 PM | Train: [ 83/180] Step 150/1249 Loss 1.801 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.751, lat_loss 22.031
09/21 09:32:04 PM | Train: [ 83/180] Step 200/1249 Loss 1.800 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.750, lat_loss 22.031
09/21 09:32:30 PM | Train: [ 83/180] Step 250/1249 Loss 1.787 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.750, lat_loss 22.031
09/21 09:32:54 PM | Train: [ 83/180] Step 300/1249 Loss 1.807 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.750, lat_loss 22.031
09/21 09:33:19 PM | Train: [ 83/180] Step 350/1249 Loss 1.799 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.750, lat_loss 22.031
09/21 09:33:44 PM | Train: [ 83/180] Step 400/1249 Loss 1.792 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.750, lat_loss 22.031
09/21 09:34:08 PM | Train: [ 83/180] Step 450/1249 Loss 1.789 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.750, lat_loss 22.031
09/21 09:34:33 PM | Train: [ 83/180] Step 500/1249 Loss 1.804 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.750, lat_loss 22.031
09/21 09:34:57 PM | Train: [ 83/180] Step 550/1249 Loss 1.806 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.750, lat_loss 22.031
09/21 09:35:20 PM | Train: [ 83/180] Step 600/1249 Loss 1.811 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.749, lat_loss 22.031
09/21 09:35:43 PM | Train: [ 83/180] Step 650/1249 Loss 1.812 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.749, lat_loss 22.031
09/21 09:36:07 PM | Train: [ 83/180] Step 700/1249 Loss 1.817 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.749, lat_loss 22.031
09/21 09:36:32 PM | Train: [ 83/180] Step 750/1249 Loss 1.810 Prec@(1,3) (85.9%, 99.5%), ce_loss 0.749, lat_loss 22.031
09/21 09:36:59 PM | Train: [ 83/180] Step 800/1249 Loss 1.824 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.749, lat_loss 22.031
09/21 09:37:26 PM | Train: [ 83/180] Step 850/1249 Loss 1.826 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.749, lat_loss 22.031
09/21 09:37:49 PM | Train: [ 83/180] Step 900/1249 Loss 1.830 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.749, lat_loss 22.031
09/21 09:38:12 PM | Train: [ 83/180] Step 950/1249 Loss 1.839 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.749, lat_loss 22.031
09/21 09:38:31 PM | Train: [ 83/180] Step 1000/1249 Loss 1.837 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.749, lat_loss 22.031
09/21 09:38:51 PM | Train: [ 83/180] Step 1050/1249 Loss 1.839 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.749, lat_loss 22.031
09/21 09:39:17 PM | Train: [ 83/180] Step 1100/1249 Loss 1.848 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.748, lat_loss 22.030
09/21 09:39:42 PM | Train: [ 83/180] Step 1150/1249 Loss 1.847 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.748, lat_loss 22.030
09/21 09:40:06 PM | Train: [ 83/180] Step 1200/1249 Loss 1.839 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.748, lat_loss 22.030
09/21 09:40:31 PM | Train: [ 83/180] Step 1249/1249 Loss 1.842 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.748, lat_loss 22.030
09/21 09:40:31 PM | _w_step_train: [ 83/180] Final Prec@1 85.6750% Time 604.66
09/21 09:40:31 PM | Start to train theta for epoch 82
09/21 09:40:53 PM | Train: [ 83/180] Step 050/312 Loss 2.257 Prec@(1,3) (82.8%, 98.9%), ce_loss 0.748, lat_loss 22.030
09/21 09:41:13 PM | Train: [ 83/180] Step 100/312 Loss 2.348 Prec@(1,3) (82.4%, 98.9%), ce_loss 0.748, lat_loss 22.030
09/21 09:41:34 PM | Train: [ 83/180] Step 150/312 Loss 2.206 Prec@(1,3) (83.3%, 99.0%), ce_loss 0.748, lat_loss 22.030
09/21 09:41:55 PM | Train: [ 83/180] Step 200/312 Loss 2.207 Prec@(1,3) (83.3%, 99.0%), ce_loss 0.748, lat_loss 22.030
09/21 09:42:15 PM | Train: [ 83/180] Step 250/312 Loss 2.224 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.748, lat_loss 22.030
09/21 09:42:36 PM | Train: [ 83/180] Step 300/312 Loss 2.208 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.748, lat_loss 22.030
09/21 09:42:41 PM | Train: [ 83/180] Step 312/312 Loss 2.211 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.748, lat_loss 22.030
09/21 09:42:41 PM | _theta_step_train: [ 83/180] Final Prec@1 83.2100% Time 129.75
09/21 09:42:46 PM | Valid: [ 83/180] Step 050/312 Loss 1.996 Prec@(1,3) (85.2%, 99.3%), ce_loss 0.747, lat_loss 22.030
09/21 09:42:51 PM | Valid: [ 83/180] Step 100/312 Loss 2.182 Prec@(1,3) (83.7%, 99.3%), ce_loss 0.747, lat_loss 22.030
09/21 09:42:55 PM | Valid: [ 83/180] Step 150/312 Loss 2.240 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.747, lat_loss 22.030
09/21 09:42:59 PM | Valid: [ 83/180] Step 200/312 Loss 2.201 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.747, lat_loss 22.030
09/21 09:43:04 PM | Valid: [ 83/180] Step 250/312 Loss 2.220 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.747, lat_loss 22.030
09/21 09:43:08 PM | Valid: [ 83/180] Step 300/312 Loss 2.230 Prec@(1,3) (83.3%, 99.0%), ce_loss 0.747, lat_loss 22.030
09/21 09:43:09 PM | Valid: [ 83/180] Step 312/312 Loss 2.255 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.747, lat_loss 22.030
09/21 09:43:09 PM | val: [ 83/180] Final Prec@1 83.0700% Time 28.68
09/21 09:43:10 PM | Best top1 acc by now. Save model
09/21 09:43:10 PM | Start to train weights for epoch 83
09/21 09:43:34 PM | Train: [ 84/180] Step 050/1249 Loss 1.957 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.747, lat_loss 22.030
09/21 09:43:57 PM | Train: [ 84/180] Step 100/1249 Loss 2.075 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.747, lat_loss 22.030
09/21 09:44:20 PM | Train: [ 84/180] Step 150/1249 Loss 1.947 Prec@(1,3) (85.1%, 99.2%), ce_loss 0.747, lat_loss 22.030
09/21 09:44:45 PM | Train: [ 84/180] Step 200/1249 Loss 1.945 Prec@(1,3) (85.1%, 99.2%), ce_loss 0.747, lat_loss 22.030
09/21 09:45:10 PM | Train: [ 84/180] Step 250/1249 Loss 1.868 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.747, lat_loss 22.030
09/21 09:45:34 PM | Train: [ 84/180] Step 300/1249 Loss 1.847 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.746, lat_loss 22.030
09/21 09:45:59 PM | Train: [ 84/180] Step 350/1249 Loss 1.862 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.746, lat_loss 22.030
09/21 09:46:23 PM | Train: [ 84/180] Step 400/1249 Loss 1.862 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.746, lat_loss 22.030
09/21 09:46:48 PM | Train: [ 84/180] Step 450/1249 Loss 1.878 Prec@(1,3) (85.3%, 99.4%), ce_loss 0.746, lat_loss 22.030
09/21 09:47:12 PM | Train: [ 84/180] Step 500/1249 Loss 1.879 Prec@(1,3) (85.4%, 99.4%), ce_loss 0.746, lat_loss 22.030
09/21 09:47:36 PM | Train: [ 84/180] Step 550/1249 Loss 1.883 Prec@(1,3) (85.4%, 99.4%), ce_loss 0.746, lat_loss 22.030
09/21 09:47:59 PM | Train: [ 84/180] Step 600/1249 Loss 1.869 Prec@(1,3) (85.4%, 99.4%), ce_loss 0.746, lat_loss 22.030
09/21 09:48:24 PM | Train: [ 84/180] Step 650/1249 Loss 1.874 Prec@(1,3) (85.4%, 99.4%), ce_loss 0.746, lat_loss 22.030
09/21 09:48:48 PM | Train: [ 84/180] Step 700/1249 Loss 1.859 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.746, lat_loss 22.030
09/21 09:49:12 PM | Train: [ 84/180] Step 750/1249 Loss 1.865 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.745, lat_loss 22.030
09/21 09:49:37 PM | Train: [ 84/180] Step 800/1249 Loss 1.866 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.745, lat_loss 22.030
09/21 09:50:00 PM | Train: [ 84/180] Step 850/1249 Loss 1.865 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.745, lat_loss 22.030
09/21 09:50:24 PM | Train: [ 84/180] Step 900/1249 Loss 1.848 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.745, lat_loss 22.030
09/21 09:50:48 PM | Train: [ 84/180] Step 950/1249 Loss 1.845 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.745, lat_loss 22.029
09/21 09:51:12 PM | Train: [ 84/180] Step 1000/1249 Loss 1.835 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.745, lat_loss 22.029
09/21 09:51:36 PM | Train: [ 84/180] Step 1050/1249 Loss 1.835 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.745, lat_loss 22.029
09/21 09:52:00 PM | Train: [ 84/180] Step 1100/1249 Loss 1.834 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.745, lat_loss 22.029
09/21 09:52:23 PM | Train: [ 84/180] Step 1150/1249 Loss 1.843 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.745, lat_loss 22.029
09/21 09:52:46 PM | Train: [ 84/180] Step 1200/1249 Loss 1.840 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.744, lat_loss 22.029
09/21 09:53:09 PM | Train: [ 84/180] Step 1249/1249 Loss 1.845 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.744, lat_loss 22.029
09/21 09:53:09 PM | _w_step_train: [ 84/180] Final Prec@1 85.7425% Time 599.01
09/21 09:53:09 PM | Start to train theta for epoch 83
09/21 09:53:30 PM | Train: [ 84/180] Step 050/312 Loss 2.288 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.744, lat_loss 22.029
09/21 09:53:50 PM | Train: [ 84/180] Step 100/312 Loss 2.370 Prec@(1,3) (83.0%, 98.9%), ce_loss 0.744, lat_loss 22.029
09/21 09:54:11 PM | Train: [ 84/180] Step 150/312 Loss 2.342 Prec@(1,3) (82.9%, 98.9%), ce_loss 0.744, lat_loss 22.029
09/21 09:54:30 PM | Train: [ 84/180] Step 200/312 Loss 2.334 Prec@(1,3) (82.8%, 98.9%), ce_loss 0.744, lat_loss 22.029
09/21 09:54:43 PM | Train: [ 84/180] Step 250/312 Loss 2.328 Prec@(1,3) (82.9%, 98.9%), ce_loss 0.744, lat_loss 22.029
09/21 09:54:55 PM | Train: [ 84/180] Step 300/312 Loss 2.305 Prec@(1,3) (83.1%, 98.9%), ce_loss 0.744, lat_loss 22.029
09/21 09:54:58 PM | Train: [ 84/180] Step 312/312 Loss 2.339 Prec@(1,3) (82.9%, 98.9%), ce_loss 0.744, lat_loss 22.029
09/21 09:54:58 PM | _theta_step_train: [ 84/180] Final Prec@1 82.8700% Time 108.96
09/21 09:55:03 PM | Valid: [ 84/180] Step 050/312 Loss 2.247 Prec@(1,3) (82.2%, 99.2%), ce_loss 0.744, lat_loss 22.029
09/21 09:55:08 PM | Valid: [ 84/180] Step 100/312 Loss 2.428 Prec@(1,3) (81.2%, 98.7%), ce_loss 0.744, lat_loss 22.029
09/21 09:55:13 PM | Valid: [ 84/180] Step 150/312 Loss 2.404 Prec@(1,3) (81.8%, 98.8%), ce_loss 0.744, lat_loss 22.029
09/21 09:55:17 PM | Valid: [ 84/180] Step 200/312 Loss 2.369 Prec@(1,3) (82.3%, 98.9%), ce_loss 0.744, lat_loss 22.029
09/21 09:55:22 PM | Valid: [ 84/180] Step 250/312 Loss 2.308 Prec@(1,3) (82.7%, 99.0%), ce_loss 0.744, lat_loss 22.029
09/21 09:55:27 PM | Valid: [ 84/180] Step 300/312 Loss 2.262 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.743, lat_loss 22.029
09/21 09:55:28 PM | Valid: [ 84/180] Step 312/312 Loss 2.255 Prec@(1,3) (83.1%, 99.1%), ce_loss 0.743, lat_loss 22.029
09/21 09:55:28 PM | val: [ 84/180] Final Prec@1 83.0600% Time 29.87
09/21 09:55:28 PM | Start to train weights for epoch 84
09/21 09:55:54 PM | Train: [ 85/180] Step 050/1249 Loss 1.920 Prec@(1,3) (85.7%, 99.0%), ce_loss 0.743, lat_loss 22.029
09/21 09:56:17 PM | Train: [ 85/180] Step 100/1249 Loss 1.766 Prec@(1,3) (87.0%, 99.2%), ce_loss 0.743, lat_loss 22.029
09/21 09:56:39 PM | Train: [ 85/180] Step 150/1249 Loss 1.755 Prec@(1,3) (87.0%, 99.2%), ce_loss 0.743, lat_loss 22.029
09/21 09:57:00 PM | Train: [ 85/180] Step 200/1249 Loss 1.724 Prec@(1,3) (87.1%, 99.3%), ce_loss 0.743, lat_loss 22.029
09/21 09:57:22 PM | Train: [ 85/180] Step 250/1249 Loss 1.747 Prec@(1,3) (86.8%, 99.3%), ce_loss 0.743, lat_loss 22.029
09/21 09:57:44 PM | Train: [ 85/180] Step 300/1249 Loss 1.766 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.743, lat_loss 22.029
09/21 09:58:07 PM | Train: [ 85/180] Step 350/1249 Loss 1.750 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.743, lat_loss 22.029
09/21 09:58:30 PM | Train: [ 85/180] Step 400/1249 Loss 1.733 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.743, lat_loss 22.029
09/21 09:58:52 PM | Train: [ 85/180] Step 450/1249 Loss 1.736 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.742, lat_loss 22.029
09/21 09:59:15 PM | Train: [ 85/180] Step 500/1249 Loss 1.760 Prec@(1,3) (86.7%, 99.4%), ce_loss 0.742, lat_loss 22.029
09/21 09:59:37 PM | Train: [ 85/180] Step 550/1249 Loss 1.742 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.742, lat_loss 22.029
09/21 10:00:00 PM | Train: [ 85/180] Step 600/1249 Loss 1.742 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.742, lat_loss 22.029
09/21 10:00:22 PM | Train: [ 85/180] Step 650/1249 Loss 1.750 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.742, lat_loss 22.028
09/21 10:00:44 PM | Train: [ 85/180] Step 700/1249 Loss 1.753 Prec@(1,3) (86.7%, 99.4%), ce_loss 0.742, lat_loss 22.028
09/21 10:01:06 PM | Train: [ 85/180] Step 750/1249 Loss 1.752 Prec@(1,3) (86.7%, 99.4%), ce_loss 0.742, lat_loss 22.028
09/21 10:01:29 PM | Train: [ 85/180] Step 800/1249 Loss 1.752 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.742, lat_loss 22.028
09/21 10:01:53 PM | Train: [ 85/180] Step 850/1249 Loss 1.768 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.742, lat_loss 22.028
09/21 10:02:15 PM | Train: [ 85/180] Step 900/1249 Loss 1.773 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.741, lat_loss 22.028
09/21 10:02:37 PM | Train: [ 85/180] Step 950/1249 Loss 1.806 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.741, lat_loss 22.028
09/21 10:02:59 PM | Train: [ 85/180] Step 1000/1249 Loss 1.825 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.741, lat_loss 22.028
09/21 10:03:22 PM | Train: [ 85/180] Step 1050/1249 Loss 1.816 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.741, lat_loss 22.028
09/21 10:03:44 PM | Train: [ 85/180] Step 1100/1249 Loss 1.819 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.741, lat_loss 22.028
09/21 10:04:06 PM | Train: [ 85/180] Step 1150/1249 Loss 1.811 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.741, lat_loss 22.028
09/21 10:04:28 PM | Train: [ 85/180] Step 1200/1249 Loss 1.803 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.741, lat_loss 22.028
09/21 10:04:53 PM | Train: [ 85/180] Step 1249/1249 Loss 1.801 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.741, lat_loss 22.028
09/21 10:04:53 PM | _w_step_train: [ 85/180] Final Prec@1 86.3675% Time 564.97
09/21 10:04:53 PM | Start to train theta for epoch 84
09/21 10:05:11 PM | Train: [ 85/180] Step 050/312 Loss 2.483 Prec@(1,3) (81.9%, 98.7%), ce_loss 0.741, lat_loss 22.028
09/21 10:05:31 PM | Train: [ 85/180] Step 100/312 Loss 2.445 Prec@(1,3) (82.3%, 98.9%), ce_loss 0.741, lat_loss 22.028
09/21 10:05:52 PM | Train: [ 85/180] Step 150/312 Loss 2.378 Prec@(1,3) (82.5%, 98.9%), ce_loss 0.741, lat_loss 22.028
09/21 10:06:13 PM | Train: [ 85/180] Step 200/312 Loss 2.388 Prec@(1,3) (82.8%, 98.8%), ce_loss 0.740, lat_loss 22.028
09/21 10:06:33 PM | Train: [ 85/180] Step 250/312 Loss 2.392 Prec@(1,3) (82.8%, 98.7%), ce_loss 0.740, lat_loss 22.028
09/21 10:06:54 PM | Train: [ 85/180] Step 300/312 Loss 2.385 Prec@(1,3) (82.8%, 98.7%), ce_loss 0.740, lat_loss 22.028
09/21 10:06:59 PM | Train: [ 85/180] Step 312/312 Loss 2.386 Prec@(1,3) (82.7%, 98.7%), ce_loss 0.740, lat_loss 22.028
09/21 10:06:59 PM | _theta_step_train: [ 85/180] Final Prec@1 82.7400% Time 126.15
09/21 10:07:04 PM | Valid: [ 85/180] Step 050/312 Loss 2.036 Prec@(1,3) (84.7%, 99.5%), ce_loss 0.740, lat_loss 22.028
09/21 10:07:09 PM | Valid: [ 85/180] Step 100/312 Loss 2.305 Prec@(1,3) (82.5%, 99.4%), ce_loss 0.740, lat_loss 22.028
09/21 10:07:14 PM | Valid: [ 85/180] Step 150/312 Loss 2.292 Prec@(1,3) (82.5%, 99.1%), ce_loss 0.740, lat_loss 22.028
09/21 10:07:18 PM | Valid: [ 85/180] Step 200/312 Loss 2.307 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.740, lat_loss 22.028
09/21 10:07:23 PM | Valid: [ 85/180] Step 250/312 Loss 2.275 Prec@(1,3) (82.8%, 99.2%), ce_loss 0.740, lat_loss 22.028
09/21 10:07:28 PM | Valid: [ 85/180] Step 300/312 Loss 2.265 Prec@(1,3) (82.8%, 99.2%), ce_loss 0.740, lat_loss 22.028
09/21 10:07:29 PM | Valid: [ 85/180] Step 312/312 Loss 2.274 Prec@(1,3) (82.7%, 99.2%), ce_loss 0.740, lat_loss 22.028
09/21 10:07:29 PM | val: [ 85/180] Final Prec@1 82.6700% Time 30.07
09/21 10:07:29 PM | Start to train weights for epoch 85
09/21 10:07:55 PM | Train: [ 86/180] Step 050/1249 Loss 1.662 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.740, lat_loss 22.028
09/21 10:08:19 PM | Train: [ 86/180] Step 100/1249 Loss 1.706 Prec@(1,3) (86.8%, 99.3%), ce_loss 0.740, lat_loss 22.028
09/21 10:08:44 PM | Train: [ 86/180] Step 150/1249 Loss 1.780 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.740, lat_loss 22.028
09/21 10:09:06 PM | Train: [ 86/180] Step 200/1249 Loss 1.727 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.739, lat_loss 22.028
09/21 10:09:27 PM | Train: [ 86/180] Step 250/1249 Loss 1.734 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.739, lat_loss 22.028
09/21 10:09:49 PM | Train: [ 86/180] Step 300/1249 Loss 1.716 Prec@(1,3) (86.7%, 99.4%), ce_loss 0.739, lat_loss 22.028
09/21 10:10:10 PM | Train: [ 86/180] Step 350/1249 Loss 1.756 Prec@(1,3) (86.4%, 99.3%), ce_loss 0.739, lat_loss 22.028
09/21 10:10:32 PM | Train: [ 86/180] Step 400/1249 Loss 1.767 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.739, lat_loss 22.027
09/21 10:10:53 PM | Train: [ 86/180] Step 450/1249 Loss 1.802 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.739, lat_loss 22.027
09/21 10:11:15 PM | Train: [ 86/180] Step 500/1249 Loss 1.809 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.739, lat_loss 22.027
09/21 10:11:36 PM | Train: [ 86/180] Step 550/1249 Loss 1.847 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.739, lat_loss 22.027
09/21 10:12:00 PM | Train: [ 86/180] Step 600/1249 Loss 1.832 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.739, lat_loss 22.027
09/21 10:12:23 PM | Train: [ 86/180] Step 650/1249 Loss 1.844 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.739, lat_loss 22.027
09/21 10:12:47 PM | Train: [ 86/180] Step 700/1249 Loss 1.876 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.738, lat_loss 22.027
09/21 10:13:11 PM | Train: [ 86/180] Step 750/1249 Loss 1.873 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.738, lat_loss 22.027
09/21 10:13:35 PM | Train: [ 86/180] Step 800/1249 Loss 1.874 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.738, lat_loss 22.027
09/21 10:13:59 PM | Train: [ 86/180] Step 850/1249 Loss 1.869 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.738, lat_loss 22.027
09/21 10:14:23 PM | Train: [ 86/180] Step 900/1249 Loss 1.853 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.738, lat_loss 22.027
09/21 10:14:46 PM | Train: [ 86/180] Step 950/1249 Loss 1.844 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.738, lat_loss 22.027
09/21 10:15:10 PM | Train: [ 86/180] Step 1000/1249 Loss 1.852 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.738, lat_loss 22.027
09/21 10:15:33 PM | Train: [ 86/180] Step 1050/1249 Loss 1.848 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.738, lat_loss 22.027
09/21 10:15:56 PM | Train: [ 86/180] Step 1100/1249 Loss 1.848 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.738, lat_loss 22.027
09/21 10:16:20 PM | Train: [ 86/180] Step 1150/1249 Loss 1.846 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.737, lat_loss 22.027
09/21 10:16:43 PM | Train: [ 86/180] Step 1200/1249 Loss 1.833 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.737, lat_loss 22.027
09/21 10:17:08 PM | Train: [ 86/180] Step 1249/1249 Loss 1.829 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.737, lat_loss 22.027
09/21 10:17:08 PM | _w_step_train: [ 86/180] Final Prec@1 85.8550% Time 578.77
09/21 10:17:08 PM | Start to train theta for epoch 85
09/21 10:17:30 PM | Train: [ 86/180] Step 050/312 Loss 2.153 Prec@(1,3) (84.4%, 98.8%), ce_loss 0.737, lat_loss 22.027
09/21 10:17:50 PM | Train: [ 86/180] Step 100/312 Loss 2.229 Prec@(1,3) (83.6%, 98.8%), ce_loss 0.737, lat_loss 22.027
09/21 10:18:11 PM | Train: [ 86/180] Step 150/312 Loss 2.274 Prec@(1,3) (83.1%, 98.9%), ce_loss 0.737, lat_loss 22.027
09/21 10:18:31 PM | Train: [ 86/180] Step 200/312 Loss 2.298 Prec@(1,3) (82.9%, 98.9%), ce_loss 0.737, lat_loss 22.027
09/21 10:18:52 PM | Train: [ 86/180] Step 250/312 Loss 2.313 Prec@(1,3) (82.8%, 99.0%), ce_loss 0.737, lat_loss 22.027
09/21 10:19:12 PM | Train: [ 86/180] Step 300/312 Loss 2.305 Prec@(1,3) (82.9%, 98.9%), ce_loss 0.737, lat_loss 22.027
09/21 10:19:17 PM | Train: [ 86/180] Step 312/312 Loss 2.290 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.737, lat_loss 22.027
09/21 10:19:17 PM | _theta_step_train: [ 86/180] Final Prec@1 82.9700% Time 129.31
09/21 10:19:23 PM | Valid: [ 86/180] Step 050/312 Loss 2.192 Prec@(1,3) (82.8%, 99.1%), ce_loss 0.737, lat_loss 22.027
09/21 10:19:27 PM | Valid: [ 86/180] Step 100/312 Loss 2.221 Prec@(1,3) (83.2%, 99.0%), ce_loss 0.737, lat_loss 22.027
09/21 10:19:32 PM | Valid: [ 86/180] Step 150/312 Loss 2.273 Prec@(1,3) (83.0%, 98.8%), ce_loss 0.737, lat_loss 22.027
09/21 10:19:37 PM | Valid: [ 86/180] Step 200/312 Loss 2.233 Prec@(1,3) (83.6%, 98.8%), ce_loss 0.737, lat_loss 22.027
09/21 10:19:41 PM | Valid: [ 86/180] Step 250/312 Loss 2.200 Prec@(1,3) (83.6%, 98.9%), ce_loss 0.736, lat_loss 22.027
09/21 10:19:46 PM | Valid: [ 86/180] Step 300/312 Loss 2.198 Prec@(1,3) (83.7%, 98.9%), ce_loss 0.736, lat_loss 22.027
09/21 10:19:47 PM | Valid: [ 86/180] Step 312/312 Loss 2.198 Prec@(1,3) (83.6%, 98.9%), ce_loss 0.736, lat_loss 22.027
09/21 10:19:47 PM | val: [ 86/180] Final Prec@1 83.6400% Time 30.00
09/21 10:19:47 PM | Best top1 acc by now. Save model
09/21 10:19:48 PM | Start to train weights for epoch 86
09/21 10:20:13 PM | Train: [ 87/180] Step 050/1249 Loss 2.060 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.736, lat_loss 22.027
09/21 10:20:38 PM | Train: [ 87/180] Step 100/1249 Loss 1.875 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.736, lat_loss 22.027
09/21 10:21:02 PM | Train: [ 87/180] Step 150/1249 Loss 1.785 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.736, lat_loss 22.027
09/21 10:21:26 PM | Train: [ 87/180] Step 200/1249 Loss 1.758 Prec@(1,3) (86.4%, 99.5%), ce_loss 0.736, lat_loss 22.026
09/21 10:21:51 PM | Train: [ 87/180] Step 250/1249 Loss 1.727 Prec@(1,3) (86.6%, 99.6%), ce_loss 0.736, lat_loss 22.026
09/21 10:22:15 PM | Train: [ 87/180] Step 300/1249 Loss 1.729 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.736, lat_loss 22.026
09/21 10:22:40 PM | Train: [ 87/180] Step 350/1249 Loss 1.721 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.736, lat_loss 22.026
09/21 10:23:05 PM | Train: [ 87/180] Step 400/1249 Loss 1.711 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.735, lat_loss 22.026
09/21 10:23:29 PM | Train: [ 87/180] Step 450/1249 Loss 1.724 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.735, lat_loss 22.026
09/21 10:23:53 PM | Train: [ 87/180] Step 500/1249 Loss 1.735 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.735, lat_loss 22.026
09/21 10:24:17 PM | Train: [ 87/180] Step 550/1249 Loss 1.733 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.735, lat_loss 22.026
09/21 10:24:42 PM | Train: [ 87/180] Step 600/1249 Loss 1.754 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.735, lat_loss 22.026
09/21 10:25:06 PM | Train: [ 87/180] Step 650/1249 Loss 1.752 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.735, lat_loss 22.026
09/21 10:25:31 PM | Train: [ 87/180] Step 700/1249 Loss 1.755 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.735, lat_loss 22.026
09/21 10:25:55 PM | Train: [ 87/180] Step 750/1249 Loss 1.760 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.735, lat_loss 22.026
09/21 10:26:19 PM | Train: [ 87/180] Step 800/1249 Loss 1.756 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.735, lat_loss 22.026
09/21 10:26:43 PM | Train: [ 87/180] Step 850/1249 Loss 1.756 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.735, lat_loss 22.026
09/21 10:27:08 PM | Train: [ 87/180] Step 900/1249 Loss 1.762 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.734, lat_loss 22.026
09/21 10:27:32 PM | Train: [ 87/180] Step 950/1249 Loss 1.772 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.734, lat_loss 22.026
09/21 10:27:56 PM | Train: [ 87/180] Step 1000/1249 Loss 1.767 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.734, lat_loss 22.026
09/21 10:28:20 PM | Train: [ 87/180] Step 1050/1249 Loss 1.762 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.734, lat_loss 22.026
09/21 10:28:44 PM | Train: [ 87/180] Step 1100/1249 Loss 1.764 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.734, lat_loss 22.026
09/21 10:29:09 PM | Train: [ 87/180] Step 1150/1249 Loss 1.772 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.734, lat_loss 22.026
09/21 10:29:33 PM | Train: [ 87/180] Step 1200/1249 Loss 1.778 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.734, lat_loss 22.026
09/21 10:29:57 PM | Train: [ 87/180] Step 1249/1249 Loss 1.782 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.734, lat_loss 22.026
09/21 10:29:57 PM | _w_step_train: [ 87/180] Final Prec@1 86.3075% Time 609.87
09/21 10:29:57 PM | Start to train theta for epoch 86
09/21 10:30:18 PM | Train: [ 87/180] Step 050/312 Loss 2.426 Prec@(1,3) (82.3%, 98.8%), ce_loss 0.734, lat_loss 22.026
09/21 10:30:34 PM | Train: [ 87/180] Step 100/312 Loss 2.380 Prec@(1,3) (82.4%, 99.0%), ce_loss 0.734, lat_loss 22.026
09/21 10:30:51 PM | Train: [ 87/180] Step 150/312 Loss 2.380 Prec@(1,3) (82.4%, 99.0%), ce_loss 0.734, lat_loss 22.026
09/21 10:31:08 PM | Train: [ 87/180] Step 200/312 Loss 2.425 Prec@(1,3) (82.1%, 98.9%), ce_loss 0.733, lat_loss 22.026
09/21 10:31:26 PM | Train: [ 87/180] Step 250/312 Loss 2.410 Prec@(1,3) (82.0%, 98.8%), ce_loss 0.733, lat_loss 22.026
09/21 10:31:46 PM | Train: [ 87/180] Step 300/312 Loss 2.381 Prec@(1,3) (82.3%, 98.8%), ce_loss 0.733, lat_loss 22.026
09/21 10:31:51 PM | Train: [ 87/180] Step 312/312 Loss 2.380 Prec@(1,3) (82.3%, 98.8%), ce_loss 0.733, lat_loss 22.026
09/21 10:31:51 PM | _theta_step_train: [ 87/180] Final Prec@1 82.3200% Time 113.28
09/21 10:31:56 PM | Valid: [ 87/180] Step 050/312 Loss 2.477 Prec@(1,3) (81.7%, 98.0%), ce_loss 0.733, lat_loss 22.026
09/21 10:32:01 PM | Valid: [ 87/180] Step 100/312 Loss 2.433 Prec@(1,3) (81.9%, 98.4%), ce_loss 0.733, lat_loss 22.026
09/21 10:32:05 PM | Valid: [ 87/180] Step 150/312 Loss 2.539 Prec@(1,3) (81.3%, 98.2%), ce_loss 0.733, lat_loss 22.026
09/21 10:32:10 PM | Valid: [ 87/180] Step 200/312 Loss 2.487 Prec@(1,3) (81.9%, 98.3%), ce_loss 0.733, lat_loss 22.026
09/21 10:32:15 PM | Valid: [ 87/180] Step 250/312 Loss 2.421 Prec@(1,3) (82.1%, 98.5%), ce_loss 0.733, lat_loss 22.026
09/21 10:32:19 PM | Valid: [ 87/180] Step 300/312 Loss 2.394 Prec@(1,3) (82.0%, 98.6%), ce_loss 0.733, lat_loss 22.026
09/21 10:32:21 PM | Valid: [ 87/180] Step 312/312 Loss 2.379 Prec@(1,3) (82.1%, 98.7%), ce_loss 0.733, lat_loss 22.026
09/21 10:32:21 PM | val: [ 87/180] Final Prec@1 82.1100% Time 29.91
09/21 10:32:21 PM | Start to train weights for epoch 87
09/21 10:32:46 PM | Train: [ 88/180] Step 050/1249 Loss 1.943 Prec@(1,3) (86.3%, 99.1%), ce_loss 0.733, lat_loss 22.026
09/21 10:33:10 PM | Train: [ 88/180] Step 100/1249 Loss 1.803 Prec@(1,3) (86.8%, 99.3%), ce_loss 0.733, lat_loss 22.026
09/21 10:33:35 PM | Train: [ 88/180] Step 150/1249 Loss 1.733 Prec@(1,3) (86.9%, 99.3%), ce_loss 0.733, lat_loss 22.025
09/21 10:34:00 PM | Train: [ 88/180] Step 200/1249 Loss 1.706 Prec@(1,3) (87.0%, 99.3%), ce_loss 0.732, lat_loss 22.025
09/21 10:34:24 PM | Train: [ 88/180] Step 250/1249 Loss 1.735 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.732, lat_loss 22.025
09/21 10:34:49 PM | Train: [ 88/180] Step 300/1249 Loss 1.739 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.732, lat_loss 22.025
09/21 10:35:14 PM | Train: [ 88/180] Step 350/1249 Loss 1.721 Prec@(1,3) (86.7%, 99.4%), ce_loss 0.732, lat_loss 22.025
09/21 10:35:38 PM | Train: [ 88/180] Step 400/1249 Loss 1.740 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.732, lat_loss 22.025
09/21 10:36:03 PM | Train: [ 88/180] Step 450/1249 Loss 1.727 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.732, lat_loss 22.025
09/21 10:36:27 PM | Train: [ 88/180] Step 500/1249 Loss 1.724 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.732, lat_loss 22.025
09/21 10:36:52 PM | Train: [ 88/180] Step 550/1249 Loss 1.705 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.732, lat_loss 22.025
09/21 10:37:16 PM | Train: [ 88/180] Step 600/1249 Loss 1.710 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.732, lat_loss 22.025
09/21 10:37:40 PM | Train: [ 88/180] Step 650/1249 Loss 1.705 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.732, lat_loss 22.025
09/21 10:38:04 PM | Train: [ 88/180] Step 700/1249 Loss 1.712 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.731, lat_loss 22.025
09/21 10:38:29 PM | Train: [ 88/180] Step 750/1249 Loss 1.712 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.731, lat_loss 22.025
09/21 10:38:53 PM | Train: [ 88/180] Step 800/1249 Loss 1.720 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.731, lat_loss 22.025
09/21 10:39:17 PM | Train: [ 88/180] Step 850/1249 Loss 1.735 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.731, lat_loss 22.025
09/21 10:39:41 PM | Train: [ 88/180] Step 900/1249 Loss 1.732 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.731, lat_loss 22.025
09/21 10:40:05 PM | Train: [ 88/180] Step 950/1249 Loss 1.727 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.731, lat_loss 22.025
09/21 10:40:30 PM | Train: [ 88/180] Step 1000/1249 Loss 1.730 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.731, lat_loss 22.025
09/21 10:40:54 PM | Train: [ 88/180] Step 1050/1249 Loss 1.732 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.731, lat_loss 22.025
09/21 10:41:18 PM | Train: [ 88/180] Step 1100/1249 Loss 1.729 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.731, lat_loss 22.025
09/21 10:41:43 PM | Train: [ 88/180] Step 1150/1249 Loss 1.733 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.730, lat_loss 22.025
09/21 10:42:07 PM | Train: [ 88/180] Step 1200/1249 Loss 1.739 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.730, lat_loss 22.025
09/21 10:42:32 PM | Train: [ 88/180] Step 1249/1249 Loss 1.733 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.730, lat_loss 22.025
09/21 10:42:32 PM | _w_step_train: [ 88/180] Final Prec@1 86.5175% Time 611.04
09/21 10:42:32 PM | Start to train theta for epoch 87
09/21 10:42:45 PM | Train: [ 88/180] Step 050/312 Loss 2.317 Prec@(1,3) (82.4%, 99.1%), ce_loss 0.730, lat_loss 22.025
09/21 10:42:57 PM | Train: [ 88/180] Step 100/312 Loss 2.243 Prec@(1,3) (83.1%, 99.1%), ce_loss 0.730, lat_loss 22.025
09/21 10:43:09 PM | Train: [ 88/180] Step 150/312 Loss 2.221 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.730, lat_loss 22.025
09/21 10:43:22 PM | Train: [ 88/180] Step 200/312 Loss 2.180 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.730, lat_loss 22.025
09/21 10:43:34 PM | Train: [ 88/180] Step 250/312 Loss 2.238 Prec@(1,3) (83.5%, 99.0%), ce_loss 0.730, lat_loss 22.025
09/21 10:43:47 PM | Train: [ 88/180] Step 300/312 Loss 2.206 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.730, lat_loss 22.025
09/21 10:43:50 PM | Train: [ 88/180] Step 312/312 Loss 2.200 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.730, lat_loss 22.025
09/21 10:43:50 PM | _theta_step_train: [ 88/180] Final Prec@1 83.4200% Time 77.98
09/21 10:43:55 PM | Valid: [ 88/180] Step 050/312 Loss 2.112 Prec@(1,3) (83.7%, 99.4%), ce_loss 0.730, lat_loss 22.025
09/21 10:43:59 PM | Valid: [ 88/180] Step 100/312 Loss 2.259 Prec@(1,3) (82.6%, 99.2%), ce_loss 0.730, lat_loss 22.025
09/21 10:44:04 PM | Valid: [ 88/180] Step 150/312 Loss 2.282 Prec@(1,3) (82.7%, 99.1%), ce_loss 0.730, lat_loss 22.025
09/21 10:44:09 PM | Valid: [ 88/180] Step 200/312 Loss 2.267 Prec@(1,3) (82.8%, 99.0%), ce_loss 0.730, lat_loss 22.025
09/21 10:44:13 PM | Valid: [ 88/180] Step 250/312 Loss 2.242 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.729, lat_loss 22.025
09/21 10:44:18 PM | Valid: [ 88/180] Step 300/312 Loss 2.203 Prec@(1,3) (83.2%, 99.2%), ce_loss 0.729, lat_loss 22.025
09/21 10:44:19 PM | Valid: [ 88/180] Step 312/312 Loss 2.211 Prec@(1,3) (83.2%, 99.2%), ce_loss 0.729, lat_loss 22.025
09/21 10:44:19 PM | val: [ 88/180] Final Prec@1 83.2400% Time 29.41
09/21 10:44:19 PM | Start to train weights for epoch 88
09/21 10:44:45 PM | Train: [ 89/180] Step 050/1249 Loss 1.574 Prec@(1,3) (87.5%, 99.3%), ce_loss 0.729, lat_loss 22.025
09/21 10:45:09 PM | Train: [ 89/180] Step 100/1249 Loss 1.627 Prec@(1,3) (87.0%, 99.3%), ce_loss 0.729, lat_loss 22.025
09/21 10:45:34 PM | Train: [ 89/180] Step 150/1249 Loss 1.546 Prec@(1,3) (87.8%, 99.4%), ce_loss 0.729, lat_loss 22.025
09/21 10:45:59 PM | Train: [ 89/180] Step 200/1249 Loss 1.567 Prec@(1,3) (87.7%, 99.4%), ce_loss 0.729, lat_loss 22.025
09/21 10:46:23 PM | Train: [ 89/180] Step 250/1249 Loss 1.591 Prec@(1,3) (87.5%, 99.4%), ce_loss 0.729, lat_loss 22.025
09/21 10:46:48 PM | Train: [ 89/180] Step 300/1249 Loss 1.623 Prec@(1,3) (87.4%, 99.4%), ce_loss 0.729, lat_loss 22.025
09/21 10:47:12 PM | Train: [ 89/180] Step 350/1249 Loss 1.665 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.729, lat_loss 22.025
09/21 10:47:37 PM | Train: [ 89/180] Step 400/1249 Loss 1.689 Prec@(1,3) (87.2%, 99.3%), ce_loss 0.728, lat_loss 22.025
09/21 10:48:01 PM | Train: [ 89/180] Step 450/1249 Loss 1.718 Prec@(1,3) (86.9%, 99.3%), ce_loss 0.728, lat_loss 22.025
09/21 10:48:25 PM | Train: [ 89/180] Step 500/1249 Loss 1.706 Prec@(1,3) (87.0%, 99.3%), ce_loss 0.728, lat_loss 22.024
09/21 10:48:50 PM | Train: [ 89/180] Step 550/1249 Loss 1.743 Prec@(1,3) (86.7%, 99.3%), ce_loss 0.728, lat_loss 22.024
09/21 10:49:15 PM | Train: [ 89/180] Step 600/1249 Loss 1.753 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.728, lat_loss 22.024
09/21 10:49:40 PM | Train: [ 89/180] Step 650/1249 Loss 1.758 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.728, lat_loss 22.024
09/21 10:50:04 PM | Train: [ 89/180] Step 700/1249 Loss 1.765 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.728, lat_loss 22.024
09/21 10:50:29 PM | Train: [ 89/180] Step 750/1249 Loss 1.761 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.728, lat_loss 22.024
09/21 10:50:53 PM | Train: [ 89/180] Step 800/1249 Loss 1.760 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.728, lat_loss 22.024
09/21 10:51:18 PM | Train: [ 89/180] Step 850/1249 Loss 1.774 Prec@(1,3) (86.4%, 99.3%), ce_loss 0.728, lat_loss 22.024
09/21 10:51:43 PM | Train: [ 89/180] Step 900/1249 Loss 1.768 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.728, lat_loss 22.024
09/21 10:52:06 PM | Train: [ 89/180] Step 950/1249 Loss 1.768 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.727, lat_loss 22.024
09/21 10:52:31 PM | Train: [ 89/180] Step 1000/1249 Loss 1.762 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.727, lat_loss 22.024
09/21 10:52:55 PM | Train: [ 89/180] Step 1050/1249 Loss 1.760 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.727, lat_loss 22.024
09/21 10:53:19 PM | Train: [ 89/180] Step 1100/1249 Loss 1.771 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.727, lat_loss 22.024
09/21 10:53:44 PM | Train: [ 89/180] Step 1150/1249 Loss 1.769 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.727, lat_loss 22.024
09/21 10:54:08 PM | Train: [ 89/180] Step 1200/1249 Loss 1.765 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.727, lat_loss 22.024
09/21 10:54:32 PM | Train: [ 89/180] Step 1249/1249 Loss 1.781 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.727, lat_loss 22.024
09/21 10:54:32 PM | _w_step_train: [ 89/180] Final Prec@1 86.4825% Time 613.15
09/21 10:54:32 PM | Start to train theta for epoch 88
09/21 10:54:52 PM | Train: [ 89/180] Step 050/312 Loss 2.022 Prec@(1,3) (84.5%, 98.8%), ce_loss 0.727, lat_loss 22.024
09/21 10:55:12 PM | Train: [ 89/180] Step 100/312 Loss 2.244 Prec@(1,3) (82.5%, 98.9%), ce_loss 0.727, lat_loss 22.024
09/21 10:55:31 PM | Train: [ 89/180] Step 150/312 Loss 2.244 Prec@(1,3) (82.6%, 98.9%), ce_loss 0.727, lat_loss 22.024
09/21 10:55:52 PM | Train: [ 89/180] Step 200/312 Loss 2.232 Prec@(1,3) (82.9%, 98.8%), ce_loss 0.727, lat_loss 22.024
09/21 10:56:12 PM | Train: [ 89/180] Step 250/312 Loss 2.251 Prec@(1,3) (82.8%, 98.9%), ce_loss 0.727, lat_loss 22.024
09/21 10:56:33 PM | Train: [ 89/180] Step 300/312 Loss 2.263 Prec@(1,3) (82.8%, 98.9%), ce_loss 0.726, lat_loss 22.024
09/21 10:56:38 PM | Train: [ 89/180] Step 312/312 Loss 2.252 Prec@(1,3) (82.8%, 99.0%), ce_loss 0.726, lat_loss 22.024
09/21 10:56:38 PM | _theta_step_train: [ 89/180] Final Prec@1 82.8200% Time 125.99
09/21 10:56:43 PM | Valid: [ 89/180] Step 050/312 Loss 2.060 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.726, lat_loss 22.024
09/21 10:56:48 PM | Valid: [ 89/180] Step 100/312 Loss 2.132 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.726, lat_loss 22.024
09/21 10:56:53 PM | Valid: [ 89/180] Step 150/312 Loss 2.192 Prec@(1,3) (84.0%, 99.0%), ce_loss 0.726, lat_loss 22.024
09/21 10:56:58 PM | Valid: [ 89/180] Step 200/312 Loss 2.156 Prec@(1,3) (84.2%, 99.1%), ce_loss 0.726, lat_loss 22.024
09/21 10:57:02 PM | Valid: [ 89/180] Step 250/312 Loss 2.158 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.726, lat_loss 22.024
09/21 10:57:07 PM | Valid: [ 89/180] Step 300/312 Loss 2.133 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.726, lat_loss 22.024
09/21 10:57:08 PM | Valid: [ 89/180] Step 312/312 Loss 2.144 Prec@(1,3) (83.8%, 99.1%), ce_loss 0.726, lat_loss 22.024
09/21 10:57:08 PM | val: [ 89/180] Final Prec@1 83.8300% Time 29.75
09/21 10:57:08 PM | Best top1 acc by now. Save model
09/21 10:57:08 PM | Start to train weights for epoch 89
09/21 10:57:34 PM | Train: [ 90/180] Step 050/1249 Loss 1.830 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.726, lat_loss 22.024
09/21 10:57:59 PM | Train: [ 90/180] Step 100/1249 Loss 1.766 Prec@(1,3) (86.8%, 99.5%), ce_loss 0.726, lat_loss 22.024
09/21 10:58:24 PM | Train: [ 90/180] Step 150/1249 Loss 1.709 Prec@(1,3) (87.0%, 99.6%), ce_loss 0.726, lat_loss 22.024
09/21 10:58:50 PM | Train: [ 90/180] Step 200/1249 Loss 1.652 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.726, lat_loss 22.024
09/21 10:59:15 PM | Train: [ 90/180] Step 250/1249 Loss 1.630 Prec@(1,3) (87.3%, 99.6%), ce_loss 0.725, lat_loss 22.024
09/21 10:59:40 PM | Train: [ 90/180] Step 300/1249 Loss 1.667 Prec@(1,3) (87.0%, 99.6%), ce_loss 0.725, lat_loss 22.024
09/21 11:00:04 PM | Train: [ 90/180] Step 350/1249 Loss 1.685 Prec@(1,3) (86.9%, 99.6%), ce_loss 0.725, lat_loss 22.024
09/21 11:00:29 PM | Train: [ 90/180] Step 400/1249 Loss 1.688 Prec@(1,3) (86.9%, 99.5%), ce_loss 0.725, lat_loss 22.024
09/21 11:00:56 PM | Train: [ 90/180] Step 450/1249 Loss 1.716 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.725, lat_loss 22.024
09/21 11:01:22 PM | Train: [ 90/180] Step 500/1249 Loss 1.742 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.725, lat_loss 22.024
09/21 11:01:44 PM | Train: [ 90/180] Step 550/1249 Loss 1.736 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.725, lat_loss 22.024
09/21 11:02:06 PM | Train: [ 90/180] Step 600/1249 Loss 1.735 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.725, lat_loss 22.024
09/21 11:02:29 PM | Train: [ 90/180] Step 650/1249 Loss 1.727 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.725, lat_loss 22.023
09/21 11:02:52 PM | Train: [ 90/180] Step 700/1249 Loss 1.718 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.725, lat_loss 22.023
09/21 11:03:18 PM | Train: [ 90/180] Step 750/1249 Loss 1.705 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.724, lat_loss 22.023
09/21 11:03:46 PM | Train: [ 90/180] Step 800/1249 Loss 1.718 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.724, lat_loss 22.023
09/21 11:04:12 PM | Train: [ 90/180] Step 850/1249 Loss 1.717 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.724, lat_loss 22.023
09/21 11:04:39 PM | Train: [ 90/180] Step 900/1249 Loss 1.713 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.724, lat_loss 22.023
09/21 11:05:04 PM | Train: [ 90/180] Step 950/1249 Loss 1.706 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.724, lat_loss 22.023
09/21 11:05:29 PM | Train: [ 90/180] Step 1000/1249 Loss 1.708 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.724, lat_loss 22.023
09/21 11:05:54 PM | Train: [ 90/180] Step 1050/1249 Loss 1.710 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.724, lat_loss 22.023
09/21 11:06:19 PM | Train: [ 90/180] Step 1100/1249 Loss 1.703 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.724, lat_loss 22.023
09/21 11:06:44 PM | Train: [ 90/180] Step 1150/1249 Loss 1.709 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.724, lat_loss 22.023
09/21 11:07:09 PM | Train: [ 90/180] Step 1200/1249 Loss 1.715 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.723, lat_loss 22.023
09/21 11:07:34 PM | Train: [ 90/180] Step 1249/1249 Loss 1.714 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.723, lat_loss 22.023
09/21 11:07:34 PM | _w_step_train: [ 90/180] Final Prec@1 86.6925% Time 625.67
09/21 11:07:34 PM | Start to train theta for epoch 89
09/21 11:07:54 PM | Train: [ 90/180] Step 050/312 Loss 2.142 Prec@(1,3) (84.4%, 99.0%), ce_loss 0.723, lat_loss 22.023
09/21 11:08:13 PM | Train: [ 90/180] Step 100/312 Loss 2.204 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.723, lat_loss 22.023
09/21 11:08:34 PM | Train: [ 90/180] Step 150/312 Loss 2.168 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.723, lat_loss 22.023
09/21 11:08:54 PM | Train: [ 90/180] Step 200/312 Loss 2.187 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.723, lat_loss 22.023
09/21 11:09:15 PM | Train: [ 90/180] Step 250/312 Loss 2.192 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.723, lat_loss 22.023
09/21 11:09:36 PM | Train: [ 90/180] Step 300/312 Loss 2.198 Prec@(1,3) (83.9%, 99.0%), ce_loss 0.723, lat_loss 22.023
09/21 11:09:41 PM | Train: [ 90/180] Step 312/312 Loss 2.189 Prec@(1,3) (83.9%, 99.0%), ce_loss 0.723, lat_loss 22.023
09/21 11:09:41 PM | _theta_step_train: [ 90/180] Final Prec@1 83.8700% Time 127.13
09/21 11:09:46 PM | Valid: [ 90/180] Step 050/312 Loss 2.031 Prec@(1,3) (84.8%, 99.4%), ce_loss 0.723, lat_loss 22.023
09/21 11:09:51 PM | Valid: [ 90/180] Step 100/312 Loss 2.151 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.723, lat_loss 22.023
09/21 11:09:56 PM | Valid: [ 90/180] Step 150/312 Loss 2.177 Prec@(1,3) (83.9%, 99.2%), ce_loss 0.723, lat_loss 22.023
09/21 11:10:00 PM | Valid: [ 90/180] Step 200/312 Loss 2.167 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.723, lat_loss 22.023
09/21 11:10:05 PM | Valid: [ 90/180] Step 250/312 Loss 2.157 Prec@(1,3) (83.7%, 99.2%), ce_loss 0.723, lat_loss 22.023
09/21 11:10:10 PM | Valid: [ 90/180] Step 300/312 Loss 2.136 Prec@(1,3) (83.8%, 99.2%), ce_loss 0.723, lat_loss 22.023
09/21 11:10:11 PM | Valid: [ 90/180] Step 312/312 Loss 2.142 Prec@(1,3) (83.9%, 99.2%), ce_loss 0.722, lat_loss 22.023
09/21 11:10:11 PM | val: [ 90/180] Final Prec@1 83.8600% Time 30.04
09/21 11:10:11 PM | Best top1 acc by now. Save model
09/21 11:10:11 PM | Start to train weights for epoch 90
09/21 11:10:36 PM | Train: [ 91/180] Step 050/1249 Loss 1.590 Prec@(1,3) (87.8%, 99.5%), ce_loss 0.722, lat_loss 22.023
09/21 11:11:00 PM | Train: [ 91/180] Step 100/1249 Loss 1.614 Prec@(1,3) (87.7%, 99.4%), ce_loss 0.722, lat_loss 22.023
09/21 11:11:24 PM | Train: [ 91/180] Step 150/1249 Loss 1.605 Prec@(1,3) (87.6%, 99.4%), ce_loss 0.722, lat_loss 22.023
09/21 11:11:47 PM | Train: [ 91/180] Step 200/1249 Loss 1.678 Prec@(1,3) (87.2%, 99.3%), ce_loss 0.722, lat_loss 22.023
09/21 11:12:10 PM | Train: [ 91/180] Step 250/1249 Loss 1.730 Prec@(1,3) (87.1%, 99.3%), ce_loss 0.722, lat_loss 22.023
09/21 11:12:32 PM | Train: [ 91/180] Step 300/1249 Loss 1.700 Prec@(1,3) (87.2%, 99.4%), ce_loss 0.722, lat_loss 22.023
09/21 11:12:55 PM | Train: [ 91/180] Step 350/1249 Loss 1.672 Prec@(1,3) (87.4%, 99.4%), ce_loss 0.722, lat_loss 22.023
09/21 11:13:17 PM | Train: [ 91/180] Step 400/1249 Loss 1.660 Prec@(1,3) (87.4%, 99.4%), ce_loss 0.722, lat_loss 22.023
09/21 11:13:40 PM | Train: [ 91/180] Step 450/1249 Loss 1.672 Prec@(1,3) (87.3%, 99.4%), ce_loss 0.722, lat_loss 22.023
09/21 11:14:03 PM | Train: [ 91/180] Step 500/1249 Loss 1.680 Prec@(1,3) (87.2%, 99.4%), ce_loss 0.721, lat_loss 22.023
09/21 11:14:26 PM | Train: [ 91/180] Step 550/1249 Loss 1.661 Prec@(1,3) (87.4%, 99.4%), ce_loss 0.721, lat_loss 22.022
09/21 11:14:50 PM | Train: [ 91/180] Step 600/1249 Loss 1.699 Prec@(1,3) (87.2%, 99.4%), ce_loss 0.721, lat_loss 22.022
09/21 11:15:14 PM | Train: [ 91/180] Step 650/1249 Loss 1.694 Prec@(1,3) (87.3%, 99.4%), ce_loss 0.721, lat_loss 22.022
09/21 11:15:37 PM | Train: [ 91/180] Step 700/1249 Loss 1.702 Prec@(1,3) (87.3%, 99.3%), ce_loss 0.721, lat_loss 22.022
09/21 11:16:01 PM | Train: [ 91/180] Step 750/1249 Loss 1.730 Prec@(1,3) (87.0%, 99.3%), ce_loss 0.721, lat_loss 22.022
09/21 11:16:25 PM | Train: [ 91/180] Step 800/1249 Loss 1.728 Prec@(1,3) (87.0%, 99.3%), ce_loss 0.721, lat_loss 22.022
09/21 11:16:49 PM | Train: [ 91/180] Step 850/1249 Loss 1.727 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.721, lat_loss 22.022
09/21 11:17:14 PM | Train: [ 91/180] Step 900/1249 Loss 1.737 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.721, lat_loss 22.022
09/21 11:17:38 PM | Train: [ 91/180] Step 950/1249 Loss 1.731 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.721, lat_loss 22.022
09/21 11:18:02 PM | Train: [ 91/180] Step 1000/1249 Loss 1.735 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.720, lat_loss 22.022
09/21 11:18:26 PM | Train: [ 91/180] Step 1050/1249 Loss 1.734 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.720, lat_loss 22.022
09/21 11:18:50 PM | Train: [ 91/180] Step 1100/1249 Loss 1.734 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.720, lat_loss 22.022
09/21 11:19:13 PM | Train: [ 91/180] Step 1150/1249 Loss 1.741 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.720, lat_loss 22.022
09/21 11:19:38 PM | Train: [ 91/180] Step 1200/1249 Loss 1.736 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.720, lat_loss 22.022
09/21 11:20:02 PM | Train: [ 91/180] Step 1249/1249 Loss 1.728 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.720, lat_loss 22.022
09/21 11:20:03 PM | _w_step_train: [ 91/180] Final Prec@1 86.8550% Time 591.19
09/21 11:20:03 PM | Start to train theta for epoch 90
09/21 11:20:24 PM | Train: [ 91/180] Step 050/312 Loss 2.236 Prec@(1,3) (83.5%, 98.8%), ce_loss 0.720, lat_loss 22.022
09/21 11:20:44 PM | Train: [ 91/180] Step 100/312 Loss 2.247 Prec@(1,3) (83.2%, 98.9%), ce_loss 0.720, lat_loss 22.022
09/21 11:21:05 PM | Train: [ 91/180] Step 150/312 Loss 2.215 Prec@(1,3) (83.5%, 99.0%), ce_loss 0.720, lat_loss 22.022
09/21 11:21:25 PM | Train: [ 91/180] Step 200/312 Loss 2.199 Prec@(1,3) (83.6%, 99.1%), ce_loss 0.720, lat_loss 22.022
09/21 11:21:46 PM | Train: [ 91/180] Step 250/312 Loss 2.213 Prec@(1,3) (83.6%, 99.0%), ce_loss 0.720, lat_loss 22.022
09/21 11:21:59 PM | Train: [ 91/180] Step 300/312 Loss 2.186 Prec@(1,3) (83.9%, 99.0%), ce_loss 0.720, lat_loss 22.022
09/21 11:22:02 PM | Train: [ 91/180] Step 312/312 Loss 2.175 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.720, lat_loss 22.022
09/21 11:22:02 PM | _theta_step_train: [ 91/180] Final Prec@1 83.9300% Time 119.20
09/21 11:22:07 PM | Valid: [ 91/180] Step 050/312 Loss 1.978 Prec@(1,3) (84.4%, 99.5%), ce_loss 0.719, lat_loss 22.022
09/21 11:22:12 PM | Valid: [ 91/180] Step 100/312 Loss 2.271 Prec@(1,3) (82.5%, 99.3%), ce_loss 0.719, lat_loss 22.022
09/21 11:22:16 PM | Valid: [ 91/180] Step 150/312 Loss 2.192 Prec@(1,3) (83.3%, 99.2%), ce_loss 0.719, lat_loss 22.022
09/21 11:22:21 PM | Valid: [ 91/180] Step 200/312 Loss 2.182 Prec@(1,3) (83.4%, 99.2%), ce_loss 0.719, lat_loss 22.022
09/21 11:22:26 PM | Valid: [ 91/180] Step 250/312 Loss 2.147 Prec@(1,3) (83.8%, 99.2%), ce_loss 0.719, lat_loss 22.022
09/21 11:22:30 PM | Valid: [ 91/180] Step 300/312 Loss 2.140 Prec@(1,3) (83.9%, 99.2%), ce_loss 0.719, lat_loss 22.022
09/21 11:22:32 PM | Valid: [ 91/180] Step 312/312 Loss 2.146 Prec@(1,3) (83.8%, 99.2%), ce_loss 0.719, lat_loss 22.022
09/21 11:22:32 PM | val: [ 91/180] Final Prec@1 83.7700% Time 29.83
09/21 11:22:32 PM | Start to train weights for epoch 91
09/21 11:22:54 PM | Train: [ 92/180] Step 050/1249 Loss 1.550 Prec@(1,3) (88.2%, 99.3%), ce_loss 0.719, lat_loss 22.022
09/21 11:23:15 PM | Train: [ 92/180] Step 100/1249 Loss 1.640 Prec@(1,3) (87.4%, 99.4%), ce_loss 0.719, lat_loss 22.022
09/21 11:23:35 PM | Train: [ 92/180] Step 150/1249 Loss 1.625 Prec@(1,3) (87.4%, 99.4%), ce_loss 0.719, lat_loss 22.022
09/21 11:23:56 PM | Train: [ 92/180] Step 200/1249 Loss 1.642 Prec@(1,3) (87.2%, 99.4%), ce_loss 0.719, lat_loss 22.022
09/21 11:24:19 PM | Train: [ 92/180] Step 250/1249 Loss 1.643 Prec@(1,3) (87.0%, 99.5%), ce_loss 0.719, lat_loss 22.022
09/21 11:24:44 PM | Train: [ 92/180] Step 300/1249 Loss 1.651 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.718, lat_loss 22.022
09/21 11:25:09 PM | Train: [ 92/180] Step 350/1249 Loss 1.636 Prec@(1,3) (87.2%, 99.4%), ce_loss 0.718, lat_loss 22.022
09/21 11:25:33 PM | Train: [ 92/180] Step 400/1249 Loss 1.633 Prec@(1,3) (87.2%, 99.4%), ce_loss 0.718, lat_loss 22.022
09/21 11:25:56 PM | Train: [ 92/180] Step 450/1249 Loss 1.630 Prec@(1,3) (87.2%, 99.5%), ce_loss 0.718, lat_loss 22.022
09/21 11:26:18 PM | Train: [ 92/180] Step 500/1249 Loss 1.611 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.718, lat_loss 22.022
09/21 11:26:42 PM | Train: [ 92/180] Step 550/1249 Loss 1.609 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.718, lat_loss 22.022
09/21 11:27:05 PM | Train: [ 92/180] Step 600/1249 Loss 1.622 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.718, lat_loss 22.021
09/21 11:27:28 PM | Train: [ 92/180] Step 650/1249 Loss 1.627 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.718, lat_loss 22.021
09/21 11:27:52 PM | Train: [ 92/180] Step 700/1249 Loss 1.619 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.718, lat_loss 22.021
09/21 11:28:15 PM | Train: [ 92/180] Step 750/1249 Loss 1.608 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.718, lat_loss 22.021
09/21 11:28:39 PM | Train: [ 92/180] Step 800/1249 Loss 1.606 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.717, lat_loss 22.021
09/21 11:29:00 PM | Train: [ 92/180] Step 850/1249 Loss 1.603 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.717, lat_loss 22.021
09/21 11:29:21 PM | Train: [ 92/180] Step 900/1249 Loss 1.602 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.717, lat_loss 22.021
09/21 11:29:42 PM | Train: [ 92/180] Step 950/1249 Loss 1.607 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.717, lat_loss 22.021
09/21 11:30:04 PM | Train: [ 92/180] Step 1000/1249 Loss 1.609 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.717, lat_loss 22.021
09/21 11:30:24 PM | Train: [ 92/180] Step 1050/1249 Loss 1.622 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.717, lat_loss 22.021
09/21 11:30:45 PM | Train: [ 92/180] Step 1100/1249 Loss 1.631 Prec@(1,3) (87.2%, 99.5%), ce_loss 0.717, lat_loss 22.021
09/21 11:31:08 PM | Train: [ 92/180] Step 1150/1249 Loss 1.652 Prec@(1,3) (87.0%, 99.5%), ce_loss 0.717, lat_loss 22.021
09/21 11:31:32 PM | Train: [ 92/180] Step 1200/1249 Loss 1.656 Prec@(1,3) (87.0%, 99.5%), ce_loss 0.717, lat_loss 22.021
09/21 11:31:57 PM | Train: [ 92/180] Step 1249/1249 Loss 1.657 Prec@(1,3) (87.0%, 99.5%), ce_loss 0.717, lat_loss 22.021
09/21 11:31:57 PM | _w_step_train: [ 92/180] Final Prec@1 86.9825% Time 565.40
09/21 11:31:57 PM | Start to train theta for epoch 91
09/21 11:32:18 PM | Train: [ 92/180] Step 050/312 Loss 2.168 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.716, lat_loss 22.021
09/21 11:32:40 PM | Train: [ 92/180] Step 100/312 Loss 2.154 Prec@(1,3) (84.2%, 99.0%), ce_loss 0.716, lat_loss 22.021
09/21 11:33:01 PM | Train: [ 92/180] Step 150/312 Loss 2.184 Prec@(1,3) (84.4%, 98.9%), ce_loss 0.716, lat_loss 22.021
09/21 11:33:22 PM | Train: [ 92/180] Step 200/312 Loss 2.177 Prec@(1,3) (84.1%, 98.8%), ce_loss 0.716, lat_loss 22.021
09/21 11:33:42 PM | Train: [ 92/180] Step 250/312 Loss 2.210 Prec@(1,3) (83.8%, 98.9%), ce_loss 0.716, lat_loss 22.021
09/21 11:34:03 PM | Train: [ 92/180] Step 300/312 Loss 2.224 Prec@(1,3) (83.7%, 98.9%), ce_loss 0.716, lat_loss 22.021
09/21 11:34:08 PM | Train: [ 92/180] Step 312/312 Loss 2.221 Prec@(1,3) (83.7%, 98.9%), ce_loss 0.716, lat_loss 22.021
09/21 11:34:08 PM | _theta_step_train: [ 92/180] Final Prec@1 83.6900% Time 130.96
09/21 11:34:13 PM | Valid: [ 92/180] Step 050/312 Loss 2.345 Prec@(1,3) (82.2%, 99.3%), ce_loss 0.716, lat_loss 22.021
09/21 11:34:18 PM | Valid: [ 92/180] Step 100/312 Loss 2.352 Prec@(1,3) (82.5%, 99.1%), ce_loss 0.716, lat_loss 22.021
09/21 11:34:23 PM | Valid: [ 92/180] Step 150/312 Loss 2.306 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.716, lat_loss 22.021
09/21 11:34:27 PM | Valid: [ 92/180] Step 200/312 Loss 2.289 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.716, lat_loss 22.021
09/21 11:34:32 PM | Valid: [ 92/180] Step 250/312 Loss 2.312 Prec@(1,3) (83.4%, 98.9%), ce_loss 0.716, lat_loss 22.021
09/21 11:34:37 PM | Valid: [ 92/180] Step 300/312 Loss 2.254 Prec@(1,3) (83.6%, 99.0%), ce_loss 0.716, lat_loss 22.021
09/21 11:34:38 PM | Valid: [ 92/180] Step 312/312 Loss 2.261 Prec@(1,3) (83.5%, 99.0%), ce_loss 0.716, lat_loss 22.021
09/21 11:34:38 PM | val: [ 92/180] Final Prec@1 83.4800% Time 29.72
09/21 11:34:38 PM | Start to train weights for epoch 92
09/21 11:35:04 PM | Train: [ 93/180] Step 050/1249 Loss 1.403 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.716, lat_loss 22.021
09/21 11:35:29 PM | Train: [ 93/180] Step 100/1249 Loss 1.513 Prec@(1,3) (88.4%, 99.4%), ce_loss 0.716, lat_loss 22.021
09/21 11:35:53 PM | Train: [ 93/180] Step 150/1249 Loss 1.502 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.715, lat_loss 22.021
09/21 11:36:18 PM | Train: [ 93/180] Step 200/1249 Loss 1.543 Prec@(1,3) (87.9%, 99.5%), ce_loss 0.715, lat_loss 22.021
09/21 11:36:42 PM | Train: [ 93/180] Step 250/1249 Loss 1.585 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.715, lat_loss 22.021
09/21 11:37:06 PM | Train: [ 93/180] Step 300/1249 Loss 1.602 Prec@(1,3) (87.3%, 99.4%), ce_loss 0.715, lat_loss 22.021
09/21 11:37:31 PM | Train: [ 93/180] Step 350/1249 Loss 1.612 Prec@(1,3) (87.2%, 99.5%), ce_loss 0.715, lat_loss 22.021
09/21 11:37:55 PM | Train: [ 93/180] Step 400/1249 Loss 1.613 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.715, lat_loss 22.021
09/21 11:38:19 PM | Train: [ 93/180] Step 450/1249 Loss 1.615 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.715, lat_loss 22.021
09/21 11:38:43 PM | Train: [ 93/180] Step 500/1249 Loss 1.628 Prec@(1,3) (87.2%, 99.5%), ce_loss 0.715, lat_loss 22.021
09/21 11:39:07 PM | Train: [ 93/180] Step 550/1249 Loss 1.617 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.715, lat_loss 22.021
09/21 11:39:31 PM | Train: [ 93/180] Step 600/1249 Loss 1.621 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.715, lat_loss 22.021
09/21 11:39:56 PM | Train: [ 93/180] Step 650/1249 Loss 1.617 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.714, lat_loss 22.020
09/21 11:40:20 PM | Train: [ 93/180] Step 700/1249 Loss 1.623 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.714, lat_loss 22.020
09/21 11:40:44 PM | Train: [ 93/180] Step 750/1249 Loss 1.626 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.714, lat_loss 22.020
09/21 11:41:09 PM | Train: [ 93/180] Step 800/1249 Loss 1.629 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.714, lat_loss 22.020
09/21 11:41:33 PM | Train: [ 93/180] Step 850/1249 Loss 1.625 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.714, lat_loss 22.020
09/21 11:41:58 PM | Train: [ 93/180] Step 900/1249 Loss 1.621 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.714, lat_loss 22.020
09/21 11:42:22 PM | Train: [ 93/180] Step 950/1249 Loss 1.630 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.714, lat_loss 22.020
09/21 11:42:47 PM | Train: [ 93/180] Step 1000/1249 Loss 1.638 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.714, lat_loss 22.020
09/21 11:43:13 PM | Train: [ 93/180] Step 1050/1249 Loss 1.628 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.714, lat_loss 22.020
09/21 11:43:40 PM | Train: [ 93/180] Step 1100/1249 Loss 1.629 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.713, lat_loss 22.020
09/21 11:44:07 PM | Train: [ 93/180] Step 1150/1249 Loss 1.631 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.713, lat_loss 22.020
09/21 11:44:33 PM | Train: [ 93/180] Step 1200/1249 Loss 1.632 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.713, lat_loss 22.020
09/21 11:44:58 PM | Train: [ 93/180] Step 1249/1249 Loss 1.620 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.713, lat_loss 22.020
09/21 11:44:58 PM | _w_step_train: [ 93/180] Final Prec@1 87.3850% Time 619.91
09/21 11:44:58 PM | Start to train theta for epoch 92
09/21 11:45:17 PM | Train: [ 93/180] Step 050/312 Loss 2.140 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.713, lat_loss 22.020
09/21 11:45:36 PM | Train: [ 93/180] Step 100/312 Loss 2.240 Prec@(1,3) (84.0%, 99.0%), ce_loss 0.713, lat_loss 22.020
09/21 11:45:57 PM | Train: [ 93/180] Step 150/312 Loss 2.213 Prec@(1,3) (84.1%, 99.0%), ce_loss 0.713, lat_loss 22.020
09/21 11:46:16 PM | Train: [ 93/180] Step 200/312 Loss 2.239 Prec@(1,3) (83.8%, 99.1%), ce_loss 0.713, lat_loss 22.020
09/21 11:46:36 PM | Train: [ 93/180] Step 250/312 Loss 2.279 Prec@(1,3) (83.6%, 99.1%), ce_loss 0.713, lat_loss 22.020
09/21 11:46:56 PM | Train: [ 93/180] Step 300/312 Loss 2.279 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.713, lat_loss 22.020
09/21 11:47:01 PM | Train: [ 93/180] Step 312/312 Loss 2.267 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.713, lat_loss 22.020
09/21 11:47:01 PM | _theta_step_train: [ 93/180] Final Prec@1 83.7400% Time 123.44
09/21 11:47:06 PM | Valid: [ 93/180] Step 050/312 Loss 2.013 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.713, lat_loss 22.020
09/21 11:47:10 PM | Valid: [ 93/180] Step 100/312 Loss 2.127 Prec@(1,3) (84.5%, 99.4%), ce_loss 0.713, lat_loss 22.020
09/21 11:47:14 PM | Valid: [ 93/180] Step 150/312 Loss 2.410 Prec@(1,3) (83.1%, 98.5%), ce_loss 0.713, lat_loss 22.020
09/21 11:47:19 PM | Valid: [ 93/180] Step 200/312 Loss 2.346 Prec@(1,3) (83.6%, 98.7%), ce_loss 0.713, lat_loss 22.020
09/21 11:47:23 PM | Valid: [ 93/180] Step 250/312 Loss 2.291 Prec@(1,3) (83.7%, 98.8%), ce_loss 0.713, lat_loss 22.020
09/21 11:47:27 PM | Valid: [ 93/180] Step 300/312 Loss 2.220 Prec@(1,3) (84.1%, 98.9%), ce_loss 0.712, lat_loss 22.020
09/21 11:47:28 PM | Valid: [ 93/180] Step 312/312 Loss 2.218 Prec@(1,3) (84.1%, 99.0%), ce_loss 0.712, lat_loss 22.020
09/21 11:47:28 PM | val: [ 93/180] Final Prec@1 84.0800% Time 27.06
09/21 11:47:29 PM | Best top1 acc by now. Save model
09/21 11:47:29 PM | Start to train weights for epoch 93
09/21 11:47:54 PM | Train: [ 94/180] Step 050/1249 Loss 1.790 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.712, lat_loss 22.020
09/21 11:48:16 PM | Train: [ 94/180] Step 100/1249 Loss 1.606 Prec@(1,3) (87.7%, 99.5%), ce_loss 0.712, lat_loss 22.020
09/21 11:48:41 PM | Train: [ 94/180] Step 150/1249 Loss 1.652 Prec@(1,3) (87.2%, 99.5%), ce_loss 0.712, lat_loss 22.020
09/21 11:49:05 PM | Train: [ 94/180] Step 200/1249 Loss 1.616 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.712, lat_loss 22.020
09/21 11:49:30 PM | Train: [ 94/180] Step 250/1249 Loss 1.608 Prec@(1,3) (87.6%, 99.5%), ce_loss 0.712, lat_loss 22.020
09/21 11:49:52 PM | Train: [ 94/180] Step 300/1249 Loss 1.654 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.712, lat_loss 22.020
09/21 11:50:13 PM | Train: [ 94/180] Step 350/1249 Loss 1.635 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.712, lat_loss 22.020
09/21 11:50:34 PM | Train: [ 94/180] Step 400/1249 Loss 1.642 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.712, lat_loss 22.020
09/21 11:50:57 PM | Train: [ 94/180] Step 450/1249 Loss 1.656 Prec@(1,3) (87.2%, 99.5%), ce_loss 0.712, lat_loss 22.020
09/21 11:51:19 PM | Train: [ 94/180] Step 500/1249 Loss 1.648 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.711, lat_loss 22.020
09/21 11:51:43 PM | Train: [ 94/180] Step 550/1249 Loss 1.643 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.711, lat_loss 22.020
09/21 11:52:08 PM | Train: [ 94/180] Step 600/1249 Loss 1.632 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.711, lat_loss 22.019
09/21 11:52:33 PM | Train: [ 94/180] Step 650/1249 Loss 1.627 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.711, lat_loss 22.019
09/21 11:52:57 PM | Train: [ 94/180] Step 700/1249 Loss 1.620 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.711, lat_loss 22.019
09/21 11:53:22 PM | Train: [ 94/180] Step 750/1249 Loss 1.619 Prec@(1,3) (87.5%, 99.6%), ce_loss 0.711, lat_loss 22.019
09/21 11:53:47 PM | Train: [ 94/180] Step 800/1249 Loss 1.624 Prec@(1,3) (87.4%, 99.6%), ce_loss 0.711, lat_loss 22.019
09/21 11:54:12 PM | Train: [ 94/180] Step 850/1249 Loss 1.619 Prec@(1,3) (87.5%, 99.6%), ce_loss 0.711, lat_loss 22.019
09/21 11:54:37 PM | Train: [ 94/180] Step 900/1249 Loss 1.626 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.711, lat_loss 22.019
09/21 11:55:02 PM | Train: [ 94/180] Step 950/1249 Loss 1.619 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.710, lat_loss 22.019
09/21 11:55:27 PM | Train: [ 94/180] Step 1000/1249 Loss 1.631 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.710, lat_loss 22.019
09/21 11:55:51 PM | Train: [ 94/180] Step 1050/1249 Loss 1.629 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.710, lat_loss 22.019
09/21 11:56:14 PM | Train: [ 94/180] Step 1100/1249 Loss 1.629 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.710, lat_loss 22.019
09/21 11:56:35 PM | Train: [ 94/180] Step 1150/1249 Loss 1.628 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.710, lat_loss 22.019
09/21 11:56:58 PM | Train: [ 94/180] Step 1200/1249 Loss 1.624 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.710, lat_loss 22.019
09/21 11:57:22 PM | Train: [ 94/180] Step 1249/1249 Loss 1.625 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.710, lat_loss 22.019
09/21 11:57:22 PM | _w_step_train: [ 94/180] Final Prec@1 87.4475% Time 593.33
09/21 11:57:22 PM | Start to train theta for epoch 93
09/21 11:57:42 PM | Train: [ 94/180] Step 050/312 Loss 2.380 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.710, lat_loss 22.019
09/21 11:58:01 PM | Train: [ 94/180] Step 100/312 Loss 2.346 Prec@(1,3) (82.7%, 99.0%), ce_loss 0.710, lat_loss 22.019
09/21 11:58:20 PM | Train: [ 94/180] Step 150/312 Loss 2.229 Prec@(1,3) (83.6%, 99.1%), ce_loss 0.710, lat_loss 22.019
09/21 11:58:39 PM | Train: [ 94/180] Step 200/312 Loss 2.204 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.710, lat_loss 22.019
09/21 11:58:58 PM | Train: [ 94/180] Step 250/312 Loss 2.210 Prec@(1,3) (83.8%, 99.1%), ce_loss 0.710, lat_loss 22.019
09/21 11:59:17 PM | Train: [ 94/180] Step 300/312 Loss 2.188 Prec@(1,3) (84.1%, 99.1%), ce_loss 0.710, lat_loss 22.019
09/21 11:59:22 PM | Train: [ 94/180] Step 312/312 Loss 2.204 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.710, lat_loss 22.019
09/21 11:59:22 PM | _theta_step_train: [ 94/180] Final Prec@1 83.9300% Time 119.86
09/21 11:59:27 PM | Valid: [ 94/180] Step 050/312 Loss 2.119 Prec@(1,3) (83.2%, 99.3%), ce_loss 0.709, lat_loss 22.019
09/21 11:59:32 PM | Valid: [ 94/180] Step 100/312 Loss 2.211 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.709, lat_loss 22.019
09/21 11:59:37 PM | Valid: [ 94/180] Step 150/312 Loss 2.285 Prec@(1,3) (83.0%, 98.9%), ce_loss 0.709, lat_loss 22.019
09/21 11:59:41 PM | Valid: [ 94/180] Step 200/312 Loss 2.281 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.709, lat_loss 22.019
09/21 11:59:46 PM | Valid: [ 94/180] Step 250/312 Loss 2.258 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.709, lat_loss 22.019
09/21 11:59:51 PM | Valid: [ 94/180] Step 300/312 Loss 2.210 Prec@(1,3) (83.6%, 99.1%), ce_loss 0.709, lat_loss 22.019
09/21 11:59:52 PM | Valid: [ 94/180] Step 312/312 Loss 2.205 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.709, lat_loss 22.019
09/21 11:59:52 PM | val: [ 94/180] Final Prec@1 83.5400% Time 29.81
09/21 11:59:52 PM | Start to train weights for epoch 94
09/22 12:00:18 AM | Train: [ 95/180] Step 050/1249 Loss 1.694 Prec@(1,3) (87.5%, 99.3%), ce_loss 0.709, lat_loss 22.019
09/22 12:00:43 AM | Train: [ 95/180] Step 100/1249 Loss 1.674 Prec@(1,3) (87.6%, 99.2%), ce_loss 0.709, lat_loss 22.019
09/22 12:01:07 AM | Train: [ 95/180] Step 150/1249 Loss 1.626 Prec@(1,3) (87.9%, 99.4%), ce_loss 0.709, lat_loss 22.019
09/22 12:01:32 AM | Train: [ 95/180] Step 200/1249 Loss 1.788 Prec@(1,3) (87.0%, 99.1%), ce_loss 0.709, lat_loss 22.019
09/22 12:01:57 AM | Train: [ 95/180] Step 250/1249 Loss 1.718 Prec@(1,3) (87.3%, 99.2%), ce_loss 0.709, lat_loss 22.019
09/22 12:02:22 AM | Train: [ 95/180] Step 300/1249 Loss 1.717 Prec@(1,3) (87.2%, 99.2%), ce_loss 0.709, lat_loss 22.019
09/22 12:02:47 AM | Train: [ 95/180] Step 350/1249 Loss 1.671 Prec@(1,3) (87.5%, 99.2%), ce_loss 0.708, lat_loss 22.019
09/22 12:03:11 AM | Train: [ 95/180] Step 400/1249 Loss 1.676 Prec@(1,3) (87.4%, 99.3%), ce_loss 0.708, lat_loss 22.019
09/22 12:03:36 AM | Train: [ 95/180] Step 450/1249 Loss 1.677 Prec@(1,3) (87.4%, 99.3%), ce_loss 0.708, lat_loss 22.019
09/22 12:04:01 AM | Train: [ 95/180] Step 500/1249 Loss 1.665 Prec@(1,3) (87.4%, 99.3%), ce_loss 0.708, lat_loss 22.019
09/22 12:04:26 AM | Train: [ 95/180] Step 550/1249 Loss 1.673 Prec@(1,3) (87.4%, 99.3%), ce_loss 0.708, lat_loss 22.019
09/22 12:04:51 AM | Train: [ 95/180] Step 600/1249 Loss 1.668 Prec@(1,3) (87.4%, 99.3%), ce_loss 0.708, lat_loss 22.018
09/22 12:05:16 AM | Train: [ 95/180] Step 650/1249 Loss 1.666 Prec@(1,3) (87.4%, 99.3%), ce_loss 0.708, lat_loss 22.018
09/22 12:05:41 AM | Train: [ 95/180] Step 700/1249 Loss 1.657 Prec@(1,3) (87.4%, 99.3%), ce_loss 0.708, lat_loss 22.018
09/22 12:06:06 AM | Train: [ 95/180] Step 750/1249 Loss 1.635 Prec@(1,3) (87.5%, 99.3%), ce_loss 0.708, lat_loss 22.018
09/22 12:06:31 AM | Train: [ 95/180] Step 800/1249 Loss 1.634 Prec@(1,3) (87.6%, 99.3%), ce_loss 0.708, lat_loss 22.018
09/22 12:06:56 AM | Train: [ 95/180] Step 850/1249 Loss 1.633 Prec@(1,3) (87.6%, 99.3%), ce_loss 0.707, lat_loss 22.018
09/22 12:07:21 AM | Train: [ 95/180] Step 900/1249 Loss 1.633 Prec@(1,3) (87.6%, 99.4%), ce_loss 0.707, lat_loss 22.018
09/22 12:07:46 AM | Train: [ 95/180] Step 950/1249 Loss 1.629 Prec@(1,3) (87.6%, 99.4%), ce_loss 0.707, lat_loss 22.018
09/22 12:08:11 AM | Train: [ 95/180] Step 1000/1249 Loss 1.628 Prec@(1,3) (87.5%, 99.4%), ce_loss 0.707, lat_loss 22.018
09/22 12:08:36 AM | Train: [ 95/180] Step 1050/1249 Loss 1.624 Prec@(1,3) (87.6%, 99.4%), ce_loss 0.707, lat_loss 22.018
09/22 12:09:01 AM | Train: [ 95/180] Step 1100/1249 Loss 1.621 Prec@(1,3) (87.6%, 99.4%), ce_loss 0.707, lat_loss 22.018
09/22 12:09:24 AM | Train: [ 95/180] Step 1150/1249 Loss 1.625 Prec@(1,3) (87.5%, 99.4%), ce_loss 0.707, lat_loss 22.018
09/22 12:09:40 AM | Train: [ 95/180] Step 1200/1249 Loss 1.620 Prec@(1,3) (87.6%, 99.4%), ce_loss 0.707, lat_loss 22.018
09/22 12:09:56 AM | Train: [ 95/180] Step 1249/1249 Loss 1.622 Prec@(1,3) (87.6%, 99.4%), ce_loss 0.707, lat_loss 22.018
09/22 12:09:56 AM | _w_step_train: [ 95/180] Final Prec@1 87.5700% Time 603.89
09/22 12:09:56 AM | Start to train theta for epoch 94
09/22 12:10:17 AM | Train: [ 95/180] Step 050/312 Loss 2.090 Prec@(1,3) (84.2%, 99.4%), ce_loss 0.707, lat_loss 22.018
09/22 12:10:37 AM | Train: [ 95/180] Step 100/312 Loss 2.077 Prec@(1,3) (84.5%, 99.4%), ce_loss 0.707, lat_loss 22.018
09/22 12:10:58 AM | Train: [ 95/180] Step 150/312 Loss 2.102 Prec@(1,3) (84.0%, 99.4%), ce_loss 0.706, lat_loss 22.018
09/22 12:11:16 AM | Train: [ 95/180] Step 200/312 Loss 2.123 Prec@(1,3) (83.9%, 99.2%), ce_loss 0.706, lat_loss 22.018
09/22 12:11:33 AM | Train: [ 95/180] Step 250/312 Loss 2.143 Prec@(1,3) (83.8%, 99.2%), ce_loss 0.706, lat_loss 22.018
09/22 12:11:53 AM | Train: [ 95/180] Step 300/312 Loss 2.112 Prec@(1,3) (84.1%, 99.2%), ce_loss 0.706, lat_loss 22.018
09/22 12:11:58 AM | Train: [ 95/180] Step 312/312 Loss 2.100 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.706, lat_loss 22.018
09/22 12:11:59 AM | _theta_step_train: [ 95/180] Final Prec@1 84.1700% Time 123.00
09/22 12:12:04 AM | Valid: [ 95/180] Step 050/312 Loss 1.914 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.706, lat_loss 22.018
09/22 12:12:09 AM | Valid: [ 95/180] Step 100/312 Loss 2.075 Prec@(1,3) (84.2%, 99.1%), ce_loss 0.706, lat_loss 22.018
09/22 12:12:13 AM | Valid: [ 95/180] Step 150/312 Loss 2.138 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.706, lat_loss 22.018
09/22 12:12:18 AM | Valid: [ 95/180] Step 200/312 Loss 2.138 Prec@(1,3) (84.0%, 99.1%), ce_loss 0.706, lat_loss 22.018
09/22 12:12:23 AM | Valid: [ 95/180] Step 250/312 Loss 2.103 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.706, lat_loss 22.018
09/22 12:12:27 AM | Valid: [ 95/180] Step 300/312 Loss 2.104 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.706, lat_loss 22.018
09/22 12:12:28 AM | Valid: [ 95/180] Step 312/312 Loss 2.096 Prec@(1,3) (84.2%, 99.3%), ce_loss 0.706, lat_loss 22.018
09/22 12:12:28 AM | val: [ 95/180] Final Prec@1 84.2400% Time 29.64
09/22 12:12:28 AM | Best top1 acc by now. Save model
09/22 12:12:29 AM | Start to train weights for epoch 95
09/22 12:12:54 AM | Train: [ 96/180] Step 050/1249 Loss 1.571 Prec@(1,3) (87.9%, 99.4%), ce_loss 0.706, lat_loss 22.018
09/22 12:13:18 AM | Train: [ 96/180] Step 100/1249 Loss 1.507 Prec@(1,3) (88.0%, 99.6%), ce_loss 0.706, lat_loss 22.018
09/22 12:13:42 AM | Train: [ 96/180] Step 150/1249 Loss 1.521 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.706, lat_loss 22.018
09/22 12:14:07 AM | Train: [ 96/180] Step 200/1249 Loss 1.538 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.705, lat_loss 22.018
09/22 12:14:32 AM | Train: [ 96/180] Step 250/1249 Loss 1.540 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.705, lat_loss 22.018
09/22 12:14:56 AM | Train: [ 96/180] Step 300/1249 Loss 1.542 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.705, lat_loss 22.018
09/22 12:15:20 AM | Train: [ 96/180] Step 350/1249 Loss 1.556 Prec@(1,3) (88.0%, 99.6%), ce_loss 0.705, lat_loss 22.018
09/22 12:15:45 AM | Train: [ 96/180] Step 400/1249 Loss 1.559 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.705, lat_loss 22.018
09/22 12:16:10 AM | Train: [ 96/180] Step 450/1249 Loss 1.574 Prec@(1,3) (88.0%, 99.5%), ce_loss 0.705, lat_loss 22.018
09/22 12:16:34 AM | Train: [ 96/180] Step 500/1249 Loss 1.569 Prec@(1,3) (88.0%, 99.5%), ce_loss 0.705, lat_loss 22.018
09/22 12:16:58 AM | Train: [ 96/180] Step 550/1249 Loss 1.559 Prec@(1,3) (88.0%, 99.5%), ce_loss 0.705, lat_loss 22.018
09/22 12:17:23 AM | Train: [ 96/180] Step 600/1249 Loss 1.574 Prec@(1,3) (88.0%, 99.5%), ce_loss 0.705, lat_loss 22.018
09/22 12:17:47 AM | Train: [ 96/180] Step 650/1249 Loss 1.564 Prec@(1,3) (88.0%, 99.5%), ce_loss 0.705, lat_loss 22.018
09/22 12:18:11 AM | Train: [ 96/180] Step 700/1249 Loss 1.564 Prec@(1,3) (87.9%, 99.5%), ce_loss 0.704, lat_loss 22.018
09/22 12:18:35 AM | Train: [ 96/180] Step 750/1249 Loss 1.560 Prec@(1,3) (88.0%, 99.5%), ce_loss 0.704, lat_loss 22.017
09/22 12:19:00 AM | Train: [ 96/180] Step 800/1249 Loss 1.557 Prec@(1,3) (88.0%, 99.5%), ce_loss 0.704, lat_loss 22.017
09/22 12:19:25 AM | Train: [ 96/180] Step 850/1249 Loss 1.550 Prec@(1,3) (88.0%, 99.5%), ce_loss 0.704, lat_loss 22.017
09/22 12:19:49 AM | Train: [ 96/180] Step 900/1249 Loss 1.541 Prec@(1,3) (88.0%, 99.5%), ce_loss 0.704, lat_loss 22.017
09/22 12:20:14 AM | Train: [ 96/180] Step 950/1249 Loss 1.543 Prec@(1,3) (88.0%, 99.5%), ce_loss 0.704, lat_loss 22.017
09/22 12:20:38 AM | Train: [ 96/180] Step 1000/1249 Loss 1.546 Prec@(1,3) (88.0%, 99.5%), ce_loss 0.704, lat_loss 22.017
09/22 12:21:03 AM | Train: [ 96/180] Step 1050/1249 Loss 1.551 Prec@(1,3) (87.9%, 99.5%), ce_loss 0.704, lat_loss 22.017
09/22 12:21:28 AM | Train: [ 96/180] Step 1100/1249 Loss 1.553 Prec@(1,3) (87.9%, 99.5%), ce_loss 0.704, lat_loss 22.017
09/22 12:21:53 AM | Train: [ 96/180] Step 1150/1249 Loss 1.563 Prec@(1,3) (87.9%, 99.5%), ce_loss 0.704, lat_loss 22.017
09/22 12:22:17 AM | Train: [ 96/180] Step 1200/1249 Loss 1.557 Prec@(1,3) (87.9%, 99.5%), ce_loss 0.703, lat_loss 22.017
09/22 12:22:41 AM | Train: [ 96/180] Step 1249/1249 Loss 1.561 Prec@(1,3) (87.9%, 99.5%), ce_loss 0.703, lat_loss 22.017
09/22 12:22:42 AM | _w_step_train: [ 96/180] Final Prec@1 87.8600% Time 612.86
09/22 12:22:42 AM | Start to train theta for epoch 95
09/22 12:23:03 AM | Train: [ 96/180] Step 050/312 Loss 1.967 Prec@(1,3) (85.2%, 99.3%), ce_loss 0.703, lat_loss 22.017
09/22 12:23:24 AM | Train: [ 96/180] Step 100/312 Loss 2.082 Prec@(1,3) (84.2%, 99.1%), ce_loss 0.703, lat_loss 22.017
09/22 12:23:45 AM | Train: [ 96/180] Step 150/312 Loss 2.098 Prec@(1,3) (83.9%, 99.3%), ce_loss 0.703, lat_loss 22.017
09/22 12:24:06 AM | Train: [ 96/180] Step 200/312 Loss 2.126 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.703, lat_loss 22.017
09/22 12:24:26 AM | Train: [ 96/180] Step 250/312 Loss 2.138 Prec@(1,3) (83.8%, 99.1%), ce_loss 0.703, lat_loss 22.017
09/22 12:24:47 AM | Train: [ 96/180] Step 300/312 Loss 2.124 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.703, lat_loss 22.017
09/22 12:24:52 AM | Train: [ 96/180] Step 312/312 Loss 2.114 Prec@(1,3) (84.0%, 99.2%), ce_loss 0.703, lat_loss 22.017
09/22 12:24:52 AM | _theta_step_train: [ 96/180] Final Prec@1 83.9900% Time 130.63
09/22 12:24:57 AM | Valid: [ 96/180] Step 050/312 Loss 2.004 Prec@(1,3) (84.4%, 99.0%), ce_loss 0.703, lat_loss 22.017
09/22 12:25:01 AM | Valid: [ 96/180] Step 100/312 Loss 2.035 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.703, lat_loss 22.017
09/22 12:25:05 AM | Valid: [ 96/180] Step 150/312 Loss 2.033 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.703, lat_loss 22.017
09/22 12:25:10 AM | Valid: [ 96/180] Step 200/312 Loss 2.025 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.703, lat_loss 22.017
09/22 12:25:14 AM | Valid: [ 96/180] Step 250/312 Loss 2.021 Prec@(1,3) (84.5%, 99.3%), ce_loss 0.703, lat_loss 22.017
09/22 12:25:18 AM | Valid: [ 96/180] Step 300/312 Loss 2.029 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.702, lat_loss 22.017
09/22 12:25:19 AM | Valid: [ 96/180] Step 312/312 Loss 2.030 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.702, lat_loss 22.017
09/22 12:25:19 AM | val: [ 96/180] Final Prec@1 84.2700% Time 27.13
09/22 12:25:19 AM | Best top1 acc by now. Save model
09/22 12:25:19 AM | Start to train weights for epoch 96
09/22 12:25:45 AM | Train: [ 97/180] Step 050/1249 Loss 1.429 Prec@(1,3) (89.2%, 99.9%), ce_loss 0.702, lat_loss 22.017
09/22 12:26:09 AM | Train: [ 97/180] Step 100/1249 Loss 1.538 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.702, lat_loss 22.017
09/22 12:26:33 AM | Train: [ 97/180] Step 150/1249 Loss 1.510 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.702, lat_loss 22.017
09/22 12:26:58 AM | Train: [ 97/180] Step 200/1249 Loss 1.506 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.702, lat_loss 22.017
09/22 12:27:22 AM | Train: [ 97/180] Step 250/1249 Loss 1.507 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.702, lat_loss 22.017
09/22 12:27:46 AM | Train: [ 97/180] Step 300/1249 Loss 1.508 Prec@(1,3) (88.4%, 99.6%), ce_loss 0.702, lat_loss 22.017
09/22 12:28:10 AM | Train: [ 97/180] Step 350/1249 Loss 1.508 Prec@(1,3) (88.4%, 99.6%), ce_loss 0.702, lat_loss 22.017
09/22 12:28:28 AM | Train: [ 97/180] Step 400/1249 Loss 1.507 Prec@(1,3) (88.4%, 99.6%), ce_loss 0.702, lat_loss 22.017
09/22 12:28:44 AM | Train: [ 97/180] Step 450/1249 Loss 1.521 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.702, lat_loss 22.017
09/22 12:29:00 AM | Train: [ 97/180] Step 500/1249 Loss 1.520 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.701, lat_loss 22.017
09/22 12:29:16 AM | Train: [ 97/180] Step 550/1249 Loss 1.527 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.701, lat_loss 22.017
09/22 12:29:32 AM | Train: [ 97/180] Step 600/1249 Loss 1.537 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.701, lat_loss 22.017
09/22 12:29:49 AM | Train: [ 97/180] Step 650/1249 Loss 1.540 Prec@(1,3) (88.0%, 99.6%), ce_loss 0.701, lat_loss 22.017
09/22 12:30:05 AM | Train: [ 97/180] Step 700/1249 Loss 1.552 Prec@(1,3) (87.9%, 99.6%), ce_loss 0.701, lat_loss 22.017
09/22 12:30:21 AM | Train: [ 97/180] Step 750/1249 Loss 1.557 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.701, lat_loss 22.017
09/22 12:30:37 AM | Train: [ 97/180] Step 800/1249 Loss 1.564 Prec@(1,3) (87.7%, 99.6%), ce_loss 0.701, lat_loss 22.017
09/22 12:30:53 AM | Train: [ 97/180] Step 850/1249 Loss 1.563 Prec@(1,3) (87.7%, 99.6%), ce_loss 0.701, lat_loss 22.017
09/22 12:31:09 AM | Train: [ 97/180] Step 900/1249 Loss 1.550 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.701, lat_loss 22.017
09/22 12:31:25 AM | Train: [ 97/180] Step 950/1249 Loss 1.555 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.701, lat_loss 22.017
09/22 12:31:42 AM | Train: [ 97/180] Step 1000/1249 Loss 1.549 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.700, lat_loss 22.017
09/22 12:31:58 AM | Train: [ 97/180] Step 1050/1249 Loss 1.539 Prec@(1,3) (87.9%, 99.6%), ce_loss 0.700, lat_loss 22.017
09/22 12:32:14 AM | Train: [ 97/180] Step 1100/1249 Loss 1.541 Prec@(1,3) (87.9%, 99.6%), ce_loss 0.700, lat_loss 22.017
09/22 12:32:30 AM | Train: [ 97/180] Step 1150/1249 Loss 1.539 Prec@(1,3) (87.9%, 99.6%), ce_loss 0.700, lat_loss 22.016
09/22 12:32:47 AM | Train: [ 97/180] Step 1200/1249 Loss 1.543 Prec@(1,3) (87.9%, 99.6%), ce_loss 0.700, lat_loss 22.016
09/22 12:33:02 AM | Train: [ 97/180] Step 1249/1249 Loss 1.554 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.700, lat_loss 22.016
09/22 12:33:03 AM | _w_step_train: [ 97/180] Final Prec@1 87.8000% Time 463.06
09/22 12:33:03 AM | Start to train theta for epoch 96
09/22 12:33:24 AM | Train: [ 97/180] Step 050/312 Loss 2.174 Prec@(1,3) (84.3%, 98.8%), ce_loss 0.700, lat_loss 22.016
09/22 12:33:45 AM | Train: [ 97/180] Step 100/312 Loss 2.199 Prec@(1,3) (83.7%, 98.8%), ce_loss 0.700, lat_loss 22.016
09/22 12:34:06 AM | Train: [ 97/180] Step 150/312 Loss 2.268 Prec@(1,3) (83.4%, 98.8%), ce_loss 0.700, lat_loss 22.016
09/22 12:34:26 AM | Train: [ 97/180] Step 200/312 Loss 2.218 Prec@(1,3) (83.5%, 99.0%), ce_loss 0.700, lat_loss 22.016
09/22 12:34:47 AM | Train: [ 97/180] Step 250/312 Loss 2.221 Prec@(1,3) (83.4%, 99.0%), ce_loss 0.700, lat_loss 22.016
09/22 12:35:06 AM | Train: [ 97/180] Step 300/312 Loss 2.211 Prec@(1,3) (83.5%, 99.0%), ce_loss 0.700, lat_loss 22.016
09/22 12:35:11 AM | Train: [ 97/180] Step 312/312 Loss 2.202 Prec@(1,3) (83.5%, 99.0%), ce_loss 0.700, lat_loss 22.016
09/22 12:35:11 AM | _theta_step_train: [ 97/180] Final Prec@1 83.4800% Time 128.73
09/22 12:35:16 AM | Valid: [ 97/180] Step 050/312 Loss 2.137 Prec@(1,3) (83.1%, 99.3%), ce_loss 0.700, lat_loss 22.016
09/22 12:35:21 AM | Valid: [ 97/180] Step 100/312 Loss 2.215 Prec@(1,3) (82.6%, 98.8%), ce_loss 0.700, lat_loss 22.016
09/22 12:35:25 AM | Valid: [ 97/180] Step 150/312 Loss 2.356 Prec@(1,3) (82.0%, 98.6%), ce_loss 0.699, lat_loss 22.016
09/22 12:35:29 AM | Valid: [ 97/180] Step 200/312 Loss 2.350 Prec@(1,3) (82.2%, 98.6%), ce_loss 0.699, lat_loss 22.016
09/22 12:35:34 AM | Valid: [ 97/180] Step 250/312 Loss 2.301 Prec@(1,3) (82.7%, 98.7%), ce_loss 0.699, lat_loss 22.016
09/22 12:35:38 AM | Valid: [ 97/180] Step 300/312 Loss 2.266 Prec@(1,3) (82.8%, 98.8%), ce_loss 0.699, lat_loss 22.016
09/22 12:35:39 AM | Valid: [ 97/180] Step 312/312 Loss 2.273 Prec@(1,3) (82.6%, 98.8%), ce_loss 0.699, lat_loss 22.016
09/22 12:35:39 AM | val: [ 97/180] Final Prec@1 82.6400% Time 27.81
09/22 12:35:39 AM | Start to train weights for epoch 97
09/22 12:36:02 AM | Train: [ 98/180] Step 050/1249 Loss 1.600 Prec@(1,3) (87.7%, 99.5%), ce_loss 0.699, lat_loss 22.016
09/22 12:36:22 AM | Train: [ 98/180] Step 100/1249 Loss 1.843 Prec@(1,3) (86.9%, 98.9%), ce_loss 0.699, lat_loss 22.016
09/22 12:36:43 AM | Train: [ 98/180] Step 150/1249 Loss 1.758 Prec@(1,3) (87.3%, 99.1%), ce_loss 0.699, lat_loss 22.016
09/22 12:37:04 AM | Train: [ 98/180] Step 200/1249 Loss 1.692 Prec@(1,3) (87.6%, 99.2%), ce_loss 0.699, lat_loss 22.016
09/22 12:37:25 AM | Train: [ 98/180] Step 250/1249 Loss 1.671 Prec@(1,3) (87.7%, 99.3%), ce_loss 0.699, lat_loss 22.016
09/22 12:37:49 AM | Train: [ 98/180] Step 300/1249 Loss 1.650 Prec@(1,3) (87.7%, 99.4%), ce_loss 0.699, lat_loss 22.016
09/22 12:38:14 AM | Train: [ 98/180] Step 350/1249 Loss 1.621 Prec@(1,3) (87.9%, 99.4%), ce_loss 0.699, lat_loss 22.016
09/22 12:38:38 AM | Train: [ 98/180] Step 400/1249 Loss 1.597 Prec@(1,3) (88.1%, 99.4%), ce_loss 0.699, lat_loss 22.016
09/22 12:39:02 AM | Train: [ 98/180] Step 450/1249 Loss 1.586 Prec@(1,3) (88.1%, 99.5%), ce_loss 0.698, lat_loss 22.016
09/22 12:39:25 AM | Train: [ 98/180] Step 500/1249 Loss 1.601 Prec@(1,3) (88.0%, 99.5%), ce_loss 0.698, lat_loss 22.016
09/22 12:39:49 AM | Train: [ 98/180] Step 550/1249 Loss 1.615 Prec@(1,3) (87.8%, 99.5%), ce_loss 0.698, lat_loss 22.016
09/22 12:40:14 AM | Train: [ 98/180] Step 600/1249 Loss 1.609 Prec@(1,3) (87.8%, 99.5%), ce_loss 0.698, lat_loss 22.016
09/22 12:40:39 AM | Train: [ 98/180] Step 650/1249 Loss 1.588 Prec@(1,3) (87.9%, 99.6%), ce_loss 0.698, lat_loss 22.016
09/22 12:41:03 AM | Train: [ 98/180] Step 700/1249 Loss 1.589 Prec@(1,3) (87.9%, 99.5%), ce_loss 0.698, lat_loss 22.016
09/22 12:41:28 AM | Train: [ 98/180] Step 750/1249 Loss 1.589 Prec@(1,3) (87.8%, 99.5%), ce_loss 0.698, lat_loss 22.016
09/22 12:41:53 AM | Train: [ 98/180] Step 800/1249 Loss 1.597 Prec@(1,3) (87.7%, 99.6%), ce_loss 0.698, lat_loss 22.016
09/22 12:42:18 AM | Train: [ 98/180] Step 850/1249 Loss 1.599 Prec@(1,3) (87.7%, 99.6%), ce_loss 0.698, lat_loss 22.016
09/22 12:42:42 AM | Train: [ 98/180] Step 900/1249 Loss 1.599 Prec@(1,3) (87.7%, 99.5%), ce_loss 0.698, lat_loss 22.016
09/22 12:43:07 AM | Train: [ 98/180] Step 950/1249 Loss 1.589 Prec@(1,3) (87.7%, 99.5%), ce_loss 0.697, lat_loss 22.016
09/22 12:43:31 AM | Train: [ 98/180] Step 1000/1249 Loss 1.585 Prec@(1,3) (87.7%, 99.5%), ce_loss 0.697, lat_loss 22.016
09/22 12:43:55 AM | Train: [ 98/180] Step 1050/1249 Loss 1.590 Prec@(1,3) (87.7%, 99.5%), ce_loss 0.697, lat_loss 22.016
09/22 12:44:18 AM | Train: [ 98/180] Step 1100/1249 Loss 1.579 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.697, lat_loss 22.016
09/22 12:44:39 AM | Train: [ 98/180] Step 1150/1249 Loss 1.595 Prec@(1,3) (87.7%, 99.5%), ce_loss 0.697, lat_loss 22.016
09/22 12:45:01 AM | Train: [ 98/180] Step 1200/1249 Loss 1.598 Prec@(1,3) (87.7%, 99.5%), ce_loss 0.697, lat_loss 22.016
09/22 12:45:25 AM | Train: [ 98/180] Step 1249/1249 Loss 1.602 Prec@(1,3) (87.6%, 99.5%), ce_loss 0.697, lat_loss 22.016
09/22 12:45:25 AM | _w_step_train: [ 98/180] Final Prec@1 87.6300% Time 585.97
09/22 12:45:25 AM | Start to train theta for epoch 97
09/22 12:45:45 AM | Train: [ 98/180] Step 050/312 Loss 2.127 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.697, lat_loss 22.016
09/22 12:46:06 AM | Train: [ 98/180] Step 100/312 Loss 1.980 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.697, lat_loss 22.016
09/22 12:46:27 AM | Train: [ 98/180] Step 150/312 Loss 2.110 Prec@(1,3) (84.2%, 98.8%), ce_loss 0.697, lat_loss 22.016
09/22 12:46:49 AM | Train: [ 98/180] Step 200/312 Loss 2.058 Prec@(1,3) (84.4%, 99.0%), ce_loss 0.697, lat_loss 22.016
09/22 12:47:10 AM | Train: [ 98/180] Step 250/312 Loss 2.065 Prec@(1,3) (84.4%, 99.0%), ce_loss 0.697, lat_loss 22.016
09/22 12:47:32 AM | Train: [ 98/180] Step 300/312 Loss 2.091 Prec@(1,3) (84.0%, 99.0%), ce_loss 0.697, lat_loss 22.016
09/22 12:47:37 AM | Train: [ 98/180] Step 312/312 Loss 2.106 Prec@(1,3) (83.9%, 99.0%), ce_loss 0.697, lat_loss 22.016
09/22 12:47:37 AM | _theta_step_train: [ 98/180] Final Prec@1 83.8700% Time 131.98
09/22 12:47:42 AM | Valid: [ 98/180] Step 050/312 Loss 1.950 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.696, lat_loss 22.016
09/22 12:47:47 AM | Valid: [ 98/180] Step 100/312 Loss 2.056 Prec@(1,3) (84.0%, 99.1%), ce_loss 0.696, lat_loss 22.016
09/22 12:47:52 AM | Valid: [ 98/180] Step 150/312 Loss 2.083 Prec@(1,3) (83.9%, 99.0%), ce_loss 0.696, lat_loss 22.016
09/22 12:47:57 AM | Valid: [ 98/180] Step 200/312 Loss 2.066 Prec@(1,3) (84.2%, 99.1%), ce_loss 0.696, lat_loss 22.016
09/22 12:48:01 AM | Valid: [ 98/180] Step 250/312 Loss 2.148 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.696, lat_loss 22.016
09/22 12:48:06 AM | Valid: [ 98/180] Step 300/312 Loss 2.137 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.696, lat_loss 22.015
09/22 12:48:07 AM | Valid: [ 98/180] Step 312/312 Loss 2.149 Prec@(1,3) (83.6%, 99.0%), ce_loss 0.696, lat_loss 22.015
09/22 12:48:07 AM | val: [ 98/180] Final Prec@1 83.6100% Time 30.06
09/22 12:48:07 AM | Start to train weights for epoch 98
09/22 12:48:33 AM | Train: [ 99/180] Step 050/1249 Loss 1.675 Prec@(1,3) (86.3%, 99.6%), ce_loss 0.696, lat_loss 22.015
09/22 12:49:00 AM | Train: [ 99/180] Step 100/1249 Loss 1.488 Prec@(1,3) (88.4%, 99.7%), ce_loss 0.696, lat_loss 22.015
09/22 12:49:26 AM | Train: [ 99/180] Step 150/1249 Loss 1.540 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.696, lat_loss 22.015
09/22 12:49:52 AM | Train: [ 99/180] Step 200/1249 Loss 1.520 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.696, lat_loss 22.015
09/22 12:50:18 AM | Train: [ 99/180] Step 250/1249 Loss 1.526 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.696, lat_loss 22.015
09/22 12:50:44 AM | Train: [ 99/180] Step 300/1249 Loss 1.552 Prec@(1,3) (87.9%, 99.5%), ce_loss 0.696, lat_loss 22.015
09/22 12:51:11 AM | Train: [ 99/180] Step 350/1249 Loss 1.535 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.696, lat_loss 22.015
09/22 12:51:37 AM | Train: [ 99/180] Step 400/1249 Loss 1.526 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.695, lat_loss 22.015
09/22 12:52:03 AM | Train: [ 99/180] Step 450/1249 Loss 1.526 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.695, lat_loss 22.015
09/22 12:52:29 AM | Train: [ 99/180] Step 500/1249 Loss 1.512 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.695, lat_loss 22.015
09/22 12:52:55 AM | Train: [ 99/180] Step 550/1249 Loss 1.517 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.695, lat_loss 22.015
09/22 12:53:21 AM | Train: [ 99/180] Step 600/1249 Loss 1.514 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.695, lat_loss 22.015
09/22 12:53:43 AM | Train: [ 99/180] Step 650/1249 Loss 1.518 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.695, lat_loss 22.015
09/22 12:53:59 AM | Train: [ 99/180] Step 700/1249 Loss 1.518 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.695, lat_loss 22.015
09/22 12:54:15 AM | Train: [ 99/180] Step 750/1249 Loss 1.526 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.695, lat_loss 22.015
09/22 12:54:31 AM | Train: [ 99/180] Step 800/1249 Loss 1.529 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.695, lat_loss 22.015
09/22 12:54:47 AM | Train: [ 99/180] Step 850/1249 Loss 1.542 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.695, lat_loss 22.015
09/22 12:55:03 AM | Train: [ 99/180] Step 900/1249 Loss 1.533 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.694, lat_loss 22.015
09/22 12:55:18 AM | Train: [ 99/180] Step 950/1249 Loss 1.531 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.694, lat_loss 22.015
09/22 12:55:34 AM | Train: [ 99/180] Step 1000/1249 Loss 1.529 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.694, lat_loss 22.015
09/22 12:55:49 AM | Train: [ 99/180] Step 1050/1249 Loss 1.528 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.694, lat_loss 22.015
09/22 12:56:04 AM | Train: [ 99/180] Step 1100/1249 Loss 1.527 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.694, lat_loss 22.015
09/22 12:56:19 AM | Train: [ 99/180] Step 1150/1249 Loss 1.530 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.694, lat_loss 22.015
09/22 12:56:35 AM | Train: [ 99/180] Step 1200/1249 Loss 1.542 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.694, lat_loss 22.015
09/22 12:56:49 AM | Train: [ 99/180] Step 1249/1249 Loss 1.544 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.694, lat_loss 22.015
09/22 12:56:49 AM | _w_step_train: [ 99/180] Final Prec@1 88.0525% Time 522.20
09/22 12:56:49 AM | Start to train theta for epoch 98
09/22 12:57:11 AM | Train: [ 99/180] Step 050/312 Loss 1.907 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.694, lat_loss 22.015
09/22 12:57:23 AM | Train: [ 99/180] Step 100/312 Loss 2.047 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.694, lat_loss 22.015
09/22 12:57:34 AM | Train: [ 99/180] Step 150/312 Loss 2.074 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.694, lat_loss 22.015
09/22 12:57:46 AM | Train: [ 99/180] Step 200/312 Loss 2.088 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.694, lat_loss 22.015
09/22 12:57:57 AM | Train: [ 99/180] Step 250/312 Loss 2.106 Prec@(1,3) (84.4%, 99.1%), ce_loss 0.693, lat_loss 22.015
09/22 12:58:09 AM | Train: [ 99/180] Step 300/312 Loss 2.173 Prec@(1,3) (84.0%, 98.9%), ce_loss 0.693, lat_loss 22.015
09/22 12:58:11 AM | Train: [ 99/180] Step 312/312 Loss 2.157 Prec@(1,3) (84.2%, 98.9%), ce_loss 0.693, lat_loss 22.015
09/22 12:58:11 AM | _theta_step_train: [ 99/180] Final Prec@1 84.2100% Time 81.97
09/22 12:58:17 AM | Valid: [ 99/180] Step 050/312 Loss 2.067 Prec@(1,3) (83.7%, 98.5%), ce_loss 0.693, lat_loss 22.015
09/22 12:58:21 AM | Valid: [ 99/180] Step 100/312 Loss 2.149 Prec@(1,3) (83.9%, 98.6%), ce_loss 0.693, lat_loss 22.015
09/22 12:58:26 AM | Valid: [ 99/180] Step 150/312 Loss 2.191 Prec@(1,3) (83.5%, 98.7%), ce_loss 0.693, lat_loss 22.015
09/22 12:58:31 AM | Valid: [ 99/180] Step 200/312 Loss 2.118 Prec@(1,3) (84.0%, 98.9%), ce_loss 0.693, lat_loss 22.015
09/22 12:58:35 AM | Valid: [ 99/180] Step 250/312 Loss 2.084 Prec@(1,3) (84.3%, 99.0%), ce_loss 0.693, lat_loss 22.015
09/22 12:58:40 AM | Valid: [ 99/180] Step 300/312 Loss 2.104 Prec@(1,3) (84.1%, 99.0%), ce_loss 0.693, lat_loss 22.015
09/22 12:58:41 AM | Valid: [ 99/180] Step 312/312 Loss 2.105 Prec@(1,3) (84.0%, 99.0%), ce_loss 0.693, lat_loss 22.015
09/22 12:58:41 AM | val: [ 99/180] Final Prec@1 83.9900% Time 29.79
09/22 12:58:41 AM | Start to train weights for epoch 99
09/22 12:59:05 AM | Train: [100/180] Step 050/1249 Loss 1.586 Prec@(1,3) (88.6%, 99.4%), ce_loss 0.693, lat_loss 22.015
09/22 12:59:29 AM | Train: [100/180] Step 100/1249 Loss 1.658 Prec@(1,3) (88.3%, 99.3%), ce_loss 0.693, lat_loss 22.015
09/22 12:59:51 AM | Train: [100/180] Step 150/1249 Loss 1.607 Prec@(1,3) (88.1%, 99.4%), ce_loss 0.693, lat_loss 22.015
09/22 01:00:14 AM | Train: [100/180] Step 200/1249 Loss 1.551 Prec@(1,3) (88.4%, 99.5%), ce_loss 0.693, lat_loss 22.015
09/22 01:00:36 AM | Train: [100/180] Step 250/1249 Loss 1.573 Prec@(1,3) (88.3%, 99.5%), ce_loss 0.693, lat_loss 22.015
09/22 01:00:59 AM | Train: [100/180] Step 300/1249 Loss 1.544 Prec@(1,3) (88.5%, 99.5%), ce_loss 0.693, lat_loss 22.015
09/22 01:01:23 AM | Train: [100/180] Step 350/1249 Loss 1.505 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.692, lat_loss 22.015
09/22 01:01:46 AM | Train: [100/180] Step 400/1249 Loss 1.511 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.692, lat_loss 22.015
09/22 01:02:10 AM | Train: [100/180] Step 450/1249 Loss 1.523 Prec@(1,3) (88.6%, 99.5%), ce_loss 0.692, lat_loss 22.014
09/22 01:02:34 AM | Train: [100/180] Step 500/1249 Loss 1.557 Prec@(1,3) (88.4%, 99.5%), ce_loss 0.692, lat_loss 22.014
09/22 01:02:57 AM | Train: [100/180] Step 550/1249 Loss 1.549 Prec@(1,3) (88.3%, 99.5%), ce_loss 0.692, lat_loss 22.014
09/22 01:03:21 AM | Train: [100/180] Step 600/1249 Loss 1.553 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.692, lat_loss 22.014
09/22 01:03:43 AM | Train: [100/180] Step 650/1249 Loss 1.554 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.692, lat_loss 22.014
09/22 01:04:06 AM | Train: [100/180] Step 700/1249 Loss 1.545 Prec@(1,3) (88.3%, 99.5%), ce_loss 0.692, lat_loss 22.014
09/22 01:04:28 AM | Train: [100/180] Step 750/1249 Loss 1.546 Prec@(1,3) (88.3%, 99.5%), ce_loss 0.692, lat_loss 22.014
09/22 01:04:52 AM | Train: [100/180] Step 800/1249 Loss 1.548 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.692, lat_loss 22.014
09/22 01:05:15 AM | Train: [100/180] Step 850/1249 Loss 1.555 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.691, lat_loss 22.014
09/22 01:05:40 AM | Train: [100/180] Step 900/1249 Loss 1.552 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.691, lat_loss 22.014
09/22 01:06:04 AM | Train: [100/180] Step 950/1249 Loss 1.551 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.691, lat_loss 22.014
09/22 01:06:28 AM | Train: [100/180] Step 1000/1249 Loss 1.550 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.691, lat_loss 22.014
09/22 01:06:52 AM | Train: [100/180] Step 1050/1249 Loss 1.553 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.691, lat_loss 22.014
09/22 01:07:13 AM | Train: [100/180] Step 1100/1249 Loss 1.549 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.691, lat_loss 22.014
09/22 01:07:35 AM | Train: [100/180] Step 1150/1249 Loss 1.544 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.691, lat_loss 22.014
09/22 01:07:57 AM | Train: [100/180] Step 1200/1249 Loss 1.548 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.691, lat_loss 22.014
09/22 01:08:21 AM | Train: [100/180] Step 1249/1249 Loss 1.547 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.691, lat_loss 22.014
09/22 01:08:21 AM | _w_step_train: [100/180] Final Prec@1 88.2450% Time 580.13
09/22 01:08:21 AM | Start to train theta for epoch 99
09/22 01:08:42 AM | Train: [100/180] Step 050/312 Loss 2.127 Prec@(1,3) (84.0%, 99.0%), ce_loss 0.691, lat_loss 22.014
09/22 01:09:02 AM | Train: [100/180] Step 100/312 Loss 2.018 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.691, lat_loss 22.014
09/22 01:09:22 AM | Train: [100/180] Step 150/312 Loss 2.009 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.691, lat_loss 22.014
09/22 01:09:42 AM | Train: [100/180] Step 200/312 Loss 2.007 Prec@(1,3) (84.8%, 99.1%), ce_loss 0.690, lat_loss 22.014
09/22 01:10:03 AM | Train: [100/180] Step 250/312 Loss 2.030 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.690, lat_loss 22.014
09/22 01:10:23 AM | Train: [100/180] Step 300/312 Loss 2.041 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.690, lat_loss 22.014
09/22 01:10:28 AM | Train: [100/180] Step 312/312 Loss 2.036 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.690, lat_loss 22.014
09/22 01:10:28 AM | _theta_step_train: [100/180] Final Prec@1 84.7400% Time 127.01
09/22 01:10:34 AM | Valid: [100/180] Step 050/312 Loss 1.755 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.690, lat_loss 22.014
09/22 01:10:38 AM | Valid: [100/180] Step 100/312 Loss 2.068 Prec@(1,3) (83.8%, 98.9%), ce_loss 0.690, lat_loss 22.014
09/22 01:10:43 AM | Valid: [100/180] Step 150/312 Loss 2.068 Prec@(1,3) (84.2%, 99.0%), ce_loss 0.690, lat_loss 22.014
09/22 01:10:48 AM | Valid: [100/180] Step 200/312 Loss 2.023 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.690, lat_loss 22.014
09/22 01:10:52 AM | Valid: [100/180] Step 250/312 Loss 2.042 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.690, lat_loss 22.014
09/22 01:10:57 AM | Valid: [100/180] Step 300/312 Loss 2.023 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.690, lat_loss 22.014
09/22 01:10:58 AM | Valid: [100/180] Step 312/312 Loss 2.031 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.690, lat_loss 22.014
09/22 01:10:58 AM | val: [100/180] Final Prec@1 84.2800% Time 29.80
09/22 01:10:58 AM | Best top1 acc by now. Save model
09/22 01:10:58 AM | Start to train weights for epoch 100
09/22 01:11:24 AM | Train: [101/180] Step 050/1249 Loss 1.309 Prec@(1,3) (90.4%, 99.9%), ce_loss 0.690, lat_loss 22.014
09/22 01:11:47 AM | Train: [101/180] Step 100/1249 Loss 1.355 Prec@(1,3) (89.9%, 99.9%), ce_loss 0.690, lat_loss 22.014
09/22 01:12:12 AM | Train: [101/180] Step 150/1249 Loss 1.369 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.690, lat_loss 22.014
09/22 01:12:37 AM | Train: [101/180] Step 200/1249 Loss 1.369 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.690, lat_loss 22.014
09/22 01:13:02 AM | Train: [101/180] Step 250/1249 Loss 1.368 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.689, lat_loss 22.014
09/22 01:13:27 AM | Train: [101/180] Step 300/1249 Loss 1.394 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.689, lat_loss 22.014
09/22 01:13:51 AM | Train: [101/180] Step 350/1249 Loss 1.412 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.689, lat_loss 22.014
09/22 01:14:08 AM | Train: [101/180] Step 400/1249 Loss 1.412 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.689, lat_loss 22.014
09/22 01:14:25 AM | Train: [101/180] Step 450/1249 Loss 1.408 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.689, lat_loss 22.014
09/22 01:14:41 AM | Train: [101/180] Step 500/1249 Loss 1.410 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.689, lat_loss 22.014
09/22 01:14:58 AM | Train: [101/180] Step 550/1249 Loss 1.412 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.689, lat_loss 22.014
09/22 01:15:14 AM | Train: [101/180] Step 600/1249 Loss 1.446 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.689, lat_loss 22.014
09/22 01:15:30 AM | Train: [101/180] Step 650/1249 Loss 1.457 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.689, lat_loss 22.013
09/22 01:15:47 AM | Train: [101/180] Step 700/1249 Loss 1.449 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.689, lat_loss 22.013
09/22 01:16:03 AM | Train: [101/180] Step 750/1249 Loss 1.441 Prec@(1,3) (88.9%, 99.7%), ce_loss 0.688, lat_loss 22.013
09/22 01:16:20 AM | Train: [101/180] Step 800/1249 Loss 1.449 Prec@(1,3) (88.8%, 99.7%), ce_loss 0.688, lat_loss 22.013
09/22 01:16:37 AM | Train: [101/180] Step 850/1249 Loss 1.455 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.688, lat_loss 22.013
09/22 01:16:53 AM | Train: [101/180] Step 900/1249 Loss 1.470 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.688, lat_loss 22.013
09/22 01:17:10 AM | Train: [101/180] Step 950/1249 Loss 1.474 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.688, lat_loss 22.013
09/22 01:17:26 AM | Train: [101/180] Step 1000/1249 Loss 1.474 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.688, lat_loss 22.013
09/22 01:17:42 AM | Train: [101/180] Step 1050/1249 Loss 1.472 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.688, lat_loss 22.013
09/22 01:17:59 AM | Train: [101/180] Step 1100/1249 Loss 1.475 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.688, lat_loss 22.013
09/22 01:18:14 AM | Train: [101/180] Step 1150/1249 Loss 1.481 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.688, lat_loss 22.013
09/22 01:18:31 AM | Train: [101/180] Step 1200/1249 Loss 1.485 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.688, lat_loss 22.013
09/22 01:18:47 AM | Train: [101/180] Step 1249/1249 Loss 1.490 Prec@(1,3) (88.5%, 99.6%), ce_loss 0.688, lat_loss 22.013
09/22 01:18:47 AM | _w_step_train: [101/180] Final Prec@1 88.5200% Time 468.94
09/22 01:18:47 AM | Start to train theta for epoch 100
09/22 01:19:09 AM | Train: [101/180] Step 050/312 Loss 2.051 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.687, lat_loss 22.013
09/22 01:19:29 AM | Train: [101/180] Step 100/312 Loss 2.044 Prec@(1,3) (84.2%, 99.1%), ce_loss 0.687, lat_loss 22.013
09/22 01:19:49 AM | Train: [101/180] Step 150/312 Loss 2.016 Prec@(1,3) (84.7%, 99.0%), ce_loss 0.687, lat_loss 22.013
09/22 01:20:09 AM | Train: [101/180] Step 200/312 Loss 2.063 Prec@(1,3) (84.4%, 99.1%), ce_loss 0.687, lat_loss 22.013
09/22 01:20:29 AM | Train: [101/180] Step 250/312 Loss 2.106 Prec@(1,3) (84.0%, 99.0%), ce_loss 0.687, lat_loss 22.013
09/22 01:20:48 AM | Train: [101/180] Step 300/312 Loss 2.097 Prec@(1,3) (84.1%, 99.0%), ce_loss 0.687, lat_loss 22.013
09/22 01:20:53 AM | Train: [101/180] Step 312/312 Loss 2.097 Prec@(1,3) (84.1%, 99.0%), ce_loss 0.687, lat_loss 22.013
09/22 01:20:53 AM | _theta_step_train: [101/180] Final Prec@1 84.1300% Time 126.15
09/22 01:20:59 AM | Valid: [101/180] Step 050/312 Loss 1.928 Prec@(1,3) (85.9%, 99.7%), ce_loss 0.687, lat_loss 22.013
09/22 01:21:03 AM | Valid: [101/180] Step 100/312 Loss 2.086 Prec@(1,3) (85.0%, 99.2%), ce_loss 0.687, lat_loss 22.013
09/22 01:21:08 AM | Valid: [101/180] Step 150/312 Loss 2.084 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.687, lat_loss 22.013
09/22 01:21:13 AM | Valid: [101/180] Step 200/312 Loss 2.057 Prec@(1,3) (85.0%, 99.1%), ce_loss 0.687, lat_loss 22.013
09/22 01:21:17 AM | Valid: [101/180] Step 250/312 Loss 2.086 Prec@(1,3) (84.6%, 99.0%), ce_loss 0.687, lat_loss 22.013
09/22 01:21:22 AM | Valid: [101/180] Step 300/312 Loss 2.051 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.687, lat_loss 22.013
09/22 01:21:23 AM | Valid: [101/180] Step 312/312 Loss 2.069 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.687, lat_loss 22.013
09/22 01:21:23 AM | val: [101/180] Final Prec@1 84.6400% Time 29.76
09/22 01:21:23 AM | Best top1 acc by now. Save model
09/22 01:21:23 AM | Start to train weights for epoch 101
09/22 01:21:49 AM | Train: [102/180] Step 050/1249 Loss 1.292 Prec@(1,3) (89.8%, 99.9%), ce_loss 0.687, lat_loss 22.013
09/22 01:22:13 AM | Train: [102/180] Step 100/1249 Loss 1.291 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.687, lat_loss 22.013
09/22 01:22:38 AM | Train: [102/180] Step 150/1249 Loss 1.324 Prec@(1,3) (89.8%, 99.8%), ce_loss 0.686, lat_loss 22.013
09/22 01:23:03 AM | Train: [102/180] Step 200/1249 Loss 1.368 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.686, lat_loss 22.013
09/22 01:23:26 AM | Train: [102/180] Step 250/1249 Loss 1.381 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.686, lat_loss 22.013
09/22 01:23:50 AM | Train: [102/180] Step 300/1249 Loss 1.444 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.686, lat_loss 22.013
09/22 01:24:13 AM | Train: [102/180] Step 350/1249 Loss 1.449 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.686, lat_loss 22.013
09/22 01:24:36 AM | Train: [102/180] Step 400/1249 Loss 1.445 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.686, lat_loss 22.013
09/22 01:24:59 AM | Train: [102/180] Step 450/1249 Loss 1.437 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.686, lat_loss 22.013
09/22 01:25:23 AM | Train: [102/180] Step 500/1249 Loss 1.429 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.686, lat_loss 22.013
09/22 01:25:46 AM | Train: [102/180] Step 550/1249 Loss 1.446 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.686, lat_loss 22.013
09/22 01:26:09 AM | Train: [102/180] Step 600/1249 Loss 1.445 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.686, lat_loss 22.013
09/22 01:26:32 AM | Train: [102/180] Step 650/1249 Loss 1.456 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.686, lat_loss 22.013
09/22 01:26:56 AM | Train: [102/180] Step 700/1249 Loss 1.452 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.685, lat_loss 22.013
09/22 01:27:21 AM | Train: [102/180] Step 750/1249 Loss 1.450 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.685, lat_loss 22.013
09/22 01:27:47 AM | Train: [102/180] Step 800/1249 Loss 1.479 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.685, lat_loss 22.013
09/22 01:28:11 AM | Train: [102/180] Step 850/1249 Loss 1.487 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.685, lat_loss 22.013
09/22 01:28:36 AM | Train: [102/180] Step 900/1249 Loss 1.486 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.685, lat_loss 22.013
09/22 01:29:01 AM | Train: [102/180] Step 950/1249 Loss 1.498 Prec@(1,3) (88.6%, 99.5%), ce_loss 0.685, lat_loss 22.013
09/22 01:29:26 AM | Train: [102/180] Step 1000/1249 Loss 1.496 Prec@(1,3) (88.6%, 99.5%), ce_loss 0.685, lat_loss 22.012
09/22 01:29:51 AM | Train: [102/180] Step 1050/1249 Loss 1.494 Prec@(1,3) (88.6%, 99.5%), ce_loss 0.685, lat_loss 22.012
09/22 01:30:16 AM | Train: [102/180] Step 1100/1249 Loss 1.488 Prec@(1,3) (88.6%, 99.5%), ce_loss 0.685, lat_loss 22.012
09/22 01:30:41 AM | Train: [102/180] Step 1150/1249 Loss 1.491 Prec@(1,3) (88.7%, 99.5%), ce_loss 0.685, lat_loss 22.012
09/22 01:31:06 AM | Train: [102/180] Step 1200/1249 Loss 1.499 Prec@(1,3) (88.6%, 99.5%), ce_loss 0.685, lat_loss 22.012
09/22 01:31:30 AM | Train: [102/180] Step 1249/1249 Loss 1.506 Prec@(1,3) (88.6%, 99.5%), ce_loss 0.684, lat_loss 22.012
09/22 01:31:30 AM | _w_step_train: [102/180] Final Prec@1 88.5700% Time 606.79
09/22 01:31:30 AM | Start to train theta for epoch 101
09/22 01:31:50 AM | Train: [102/180] Step 050/312 Loss 2.267 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.684, lat_loss 22.012
09/22 01:32:08 AM | Train: [102/180] Step 100/312 Loss 2.296 Prec@(1,3) (83.7%, 98.7%), ce_loss 0.684, lat_loss 22.012
09/22 01:32:28 AM | Train: [102/180] Step 150/312 Loss 2.258 Prec@(1,3) (83.8%, 98.9%), ce_loss 0.684, lat_loss 22.012
09/22 01:32:46 AM | Train: [102/180] Step 200/312 Loss 2.199 Prec@(1,3) (83.9%, 98.8%), ce_loss 0.684, lat_loss 22.012
09/22 01:33:07 AM | Train: [102/180] Step 250/312 Loss 2.219 Prec@(1,3) (84.0%, 98.9%), ce_loss 0.684, lat_loss 22.012
09/22 01:33:28 AM | Train: [102/180] Step 300/312 Loss 2.218 Prec@(1,3) (83.8%, 98.9%), ce_loss 0.684, lat_loss 22.012
09/22 01:33:33 AM | Train: [102/180] Step 312/312 Loss 2.214 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.684, lat_loss 22.012
09/22 01:33:34 AM | _theta_step_train: [102/180] Final Prec@1 83.8200% Time 123.50
09/22 01:33:39 AM | Valid: [102/180] Step 050/312 Loss 2.351 Prec@(1,3) (82.5%, 97.9%), ce_loss 0.684, lat_loss 22.012
09/22 01:33:44 AM | Valid: [102/180] Step 100/312 Loss 2.279 Prec@(1,3) (82.8%, 98.3%), ce_loss 0.684, lat_loss 22.012
09/22 01:33:48 AM | Valid: [102/180] Step 150/312 Loss 2.295 Prec@(1,3) (82.8%, 98.5%), ce_loss 0.684, lat_loss 22.012
09/22 01:33:53 AM | Valid: [102/180] Step 200/312 Loss 2.222 Prec@(1,3) (83.2%, 98.8%), ce_loss 0.684, lat_loss 22.012
09/22 01:33:58 AM | Valid: [102/180] Step 250/312 Loss 2.202 Prec@(1,3) (83.3%, 98.8%), ce_loss 0.684, lat_loss 22.012
09/22 01:34:03 AM | Valid: [102/180] Step 300/312 Loss 2.177 Prec@(1,3) (83.5%, 99.0%), ce_loss 0.684, lat_loss 22.012
09/22 01:34:04 AM | Valid: [102/180] Step 312/312 Loss 2.171 Prec@(1,3) (83.5%, 99.0%), ce_loss 0.684, lat_loss 22.012
09/22 01:34:04 AM | val: [102/180] Final Prec@1 83.5300% Time 30.15
09/22 01:34:04 AM | Start to train weights for epoch 102
09/22 01:34:28 AM | Train: [103/180] Step 050/1249 Loss 1.344 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.684, lat_loss 22.012
09/22 01:34:50 AM | Train: [103/180] Step 100/1249 Loss 1.400 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.684, lat_loss 22.012
09/22 01:35:13 AM | Train: [103/180] Step 150/1249 Loss 1.395 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.684, lat_loss 22.012
09/22 01:35:38 AM | Train: [103/180] Step 200/1249 Loss 1.348 Prec@(1,3) (89.5%, 99.6%), ce_loss 0.683, lat_loss 22.012
09/22 01:36:00 AM | Train: [103/180] Step 250/1249 Loss 1.358 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.683, lat_loss 22.012
09/22 01:36:23 AM | Train: [103/180] Step 300/1249 Loss 1.389 Prec@(1,3) (89.3%, 99.6%), ce_loss 0.683, lat_loss 22.012
09/22 01:36:46 AM | Train: [103/180] Step 350/1249 Loss 1.416 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.683, lat_loss 22.012
09/22 01:37:10 AM | Train: [103/180] Step 400/1249 Loss 1.433 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.683, lat_loss 22.012
09/22 01:37:33 AM | Train: [103/180] Step 450/1249 Loss 1.419 Prec@(1,3) (88.8%, 99.7%), ce_loss 0.683, lat_loss 22.012
09/22 01:37:57 AM | Train: [103/180] Step 500/1249 Loss 1.428 Prec@(1,3) (88.7%, 99.7%), ce_loss 0.683, lat_loss 22.012
09/22 01:38:20 AM | Train: [103/180] Step 550/1249 Loss 1.439 Prec@(1,3) (88.7%, 99.7%), ce_loss 0.683, lat_loss 22.012
09/22 01:38:44 AM | Train: [103/180] Step 600/1249 Loss 1.455 Prec@(1,3) (88.5%, 99.7%), ce_loss 0.683, lat_loss 22.012
09/22 01:39:07 AM | Train: [103/180] Step 650/1249 Loss 1.452 Prec@(1,3) (88.5%, 99.6%), ce_loss 0.683, lat_loss 22.012
09/22 01:39:30 AM | Train: [103/180] Step 700/1249 Loss 1.441 Prec@(1,3) (88.6%, 99.7%), ce_loss 0.683, lat_loss 22.012
09/22 01:39:54 AM | Train: [103/180] Step 750/1249 Loss 1.442 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.682, lat_loss 22.012
09/22 01:40:18 AM | Train: [103/180] Step 800/1249 Loss 1.446 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.682, lat_loss 22.012
09/22 01:40:42 AM | Train: [103/180] Step 850/1249 Loss 1.452 Prec@(1,3) (88.6%, 99.7%), ce_loss 0.682, lat_loss 22.012
09/22 01:41:06 AM | Train: [103/180] Step 900/1249 Loss 1.449 Prec@(1,3) (88.7%, 99.7%), ce_loss 0.682, lat_loss 22.012
09/22 01:41:31 AM | Train: [103/180] Step 950/1249 Loss 1.455 Prec@(1,3) (88.6%, 99.7%), ce_loss 0.682, lat_loss 22.012
09/22 01:41:56 AM | Train: [103/180] Step 1000/1249 Loss 1.457 Prec@(1,3) (88.6%, 99.7%), ce_loss 0.682, lat_loss 22.012
09/22 01:42:20 AM | Train: [103/180] Step 1050/1249 Loss 1.456 Prec@(1,3) (88.6%, 99.7%), ce_loss 0.682, lat_loss 22.012
09/22 01:42:45 AM | Train: [103/180] Step 1100/1249 Loss 1.468 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.682, lat_loss 22.012
09/22 01:43:10 AM | Train: [103/180] Step 1150/1249 Loss 1.469 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.682, lat_loss 22.012
09/22 01:43:35 AM | Train: [103/180] Step 1200/1249 Loss 1.473 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.682, lat_loss 22.012
09/22 01:43:59 AM | Train: [103/180] Step 1249/1249 Loss 1.469 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.682, lat_loss 22.012
09/22 01:43:59 AM | _w_step_train: [103/180] Final Prec@1 88.5925% Time 595.20
09/22 01:43:59 AM | Start to train theta for epoch 102
09/22 01:44:19 AM | Train: [103/180] Step 050/312 Loss 2.548 Prec@(1,3) (82.2%, 98.7%), ce_loss 0.681, lat_loss 22.012
09/22 01:44:38 AM | Train: [103/180] Step 100/312 Loss 2.367 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.681, lat_loss 22.012
09/22 01:44:58 AM | Train: [103/180] Step 150/312 Loss 2.272 Prec@(1,3) (83.6%, 99.1%), ce_loss 0.681, lat_loss 22.012
09/22 01:45:17 AM | Train: [103/180] Step 200/312 Loss 2.305 Prec@(1,3) (83.4%, 98.9%), ce_loss 0.681, lat_loss 22.011
09/22 01:45:35 AM | Train: [103/180] Step 250/312 Loss 2.245 Prec@(1,3) (83.6%, 98.9%), ce_loss 0.681, lat_loss 22.011
09/22 01:45:55 AM | Train: [103/180] Step 300/312 Loss 2.218 Prec@(1,3) (83.7%, 99.0%), ce_loss 0.681, lat_loss 22.011
09/22 01:46:00 AM | Train: [103/180] Step 312/312 Loss 2.213 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.681, lat_loss 22.011
09/22 01:46:00 AM | _theta_step_train: [103/180] Final Prec@1 83.7500% Time 121.05
09/22 01:46:05 AM | Valid: [103/180] Step 050/312 Loss 1.938 Prec@(1,3) (83.8%, 99.3%), ce_loss 0.681, lat_loss 22.011
09/22 01:46:10 AM | Valid: [103/180] Step 100/312 Loss 2.046 Prec@(1,3) (83.8%, 99.2%), ce_loss 0.681, lat_loss 22.011
09/22 01:46:15 AM | Valid: [103/180] Step 150/312 Loss 2.118 Prec@(1,3) (83.6%, 99.0%), ce_loss 0.681, lat_loss 22.011
09/22 01:46:19 AM | Valid: [103/180] Step 200/312 Loss 2.130 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.681, lat_loss 22.011
09/22 01:46:24 AM | Valid: [103/180] Step 250/312 Loss 2.145 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.681, lat_loss 22.011
09/22 01:46:29 AM | Valid: [103/180] Step 300/312 Loss 2.117 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.681, lat_loss 22.011
09/22 01:46:30 AM | Valid: [103/180] Step 312/312 Loss 2.111 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.681, lat_loss 22.011
09/22 01:46:30 AM | val: [103/180] Final Prec@1 83.5300% Time 29.70
09/22 01:46:30 AM | Start to train weights for epoch 103
09/22 01:46:47 AM | Train: [104/180] Step 050/1249 Loss 1.287 Prec@(1,3) (90.1%, 99.8%), ce_loss 0.681, lat_loss 22.011
09/22 01:47:08 AM | Train: [104/180] Step 100/1249 Loss 1.355 Prec@(1,3) (89.3%, 99.8%), ce_loss 0.681, lat_loss 22.011
09/22 01:47:32 AM | Train: [104/180] Step 150/1249 Loss 1.408 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.681, lat_loss 22.011
09/22 01:47:55 AM | Train: [104/180] Step 200/1249 Loss 1.444 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.681, lat_loss 22.011
09/22 01:48:18 AM | Train: [104/180] Step 250/1249 Loss 1.419 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.680, lat_loss 22.011
09/22 01:48:43 AM | Train: [104/180] Step 300/1249 Loss 1.414 Prec@(1,3) (89.3%, 99.6%), ce_loss 0.680, lat_loss 22.011
09/22 01:49:08 AM | Train: [104/180] Step 350/1249 Loss 1.440 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.680, lat_loss 22.011
09/22 01:49:32 AM | Train: [104/180] Step 400/1249 Loss 1.434 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.680, lat_loss 22.011
09/22 01:49:57 AM | Train: [104/180] Step 450/1249 Loss 1.444 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.680, lat_loss 22.011
09/22 01:50:21 AM | Train: [104/180] Step 500/1249 Loss 1.457 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.680, lat_loss 22.011
09/22 01:50:46 AM | Train: [104/180] Step 550/1249 Loss 1.455 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.680, lat_loss 22.011
09/22 01:51:10 AM | Train: [104/180] Step 600/1249 Loss 1.455 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.680, lat_loss 22.011
09/22 01:51:34 AM | Train: [104/180] Step 650/1249 Loss 1.447 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.680, lat_loss 22.011
09/22 01:51:58 AM | Train: [104/180] Step 700/1249 Loss 1.439 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.680, lat_loss 22.011
09/22 01:52:22 AM | Train: [104/180] Step 750/1249 Loss 1.437 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.679, lat_loss 22.011
09/22 01:52:47 AM | Train: [104/180] Step 800/1249 Loss 1.444 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.679, lat_loss 22.011
09/22 01:53:10 AM | Train: [104/180] Step 850/1249 Loss 1.447 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.679, lat_loss 22.011
09/22 01:53:34 AM | Train: [104/180] Step 900/1249 Loss 1.432 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.679, lat_loss 22.011
09/22 01:53:57 AM | Train: [104/180] Step 950/1249 Loss 1.431 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.679, lat_loss 22.011
09/22 01:54:22 AM | Train: [104/180] Step 1000/1249 Loss 1.439 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.679, lat_loss 22.011
09/22 01:54:46 AM | Train: [104/180] Step 1050/1249 Loss 1.443 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.679, lat_loss 22.011
09/22 01:55:11 AM | Train: [104/180] Step 1100/1249 Loss 1.441 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.679, lat_loss 22.011
09/22 01:55:34 AM | Train: [104/180] Step 1150/1249 Loss 1.450 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.679, lat_loss 22.011
09/22 01:55:59 AM | Train: [104/180] Step 1200/1249 Loss 1.455 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.679, lat_loss 22.011
09/22 01:56:23 AM | Train: [104/180] Step 1249/1249 Loss 1.454 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.679, lat_loss 22.011
09/22 01:56:23 AM | _w_step_train: [104/180] Final Prec@1 88.6775% Time 593.13
09/22 01:56:23 AM | Start to train theta for epoch 103
09/22 01:56:45 AM | Train: [104/180] Step 050/312 Loss 2.193 Prec@(1,3) (84.4%, 99.0%), ce_loss 0.679, lat_loss 22.011
09/22 01:57:05 AM | Train: [104/180] Step 100/312 Loss 2.280 Prec@(1,3) (83.4%, 98.7%), ce_loss 0.678, lat_loss 22.011
09/22 01:57:26 AM | Train: [104/180] Step 150/312 Loss 2.225 Prec@(1,3) (83.7%, 98.9%), ce_loss 0.678, lat_loss 22.011
09/22 01:57:47 AM | Train: [104/180] Step 200/312 Loss 2.230 Prec@(1,3) (83.7%, 98.9%), ce_loss 0.678, lat_loss 22.011
09/22 01:58:07 AM | Train: [104/180] Step 250/312 Loss 2.193 Prec@(1,3) (84.1%, 98.9%), ce_loss 0.678, lat_loss 22.011
09/22 01:58:27 AM | Train: [104/180] Step 300/312 Loss 2.150 Prec@(1,3) (84.3%, 99.0%), ce_loss 0.678, lat_loss 22.011
09/22 01:58:32 AM | Train: [104/180] Step 312/312 Loss 2.146 Prec@(1,3) (84.3%, 99.0%), ce_loss 0.678, lat_loss 22.011
09/22 01:58:32 AM | _theta_step_train: [104/180] Final Prec@1 84.3200% Time 129.16
09/22 01:58:37 AM | Valid: [104/180] Step 050/312 Loss 2.113 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.678, lat_loss 22.011
09/22 01:58:42 AM | Valid: [104/180] Step 100/312 Loss 2.196 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.678, lat_loss 22.011
09/22 01:58:47 AM | Valid: [104/180] Step 150/312 Loss 2.240 Prec@(1,3) (83.3%, 99.0%), ce_loss 0.678, lat_loss 22.011
09/22 01:58:51 AM | Valid: [104/180] Step 200/312 Loss 2.303 Prec@(1,3) (83.1%, 98.9%), ce_loss 0.678, lat_loss 22.011
09/22 01:58:56 AM | Valid: [104/180] Step 250/312 Loss 2.325 Prec@(1,3) (83.0%, 98.8%), ce_loss 0.678, lat_loss 22.011
09/22 01:59:01 AM | Valid: [104/180] Step 300/312 Loss 2.277 Prec@(1,3) (83.3%, 99.0%), ce_loss 0.678, lat_loss 22.010
09/22 01:59:02 AM | Valid: [104/180] Step 312/312 Loss 2.268 Prec@(1,3) (83.4%, 99.0%), ce_loss 0.678, lat_loss 22.010
09/22 01:59:02 AM | val: [104/180] Final Prec@1 83.3600% Time 29.87
09/22 01:59:02 AM | Start to train weights for epoch 104
09/22 01:59:27 AM | Train: [105/180] Step 050/1249 Loss 1.476 Prec@(1,3) (88.4%, 99.4%), ce_loss 0.678, lat_loss 22.010
09/22 01:59:50 AM | Train: [105/180] Step 100/1249 Loss 1.515 Prec@(1,3) (88.4%, 99.6%), ce_loss 0.678, lat_loss 22.010
09/22 02:00:13 AM | Train: [105/180] Step 150/1249 Loss 1.451 Prec@(1,3) (88.8%, 99.7%), ce_loss 0.678, lat_loss 22.010
09/22 02:00:34 AM | Train: [105/180] Step 200/1249 Loss 1.417 Prec@(1,3) (89.1%, 99.8%), ce_loss 0.678, lat_loss 22.010
09/22 02:00:56 AM | Train: [105/180] Step 250/1249 Loss 1.400 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.678, lat_loss 22.010
09/22 02:01:18 AM | Train: [105/180] Step 300/1249 Loss 1.420 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.677, lat_loss 22.010
09/22 02:01:39 AM | Train: [105/180] Step 350/1249 Loss 1.414 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.677, lat_loss 22.010
09/22 02:02:01 AM | Train: [105/180] Step 400/1249 Loss 1.415 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.677, lat_loss 22.010
09/22 02:02:23 AM | Train: [105/180] Step 450/1249 Loss 1.407 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.677, lat_loss 22.010
09/22 02:02:44 AM | Train: [105/180] Step 500/1249 Loss 1.408 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.677, lat_loss 22.010
09/22 02:03:04 AM | Train: [105/180] Step 550/1249 Loss 1.417 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.677, lat_loss 22.010
09/22 02:03:26 AM | Train: [105/180] Step 600/1249 Loss 1.412 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.677, lat_loss 22.010
09/22 02:03:47 AM | Train: [105/180] Step 650/1249 Loss 1.423 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.677, lat_loss 22.010
09/22 02:04:10 AM | Train: [105/180] Step 700/1249 Loss 1.416 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.677, lat_loss 22.010
09/22 02:04:31 AM | Train: [105/180] Step 750/1249 Loss 1.417 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.677, lat_loss 22.010
09/22 02:04:53 AM | Train: [105/180] Step 800/1249 Loss 1.419 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.676, lat_loss 22.010
09/22 02:05:14 AM | Train: [105/180] Step 850/1249 Loss 1.419 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.676, lat_loss 22.010
09/22 02:05:35 AM | Train: [105/180] Step 900/1249 Loss 1.418 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.676, lat_loss 22.010
09/22 02:05:56 AM | Train: [105/180] Step 950/1249 Loss 1.419 Prec@(1,3) (89.2%, 99.6%), ce_loss 0.676, lat_loss 22.010
09/22 02:06:17 AM | Train: [105/180] Step 1000/1249 Loss 1.427 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.676, lat_loss 22.010
09/22 02:06:40 AM | Train: [105/180] Step 1050/1249 Loss 1.426 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.676, lat_loss 22.010
09/22 02:07:02 AM | Train: [105/180] Step 1100/1249 Loss 1.421 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.676, lat_loss 22.010
09/22 02:07:23 AM | Train: [105/180] Step 1150/1249 Loss 1.418 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.676, lat_loss 22.010
09/22 02:07:45 AM | Train: [105/180] Step 1200/1249 Loss 1.420 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.676, lat_loss 22.010
09/22 02:08:09 AM | Train: [105/180] Step 1249/1249 Loss 1.418 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.676, lat_loss 22.010
09/22 02:08:09 AM | _w_step_train: [105/180] Final Prec@1 89.1075% Time 547.43
09/22 02:08:09 AM | Start to train theta for epoch 104
09/22 02:08:31 AM | Train: [105/180] Step 050/312 Loss 2.010 Prec@(1,3) (85.4%, 98.8%), ce_loss 0.676, lat_loss 22.010
09/22 02:08:51 AM | Train: [105/180] Step 100/312 Loss 2.019 Prec@(1,3) (85.0%, 99.1%), ce_loss 0.676, lat_loss 22.010
09/22 02:09:10 AM | Train: [105/180] Step 150/312 Loss 2.002 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.675, lat_loss 22.010
09/22 02:09:28 AM | Train: [105/180] Step 200/312 Loss 1.994 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.675, lat_loss 22.010
09/22 02:09:46 AM | Train: [105/180] Step 250/312 Loss 2.004 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.675, lat_loss 22.010
09/22 02:10:06 AM | Train: [105/180] Step 300/312 Loss 2.003 Prec@(1,3) (85.0%, 99.1%), ce_loss 0.675, lat_loss 22.010
09/22 02:10:11 AM | Train: [105/180] Step 312/312 Loss 2.028 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.675, lat_loss 22.010
09/22 02:10:11 AM | _theta_step_train: [105/180] Final Prec@1 84.9400% Time 121.93
09/22 02:10:17 AM | Valid: [105/180] Step 050/312 Loss 1.756 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.675, lat_loss 22.010
09/22 02:10:22 AM | Valid: [105/180] Step 100/312 Loss 1.948 Prec@(1,3) (85.2%, 99.3%), ce_loss 0.675, lat_loss 22.010
09/22 02:10:27 AM | Valid: [105/180] Step 150/312 Loss 2.111 Prec@(1,3) (84.0%, 98.9%), ce_loss 0.675, lat_loss 22.010
09/22 02:10:31 AM | Valid: [105/180] Step 200/312 Loss 2.108 Prec@(1,3) (84.2%, 99.0%), ce_loss 0.675, lat_loss 22.010
09/22 02:10:36 AM | Valid: [105/180] Step 250/312 Loss 2.135 Prec@(1,3) (83.9%, 99.0%), ce_loss 0.675, lat_loss 22.010
09/22 02:10:41 AM | Valid: [105/180] Step 300/312 Loss 2.095 Prec@(1,3) (84.1%, 99.0%), ce_loss 0.675, lat_loss 22.010
09/22 02:10:42 AM | Valid: [105/180] Step 312/312 Loss 2.081 Prec@(1,3) (84.1%, 99.0%), ce_loss 0.675, lat_loss 22.010
09/22 02:10:42 AM | val: [105/180] Final Prec@1 84.1400% Time 30.61
09/22 02:10:42 AM | Start to train weights for epoch 105
09/22 02:11:08 AM | Train: [106/180] Step 050/1249 Loss 1.116 Prec@(1,3) (90.9%, 99.8%), ce_loss 0.675, lat_loss 22.010
09/22 02:11:33 AM | Train: [106/180] Step 100/1249 Loss 1.253 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.675, lat_loss 22.010
09/22 02:11:57 AM | Train: [106/180] Step 150/1249 Loss 1.195 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.675, lat_loss 22.010
09/22 02:12:19 AM | Train: [106/180] Step 200/1249 Loss 1.242 Prec@(1,3) (90.4%, 99.8%), ce_loss 0.675, lat_loss 22.010
09/22 02:12:43 AM | Train: [106/180] Step 250/1249 Loss 1.253 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.674, lat_loss 22.010
09/22 02:13:07 AM | Train: [106/180] Step 300/1249 Loss 1.255 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.674, lat_loss 22.010
09/22 02:13:31 AM | Train: [106/180] Step 350/1249 Loss 1.278 Prec@(1,3) (90.2%, 99.8%), ce_loss 0.674, lat_loss 22.010
09/22 02:13:54 AM | Train: [106/180] Step 400/1249 Loss 1.301 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.674, lat_loss 22.010
09/22 02:14:16 AM | Train: [106/180] Step 450/1249 Loss 1.307 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.674, lat_loss 22.010
09/22 02:14:41 AM | Train: [106/180] Step 500/1249 Loss 1.320 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.674, lat_loss 22.010
09/22 02:15:06 AM | Train: [106/180] Step 550/1249 Loss 1.319 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.674, lat_loss 22.010
09/22 02:15:31 AM | Train: [106/180] Step 600/1249 Loss 1.329 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.674, lat_loss 22.010
09/22 02:15:55 AM | Train: [106/180] Step 650/1249 Loss 1.342 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.674, lat_loss 22.010
09/22 02:16:20 AM | Train: [106/180] Step 700/1249 Loss 1.354 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.674, lat_loss 22.010
09/22 02:16:44 AM | Train: [106/180] Step 750/1249 Loss 1.346 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.674, lat_loss 22.010
09/22 02:17:10 AM | Train: [106/180] Step 800/1249 Loss 1.363 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.673, lat_loss 22.010
09/22 02:17:34 AM | Train: [106/180] Step 850/1249 Loss 1.365 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.673, lat_loss 22.009
09/22 02:17:59 AM | Train: [106/180] Step 900/1249 Loss 1.364 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.673, lat_loss 22.009
09/22 02:18:23 AM | Train: [106/180] Step 950/1249 Loss 1.369 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.673, lat_loss 22.009
09/22 02:18:49 AM | Train: [106/180] Step 1000/1249 Loss 1.380 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.673, lat_loss 22.009
09/22 02:19:14 AM | Train: [106/180] Step 1050/1249 Loss 1.384 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.673, lat_loss 22.009
09/22 02:19:38 AM | Train: [106/180] Step 1100/1249 Loss 1.378 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.673, lat_loss 22.009
09/22 02:20:03 AM | Train: [106/180] Step 1150/1249 Loss 1.382 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.673, lat_loss 22.009
09/22 02:20:29 AM | Train: [106/180] Step 1200/1249 Loss 1.384 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.673, lat_loss 22.009
09/22 02:20:53 AM | Train: [106/180] Step 1249/1249 Loss 1.386 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.673, lat_loss 22.009
09/22 02:20:53 AM | _w_step_train: [106/180] Final Prec@1 89.3125% Time 610.89
09/22 02:20:53 AM | Start to train theta for epoch 105
09/22 02:21:06 AM | Train: [106/180] Step 050/312 Loss 2.271 Prec@(1,3) (84.0%, 99.0%), ce_loss 0.673, lat_loss 22.009
09/22 02:21:18 AM | Train: [106/180] Step 100/312 Loss 2.271 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.673, lat_loss 22.009
09/22 02:21:36 AM | Train: [106/180] Step 150/312 Loss 2.186 Prec@(1,3) (84.1%, 99.2%), ce_loss 0.672, lat_loss 22.009
09/22 02:21:54 AM | Train: [106/180] Step 200/312 Loss 2.195 Prec@(1,3) (84.2%, 99.0%), ce_loss 0.672, lat_loss 22.009
09/22 02:22:13 AM | Train: [106/180] Step 250/312 Loss 2.139 Prec@(1,3) (84.5%, 99.1%), ce_loss 0.672, lat_loss 22.009
09/22 02:22:31 AM | Train: [106/180] Step 300/312 Loss 2.166 Prec@(1,3) (84.1%, 99.0%), ce_loss 0.672, lat_loss 22.009
09/22 02:22:36 AM | Train: [106/180] Step 312/312 Loss 2.175 Prec@(1,3) (84.0%, 99.0%), ce_loss 0.672, lat_loss 22.009
09/22 02:22:36 AM | _theta_step_train: [106/180] Final Prec@1 84.0500% Time 102.96
09/22 02:22:41 AM | Valid: [106/180] Step 050/312 Loss 1.924 Prec@(1,3) (85.8%, 99.7%), ce_loss 0.672, lat_loss 22.009
09/22 02:22:46 AM | Valid: [106/180] Step 100/312 Loss 2.027 Prec@(1,3) (84.9%, 99.4%), ce_loss 0.672, lat_loss 22.009
09/22 02:22:51 AM | Valid: [106/180] Step 150/312 Loss 2.084 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.672, lat_loss 22.009
09/22 02:22:55 AM | Valid: [106/180] Step 200/312 Loss 2.073 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.672, lat_loss 22.009
09/22 02:23:00 AM | Valid: [106/180] Step 250/312 Loss 2.039 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.672, lat_loss 22.009
09/22 02:23:05 AM | Valid: [106/180] Step 300/312 Loss 2.022 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.672, lat_loss 22.009
09/22 02:23:06 AM | Valid: [106/180] Step 312/312 Loss 2.013 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.672, lat_loss 22.009
09/22 02:23:06 AM | val: [106/180] Final Prec@1 85.0900% Time 29.74
09/22 02:23:06 AM | Best top1 acc by now. Save model
09/22 02:23:06 AM | Start to train weights for epoch 106
09/22 02:23:28 AM | Train: [107/180] Step 050/1249 Loss 1.354 Prec@(1,3) (89.6%, 99.4%), ce_loss 0.672, lat_loss 22.009
09/22 02:23:53 AM | Train: [107/180] Step 100/1249 Loss 1.258 Prec@(1,3) (90.2%, 99.6%), ce_loss 0.672, lat_loss 22.009
09/22 02:24:18 AM | Train: [107/180] Step 150/1249 Loss 1.320 Prec@(1,3) (89.6%, 99.5%), ce_loss 0.672, lat_loss 22.009
09/22 02:24:43 AM | Train: [107/180] Step 200/1249 Loss 1.346 Prec@(1,3) (89.5%, 99.6%), ce_loss 0.672, lat_loss 22.009
09/22 02:25:07 AM | Train: [107/180] Step 250/1249 Loss 1.333 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.672, lat_loss 22.009
09/22 02:25:32 AM | Train: [107/180] Step 300/1249 Loss 1.338 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.671, lat_loss 22.009
09/22 02:25:57 AM | Train: [107/180] Step 350/1249 Loss 1.334 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.671, lat_loss 22.009
09/22 02:26:21 AM | Train: [107/180] Step 400/1249 Loss 1.338 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.671, lat_loss 22.009
09/22 02:26:47 AM | Train: [107/180] Step 450/1249 Loss 1.357 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.671, lat_loss 22.009
09/22 02:27:11 AM | Train: [107/180] Step 500/1249 Loss 1.362 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.671, lat_loss 22.009
09/22 02:27:36 AM | Train: [107/180] Step 550/1249 Loss 1.365 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.671, lat_loss 22.009
09/22 02:28:01 AM | Train: [107/180] Step 600/1249 Loss 1.365 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.671, lat_loss 22.009
09/22 02:28:25 AM | Train: [107/180] Step 650/1249 Loss 1.365 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.671, lat_loss 22.009
09/22 02:28:50 AM | Train: [107/180] Step 700/1249 Loss 1.374 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.671, lat_loss 22.009
09/22 02:29:15 AM | Train: [107/180] Step 750/1249 Loss 1.377 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.671, lat_loss 22.009
09/22 02:29:39 AM | Train: [107/180] Step 800/1249 Loss 1.382 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.671, lat_loss 22.009
09/22 02:30:04 AM | Train: [107/180] Step 850/1249 Loss 1.381 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.670, lat_loss 22.009
09/22 02:30:29 AM | Train: [107/180] Step 900/1249 Loss 1.373 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.670, lat_loss 22.009
09/22 02:30:53 AM | Train: [107/180] Step 950/1249 Loss 1.365 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.670, lat_loss 22.009
09/22 02:31:18 AM | Train: [107/180] Step 1000/1249 Loss 1.373 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.670, lat_loss 22.009
09/22 02:31:42 AM | Train: [107/180] Step 1050/1249 Loss 1.372 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.670, lat_loss 22.009
09/22 02:32:07 AM | Train: [107/180] Step 1100/1249 Loss 1.371 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.670, lat_loss 22.009
09/22 02:32:32 AM | Train: [107/180] Step 1150/1249 Loss 1.374 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.670, lat_loss 22.009
09/22 02:32:54 AM | Train: [107/180] Step 1200/1249 Loss 1.375 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.670, lat_loss 22.009
09/22 02:33:16 AM | Train: [107/180] Step 1249/1249 Loss 1.370 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.670, lat_loss 22.009
09/22 02:33:16 AM | _w_step_train: [107/180] Final Prec@1 89.2400% Time 610.60
09/22 02:33:16 AM | Start to train theta for epoch 106
09/22 02:33:36 AM | Train: [107/180] Step 050/312 Loss 2.028 Prec@(1,3) (84.8%, 99.0%), ce_loss 0.670, lat_loss 22.009
09/22 02:33:54 AM | Train: [107/180] Step 100/312 Loss 2.077 Prec@(1,3) (84.8%, 99.0%), ce_loss 0.670, lat_loss 22.009
09/22 02:34:12 AM | Train: [107/180] Step 150/312 Loss 2.051 Prec@(1,3) (84.9%, 99.0%), ce_loss 0.670, lat_loss 22.009
09/22 02:34:30 AM | Train: [107/180] Step 200/312 Loss 2.150 Prec@(1,3) (84.4%, 98.9%), ce_loss 0.669, lat_loss 22.009
09/22 02:34:50 AM | Train: [107/180] Step 250/312 Loss 2.160 Prec@(1,3) (84.3%, 98.9%), ce_loss 0.669, lat_loss 22.009
09/22 02:35:10 AM | Train: [107/180] Step 300/312 Loss 2.159 Prec@(1,3) (84.4%, 99.0%), ce_loss 0.669, lat_loss 22.009
09/22 02:35:15 AM | Train: [107/180] Step 312/312 Loss 2.147 Prec@(1,3) (84.5%, 99.0%), ce_loss 0.669, lat_loss 22.009
09/22 02:35:15 AM | _theta_step_train: [107/180] Final Prec@1 84.5100% Time 118.77
09/22 02:35:21 AM | Valid: [107/180] Step 050/312 Loss 1.855 Prec@(1,3) (86.0%, 99.6%), ce_loss 0.669, lat_loss 22.009
09/22 02:35:26 AM | Valid: [107/180] Step 100/312 Loss 1.926 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.669, lat_loss 22.009
09/22 02:35:30 AM | Valid: [107/180] Step 150/312 Loss 1.983 Prec@(1,3) (85.3%, 99.4%), ce_loss 0.669, lat_loss 22.009
09/22 02:35:35 AM | Valid: [107/180] Step 200/312 Loss 2.041 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.669, lat_loss 22.009
09/22 02:35:40 AM | Valid: [107/180] Step 250/312 Loss 2.056 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.669, lat_loss 22.009
09/22 02:35:44 AM | Valid: [107/180] Step 300/312 Loss 2.043 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.669, lat_loss 22.009
09/22 02:35:45 AM | Valid: [107/180] Step 312/312 Loss 2.048 Prec@(1,3) (84.6%, 99.4%), ce_loss 0.669, lat_loss 22.009
09/22 02:35:45 AM | val: [107/180] Final Prec@1 84.6100% Time 30.21
09/22 02:35:45 AM | Start to train weights for epoch 107
09/22 02:36:08 AM | Train: [108/180] Step 050/1249 Loss 1.407 Prec@(1,3) (88.8%, 99.8%), ce_loss 0.669, lat_loss 22.009
09/22 02:36:32 AM | Train: [108/180] Step 100/1249 Loss 1.297 Prec@(1,3) (90.0%, 99.8%), ce_loss 0.669, lat_loss 22.009
09/22 02:36:54 AM | Train: [108/180] Step 150/1249 Loss 1.379 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.669, lat_loss 22.009
09/22 02:37:16 AM | Train: [108/180] Step 200/1249 Loss 1.345 Prec@(1,3) (89.7%, 99.8%), ce_loss 0.669, lat_loss 22.008
09/22 02:37:38 AM | Train: [108/180] Step 250/1249 Loss 1.309 Prec@(1,3) (90.0%, 99.8%), ce_loss 0.669, lat_loss 22.008
09/22 02:38:00 AM | Train: [108/180] Step 300/1249 Loss 1.358 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.669, lat_loss 22.008
09/22 02:38:23 AM | Train: [108/180] Step 350/1249 Loss 1.416 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.668, lat_loss 22.008
09/22 02:38:42 AM | Train: [108/180] Step 400/1249 Loss 1.416 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.668, lat_loss 22.008
09/22 02:39:02 AM | Train: [108/180] Step 450/1249 Loss 1.413 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.668, lat_loss 22.008
09/22 02:39:23 AM | Train: [108/180] Step 500/1249 Loss 1.400 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.668, lat_loss 22.008
09/22 02:39:45 AM | Train: [108/180] Step 550/1249 Loss 1.385 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.668, lat_loss 22.008
09/22 02:40:08 AM | Train: [108/180] Step 600/1249 Loss 1.373 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.668, lat_loss 22.008
09/22 02:40:31 AM | Train: [108/180] Step 650/1249 Loss 1.361 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.668, lat_loss 22.008
09/22 02:40:55 AM | Train: [108/180] Step 700/1249 Loss 1.358 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.668, lat_loss 22.008
09/22 02:41:17 AM | Train: [108/180] Step 750/1249 Loss 1.361 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.668, lat_loss 22.008
09/22 02:41:40 AM | Train: [108/180] Step 800/1249 Loss 1.361 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.668, lat_loss 22.008
09/22 02:42:02 AM | Train: [108/180] Step 850/1249 Loss 1.354 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.667, lat_loss 22.008
09/22 02:42:24 AM | Train: [108/180] Step 900/1249 Loss 1.358 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.667, lat_loss 22.008
09/22 02:42:48 AM | Train: [108/180] Step 950/1249 Loss 1.359 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.667, lat_loss 22.008
09/22 02:43:11 AM | Train: [108/180] Step 1000/1249 Loss 1.361 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.667, lat_loss 22.008
09/22 02:43:33 AM | Train: [108/180] Step 1050/1249 Loss 1.368 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.667, lat_loss 22.008
09/22 02:43:54 AM | Train: [108/180] Step 1100/1249 Loss 1.371 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.667, lat_loss 22.008
09/22 02:44:16 AM | Train: [108/180] Step 1150/1249 Loss 1.368 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.667, lat_loss 22.008
09/22 02:44:38 AM | Train: [108/180] Step 1200/1249 Loss 1.392 Prec@(1,3) (89.3%, 99.6%), ce_loss 0.667, lat_loss 22.008
09/22 02:45:00 AM | Train: [108/180] Step 1249/1249 Loss 1.392 Prec@(1,3) (89.3%, 99.6%), ce_loss 0.667, lat_loss 22.008
09/22 02:45:01 AM | _w_step_train: [108/180] Final Prec@1 89.3125% Time 555.03
09/22 02:45:01 AM | Start to train theta for epoch 107
09/22 02:45:14 AM | Train: [108/180] Step 050/312 Loss 2.164 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.667, lat_loss 22.008
09/22 02:45:26 AM | Train: [108/180] Step 100/312 Loss 2.049 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.667, lat_loss 22.008
09/22 02:45:39 AM | Train: [108/180] Step 150/312 Loss 2.013 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.667, lat_loss 22.008
09/22 02:45:54 AM | Train: [108/180] Step 200/312 Loss 2.009 Prec@(1,3) (85.4%, 99.0%), ce_loss 0.667, lat_loss 22.008
09/22 02:46:13 AM | Train: [108/180] Step 250/312 Loss 2.001 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.667, lat_loss 22.008
09/22 02:46:32 AM | Train: [108/180] Step 300/312 Loss 2.006 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.666, lat_loss 22.008
09/22 02:46:37 AM | Train: [108/180] Step 312/312 Loss 2.019 Prec@(1,3) (85.2%, 99.0%), ce_loss 0.666, lat_loss 22.008
09/22 02:46:37 AM | _theta_step_train: [108/180] Final Prec@1 85.2300% Time 96.23
09/22 02:46:42 AM | Valid: [108/180] Step 050/312 Loss 1.877 Prec@(1,3) (85.4%, 99.5%), ce_loss 0.666, lat_loss 22.008
09/22 02:46:47 AM | Valid: [108/180] Step 100/312 Loss 1.947 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.666, lat_loss 22.008
09/22 02:46:51 AM | Valid: [108/180] Step 150/312 Loss 2.011 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.666, lat_loss 22.008
09/22 02:46:56 AM | Valid: [108/180] Step 200/312 Loss 2.036 Prec@(1,3) (85.0%, 99.1%), ce_loss 0.666, lat_loss 22.008
09/22 02:47:01 AM | Valid: [108/180] Step 250/312 Loss 2.002 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.666, lat_loss 22.008
09/22 02:47:06 AM | Valid: [108/180] Step 300/312 Loss 1.987 Prec@(1,3) (85.2%, 99.3%), ce_loss 0.666, lat_loss 22.008
09/22 02:47:07 AM | Valid: [108/180] Step 312/312 Loss 2.028 Prec@(1,3) (85.0%, 99.2%), ce_loss 0.666, lat_loss 22.008
09/22 02:47:07 AM | val: [108/180] Final Prec@1 85.0300% Time 29.97
09/22 02:47:07 AM | Start to train weights for epoch 108
09/22 02:47:32 AM | Train: [109/180] Step 050/1249 Loss 1.288 Prec@(1,3) (90.2%, 99.4%), ce_loss 0.666, lat_loss 22.008
09/22 02:47:57 AM | Train: [109/180] Step 100/1249 Loss 1.221 Prec@(1,3) (90.6%, 99.6%), ce_loss 0.666, lat_loss 22.008
09/22 02:48:20 AM | Train: [109/180] Step 150/1249 Loss 1.398 Prec@(1,3) (89.7%, 99.4%), ce_loss 0.666, lat_loss 22.008
09/22 02:48:44 AM | Train: [109/180] Step 200/1249 Loss 1.371 Prec@(1,3) (89.8%, 99.4%), ce_loss 0.666, lat_loss 22.008
09/22 02:49:07 AM | Train: [109/180] Step 250/1249 Loss 1.393 Prec@(1,3) (89.4%, 99.5%), ce_loss 0.666, lat_loss 22.008
09/22 02:49:27 AM | Train: [109/180] Step 300/1249 Loss 1.390 Prec@(1,3) (89.2%, 99.6%), ce_loss 0.666, lat_loss 22.008
09/22 02:49:49 AM | Train: [109/180] Step 350/1249 Loss 1.380 Prec@(1,3) (89.3%, 99.5%), ce_loss 0.666, lat_loss 22.008
09/22 02:50:13 AM | Train: [109/180] Step 400/1249 Loss 1.362 Prec@(1,3) (89.4%, 99.6%), ce_loss 0.665, lat_loss 22.008
09/22 02:50:36 AM | Train: [109/180] Step 450/1249 Loss 1.346 Prec@(1,3) (89.5%, 99.6%), ce_loss 0.665, lat_loss 22.008
09/22 02:51:00 AM | Train: [109/180] Step 500/1249 Loss 1.355 Prec@(1,3) (89.4%, 99.6%), ce_loss 0.665, lat_loss 22.008
09/22 02:51:22 AM | Train: [109/180] Step 550/1249 Loss 1.365 Prec@(1,3) (89.4%, 99.6%), ce_loss 0.665, lat_loss 22.008
09/22 02:51:45 AM | Train: [109/180] Step 600/1249 Loss 1.357 Prec@(1,3) (89.4%, 99.6%), ce_loss 0.665, lat_loss 22.008
09/22 02:52:08 AM | Train: [109/180] Step 650/1249 Loss 1.357 Prec@(1,3) (89.4%, 99.6%), ce_loss 0.665, lat_loss 22.008
09/22 02:52:30 AM | Train: [109/180] Step 700/1249 Loss 1.374 Prec@(1,3) (89.3%, 99.6%), ce_loss 0.665, lat_loss 22.008
09/22 02:52:54 AM | Train: [109/180] Step 750/1249 Loss 1.369 Prec@(1,3) (89.4%, 99.6%), ce_loss 0.665, lat_loss 22.008
09/22 02:53:18 AM | Train: [109/180] Step 800/1249 Loss 1.368 Prec@(1,3) (89.4%, 99.6%), ce_loss 0.665, lat_loss 22.008
09/22 02:53:40 AM | Train: [109/180] Step 850/1249 Loss 1.356 Prec@(1,3) (89.5%, 99.6%), ce_loss 0.665, lat_loss 22.008
09/22 02:54:02 AM | Train: [109/180] Step 900/1249 Loss 1.350 Prec@(1,3) (89.5%, 99.6%), ce_loss 0.665, lat_loss 22.008
09/22 02:54:26 AM | Train: [109/180] Step 950/1249 Loss 1.349 Prec@(1,3) (89.6%, 99.6%), ce_loss 0.664, lat_loss 22.008
09/22 02:54:48 AM | Train: [109/180] Step 1000/1249 Loss 1.345 Prec@(1,3) (89.6%, 99.6%), ce_loss 0.664, lat_loss 22.008
09/22 02:55:12 AM | Train: [109/180] Step 1050/1249 Loss 1.360 Prec@(1,3) (89.5%, 99.6%), ce_loss 0.664, lat_loss 22.008
09/22 02:55:35 AM | Train: [109/180] Step 1100/1249 Loss 1.362 Prec@(1,3) (89.4%, 99.6%), ce_loss 0.664, lat_loss 22.008
09/22 02:55:59 AM | Train: [109/180] Step 1150/1249 Loss 1.366 Prec@(1,3) (89.4%, 99.6%), ce_loss 0.664, lat_loss 22.008
09/22 02:56:22 AM | Train: [109/180] Step 1200/1249 Loss 1.367 Prec@(1,3) (89.4%, 99.6%), ce_loss 0.664, lat_loss 22.008
09/22 02:56:47 AM | Train: [109/180] Step 1249/1249 Loss 1.363 Prec@(1,3) (89.4%, 99.6%), ce_loss 0.664, lat_loss 22.008
09/22 02:56:47 AM | _w_step_train: [109/180] Final Prec@1 89.4225% Time 580.26
09/22 02:56:47 AM | Start to train theta for epoch 108
09/22 02:57:09 AM | Train: [109/180] Step 050/312 Loss 2.262 Prec@(1,3) (82.7%, 99.1%), ce_loss 0.664, lat_loss 22.008
09/22 02:57:29 AM | Train: [109/180] Step 100/312 Loss 2.168 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.664, lat_loss 22.007
09/22 02:57:49 AM | Train: [109/180] Step 150/312 Loss 2.058 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.664, lat_loss 22.007
09/22 02:58:10 AM | Train: [109/180] Step 200/312 Loss 2.042 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.664, lat_loss 22.007
09/22 02:58:30 AM | Train: [109/180] Step 250/312 Loss 2.075 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.664, lat_loss 22.007
09/22 02:58:50 AM | Train: [109/180] Step 300/312 Loss 2.078 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.664, lat_loss 22.007
09/22 02:58:55 AM | Train: [109/180] Step 312/312 Loss 2.063 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.664, lat_loss 22.007
09/22 02:58:55 AM | _theta_step_train: [109/180] Final Prec@1 84.8300% Time 128.22
09/22 02:59:00 AM | Valid: [109/180] Step 050/312 Loss 1.749 Prec@(1,3) (86.6%, 99.6%), ce_loss 0.664, lat_loss 22.007
09/22 02:59:05 AM | Valid: [109/180] Step 100/312 Loss 1.883 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.663, lat_loss 22.007
09/22 02:59:10 AM | Valid: [109/180] Step 150/312 Loss 1.969 Prec@(1,3) (85.3%, 99.4%), ce_loss 0.663, lat_loss 22.007
09/22 02:59:14 AM | Valid: [109/180] Step 200/312 Loss 1.962 Prec@(1,3) (85.4%, 99.3%), ce_loss 0.663, lat_loss 22.007
09/22 02:59:19 AM | Valid: [109/180] Step 250/312 Loss 1.964 Prec@(1,3) (85.3%, 99.4%), ce_loss 0.663, lat_loss 22.007
09/22 02:59:24 AM | Valid: [109/180] Step 300/312 Loss 1.949 Prec@(1,3) (85.2%, 99.3%), ce_loss 0.663, lat_loss 22.007
09/22 02:59:25 AM | Valid: [109/180] Step 312/312 Loss 1.940 Prec@(1,3) (85.3%, 99.4%), ce_loss 0.663, lat_loss 22.007
09/22 02:59:25 AM | val: [109/180] Final Prec@1 85.3000% Time 29.74
09/22 02:59:25 AM | Best top1 acc by now. Save model
09/22 02:59:25 AM | Start to train weights for epoch 109
09/22 02:59:49 AM | Train: [110/180] Step 050/1249 Loss 1.490 Prec@(1,3) (89.1%, 99.5%), ce_loss 0.663, lat_loss 22.007
09/22 03:00:10 AM | Train: [110/180] Step 100/1249 Loss 1.450 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.663, lat_loss 22.007
09/22 03:00:30 AM | Train: [110/180] Step 150/1249 Loss 1.411 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.663, lat_loss 22.007
09/22 03:00:51 AM | Train: [110/180] Step 200/1249 Loss 1.364 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.663, lat_loss 22.007
09/22 03:01:13 AM | Train: [110/180] Step 250/1249 Loss 1.359 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.663, lat_loss 22.007
09/22 03:01:36 AM | Train: [110/180] Step 300/1249 Loss 1.357 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.663, lat_loss 22.007
09/22 03:01:58 AM | Train: [110/180] Step 350/1249 Loss 1.359 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.663, lat_loss 22.007
09/22 03:02:20 AM | Train: [110/180] Step 400/1249 Loss 1.350 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.663, lat_loss 22.007
09/22 03:02:43 AM | Train: [110/180] Step 450/1249 Loss 1.355 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.662, lat_loss 22.007
09/22 03:03:05 AM | Train: [110/180] Step 500/1249 Loss 1.357 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.662, lat_loss 22.007
09/22 03:03:28 AM | Train: [110/180] Step 550/1249 Loss 1.375 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.662, lat_loss 22.007
09/22 03:03:49 AM | Train: [110/180] Step 600/1249 Loss 1.378 Prec@(1,3) (89.3%, 99.6%), ce_loss 0.662, lat_loss 22.007
09/22 03:04:13 AM | Train: [110/180] Step 650/1249 Loss 1.375 Prec@(1,3) (89.3%, 99.6%), ce_loss 0.662, lat_loss 22.007
09/22 03:04:35 AM | Train: [110/180] Step 700/1249 Loss 1.373 Prec@(1,3) (89.3%, 99.6%), ce_loss 0.662, lat_loss 22.007
09/22 03:04:57 AM | Train: [110/180] Step 750/1249 Loss 1.367 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.662, lat_loss 22.007
09/22 03:05:19 AM | Train: [110/180] Step 800/1249 Loss 1.392 Prec@(1,3) (89.2%, 99.6%), ce_loss 0.662, lat_loss 22.007
09/22 03:05:39 AM | Train: [110/180] Step 850/1249 Loss 1.398 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.662, lat_loss 22.007
09/22 03:06:01 AM | Train: [110/180] Step 900/1249 Loss 1.397 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.662, lat_loss 22.007
09/22 03:06:20 AM | Train: [110/180] Step 950/1249 Loss 1.384 Prec@(1,3) (89.2%, 99.6%), ce_loss 0.662, lat_loss 22.007
09/22 03:06:41 AM | Train: [110/180] Step 1000/1249 Loss 1.382 Prec@(1,3) (89.3%, 99.6%), ce_loss 0.662, lat_loss 22.007
09/22 03:07:02 AM | Train: [110/180] Step 1050/1249 Loss 1.374 Prec@(1,3) (89.3%, 99.6%), ce_loss 0.661, lat_loss 22.007
09/22 03:07:22 AM | Train: [110/180] Step 1100/1249 Loss 1.375 Prec@(1,3) (89.3%, 99.6%), ce_loss 0.661, lat_loss 22.007
09/22 03:07:42 AM | Train: [110/180] Step 1150/1249 Loss 1.371 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.661, lat_loss 22.007
09/22 03:08:05 AM | Train: [110/180] Step 1200/1249 Loss 1.368 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.661, lat_loss 22.007
09/22 03:08:28 AM | Train: [110/180] Step 1249/1249 Loss 1.363 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.661, lat_loss 22.007
09/22 03:08:29 AM | _w_step_train: [110/180] Final Prec@1 89.3475% Time 543.34
09/22 03:08:29 AM | Start to train theta for epoch 109
09/22 03:08:49 AM | Train: [110/180] Step 050/312 Loss 1.903 Prec@(1,3) (85.1%, 99.4%), ce_loss 0.661, lat_loss 22.007
09/22 03:09:10 AM | Train: [110/180] Step 100/312 Loss 1.960 Prec@(1,3) (85.1%, 99.5%), ce_loss 0.661, lat_loss 22.007
09/22 03:09:30 AM | Train: [110/180] Step 150/312 Loss 2.059 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.661, lat_loss 22.007
09/22 03:09:49 AM | Train: [110/180] Step 200/312 Loss 2.090 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.661, lat_loss 22.007
09/22 03:10:06 AM | Train: [110/180] Step 250/312 Loss 2.106 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.661, lat_loss 22.007
09/22 03:10:26 AM | Train: [110/180] Step 300/312 Loss 2.104 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.661, lat_loss 22.007
09/22 03:10:31 AM | Train: [110/180] Step 312/312 Loss 2.108 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.661, lat_loss 22.007
09/22 03:10:31 AM | _theta_step_train: [110/180] Final Prec@1 84.8000% Time 122.16
09/22 03:10:36 AM | Valid: [110/180] Step 050/312 Loss 2.259 Prec@(1,3) (83.8%, 98.7%), ce_loss 0.661, lat_loss 22.007
09/22 03:10:41 AM | Valid: [110/180] Step 100/312 Loss 2.208 Prec@(1,3) (84.3%, 98.6%), ce_loss 0.661, lat_loss 22.007
09/22 03:10:45 AM | Valid: [110/180] Step 150/312 Loss 2.255 Prec@(1,3) (83.7%, 98.7%), ce_loss 0.661, lat_loss 22.007
09/22 03:10:50 AM | Valid: [110/180] Step 200/312 Loss 2.183 Prec@(1,3) (84.3%, 98.9%), ce_loss 0.661, lat_loss 22.007
09/22 03:10:55 AM | Valid: [110/180] Step 250/312 Loss 2.141 Prec@(1,3) (84.4%, 99.0%), ce_loss 0.661, lat_loss 22.007
09/22 03:10:59 AM | Valid: [110/180] Step 300/312 Loss 2.124 Prec@(1,3) (84.4%, 99.1%), ce_loss 0.660, lat_loss 22.007
09/22 03:11:00 AM | Valid: [110/180] Step 312/312 Loss 2.163 Prec@(1,3) (84.3%, 99.0%), ce_loss 0.660, lat_loss 22.007
09/22 03:11:00 AM | val: [110/180] Final Prec@1 84.3100% Time 29.69
09/22 03:11:01 AM | Start to train weights for epoch 110
09/22 03:11:26 AM | Train: [111/180] Step 050/1249 Loss 1.229 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.660, lat_loss 22.007
09/22 03:11:49 AM | Train: [111/180] Step 100/1249 Loss 1.257 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.660, lat_loss 22.007
09/22 03:12:12 AM | Train: [111/180] Step 150/1249 Loss 1.254 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.660, lat_loss 22.007
09/22 03:12:33 AM | Train: [111/180] Step 200/1249 Loss 1.277 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.660, lat_loss 22.007
09/22 03:12:56 AM | Train: [111/180] Step 250/1249 Loss 1.258 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.660, lat_loss 22.007
09/22 03:13:18 AM | Train: [111/180] Step 300/1249 Loss 1.256 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.660, lat_loss 22.006
09/22 03:13:39 AM | Train: [111/180] Step 350/1249 Loss 1.284 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.660, lat_loss 22.006
09/22 03:14:01 AM | Train: [111/180] Step 400/1249 Loss 1.292 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.660, lat_loss 22.006
09/22 03:14:19 AM | Train: [111/180] Step 450/1249 Loss 1.293 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.660, lat_loss 22.006
09/22 03:14:35 AM | Train: [111/180] Step 500/1249 Loss 1.296 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.660, lat_loss 22.006
09/22 03:14:59 AM | Train: [111/180] Step 550/1249 Loss 1.300 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.659, lat_loss 22.006
09/22 03:15:24 AM | Train: [111/180] Step 600/1249 Loss 1.296 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.659, lat_loss 22.006
09/22 03:15:49 AM | Train: [111/180] Step 650/1249 Loss 1.305 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.659, lat_loss 22.006
09/22 03:16:13 AM | Train: [111/180] Step 700/1249 Loss 1.301 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.659, lat_loss 22.006
09/22 03:16:38 AM | Train: [111/180] Step 750/1249 Loss 1.304 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.659, lat_loss 22.006
09/22 03:17:03 AM | Train: [111/180] Step 800/1249 Loss 1.301 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.659, lat_loss 22.006
09/22 03:17:27 AM | Train: [111/180] Step 850/1249 Loss 1.298 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.659, lat_loss 22.006
09/22 03:17:50 AM | Train: [111/180] Step 900/1249 Loss 1.294 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.659, lat_loss 22.006
09/22 03:18:14 AM | Train: [111/180] Step 950/1249 Loss 1.293 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.659, lat_loss 22.006
09/22 03:18:38 AM | Train: [111/180] Step 1000/1249 Loss 1.284 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.659, lat_loss 22.006
09/22 03:19:03 AM | Train: [111/180] Step 1050/1249 Loss 1.288 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.659, lat_loss 22.006
09/22 03:19:28 AM | Train: [111/180] Step 1100/1249 Loss 1.294 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.658, lat_loss 22.006
09/22 03:19:53 AM | Train: [111/180] Step 1150/1249 Loss 1.296 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.658, lat_loss 22.006
09/22 03:20:17 AM | Train: [111/180] Step 1200/1249 Loss 1.300 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.658, lat_loss 22.006
09/22 03:20:42 AM | Train: [111/180] Step 1249/1249 Loss 1.303 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.658, lat_loss 22.006
09/22 03:20:42 AM | _w_step_train: [111/180] Final Prec@1 89.8950% Time 581.00
09/22 03:20:42 AM | Start to train theta for epoch 110
09/22 03:21:03 AM | Train: [111/180] Step 050/312 Loss 2.063 Prec@(1,3) (84.8%, 99.0%), ce_loss 0.658, lat_loss 22.006
09/22 03:21:24 AM | Train: [111/180] Step 100/312 Loss 2.062 Prec@(1,3) (84.5%, 99.1%), ce_loss 0.658, lat_loss 22.006
09/22 03:21:43 AM | Train: [111/180] Step 150/312 Loss 2.026 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.658, lat_loss 22.006
09/22 03:22:02 AM | Train: [111/180] Step 200/312 Loss 2.000 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.658, lat_loss 22.006
09/22 03:22:22 AM | Train: [111/180] Step 250/312 Loss 2.032 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.658, lat_loss 22.006
09/22 03:22:41 AM | Train: [111/180] Step 300/312 Loss 2.059 Prec@(1,3) (84.7%, 99.0%), ce_loss 0.658, lat_loss 22.006
09/22 03:22:46 AM | Train: [111/180] Step 312/312 Loss 2.039 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.658, lat_loss 22.006
09/22 03:22:46 AM | _theta_step_train: [111/180] Final Prec@1 84.8900% Time 124.04
09/22 03:22:51 AM | Valid: [111/180] Step 050/312 Loss 2.473 Prec@(1,3) (82.8%, 98.6%), ce_loss 0.658, lat_loss 22.006
09/22 03:22:55 AM | Valid: [111/180] Step 100/312 Loss 2.316 Prec@(1,3) (83.6%, 98.8%), ce_loss 0.658, lat_loss 22.006
09/22 03:22:59 AM | Valid: [111/180] Step 150/312 Loss 2.314 Prec@(1,3) (83.5%, 98.7%), ce_loss 0.658, lat_loss 22.006
09/22 03:23:04 AM | Valid: [111/180] Step 200/312 Loss 2.213 Prec@(1,3) (84.2%, 98.9%), ce_loss 0.658, lat_loss 22.006
09/22 03:23:08 AM | Valid: [111/180] Step 250/312 Loss 2.206 Prec@(1,3) (84.0%, 98.9%), ce_loss 0.658, lat_loss 22.006
09/22 03:23:12 AM | Valid: [111/180] Step 300/312 Loss 2.196 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.658, lat_loss 22.006
09/22 03:23:13 AM | Valid: [111/180] Step 312/312 Loss 2.198 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.658, lat_loss 22.006
09/22 03:23:13 AM | val: [111/180] Final Prec@1 83.7700% Time 27.26
09/22 03:23:13 AM | Start to train weights for epoch 111
09/22 03:23:39 AM | Train: [112/180] Step 050/1249 Loss 1.347 Prec@(1,3) (88.6%, 99.8%), ce_loss 0.658, lat_loss 22.006
09/22 03:24:00 AM | Train: [112/180] Step 100/1249 Loss 1.304 Prec@(1,3) (89.0%, 99.8%), ce_loss 0.658, lat_loss 22.006
09/22 03:24:23 AM | Train: [112/180] Step 150/1249 Loss 1.280 Prec@(1,3) (89.5%, 99.8%), ce_loss 0.657, lat_loss 22.006
09/22 03:24:46 AM | Train: [112/180] Step 200/1249 Loss 1.280 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.657, lat_loss 22.006
09/22 03:25:07 AM | Train: [112/180] Step 250/1249 Loss 1.253 Prec@(1,3) (89.8%, 99.8%), ce_loss 0.657, lat_loss 22.006
09/22 03:25:27 AM | Train: [112/180] Step 300/1249 Loss 1.263 Prec@(1,3) (89.6%, 99.8%), ce_loss 0.657, lat_loss 22.006
09/22 03:25:50 AM | Train: [112/180] Step 350/1249 Loss 1.256 Prec@(1,3) (89.8%, 99.8%), ce_loss 0.657, lat_loss 22.006
09/22 03:26:14 AM | Train: [112/180] Step 400/1249 Loss 1.260 Prec@(1,3) (89.8%, 99.8%), ce_loss 0.657, lat_loss 22.006
09/22 03:26:36 AM | Train: [112/180] Step 450/1249 Loss 1.265 Prec@(1,3) (89.9%, 99.8%), ce_loss 0.657, lat_loss 22.006
09/22 03:26:59 AM | Train: [112/180] Step 500/1249 Loss 1.267 Prec@(1,3) (89.9%, 99.8%), ce_loss 0.657, lat_loss 22.006
09/22 03:27:22 AM | Train: [112/180] Step 550/1249 Loss 1.277 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.657, lat_loss 22.006
09/22 03:27:44 AM | Train: [112/180] Step 600/1249 Loss 1.276 Prec@(1,3) (89.8%, 99.8%), ce_loss 0.657, lat_loss 22.006
09/22 03:28:07 AM | Train: [112/180] Step 650/1249 Loss 1.281 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.657, lat_loss 22.006
09/22 03:28:30 AM | Train: [112/180] Step 700/1249 Loss 1.279 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.656, lat_loss 22.006
09/22 03:28:51 AM | Train: [112/180] Step 750/1249 Loss 1.279 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.656, lat_loss 22.006
09/22 03:29:10 AM | Train: [112/180] Step 800/1249 Loss 1.273 Prec@(1,3) (89.9%, 99.8%), ce_loss 0.656, lat_loss 22.006
09/22 03:29:31 AM | Train: [112/180] Step 850/1249 Loss 1.291 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.656, lat_loss 22.006
09/22 03:29:48 AM | Train: [112/180] Step 900/1249 Loss 1.290 Prec@(1,3) (89.8%, 99.8%), ce_loss 0.656, lat_loss 22.006
09/22 03:30:04 AM | Train: [112/180] Step 950/1249 Loss 1.293 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.656, lat_loss 22.006
09/22 03:30:20 AM | Train: [112/180] Step 1000/1249 Loss 1.290 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.656, lat_loss 22.006
09/22 03:30:36 AM | Train: [112/180] Step 1050/1249 Loss 1.295 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.656, lat_loss 22.006
09/22 03:30:52 AM | Train: [112/180] Step 1100/1249 Loss 1.296 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.656, lat_loss 22.006
09/22 03:31:08 AM | Train: [112/180] Step 1150/1249 Loss 1.300 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.656, lat_loss 22.005
09/22 03:31:24 AM | Train: [112/180] Step 1200/1249 Loss 1.300 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.656, lat_loss 22.005
09/22 03:31:40 AM | Train: [112/180] Step 1249/1249 Loss 1.299 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.655, lat_loss 22.005
09/22 03:31:40 AM | _w_step_train: [112/180] Final Prec@1 89.7250% Time 506.42
09/22 03:31:40 AM | Start to train theta for epoch 111
09/22 03:31:53 AM | Train: [112/180] Step 050/312 Loss 2.003 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.655, lat_loss 22.005
09/22 03:32:05 AM | Train: [112/180] Step 100/312 Loss 2.107 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.655, lat_loss 22.005
09/22 03:32:18 AM | Train: [112/180] Step 150/312 Loss 2.118 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.655, lat_loss 22.005
09/22 03:32:34 AM | Train: [112/180] Step 200/312 Loss 2.156 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.655, lat_loss 22.005
09/22 03:32:54 AM | Train: [112/180] Step 250/312 Loss 2.143 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.655, lat_loss 22.005
09/22 03:33:14 AM | Train: [112/180] Step 300/312 Loss 2.145 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.655, lat_loss 22.005
09/22 03:33:19 AM | Train: [112/180] Step 312/312 Loss 2.133 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.655, lat_loss 22.005
09/22 03:33:19 AM | _theta_step_train: [112/180] Final Prec@1 84.6900% Time 99.13
09/22 03:33:24 AM | Valid: [112/180] Step 050/312 Loss 2.191 Prec@(1,3) (83.0%, 98.8%), ce_loss 0.655, lat_loss 22.005
09/22 03:33:29 AM | Valid: [112/180] Step 100/312 Loss 2.192 Prec@(1,3) (83.0%, 98.9%), ce_loss 0.655, lat_loss 22.005
09/22 03:33:33 AM | Valid: [112/180] Step 150/312 Loss 2.215 Prec@(1,3) (82.9%, 98.9%), ce_loss 0.655, lat_loss 22.005
09/22 03:33:38 AM | Valid: [112/180] Step 200/312 Loss 2.147 Prec@(1,3) (83.8%, 99.1%), ce_loss 0.655, lat_loss 22.005
09/22 03:33:43 AM | Valid: [112/180] Step 250/312 Loss 2.153 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.655, lat_loss 22.005
09/22 03:33:47 AM | Valid: [112/180] Step 300/312 Loss 2.135 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.655, lat_loss 22.005
09/22 03:33:48 AM | Valid: [112/180] Step 312/312 Loss 2.125 Prec@(1,3) (83.7%, 99.2%), ce_loss 0.655, lat_loss 22.005
09/22 03:33:49 AM | val: [112/180] Final Prec@1 83.7200% Time 29.73
09/22 03:33:49 AM | Start to train weights for epoch 112
09/22 03:34:13 AM | Train: [113/180] Step 050/1249 Loss 1.253 Prec@(1,3) (90.0%, 99.9%), ce_loss 0.655, lat_loss 22.005
09/22 03:34:35 AM | Train: [113/180] Step 100/1249 Loss 1.264 Prec@(1,3) (90.1%, 99.8%), ce_loss 0.655, lat_loss 22.005
09/22 03:34:55 AM | Train: [113/180] Step 150/1249 Loss 1.227 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.655, lat_loss 22.005
09/22 03:35:16 AM | Train: [113/180] Step 200/1249 Loss 1.203 Prec@(1,3) (90.5%, 99.8%), ce_loss 0.655, lat_loss 22.005
09/22 03:35:37 AM | Train: [113/180] Step 250/1249 Loss 1.224 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.654, lat_loss 22.005
09/22 03:36:00 AM | Train: [113/180] Step 300/1249 Loss 1.227 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.654, lat_loss 22.005
09/22 03:36:21 AM | Train: [113/180] Step 350/1249 Loss 1.218 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.654, lat_loss 22.005
09/22 03:36:43 AM | Train: [113/180] Step 400/1249 Loss 1.219 Prec@(1,3) (90.4%, 99.8%), ce_loss 0.654, lat_loss 22.005
09/22 03:37:04 AM | Train: [113/180] Step 450/1249 Loss 1.222 Prec@(1,3) (90.4%, 99.8%), ce_loss 0.654, lat_loss 22.005
09/22 03:37:27 AM | Train: [113/180] Step 500/1249 Loss 1.206 Prec@(1,3) (90.5%, 99.8%), ce_loss 0.654, lat_loss 22.005
09/22 03:37:50 AM | Train: [113/180] Step 550/1249 Loss 1.219 Prec@(1,3) (90.4%, 99.8%), ce_loss 0.654, lat_loss 22.005
09/22 03:38:13 AM | Train: [113/180] Step 600/1249 Loss 1.217 Prec@(1,3) (90.4%, 99.8%), ce_loss 0.654, lat_loss 22.005
09/22 03:38:35 AM | Train: [113/180] Step 650/1249 Loss 1.229 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.654, lat_loss 22.005
09/22 03:38:58 AM | Train: [113/180] Step 700/1249 Loss 1.238 Prec@(1,3) (90.2%, 99.8%), ce_loss 0.654, lat_loss 22.005
09/22 03:39:23 AM | Train: [113/180] Step 750/1249 Loss 1.240 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.654, lat_loss 22.005
09/22 03:39:46 AM | Train: [113/180] Step 800/1249 Loss 1.235 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.653, lat_loss 22.005
09/22 03:40:09 AM | Train: [113/180] Step 850/1249 Loss 1.238 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.653, lat_loss 22.005
09/22 03:40:32 AM | Train: [113/180] Step 900/1249 Loss 1.245 Prec@(1,3) (90.2%, 99.8%), ce_loss 0.653, lat_loss 22.005
09/22 03:40:55 AM | Train: [113/180] Step 950/1249 Loss 1.252 Prec@(1,3) (90.2%, 99.8%), ce_loss 0.653, lat_loss 22.005
09/22 03:41:16 AM | Train: [113/180] Step 1000/1249 Loss 1.257 Prec@(1,3) (90.1%, 99.8%), ce_loss 0.653, lat_loss 22.005
09/22 03:41:39 AM | Train: [113/180] Step 1050/1249 Loss 1.251 Prec@(1,3) (90.2%, 99.8%), ce_loss 0.653, lat_loss 22.005
09/22 03:42:02 AM | Train: [113/180] Step 1100/1249 Loss 1.257 Prec@(1,3) (90.1%, 99.8%), ce_loss 0.653, lat_loss 22.005
09/22 03:42:25 AM | Train: [113/180] Step 1150/1249 Loss 1.267 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.653, lat_loss 22.005
09/22 03:42:49 AM | Train: [113/180] Step 1200/1249 Loss 1.268 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.653, lat_loss 22.005
09/22 03:43:13 AM | Train: [113/180] Step 1249/1249 Loss 1.271 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.653, lat_loss 22.005
09/22 03:43:13 AM | _w_step_train: [113/180] Final Prec@1 90.0450% Time 564.55
09/22 03:43:13 AM | Start to train theta for epoch 112
09/22 03:43:34 AM | Train: [113/180] Step 050/312 Loss 2.088 Prec@(1,3) (84.1%, 99.1%), ce_loss 0.653, lat_loss 22.005
09/22 03:43:54 AM | Train: [113/180] Step 100/312 Loss 2.100 Prec@(1,3) (84.6%, 99.0%), ce_loss 0.653, lat_loss 22.005
09/22 03:44:14 AM | Train: [113/180] Step 150/312 Loss 2.073 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.653, lat_loss 22.005
09/22 03:44:34 AM | Train: [113/180] Step 200/312 Loss 2.048 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.653, lat_loss 22.005
09/22 03:44:55 AM | Train: [113/180] Step 250/312 Loss 2.020 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.652, lat_loss 22.005
09/22 03:45:16 AM | Train: [113/180] Step 300/312 Loss 2.084 Prec@(1,3) (84.9%, 99.0%), ce_loss 0.652, lat_loss 22.005
09/22 03:45:21 AM | Train: [113/180] Step 312/312 Loss 2.090 Prec@(1,3) (84.9%, 99.0%), ce_loss 0.652, lat_loss 22.005
09/22 03:45:21 AM | _theta_step_train: [113/180] Final Prec@1 84.9000% Time 127.50
09/22 03:45:26 AM | Valid: [113/180] Step 050/312 Loss 1.980 Prec@(1,3) (84.9%, 99.5%), ce_loss 0.652, lat_loss 22.005
09/22 03:45:30 AM | Valid: [113/180] Step 100/312 Loss 2.048 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.652, lat_loss 22.005
09/22 03:45:35 AM | Valid: [113/180] Step 150/312 Loss 2.082 Prec@(1,3) (85.2%, 99.0%), ce_loss 0.652, lat_loss 22.005
09/22 03:45:40 AM | Valid: [113/180] Step 200/312 Loss 2.066 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.652, lat_loss 22.005
09/22 03:45:44 AM | Valid: [113/180] Step 250/312 Loss 2.100 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.652, lat_loss 22.005
09/22 03:45:49 AM | Valid: [113/180] Step 300/312 Loss 2.083 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.652, lat_loss 22.005
09/22 03:45:50 AM | Valid: [113/180] Step 312/312 Loss 2.073 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.652, lat_loss 22.005
09/22 03:45:50 AM | val: [113/180] Final Prec@1 85.4400% Time 29.59
09/22 03:45:50 AM | Best top1 acc by now. Save model
09/22 03:45:50 AM | Start to train weights for epoch 113
09/22 03:46:17 AM | Train: [114/180] Step 050/1249 Loss 1.275 Prec@(1,3) (90.0%, 99.6%), ce_loss 0.652, lat_loss 22.005
09/22 03:46:42 AM | Train: [114/180] Step 100/1249 Loss 1.313 Prec@(1,3) (89.6%, 99.6%), ce_loss 0.652, lat_loss 22.005
09/22 03:47:07 AM | Train: [114/180] Step 150/1249 Loss 1.267 Prec@(1,3) (89.9%, 99.6%), ce_loss 0.652, lat_loss 22.005
09/22 03:47:31 AM | Train: [114/180] Step 200/1249 Loss 1.245 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.652, lat_loss 22.005
09/22 03:47:56 AM | Train: [114/180] Step 250/1249 Loss 1.255 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.652, lat_loss 22.005
09/22 03:48:21 AM | Train: [114/180] Step 300/1249 Loss 1.269 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.652, lat_loss 22.005
09/22 03:48:46 AM | Train: [114/180] Step 350/1249 Loss 1.280 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.652, lat_loss 22.005
09/22 03:49:11 AM | Train: [114/180] Step 400/1249 Loss 1.312 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.651, lat_loss 22.005
09/22 03:49:36 AM | Train: [114/180] Step 450/1249 Loss 1.303 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.651, lat_loss 22.005
09/22 03:50:01 AM | Train: [114/180] Step 500/1249 Loss 1.291 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.651, lat_loss 22.005
09/22 03:50:26 AM | Train: [114/180] Step 550/1249 Loss 1.290 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.651, lat_loss 22.005
09/22 03:50:51 AM | Train: [114/180] Step 600/1249 Loss 1.299 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.651, lat_loss 22.005
09/22 03:51:16 AM | Train: [114/180] Step 650/1249 Loss 1.290 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.651, lat_loss 22.005
09/22 03:51:41 AM | Train: [114/180] Step 700/1249 Loss 1.342 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.651, lat_loss 22.005
09/22 03:52:06 AM | Train: [114/180] Step 750/1249 Loss 1.338 Prec@(1,3) (89.9%, 99.6%), ce_loss 0.651, lat_loss 22.005
09/22 03:52:31 AM | Train: [114/180] Step 800/1249 Loss 1.327 Prec@(1,3) (89.9%, 99.6%), ce_loss 0.651, lat_loss 22.005
09/22 03:52:56 AM | Train: [114/180] Step 850/1249 Loss 1.323 Prec@(1,3) (89.9%, 99.6%), ce_loss 0.651, lat_loss 22.005
09/22 03:53:21 AM | Train: [114/180] Step 900/1249 Loss 1.311 Prec@(1,3) (90.0%, 99.6%), ce_loss 0.651, lat_loss 22.005
09/22 03:53:45 AM | Train: [114/180] Step 950/1249 Loss 1.328 Prec@(1,3) (89.9%, 99.6%), ce_loss 0.651, lat_loss 22.005
09/22 03:54:10 AM | Train: [114/180] Step 1000/1249 Loss 1.330 Prec@(1,3) (89.9%, 99.6%), ce_loss 0.650, lat_loss 22.005
09/22 03:54:35 AM | Train: [114/180] Step 1050/1249 Loss 1.344 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.650, lat_loss 22.005
09/22 03:55:00 AM | Train: [114/180] Step 1100/1249 Loss 1.345 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.650, lat_loss 22.005
09/22 03:55:24 AM | Train: [114/180] Step 1150/1249 Loss 1.345 Prec@(1,3) (89.7%, 99.6%), ce_loss 0.650, lat_loss 22.005
09/22 03:55:42 AM | Train: [114/180] Step 1200/1249 Loss 1.338 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.650, lat_loss 22.005
09/22 03:55:57 AM | Train: [114/180] Step 1249/1249 Loss 1.334 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.650, lat_loss 22.005
09/22 03:55:57 AM | _w_step_train: [114/180] Final Prec@1 89.7875% Time 606.89
09/22 03:55:57 AM | Start to train theta for epoch 113
09/22 03:56:17 AM | Train: [114/180] Step 050/312 Loss 1.990 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.650, lat_loss 22.005
09/22 03:56:30 AM | Train: [114/180] Step 100/312 Loss 2.053 Prec@(1,3) (85.6%, 99.1%), ce_loss 0.650, lat_loss 22.005
09/22 03:56:42 AM | Train: [114/180] Step 150/312 Loss 2.069 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.650, lat_loss 22.005
09/22 03:56:54 AM | Train: [114/180] Step 200/312 Loss 2.048 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.650, lat_loss 22.005
09/22 03:57:07 AM | Train: [114/180] Step 250/312 Loss 2.036 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.650, lat_loss 22.004
09/22 03:57:20 AM | Train: [114/180] Step 300/312 Loss 2.046 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.650, lat_loss 22.004
09/22 03:57:23 AM | Train: [114/180] Step 312/312 Loss 2.019 Prec@(1,3) (85.5%, 99.1%), ce_loss 0.650, lat_loss 22.004
09/22 03:57:23 AM | _theta_step_train: [114/180] Final Prec@1 85.4500% Time 85.25
09/22 03:57:28 AM | Valid: [114/180] Step 050/312 Loss 1.835 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.650, lat_loss 22.004
09/22 03:57:32 AM | Valid: [114/180] Step 100/312 Loss 2.070 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.650, lat_loss 22.004
09/22 03:57:37 AM | Valid: [114/180] Step 150/312 Loss 2.094 Prec@(1,3) (84.8%, 98.9%), ce_loss 0.650, lat_loss 22.004
09/22 03:57:42 AM | Valid: [114/180] Step 200/312 Loss 2.103 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.650, lat_loss 22.004
09/22 03:57:46 AM | Valid: [114/180] Step 250/312 Loss 2.098 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.650, lat_loss 22.004
09/22 03:57:51 AM | Valid: [114/180] Step 300/312 Loss 2.123 Prec@(1,3) (84.2%, 99.1%), ce_loss 0.650, lat_loss 22.004
09/22 03:57:52 AM | Valid: [114/180] Step 312/312 Loss 2.107 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.650, lat_loss 22.004
09/22 03:57:52 AM | val: [114/180] Final Prec@1 84.3100% Time 29.35
09/22 03:57:52 AM | Start to train weights for epoch 114
09/22 03:58:18 AM | Train: [115/180] Step 050/1249 Loss 1.264 Prec@(1,3) (90.1%, 99.8%), ce_loss 0.649, lat_loss 22.004
09/22 03:58:43 AM | Train: [115/180] Step 100/1249 Loss 1.301 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.649, lat_loss 22.004
09/22 03:59:08 AM | Train: [115/180] Step 150/1249 Loss 1.259 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.649, lat_loss 22.004
09/22 03:59:33 AM | Train: [115/180] Step 200/1249 Loss 1.201 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.649, lat_loss 22.004
09/22 03:59:58 AM | Train: [115/180] Step 250/1249 Loss 1.286 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.649, lat_loss 22.004
09/22 04:00:23 AM | Train: [115/180] Step 300/1249 Loss 1.295 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.649, lat_loss 22.004
09/22 04:00:48 AM | Train: [115/180] Step 350/1249 Loss 1.303 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.649, lat_loss 22.004
09/22 04:01:13 AM | Train: [115/180] Step 400/1249 Loss 1.275 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.649, lat_loss 22.004
09/22 04:01:38 AM | Train: [115/180] Step 450/1249 Loss 1.283 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.649, lat_loss 22.004
09/22 04:02:03 AM | Train: [115/180] Step 500/1249 Loss 1.276 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.649, lat_loss 22.004
09/22 04:02:28 AM | Train: [115/180] Step 550/1249 Loss 1.280 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.649, lat_loss 22.004
09/22 04:02:53 AM | Train: [115/180] Step 600/1249 Loss 1.263 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.648, lat_loss 22.004
09/22 04:03:18 AM | Train: [115/180] Step 650/1249 Loss 1.258 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.648, lat_loss 22.004
09/22 04:03:43 AM | Train: [115/180] Step 700/1249 Loss 1.258 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.648, lat_loss 22.004
09/22 04:04:08 AM | Train: [115/180] Step 750/1249 Loss 1.244 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.648, lat_loss 22.004
09/22 04:04:33 AM | Train: [115/180] Step 800/1249 Loss 1.256 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.648, lat_loss 22.004
09/22 04:04:58 AM | Train: [115/180] Step 850/1249 Loss 1.261 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.648, lat_loss 22.004
09/22 04:05:23 AM | Train: [115/180] Step 900/1249 Loss 1.258 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.648, lat_loss 22.004
09/22 04:05:48 AM | Train: [115/180] Step 950/1249 Loss 1.254 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.648, lat_loss 22.004
09/22 04:06:13 AM | Train: [115/180] Step 1000/1249 Loss 1.257 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.648, lat_loss 22.004
09/22 04:06:38 AM | Train: [115/180] Step 1050/1249 Loss 1.265 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.648, lat_loss 22.004
09/22 04:07:03 AM | Train: [115/180] Step 1100/1249 Loss 1.272 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.648, lat_loss 22.004
09/22 04:07:28 AM | Train: [115/180] Step 1150/1249 Loss 1.269 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.648, lat_loss 22.004
09/22 04:07:53 AM | Train: [115/180] Step 1200/1249 Loss 1.275 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.647, lat_loss 22.004
09/22 04:08:18 AM | Train: [115/180] Step 1249/1249 Loss 1.275 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.647, lat_loss 22.004
09/22 04:08:18 AM | _w_step_train: [115/180] Final Prec@1 90.0350% Time 625.76
09/22 04:08:18 AM | Start to train theta for epoch 114
09/22 04:08:39 AM | Train: [115/180] Step 050/312 Loss 1.821 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.647, lat_loss 22.004
09/22 04:08:59 AM | Train: [115/180] Step 100/312 Loss 2.040 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.647, lat_loss 22.004
09/22 04:09:20 AM | Train: [115/180] Step 150/312 Loss 2.116 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.647, lat_loss 22.004
09/22 04:09:40 AM | Train: [115/180] Step 200/312 Loss 2.096 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.647, lat_loss 22.004
09/22 04:10:01 AM | Train: [115/180] Step 250/312 Loss 2.072 Prec@(1,3) (85.0%, 99.2%), ce_loss 0.647, lat_loss 22.004
09/22 04:10:21 AM | Train: [115/180] Step 300/312 Loss 2.067 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.647, lat_loss 22.004
09/22 04:10:26 AM | Train: [115/180] Step 312/312 Loss 2.064 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.647, lat_loss 22.004
09/22 04:10:27 AM | _theta_step_train: [115/180] Final Prec@1 85.0100% Time 128.97
09/22 04:10:32 AM | Valid: [115/180] Step 050/312 Loss 1.714 Prec@(1,3) (87.2%, 99.4%), ce_loss 0.647, lat_loss 22.004
09/22 04:10:37 AM | Valid: [115/180] Step 100/312 Loss 1.943 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.647, lat_loss 22.004
09/22 04:10:42 AM | Valid: [115/180] Step 150/312 Loss 2.003 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.647, lat_loss 22.004
09/22 04:10:46 AM | Valid: [115/180] Step 200/312 Loss 2.001 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.647, lat_loss 22.004
09/22 04:10:51 AM | Valid: [115/180] Step 250/312 Loss 2.007 Prec@(1,3) (85.2%, 99.3%), ce_loss 0.647, lat_loss 22.004
09/22 04:10:56 AM | Valid: [115/180] Step 300/312 Loss 1.969 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.647, lat_loss 22.004
09/22 04:10:57 AM | Valid: [115/180] Step 312/312 Loss 1.963 Prec@(1,3) (85.4%, 99.3%), ce_loss 0.647, lat_loss 22.004
09/22 04:10:57 AM | val: [115/180] Final Prec@1 85.3600% Time 30.44
09/22 04:10:57 AM | Start to train weights for epoch 115
09/22 04:11:23 AM | Train: [116/180] Step 050/1249 Loss 1.089 Prec@(1,3) (92.0%, 99.9%), ce_loss 0.647, lat_loss 22.004
09/22 04:11:46 AM | Train: [116/180] Step 100/1249 Loss 1.120 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.647, lat_loss 22.004
09/22 04:12:09 AM | Train: [116/180] Step 150/1249 Loss 1.147 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.647, lat_loss 22.004
09/22 04:12:32 AM | Train: [116/180] Step 200/1249 Loss 1.183 Prec@(1,3) (90.9%, 99.8%), ce_loss 0.646, lat_loss 22.004
09/22 04:12:55 AM | Train: [116/180] Step 250/1249 Loss 1.254 Prec@(1,3) (90.7%, 99.6%), ce_loss 0.646, lat_loss 22.004
09/22 04:13:19 AM | Train: [116/180] Step 300/1249 Loss 1.335 Prec@(1,3) (90.1%, 99.6%), ce_loss 0.646, lat_loss 22.004
09/22 04:13:42 AM | Train: [116/180] Step 350/1249 Loss 1.334 Prec@(1,3) (90.0%, 99.6%), ce_loss 0.646, lat_loss 22.004
09/22 04:14:06 AM | Train: [116/180] Step 400/1249 Loss 1.329 Prec@(1,3) (90.0%, 99.6%), ce_loss 0.646, lat_loss 22.004
09/22 04:14:29 AM | Train: [116/180] Step 450/1249 Loss 1.318 Prec@(1,3) (90.0%, 99.6%), ce_loss 0.646, lat_loss 22.004
09/22 04:14:53 AM | Train: [116/180] Step 500/1249 Loss 1.314 Prec@(1,3) (90.0%, 99.6%), ce_loss 0.646, lat_loss 22.004
09/22 04:15:17 AM | Train: [116/180] Step 550/1249 Loss 1.315 Prec@(1,3) (90.0%, 99.6%), ce_loss 0.646, lat_loss 22.004
09/22 04:15:41 AM | Train: [116/180] Step 600/1249 Loss 1.330 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.646, lat_loss 22.004
09/22 04:16:05 AM | Train: [116/180] Step 650/1249 Loss 1.321 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.646, lat_loss 22.004
09/22 04:16:28 AM | Train: [116/180] Step 700/1249 Loss 1.311 Prec@(1,3) (89.9%, 99.6%), ce_loss 0.646, lat_loss 22.004
09/22 04:16:49 AM | Train: [116/180] Step 750/1249 Loss 1.312 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.646, lat_loss 22.004
09/22 04:17:06 AM | Train: [116/180] Step 800/1249 Loss 1.310 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.645, lat_loss 22.004
09/22 04:17:23 AM | Train: [116/180] Step 850/1249 Loss 1.306 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.645, lat_loss 22.004
09/22 04:17:39 AM | Train: [116/180] Step 900/1249 Loss 1.295 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.645, lat_loss 22.004
09/22 04:17:56 AM | Train: [116/180] Step 950/1249 Loss 1.288 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.645, lat_loss 22.004
09/22 04:18:12 AM | Train: [116/180] Step 1000/1249 Loss 1.296 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.645, lat_loss 22.004
09/22 04:18:28 AM | Train: [116/180] Step 1050/1249 Loss 1.289 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.645, lat_loss 22.004
09/22 04:18:45 AM | Train: [116/180] Step 1100/1249 Loss 1.280 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.645, lat_loss 22.004
09/22 04:19:05 AM | Train: [116/180] Step 1150/1249 Loss 1.282 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.645, lat_loss 22.004
09/22 04:19:29 AM | Train: [116/180] Step 1200/1249 Loss 1.289 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.645, lat_loss 22.004
09/22 04:19:53 AM | Train: [116/180] Step 1249/1249 Loss 1.279 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.645, lat_loss 22.004
09/22 04:19:53 AM | _w_step_train: [116/180] Final Prec@1 90.0425% Time 536.26
09/22 04:19:53 AM | Start to train theta for epoch 115
09/22 04:20:13 AM | Train: [116/180] Step 050/312 Loss 2.071 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.645, lat_loss 22.004
09/22 04:20:32 AM | Train: [116/180] Step 100/312 Loss 2.344 Prec@(1,3) (84.2%, 98.7%), ce_loss 0.645, lat_loss 22.004
09/22 04:20:51 AM | Train: [116/180] Step 150/312 Loss 2.241 Prec@(1,3) (84.5%, 98.8%), ce_loss 0.645, lat_loss 22.004
09/22 04:21:11 AM | Train: [116/180] Step 200/312 Loss 2.226 Prec@(1,3) (84.6%, 98.9%), ce_loss 0.645, lat_loss 22.004
09/22 04:21:29 AM | Train: [116/180] Step 250/312 Loss 2.212 Prec@(1,3) (84.6%, 99.0%), ce_loss 0.645, lat_loss 22.004
09/22 04:21:46 AM | Train: [116/180] Step 300/312 Loss 2.180 Prec@(1,3) (84.6%, 99.0%), ce_loss 0.644, lat_loss 22.004
09/22 04:21:51 AM | Train: [116/180] Step 312/312 Loss 2.164 Prec@(1,3) (84.7%, 99.0%), ce_loss 0.644, lat_loss 22.004
09/22 04:21:51 AM | _theta_step_train: [116/180] Final Prec@1 84.7200% Time 117.16
09/22 04:21:56 AM | Valid: [116/180] Step 050/312 Loss 1.838 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.644, lat_loss 22.004
09/22 04:22:01 AM | Valid: [116/180] Step 100/312 Loss 1.995 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.644, lat_loss 22.004
09/22 04:22:06 AM | Valid: [116/180] Step 150/312 Loss 2.020 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.644, lat_loss 22.004
09/22 04:22:10 AM | Valid: [116/180] Step 200/312 Loss 2.028 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.644, lat_loss 22.004
09/22 04:22:15 AM | Valid: [116/180] Step 250/312 Loss 2.026 Prec@(1,3) (84.9%, 99.2%), ce_loss 0.644, lat_loss 22.004
09/22 04:22:20 AM | Valid: [116/180] Step 300/312 Loss 2.003 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.644, lat_loss 22.004
09/22 04:22:21 AM | Valid: [116/180] Step 312/312 Loss 1.996 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.644, lat_loss 22.004
09/22 04:22:21 AM | val: [116/180] Final Prec@1 85.0800% Time 30.61
09/22 04:22:21 AM | Start to train weights for epoch 116
09/22 04:22:46 AM | Train: [117/180] Step 050/1249 Loss 1.019 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.644, lat_loss 22.004
09/22 04:23:08 AM | Train: [117/180] Step 100/1249 Loss 1.040 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.644, lat_loss 22.004
09/22 04:23:28 AM | Train: [117/180] Step 150/1249 Loss 1.081 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.644, lat_loss 22.004
09/22 04:23:50 AM | Train: [117/180] Step 200/1249 Loss 1.103 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.644, lat_loss 22.003
09/22 04:24:12 AM | Train: [117/180] Step 250/1249 Loss 1.121 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.644, lat_loss 22.003
09/22 04:24:34 AM | Train: [117/180] Step 300/1249 Loss 1.140 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.644, lat_loss 22.003
09/22 04:24:56 AM | Train: [117/180] Step 350/1249 Loss 1.185 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.644, lat_loss 22.003
09/22 04:25:19 AM | Train: [117/180] Step 400/1249 Loss 1.212 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.644, lat_loss 22.003
09/22 04:25:41 AM | Train: [117/180] Step 450/1249 Loss 1.221 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.643, lat_loss 22.003
09/22 04:26:04 AM | Train: [117/180] Step 500/1249 Loss 1.215 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.643, lat_loss 22.003
09/22 04:26:26 AM | Train: [117/180] Step 550/1249 Loss 1.217 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.643, lat_loss 22.003
09/22 04:26:48 AM | Train: [117/180] Step 600/1249 Loss 1.218 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.643, lat_loss 22.003
09/22 04:27:11 AM | Train: [117/180] Step 650/1249 Loss 1.227 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.643, lat_loss 22.003
09/22 04:27:33 AM | Train: [117/180] Step 700/1249 Loss 1.228 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.643, lat_loss 22.003
09/22 04:27:55 AM | Train: [117/180] Step 750/1249 Loss 1.220 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.643, lat_loss 22.003
09/22 04:28:18 AM | Train: [117/180] Step 800/1249 Loss 1.217 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.643, lat_loss 22.003
09/22 04:28:40 AM | Train: [117/180] Step 850/1249 Loss 1.219 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.643, lat_loss 22.003
09/22 04:29:03 AM | Train: [117/180] Step 900/1249 Loss 1.214 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.643, lat_loss 22.003
09/22 04:29:26 AM | Train: [117/180] Step 950/1249 Loss 1.208 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.643, lat_loss 22.003
09/22 04:29:47 AM | Train: [117/180] Step 1000/1249 Loss 1.209 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.642, lat_loss 22.003
09/22 04:30:10 AM | Train: [117/180] Step 1050/1249 Loss 1.220 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.642, lat_loss 22.003
09/22 04:30:32 AM | Train: [117/180] Step 1100/1249 Loss 1.231 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.642, lat_loss 22.003
09/22 04:30:54 AM | Train: [117/180] Step 1150/1249 Loss 1.233 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.642, lat_loss 22.003
09/22 04:31:16 AM | Train: [117/180] Step 1200/1249 Loss 1.229 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.642, lat_loss 22.003
09/22 04:31:40 AM | Train: [117/180] Step 1249/1249 Loss 1.227 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.642, lat_loss 22.003
09/22 04:31:40 AM | _w_step_train: [117/180] Final Prec@1 90.5475% Time 558.51
09/22 04:31:40 AM | Start to train theta for epoch 116
09/22 04:32:00 AM | Train: [117/180] Step 050/312 Loss 1.926 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.642, lat_loss 22.003
09/22 04:32:17 AM | Train: [117/180] Step 100/312 Loss 1.996 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.642, lat_loss 22.003
09/22 04:32:32 AM | Train: [117/180] Step 150/312 Loss 2.118 Prec@(1,3) (85.2%, 99.0%), ce_loss 0.642, lat_loss 22.003
09/22 04:32:48 AM | Train: [117/180] Step 200/312 Loss 2.083 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.642, lat_loss 22.003
09/22 04:33:06 AM | Train: [117/180] Step 250/312 Loss 2.081 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.642, lat_loss 22.003
09/22 04:33:25 AM | Train: [117/180] Step 300/312 Loss 2.039 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.642, lat_loss 22.003
09/22 04:33:30 AM | Train: [117/180] Step 312/312 Loss 2.039 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.642, lat_loss 22.003
09/22 04:33:30 AM | _theta_step_train: [117/180] Final Prec@1 85.6000% Time 109.95
09/22 04:33:35 AM | Valid: [117/180] Step 050/312 Loss 1.712 Prec@(1,3) (87.2%, 99.3%), ce_loss 0.642, lat_loss 22.003
09/22 04:33:40 AM | Valid: [117/180] Step 100/312 Loss 1.868 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.642, lat_loss 22.003
09/22 04:33:44 AM | Valid: [117/180] Step 150/312 Loss 2.001 Prec@(1,3) (84.9%, 99.0%), ce_loss 0.642, lat_loss 22.003
09/22 04:33:49 AM | Valid: [117/180] Step 200/312 Loss 1.981 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.642, lat_loss 22.003
09/22 04:33:54 AM | Valid: [117/180] Step 250/312 Loss 1.993 Prec@(1,3) (85.1%, 99.2%), ce_loss 0.642, lat_loss 22.003
09/22 04:33:58 AM | Valid: [117/180] Step 300/312 Loss 1.970 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.642, lat_loss 22.003
09/22 04:34:00 AM | Valid: [117/180] Step 312/312 Loss 1.965 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.642, lat_loss 22.003
09/22 04:34:00 AM | val: [117/180] Final Prec@1 85.1000% Time 29.92
09/22 04:34:00 AM | Start to train weights for epoch 117
09/22 04:34:23 AM | Train: [118/180] Step 050/1249 Loss 1.215 Prec@(1,3) (90.1%, 99.6%), ce_loss 0.641, lat_loss 22.003
09/22 04:34:42 AM | Train: [118/180] Step 100/1249 Loss 1.190 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.641, lat_loss 22.003
09/22 04:35:05 AM | Train: [118/180] Step 150/1249 Loss 1.210 Prec@(1,3) (90.3%, 99.6%), ce_loss 0.641, lat_loss 22.003
09/22 04:35:29 AM | Train: [118/180] Step 200/1249 Loss 1.212 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.641, lat_loss 22.003
09/22 04:35:52 AM | Train: [118/180] Step 250/1249 Loss 1.202 Prec@(1,3) (90.4%, 99.8%), ce_loss 0.641, lat_loss 22.003
09/22 04:36:15 AM | Train: [118/180] Step 300/1249 Loss 1.219 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.641, lat_loss 22.003
09/22 04:36:38 AM | Train: [118/180] Step 350/1249 Loss 1.213 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.641, lat_loss 22.003
09/22 04:37:01 AM | Train: [118/180] Step 400/1249 Loss 1.215 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.641, lat_loss 22.003
09/22 04:37:21 AM | Train: [118/180] Step 450/1249 Loss 1.219 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.641, lat_loss 22.003
09/22 04:37:43 AM | Train: [118/180] Step 500/1249 Loss 1.206 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.641, lat_loss 22.003
09/22 04:38:07 AM | Train: [118/180] Step 550/1249 Loss 1.215 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.641, lat_loss 22.003
09/22 04:38:31 AM | Train: [118/180] Step 600/1249 Loss 1.200 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.640, lat_loss 22.003
09/22 04:38:54 AM | Train: [118/180] Step 650/1249 Loss 1.195 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.640, lat_loss 22.003
09/22 04:39:17 AM | Train: [118/180] Step 700/1249 Loss 1.203 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.640, lat_loss 22.003
09/22 04:39:40 AM | Train: [118/180] Step 750/1249 Loss 1.205 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.640, lat_loss 22.003
09/22 04:40:03 AM | Train: [118/180] Step 800/1249 Loss 1.199 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.640, lat_loss 22.003
09/22 04:40:27 AM | Train: [118/180] Step 850/1249 Loss 1.197 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.640, lat_loss 22.003
09/22 04:40:50 AM | Train: [118/180] Step 900/1249 Loss 1.196 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.640, lat_loss 22.003
09/22 04:41:14 AM | Train: [118/180] Step 950/1249 Loss 1.212 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.640, lat_loss 22.003
09/22 04:41:39 AM | Train: [118/180] Step 1000/1249 Loss 1.210 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.640, lat_loss 22.003
09/22 04:42:04 AM | Train: [118/180] Step 1050/1249 Loss 1.217 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.640, lat_loss 22.003
09/22 04:42:29 AM | Train: [118/180] Step 1100/1249 Loss 1.230 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.640, lat_loss 22.003
09/22 04:42:52 AM | Train: [118/180] Step 1150/1249 Loss 1.229 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.640, lat_loss 22.003
09/22 04:43:16 AM | Train: [118/180] Step 1200/1249 Loss 1.230 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.639, lat_loss 22.003
09/22 04:43:40 AM | Train: [118/180] Step 1249/1249 Loss 1.230 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.639, lat_loss 22.003
09/22 04:43:40 AM | _w_step_train: [118/180] Final Prec@1 90.5000% Time 580.81
09/22 04:43:40 AM | Start to train theta for epoch 117
09/22 04:44:02 AM | Train: [118/180] Step 050/312 Loss 2.003 Prec@(1,3) (85.7%, 98.9%), ce_loss 0.639, lat_loss 22.003
09/22 04:44:22 AM | Train: [118/180] Step 100/312 Loss 1.934 Prec@(1,3) (86.4%, 99.1%), ce_loss 0.639, lat_loss 22.003
09/22 04:44:43 AM | Train: [118/180] Step 150/312 Loss 1.931 Prec@(1,3) (86.3%, 99.2%), ce_loss 0.639, lat_loss 22.003
09/22 04:45:04 AM | Train: [118/180] Step 200/312 Loss 1.966 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.639, lat_loss 22.003
09/22 04:45:25 AM | Train: [118/180] Step 250/312 Loss 1.985 Prec@(1,3) (85.9%, 99.1%), ce_loss 0.639, lat_loss 22.003
09/22 04:45:45 AM | Train: [118/180] Step 300/312 Loss 2.016 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.639, lat_loss 22.003
09/22 04:45:50 AM | Train: [118/180] Step 312/312 Loss 2.019 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.639, lat_loss 22.003
09/22 04:45:51 AM | _theta_step_train: [118/180] Final Prec@1 85.6700% Time 130.43
09/22 04:45:56 AM | Valid: [118/180] Step 050/312 Loss 1.826 Prec@(1,3) (86.2%, 99.7%), ce_loss 0.639, lat_loss 22.003
09/22 04:46:01 AM | Valid: [118/180] Step 100/312 Loss 2.127 Prec@(1,3) (84.3%, 98.9%), ce_loss 0.639, lat_loss 22.003
09/22 04:46:06 AM | Valid: [118/180] Step 150/312 Loss 2.099 Prec@(1,3) (84.7%, 98.9%), ce_loss 0.639, lat_loss 22.003
09/22 04:46:10 AM | Valid: [118/180] Step 200/312 Loss 2.092 Prec@(1,3) (84.8%, 98.9%), ce_loss 0.639, lat_loss 22.003
09/22 04:46:15 AM | Valid: [118/180] Step 250/312 Loss 2.057 Prec@(1,3) (84.9%, 99.0%), ce_loss 0.639, lat_loss 22.003
09/22 04:46:20 AM | Valid: [118/180] Step 300/312 Loss 2.036 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.639, lat_loss 22.003
09/22 04:46:21 AM | Valid: [118/180] Step 312/312 Loss 2.045 Prec@(1,3) (85.0%, 99.1%), ce_loss 0.639, lat_loss 22.003
09/22 04:46:21 AM | val: [118/180] Final Prec@1 85.0300% Time 30.04
09/22 04:46:21 AM | Start to train weights for epoch 118
09/22 04:46:46 AM | Train: [119/180] Step 050/1249 Loss 1.366 Prec@(1,3) (88.9%, 99.8%), ce_loss 0.639, lat_loss 22.003
09/22 04:47:11 AM | Train: [119/180] Step 100/1249 Loss 1.327 Prec@(1,3) (89.4%, 99.8%), ce_loss 0.639, lat_loss 22.003
09/22 04:47:36 AM | Train: [119/180] Step 150/1249 Loss 1.263 Prec@(1,3) (90.2%, 99.8%), ce_loss 0.639, lat_loss 22.003
09/22 04:48:01 AM | Train: [119/180] Step 200/1249 Loss 1.208 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.639, lat_loss 22.003
09/22 04:48:26 AM | Train: [119/180] Step 250/1249 Loss 1.177 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.638, lat_loss 22.003
09/22 04:48:51 AM | Train: [119/180] Step 300/1249 Loss 1.175 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.638, lat_loss 22.003
09/22 04:49:16 AM | Train: [119/180] Step 350/1249 Loss 1.179 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.638, lat_loss 22.003
09/22 04:49:41 AM | Train: [119/180] Step 400/1249 Loss 1.176 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.638, lat_loss 22.003
09/22 04:50:05 AM | Train: [119/180] Step 450/1249 Loss 1.180 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.638, lat_loss 22.003
09/22 04:50:30 AM | Train: [119/180] Step 500/1249 Loss 1.168 Prec@(1,3) (90.9%, 99.8%), ce_loss 0.638, lat_loss 22.002
09/22 04:50:55 AM | Train: [119/180] Step 550/1249 Loss 1.168 Prec@(1,3) (90.9%, 99.8%), ce_loss 0.638, lat_loss 22.002
09/22 04:51:19 AM | Train: [119/180] Step 600/1249 Loss 1.185 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.638, lat_loss 22.002
09/22 04:51:41 AM | Train: [119/180] Step 650/1249 Loss 1.202 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.638, lat_loss 22.002
09/22 04:52:05 AM | Train: [119/180] Step 700/1249 Loss 1.228 Prec@(1,3) (90.4%, 99.8%), ce_loss 0.638, lat_loss 22.002
09/22 04:52:29 AM | Train: [119/180] Step 750/1249 Loss 1.224 Prec@(1,3) (90.4%, 99.8%), ce_loss 0.638, lat_loss 22.002
09/22 04:52:51 AM | Train: [119/180] Step 800/1249 Loss 1.226 Prec@(1,3) (90.4%, 99.8%), ce_loss 0.638, lat_loss 22.002
09/22 04:53:15 AM | Train: [119/180] Step 850/1249 Loss 1.223 Prec@(1,3) (90.5%, 99.8%), ce_loss 0.637, lat_loss 22.002
09/22 04:53:38 AM | Train: [119/180] Step 900/1249 Loss 1.235 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.637, lat_loss 22.002
09/22 04:54:02 AM | Train: [119/180] Step 950/1249 Loss 1.236 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.637, lat_loss 22.002
09/22 04:54:26 AM | Train: [119/180] Step 1000/1249 Loss 1.251 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.637, lat_loss 22.002
09/22 04:54:49 AM | Train: [119/180] Step 1050/1249 Loss 1.248 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.637, lat_loss 22.002
09/22 04:55:12 AM | Train: [119/180] Step 1100/1249 Loss 1.243 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.637, lat_loss 22.002
09/22 04:55:37 AM | Train: [119/180] Step 1150/1249 Loss 1.237 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.637, lat_loss 22.002
09/22 04:56:01 AM | Train: [119/180] Step 1200/1249 Loss 1.234 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.637, lat_loss 22.002
09/22 04:56:26 AM | Train: [119/180] Step 1249/1249 Loss 1.234 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.637, lat_loss 22.002
09/22 04:56:26 AM | _w_step_train: [119/180] Final Prec@1 90.3275% Time 605.02
09/22 04:56:26 AM | Start to train theta for epoch 118
09/22 04:56:47 AM | Train: [119/180] Step 050/312 Loss 2.030 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.637, lat_loss 22.002
09/22 04:57:08 AM | Train: [119/180] Step 100/312 Loss 2.061 Prec@(1,3) (84.8%, 99.0%), ce_loss 0.637, lat_loss 22.002
09/22 04:57:28 AM | Train: [119/180] Step 150/312 Loss 2.072 Prec@(1,3) (84.7%, 99.0%), ce_loss 0.637, lat_loss 22.002
09/22 04:57:49 AM | Train: [119/180] Step 200/312 Loss 2.068 Prec@(1,3) (84.8%, 99.1%), ce_loss 0.637, lat_loss 22.002
09/22 04:58:09 AM | Train: [119/180] Step 250/312 Loss 2.130 Prec@(1,3) (84.4%, 99.0%), ce_loss 0.637, lat_loss 22.002
09/22 04:58:30 AM | Train: [119/180] Step 300/312 Loss 2.183 Prec@(1,3) (84.2%, 98.9%), ce_loss 0.637, lat_loss 22.002
09/22 04:58:35 AM | Train: [119/180] Step 312/312 Loss 2.158 Prec@(1,3) (84.3%, 99.0%), ce_loss 0.637, lat_loss 22.002
09/22 04:58:35 AM | _theta_step_train: [119/180] Final Prec@1 84.2900% Time 128.73
09/22 04:58:40 AM | Valid: [119/180] Step 050/312 Loss 2.009 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.637, lat_loss 22.002
09/22 04:58:45 AM | Valid: [119/180] Step 100/312 Loss 2.030 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.637, lat_loss 22.002
09/22 04:58:49 AM | Valid: [119/180] Step 150/312 Loss 2.043 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.636, lat_loss 22.002
09/22 04:58:54 AM | Valid: [119/180] Step 200/312 Loss 2.044 Prec@(1,3) (84.9%, 99.4%), ce_loss 0.636, lat_loss 22.002
09/22 04:58:59 AM | Valid: [119/180] Step 250/312 Loss 2.076 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.636, lat_loss 22.002
09/22 04:59:03 AM | Valid: [119/180] Step 300/312 Loss 2.054 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.636, lat_loss 22.002
09/22 04:59:04 AM | Valid: [119/180] Step 312/312 Loss 2.046 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.636, lat_loss 22.002
09/22 04:59:04 AM | val: [119/180] Final Prec@1 84.7000% Time 29.56
09/22 04:59:04 AM | Start to train weights for epoch 119
09/22 04:59:29 AM | Train: [120/180] Step 050/1249 Loss 1.156 Prec@(1,3) (90.9%, 100.0%), ce_loss 0.636, lat_loss 22.002
09/22 04:59:52 AM | Train: [120/180] Step 100/1249 Loss 1.097 Prec@(1,3) (91.6%, 99.9%), ce_loss 0.636, lat_loss 22.002
09/22 05:00:17 AM | Train: [120/180] Step 150/1249 Loss 1.126 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.636, lat_loss 22.002
09/22 05:00:44 AM | Train: [120/180] Step 200/1249 Loss 1.117 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.636, lat_loss 22.002
09/22 05:01:10 AM | Train: [120/180] Step 250/1249 Loss 1.146 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.636, lat_loss 22.002
09/22 05:01:37 AM | Train: [120/180] Step 300/1249 Loss 1.149 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.636, lat_loss 22.002
09/22 05:02:05 AM | Train: [120/180] Step 350/1249 Loss 1.170 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.636, lat_loss 22.002
09/22 05:02:32 AM | Train: [120/180] Step 400/1249 Loss 1.178 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.636, lat_loss 22.002
09/22 05:03:00 AM | Train: [120/180] Step 450/1249 Loss 1.183 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.636, lat_loss 22.002
09/22 05:03:26 AM | Train: [120/180] Step 500/1249 Loss 1.190 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.636, lat_loss 22.002
09/22 05:03:52 AM | Train: [120/180] Step 550/1249 Loss 1.193 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.635, lat_loss 22.002
09/22 05:04:17 AM | Train: [120/180] Step 600/1249 Loss 1.223 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.635, lat_loss 22.002
09/22 05:04:43 AM | Train: [120/180] Step 650/1249 Loss 1.216 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.635, lat_loss 22.002
09/22 05:05:08 AM | Train: [120/180] Step 700/1249 Loss 1.214 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.635, lat_loss 22.002
09/22 05:05:34 AM | Train: [120/180] Step 750/1249 Loss 1.203 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.635, lat_loss 22.002
09/22 05:06:00 AM | Train: [120/180] Step 800/1249 Loss 1.208 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.635, lat_loss 22.002
09/22 05:06:26 AM | Train: [120/180] Step 850/1249 Loss 1.208 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.635, lat_loss 22.002
09/22 05:06:52 AM | Train: [120/180] Step 900/1249 Loss 1.208 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.635, lat_loss 22.002
09/22 05:07:17 AM | Train: [120/180] Step 950/1249 Loss 1.209 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.635, lat_loss 22.002
09/22 05:07:43 AM | Train: [120/180] Step 1000/1249 Loss 1.203 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.635, lat_loss 22.002
09/22 05:08:04 AM | Train: [120/180] Step 1050/1249 Loss 1.210 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.635, lat_loss 22.002
09/22 05:08:29 AM | Train: [120/180] Step 1100/1249 Loss 1.202 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.635, lat_loss 22.002
09/22 05:08:54 AM | Train: [120/180] Step 1150/1249 Loss 1.190 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.634, lat_loss 22.002
09/22 05:09:20 AM | Train: [120/180] Step 1200/1249 Loss 1.209 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.634, lat_loss 22.002
09/22 05:09:44 AM | Train: [120/180] Step 1249/1249 Loss 1.212 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.634, lat_loss 22.002
09/22 05:09:44 AM | _w_step_train: [120/180] Final Prec@1 90.5975% Time 639.86
09/22 05:09:44 AM | Start to train theta for epoch 119
09/22 05:10:06 AM | Train: [120/180] Step 050/312 Loss 2.598 Prec@(1,3) (82.5%, 98.3%), ce_loss 0.634, lat_loss 22.002
09/22 05:10:25 AM | Train: [120/180] Step 100/312 Loss 2.397 Prec@(1,3) (84.0%, 98.4%), ce_loss 0.634, lat_loss 22.002
09/22 05:10:44 AM | Train: [120/180] Step 150/312 Loss 2.312 Prec@(1,3) (84.0%, 98.6%), ce_loss 0.634, lat_loss 22.002
09/22 05:11:03 AM | Train: [120/180] Step 200/312 Loss 2.268 Prec@(1,3) (84.3%, 98.7%), ce_loss 0.634, lat_loss 22.002
09/22 05:11:23 AM | Train: [120/180] Step 250/312 Loss 2.159 Prec@(1,3) (84.7%, 98.8%), ce_loss 0.634, lat_loss 22.002
09/22 05:11:42 AM | Train: [120/180] Step 300/312 Loss 2.151 Prec@(1,3) (84.8%, 98.9%), ce_loss 0.634, lat_loss 22.002
09/22 05:11:47 AM | Train: [120/180] Step 312/312 Loss 2.163 Prec@(1,3) (84.7%, 98.9%), ce_loss 0.634, lat_loss 22.002
09/22 05:11:47 AM | _theta_step_train: [120/180] Final Prec@1 84.7300% Time 122.41
09/22 05:11:52 AM | Valid: [120/180] Step 050/312 Loss 1.898 Prec@(1,3) (85.2%, 99.6%), ce_loss 0.634, lat_loss 22.002
09/22 05:11:57 AM | Valid: [120/180] Step 100/312 Loss 1.964 Prec@(1,3) (85.3%, 99.4%), ce_loss 0.634, lat_loss 22.002
09/22 05:12:01 AM | Valid: [120/180] Step 150/312 Loss 1.980 Prec@(1,3) (85.2%, 99.3%), ce_loss 0.634, lat_loss 22.002
09/22 05:12:06 AM | Valid: [120/180] Step 200/312 Loss 1.985 Prec@(1,3) (85.4%, 99.3%), ce_loss 0.634, lat_loss 22.002
09/22 05:12:11 AM | Valid: [120/180] Step 250/312 Loss 2.021 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.634, lat_loss 22.002
09/22 05:12:15 AM | Valid: [120/180] Step 300/312 Loss 1.983 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.634, lat_loss 22.002
09/22 05:12:17 AM | Valid: [120/180] Step 312/312 Loss 1.976 Prec@(1,3) (85.3%, 99.4%), ce_loss 0.634, lat_loss 22.002
09/22 05:12:17 AM | val: [120/180] Final Prec@1 85.3100% Time 29.93
09/22 05:12:17 AM | Start to train weights for epoch 120
09/22 05:12:43 AM | Train: [121/180] Step 050/1249 Loss 1.200 Prec@(1,3) (90.7%, 99.9%), ce_loss 0.634, lat_loss 22.002
09/22 05:13:07 AM | Train: [121/180] Step 100/1249 Loss 1.198 Prec@(1,3) (90.7%, 99.9%), ce_loss 0.634, lat_loss 22.002
09/22 05:13:32 AM | Train: [121/180] Step 150/1249 Loss 1.203 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.634, lat_loss 22.002
09/22 05:13:56 AM | Train: [121/180] Step 200/1249 Loss 1.192 Prec@(1,3) (90.5%, 99.8%), ce_loss 0.634, lat_loss 22.002
09/22 05:14:20 AM | Train: [121/180] Step 250/1249 Loss 1.168 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.633, lat_loss 22.002
09/22 05:14:43 AM | Train: [121/180] Step 300/1249 Loss 1.142 Prec@(1,3) (90.9%, 99.8%), ce_loss 0.633, lat_loss 22.002
09/22 05:15:08 AM | Train: [121/180] Step 350/1249 Loss 1.149 Prec@(1,3) (90.9%, 99.8%), ce_loss 0.633, lat_loss 22.002
09/22 05:15:32 AM | Train: [121/180] Step 400/1249 Loss 1.153 Prec@(1,3) (90.9%, 99.8%), ce_loss 0.633, lat_loss 22.002
09/22 05:15:57 AM | Train: [121/180] Step 450/1249 Loss 1.167 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.633, lat_loss 22.002
09/22 05:16:22 AM | Train: [121/180] Step 500/1249 Loss 1.162 Prec@(1,3) (90.9%, 99.8%), ce_loss 0.633, lat_loss 22.002
09/22 05:16:45 AM | Train: [121/180] Step 550/1249 Loss 1.158 Prec@(1,3) (90.9%, 99.8%), ce_loss 0.633, lat_loss 22.002
09/22 05:17:09 AM | Train: [121/180] Step 600/1249 Loss 1.154 Prec@(1,3) (90.9%, 99.8%), ce_loss 0.633, lat_loss 22.002
09/22 05:17:33 AM | Train: [121/180] Step 650/1249 Loss 1.154 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.633, lat_loss 22.002
09/22 05:17:58 AM | Train: [121/180] Step 700/1249 Loss 1.149 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.633, lat_loss 22.002
09/22 05:18:22 AM | Train: [121/180] Step 750/1249 Loss 1.182 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.633, lat_loss 22.002
09/22 05:18:45 AM | Train: [121/180] Step 800/1249 Loss 1.190 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.633, lat_loss 22.002
09/22 05:19:10 AM | Train: [121/180] Step 850/1249 Loss 1.215 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.632, lat_loss 22.002
09/22 05:19:33 AM | Train: [121/180] Step 900/1249 Loss 1.210 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.632, lat_loss 22.002
09/22 05:19:58 AM | Train: [121/180] Step 950/1249 Loss 1.196 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.632, lat_loss 22.002
09/22 05:20:24 AM | Train: [121/180] Step 1000/1249 Loss 1.210 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.632, lat_loss 22.002
09/22 05:20:45 AM | Train: [121/180] Step 1050/1249 Loss 1.222 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.632, lat_loss 22.002
09/22 05:21:05 AM | Train: [121/180] Step 1100/1249 Loss 1.220 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.632, lat_loss 22.002
09/22 05:21:26 AM | Train: [121/180] Step 1150/1249 Loss 1.216 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.632, lat_loss 22.002
09/22 05:21:47 AM | Train: [121/180] Step 1200/1249 Loss 1.216 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.632, lat_loss 22.002
09/22 05:22:11 AM | Train: [121/180] Step 1249/1249 Loss 1.211 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.632, lat_loss 22.002
09/22 05:22:11 AM | _w_step_train: [121/180] Final Prec@1 90.5700% Time 594.55
09/22 05:22:11 AM | Start to train theta for epoch 120
09/22 05:22:24 AM | Train: [121/180] Step 050/312 Loss 2.079 Prec@(1,3) (85.0%, 99.6%), ce_loss 0.632, lat_loss 22.001
09/22 05:22:37 AM | Train: [121/180] Step 100/312 Loss 2.115 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.632, lat_loss 22.001
09/22 05:22:49 AM | Train: [121/180] Step 150/312 Loss 2.038 Prec@(1,3) (85.0%, 99.4%), ce_loss 0.632, lat_loss 22.001
09/22 05:23:01 AM | Train: [121/180] Step 200/312 Loss 2.056 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.632, lat_loss 22.001
09/22 05:23:14 AM | Train: [121/180] Step 250/312 Loss 2.051 Prec@(1,3) (84.8%, 99.4%), ce_loss 0.632, lat_loss 22.001
09/22 05:23:26 AM | Train: [121/180] Step 300/312 Loss 2.046 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.632, lat_loss 22.001
09/22 05:23:29 AM | Train: [121/180] Step 312/312 Loss 2.036 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.632, lat_loss 22.001
09/22 05:23:29 AM | _theta_step_train: [121/180] Final Prec@1 85.0400% Time 77.97
09/22 05:23:34 AM | Valid: [121/180] Step 050/312 Loss 1.750 Prec@(1,3) (87.1%, 99.6%), ce_loss 0.632, lat_loss 22.001
09/22 05:23:39 AM | Valid: [121/180] Step 100/312 Loss 1.895 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.631, lat_loss 22.001
09/22 05:23:43 AM | Valid: [121/180] Step 150/312 Loss 1.937 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.631, lat_loss 22.001
09/22 05:23:48 AM | Valid: [121/180] Step 200/312 Loss 1.938 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.631, lat_loss 22.001
09/22 05:23:53 AM | Valid: [121/180] Step 250/312 Loss 1.961 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.631, lat_loss 22.001
09/22 05:23:58 AM | Valid: [121/180] Step 300/312 Loss 1.975 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.631, lat_loss 22.001
09/22 05:23:59 AM | Valid: [121/180] Step 312/312 Loss 1.972 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.631, lat_loss 22.001
09/22 05:23:59 AM | val: [121/180] Final Prec@1 85.5000% Time 29.76
09/22 05:23:59 AM | Best top1 acc by now. Save model
09/22 05:23:59 AM | Start to train weights for epoch 121
09/22 05:24:24 AM | Train: [122/180] Step 050/1249 Loss 1.055 Prec@(1,3) (92.2%, 99.9%), ce_loss 0.631, lat_loss 22.001
09/22 05:24:49 AM | Train: [122/180] Step 100/1249 Loss 0.995 Prec@(1,3) (92.7%, 99.9%), ce_loss 0.631, lat_loss 22.001
09/22 05:25:13 AM | Train: [122/180] Step 150/1249 Loss 1.053 Prec@(1,3) (92.0%, 99.9%), ce_loss 0.631, lat_loss 22.001
09/22 05:25:37 AM | Train: [122/180] Step 200/1249 Loss 1.118 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.631, lat_loss 22.001
09/22 05:26:01 AM | Train: [122/180] Step 250/1249 Loss 1.135 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.631, lat_loss 22.001
09/22 05:26:26 AM | Train: [122/180] Step 300/1249 Loss 1.108 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.631, lat_loss 22.001
09/22 05:26:48 AM | Train: [122/180] Step 350/1249 Loss 1.099 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.631, lat_loss 22.001
09/22 05:27:12 AM | Train: [122/180] Step 400/1249 Loss 1.108 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.631, lat_loss 22.001
09/22 05:27:37 AM | Train: [122/180] Step 450/1249 Loss 1.107 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.631, lat_loss 22.001
09/22 05:28:01 AM | Train: [122/180] Step 500/1249 Loss 1.132 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.630, lat_loss 22.001
09/22 05:28:24 AM | Train: [122/180] Step 550/1249 Loss 1.134 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.630, lat_loss 22.001
09/22 05:28:48 AM | Train: [122/180] Step 600/1249 Loss 1.121 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.630, lat_loss 22.001
09/22 05:29:11 AM | Train: [122/180] Step 650/1249 Loss 1.117 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.630, lat_loss 22.001
09/22 05:29:34 AM | Train: [122/180] Step 700/1249 Loss 1.116 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.630, lat_loss 22.001
09/22 05:29:57 AM | Train: [122/180] Step 750/1249 Loss 1.118 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.630, lat_loss 22.001
09/22 05:30:20 AM | Train: [122/180] Step 800/1249 Loss 1.139 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.630, lat_loss 22.001
09/22 05:30:43 AM | Train: [122/180] Step 850/1249 Loss 1.143 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.630, lat_loss 22.001
09/22 05:31:06 AM | Train: [122/180] Step 900/1249 Loss 1.149 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.630, lat_loss 22.001
09/22 05:31:30 AM | Train: [122/180] Step 950/1249 Loss 1.155 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.630, lat_loss 22.001
09/22 05:31:53 AM | Train: [122/180] Step 1000/1249 Loss 1.163 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.630, lat_loss 22.001
09/22 05:32:15 AM | Train: [122/180] Step 1050/1249 Loss 1.167 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.630, lat_loss 22.001
09/22 05:32:38 AM | Train: [122/180] Step 1100/1249 Loss 1.183 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.630, lat_loss 22.001
09/22 05:33:02 AM | Train: [122/180] Step 1150/1249 Loss 1.181 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.629, lat_loss 22.001
09/22 05:33:25 AM | Train: [122/180] Step 1200/1249 Loss 1.180 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.629, lat_loss 22.001
09/22 05:33:50 AM | Train: [122/180] Step 1249/1249 Loss 1.184 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.629, lat_loss 22.001
09/22 05:33:50 AM | _w_step_train: [122/180] Final Prec@1 90.9175% Time 590.59
09/22 05:33:50 AM | Start to train theta for epoch 121
09/22 05:34:09 AM | Train: [122/180] Step 050/312 Loss 1.958 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.629, lat_loss 22.001
09/22 05:34:25 AM | Train: [122/180] Step 100/312 Loss 2.019 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.629, lat_loss 22.001
09/22 05:34:42 AM | Train: [122/180] Step 150/312 Loss 2.021 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.629, lat_loss 22.001
09/22 05:34:58 AM | Train: [122/180] Step 200/312 Loss 2.007 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.629, lat_loss 22.001
09/22 05:35:17 AM | Train: [122/180] Step 250/312 Loss 1.979 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.629, lat_loss 22.001
09/22 05:35:37 AM | Train: [122/180] Step 300/312 Loss 1.983 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.629, lat_loss 22.001
09/22 05:35:42 AM | Train: [122/180] Step 312/312 Loss 1.978 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.629, lat_loss 22.001
09/22 05:35:42 AM | _theta_step_train: [122/180] Final Prec@1 85.2100% Time 112.28
09/22 05:35:47 AM | Valid: [122/180] Step 050/312 Loss 1.888 Prec@(1,3) (86.0%, 99.0%), ce_loss 0.629, lat_loss 22.001
09/22 05:35:52 AM | Valid: [122/180] Step 100/312 Loss 1.952 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.629, lat_loss 22.001
09/22 05:35:56 AM | Valid: [122/180] Step 150/312 Loss 2.102 Prec@(1,3) (84.6%, 98.9%), ce_loss 0.629, lat_loss 22.001
09/22 05:36:01 AM | Valid: [122/180] Step 200/312 Loss 1.994 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.629, lat_loss 22.001
09/22 05:36:06 AM | Valid: [122/180] Step 250/312 Loss 1.987 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.629, lat_loss 22.001
09/22 05:36:10 AM | Valid: [122/180] Step 300/312 Loss 1.936 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.629, lat_loss 22.001
09/22 05:36:11 AM | Valid: [122/180] Step 312/312 Loss 1.936 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.629, lat_loss 22.001
09/22 05:36:11 AM | val: [122/180] Final Prec@1 85.6400% Time 29.16
09/22 05:36:11 AM | Best top1 acc by now. Save model
09/22 05:36:11 AM | Start to train weights for epoch 122
09/22 05:36:37 AM | Train: [123/180] Step 050/1249 Loss 1.183 Prec@(1,3) (91.2%, 99.9%), ce_loss 0.629, lat_loss 22.001
09/22 05:37:02 AM | Train: [123/180] Step 100/1249 Loss 1.178 Prec@(1,3) (90.4%, 99.9%), ce_loss 0.629, lat_loss 22.001
09/22 05:37:27 AM | Train: [123/180] Step 150/1249 Loss 1.160 Prec@(1,3) (90.5%, 99.9%), ce_loss 0.629, lat_loss 22.001
09/22 05:37:52 AM | Train: [123/180] Step 200/1249 Loss 1.188 Prec@(1,3) (90.4%, 99.8%), ce_loss 0.628, lat_loss 22.001
09/22 05:38:17 AM | Train: [123/180] Step 250/1249 Loss 1.144 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.628, lat_loss 22.001
09/22 05:38:42 AM | Train: [123/180] Step 300/1249 Loss 1.137 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.628, lat_loss 22.001
09/22 05:39:07 AM | Train: [123/180] Step 350/1249 Loss 1.113 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.628, lat_loss 22.001
09/22 05:39:32 AM | Train: [123/180] Step 400/1249 Loss 1.114 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.628, lat_loss 22.001
09/22 05:39:57 AM | Train: [123/180] Step 450/1249 Loss 1.110 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.628, lat_loss 22.001
09/22 05:40:22 AM | Train: [123/180] Step 500/1249 Loss 1.107 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.628, lat_loss 22.001
09/22 05:40:46 AM | Train: [123/180] Step 550/1249 Loss 1.110 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.628, lat_loss 22.001
09/22 05:41:11 AM | Train: [123/180] Step 600/1249 Loss 1.117 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.628, lat_loss 22.001
09/22 05:41:36 AM | Train: [123/180] Step 650/1249 Loss 1.111 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.628, lat_loss 22.001
09/22 05:42:01 AM | Train: [123/180] Step 700/1249 Loss 1.117 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.628, lat_loss 22.001
09/22 05:42:26 AM | Train: [123/180] Step 750/1249 Loss 1.123 Prec@(1,3) (90.9%, 99.8%), ce_loss 0.628, lat_loss 22.001
09/22 05:42:51 AM | Train: [123/180] Step 800/1249 Loss 1.120 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.627, lat_loss 22.001
09/22 05:43:16 AM | Train: [123/180] Step 850/1249 Loss 1.115 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.627, lat_loss 22.001
09/22 05:43:41 AM | Train: [123/180] Step 900/1249 Loss 1.122 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.627, lat_loss 22.001
09/22 05:44:06 AM | Train: [123/180] Step 950/1249 Loss 1.129 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.627, lat_loss 22.000
09/22 05:44:30 AM | Train: [123/180] Step 1000/1249 Loss 1.136 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.627, lat_loss 22.000
09/22 05:44:55 AM | Train: [123/180] Step 1050/1249 Loss 1.134 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.627, lat_loss 22.000
09/22 05:45:20 AM | Train: [123/180] Step 1100/1249 Loss 1.129 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.627, lat_loss 22.000
09/22 05:45:44 AM | Train: [123/180] Step 1150/1249 Loss 1.129 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.627, lat_loss 22.000
09/22 05:46:09 AM | Train: [123/180] Step 1200/1249 Loss 1.133 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.627, lat_loss 22.000
09/22 05:46:34 AM | Train: [123/180] Step 1249/1249 Loss 1.135 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.627, lat_loss 22.000
09/22 05:46:34 AM | _w_step_train: [123/180] Final Prec@1 91.0225% Time 622.31
09/22 05:46:34 AM | Start to train theta for epoch 122
09/22 05:46:53 AM | Train: [123/180] Step 050/312 Loss 2.420 Prec@(1,3) (83.6%, 98.6%), ce_loss 0.627, lat_loss 22.000
09/22 05:47:10 AM | Train: [123/180] Step 100/312 Loss 2.149 Prec@(1,3) (85.1%, 98.9%), ce_loss 0.627, lat_loss 22.000
09/22 05:47:29 AM | Train: [123/180] Step 150/312 Loss 2.144 Prec@(1,3) (85.2%, 99.0%), ce_loss 0.627, lat_loss 22.000
09/22 05:47:49 AM | Train: [123/180] Step 200/312 Loss 2.095 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.627, lat_loss 22.000
09/22 05:48:10 AM | Train: [123/180] Step 250/312 Loss 2.070 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.627, lat_loss 22.000
09/22 05:48:30 AM | Train: [123/180] Step 300/312 Loss 2.068 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.626, lat_loss 22.000
09/22 05:48:35 AM | Train: [123/180] Step 312/312 Loss 2.068 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.626, lat_loss 22.000
09/22 05:48:36 AM | _theta_step_train: [123/180] Final Prec@1 85.1700% Time 121.96
09/22 05:48:41 AM | Valid: [123/180] Step 050/312 Loss 2.228 Prec@(1,3) (84.3%, 98.7%), ce_loss 0.626, lat_loss 22.000
09/22 05:48:45 AM | Valid: [123/180] Step 100/312 Loss 2.220 Prec@(1,3) (84.1%, 98.7%), ce_loss 0.626, lat_loss 22.000
09/22 05:48:49 AM | Valid: [123/180] Step 150/312 Loss 2.199 Prec@(1,3) (84.0%, 98.8%), ce_loss 0.626, lat_loss 22.000
09/22 05:48:53 AM | Valid: [123/180] Step 200/312 Loss 2.119 Prec@(1,3) (84.5%, 99.0%), ce_loss 0.626, lat_loss 22.000
09/22 05:48:57 AM | Valid: [123/180] Step 250/312 Loss 2.084 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.626, lat_loss 22.000
09/22 05:49:02 AM | Valid: [123/180] Step 300/312 Loss 2.024 Prec@(1,3) (85.0%, 99.2%), ce_loss 0.626, lat_loss 22.000
09/22 05:49:03 AM | Valid: [123/180] Step 312/312 Loss 2.015 Prec@(1,3) (85.1%, 99.2%), ce_loss 0.626, lat_loss 22.000
09/22 05:49:03 AM | val: [123/180] Final Prec@1 85.1100% Time 27.27
09/22 05:49:03 AM | Start to train weights for epoch 123
09/22 05:49:29 AM | Train: [124/180] Step 050/1249 Loss 0.906 Prec@(1,3) (92.8%, 99.9%), ce_loss 0.626, lat_loss 22.000
09/22 05:49:53 AM | Train: [124/180] Step 100/1249 Loss 0.960 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.626, lat_loss 22.000
09/22 05:50:17 AM | Train: [124/180] Step 150/1249 Loss 1.030 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.626, lat_loss 22.000
09/22 05:50:42 AM | Train: [124/180] Step 200/1249 Loss 1.020 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.626, lat_loss 22.000
09/22 05:51:06 AM | Train: [124/180] Step 250/1249 Loss 1.139 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.626, lat_loss 22.000
09/22 05:51:29 AM | Train: [124/180] Step 300/1249 Loss 1.114 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.626, lat_loss 22.000
09/22 05:51:53 AM | Train: [124/180] Step 350/1249 Loss 1.114 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.626, lat_loss 22.000
09/22 05:52:17 AM | Train: [124/180] Step 400/1249 Loss 1.113 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.626, lat_loss 22.000
09/22 05:52:40 AM | Train: [124/180] Step 450/1249 Loss 1.126 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.626, lat_loss 22.000
09/22 05:53:05 AM | Train: [124/180] Step 500/1249 Loss 1.137 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.625, lat_loss 22.000
09/22 05:53:29 AM | Train: [124/180] Step 550/1249 Loss 1.124 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.625, lat_loss 22.000
09/22 05:53:53 AM | Train: [124/180] Step 600/1249 Loss 1.119 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.625, lat_loss 22.000
09/22 05:54:17 AM | Train: [124/180] Step 650/1249 Loss 1.117 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.625, lat_loss 22.000
09/22 05:54:42 AM | Train: [124/180] Step 700/1249 Loss 1.115 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.625, lat_loss 22.000
09/22 05:55:05 AM | Train: [124/180] Step 750/1249 Loss 1.132 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.625, lat_loss 22.000
09/22 05:55:29 AM | Train: [124/180] Step 800/1249 Loss 1.127 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.625, lat_loss 22.000
09/22 05:55:54 AM | Train: [124/180] Step 850/1249 Loss 1.123 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.625, lat_loss 22.000
09/22 05:56:19 AM | Train: [124/180] Step 900/1249 Loss 1.134 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.625, lat_loss 22.000
09/22 05:56:43 AM | Train: [124/180] Step 950/1249 Loss 1.152 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.625, lat_loss 22.000
09/22 05:57:08 AM | Train: [124/180] Step 1000/1249 Loss 1.153 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.625, lat_loss 22.000
09/22 05:57:31 AM | Train: [124/180] Step 1050/1249 Loss 1.157 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.625, lat_loss 22.000
09/22 05:57:55 AM | Train: [124/180] Step 1100/1249 Loss 1.160 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.624, lat_loss 22.000
09/22 05:58:20 AM | Train: [124/180] Step 1150/1249 Loss 1.158 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.624, lat_loss 22.000
09/22 05:58:45 AM | Train: [124/180] Step 1200/1249 Loss 1.162 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.624, lat_loss 22.000
09/22 05:59:09 AM | Train: [124/180] Step 1249/1249 Loss 1.160 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.624, lat_loss 22.000
09/22 05:59:09 AM | _w_step_train: [124/180] Final Prec@1 91.0225% Time 606.06
09/22 05:59:09 AM | Start to train theta for epoch 123
09/22 05:59:28 AM | Train: [124/180] Step 050/312 Loss 2.304 Prec@(1,3) (84.3%, 98.5%), ce_loss 0.624, lat_loss 22.000
09/22 05:59:46 AM | Train: [124/180] Step 100/312 Loss 2.184 Prec@(1,3) (84.6%, 98.9%), ce_loss 0.624, lat_loss 22.000
09/22 06:00:07 AM | Train: [124/180] Step 150/312 Loss 2.135 Prec@(1,3) (85.1%, 98.9%), ce_loss 0.624, lat_loss 22.000
09/22 06:00:27 AM | Train: [124/180] Step 200/312 Loss 2.072 Prec@(1,3) (85.2%, 99.0%), ce_loss 0.624, lat_loss 22.000
09/22 06:00:47 AM | Train: [124/180] Step 250/312 Loss 2.070 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.624, lat_loss 22.000
09/22 06:01:08 AM | Train: [124/180] Step 300/312 Loss 2.032 Prec@(1,3) (85.6%, 99.0%), ce_loss 0.624, lat_loss 22.000
09/22 06:01:13 AM | Train: [124/180] Step 312/312 Loss 2.014 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.624, lat_loss 22.000
09/22 06:01:13 AM | _theta_step_train: [124/180] Final Prec@1 85.7300% Time 124.21
09/22 06:01:19 AM | Valid: [124/180] Step 050/312 Loss 1.828 Prec@(1,3) (86.5%, 99.6%), ce_loss 0.624, lat_loss 22.000
09/22 06:01:23 AM | Valid: [124/180] Step 100/312 Loss 2.076 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.624, lat_loss 22.000
09/22 06:01:28 AM | Valid: [124/180] Step 150/312 Loss 2.113 Prec@(1,3) (84.4%, 99.0%), ce_loss 0.624, lat_loss 22.000
09/22 06:01:33 AM | Valid: [124/180] Step 200/312 Loss 2.070 Prec@(1,3) (85.0%, 99.1%), ce_loss 0.624, lat_loss 22.000
09/22 06:01:37 AM | Valid: [124/180] Step 250/312 Loss 2.057 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.624, lat_loss 22.000
09/22 06:01:42 AM | Valid: [124/180] Step 300/312 Loss 2.029 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.624, lat_loss 22.000
09/22 06:01:43 AM | Valid: [124/180] Step 312/312 Loss 2.021 Prec@(1,3) (85.1%, 99.2%), ce_loss 0.624, lat_loss 22.000
09/22 06:01:43 AM | val: [124/180] Final Prec@1 85.1400% Time 29.69
09/22 06:01:43 AM | Start to train weights for epoch 124
09/22 06:02:09 AM | Train: [125/180] Step 050/1249 Loss 0.999 Prec@(1,3) (92.3%, 99.9%), ce_loss 0.624, lat_loss 22.000
09/22 06:02:33 AM | Train: [125/180] Step 100/1249 Loss 1.162 Prec@(1,3) (91.3%, 99.6%), ce_loss 0.624, lat_loss 22.000
09/22 06:02:58 AM | Train: [125/180] Step 150/1249 Loss 1.084 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.624, lat_loss 22.000
09/22 06:03:23 AM | Train: [125/180] Step 200/1249 Loss 1.065 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.623, lat_loss 22.000
09/22 06:03:48 AM | Train: [125/180] Step 250/1249 Loss 1.113 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.623, lat_loss 22.000
09/22 06:04:13 AM | Train: [125/180] Step 300/1249 Loss 1.124 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.623, lat_loss 22.000
09/22 06:04:37 AM | Train: [125/180] Step 350/1249 Loss 1.137 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.623, lat_loss 22.000
09/22 06:05:02 AM | Train: [125/180] Step 400/1249 Loss 1.113 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.623, lat_loss 22.000
09/22 06:05:27 AM | Train: [125/180] Step 450/1249 Loss 1.132 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.623, lat_loss 22.000
09/22 06:05:50 AM | Train: [125/180] Step 500/1249 Loss 1.121 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.623, lat_loss 22.000
09/22 06:06:13 AM | Train: [125/180] Step 550/1249 Loss 1.116 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.623, lat_loss 22.000
09/22 06:06:35 AM | Train: [125/180] Step 600/1249 Loss 1.136 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.623, lat_loss 22.000
09/22 06:06:57 AM | Train: [125/180] Step 650/1249 Loss 1.139 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.623, lat_loss 22.000
09/22 06:07:19 AM | Train: [125/180] Step 700/1249 Loss 1.144 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.623, lat_loss 22.000
09/22 06:07:44 AM | Train: [125/180] Step 750/1249 Loss 1.148 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.623, lat_loss 21.999
09/22 06:08:08 AM | Train: [125/180] Step 800/1249 Loss 1.167 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.623, lat_loss 21.999
09/22 06:08:33 AM | Train: [125/180] Step 850/1249 Loss 1.167 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.622, lat_loss 21.999
09/22 06:08:57 AM | Train: [125/180] Step 900/1249 Loss 1.170 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.622, lat_loss 21.999
09/22 06:09:22 AM | Train: [125/180] Step 950/1249 Loss 1.172 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.622, lat_loss 21.999
09/22 06:09:46 AM | Train: [125/180] Step 1000/1249 Loss 1.171 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.622, lat_loss 21.999
09/22 06:10:10 AM | Train: [125/180] Step 1050/1249 Loss 1.173 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.622, lat_loss 21.999
09/22 06:10:34 AM | Train: [125/180] Step 1100/1249 Loss 1.173 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.622, lat_loss 21.999
09/22 06:10:58 AM | Train: [125/180] Step 1150/1249 Loss 1.173 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.622, lat_loss 21.999
09/22 06:11:21 AM | Train: [125/180] Step 1200/1249 Loss 1.175 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.622, lat_loss 21.999
09/22 06:11:44 AM | Train: [125/180] Step 1249/1249 Loss 1.171 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.622, lat_loss 21.999
09/22 06:11:44 AM | _w_step_train: [125/180] Final Prec@1 91.0900% Time 600.72
09/22 06:11:44 AM | Start to train theta for epoch 124
09/22 06:12:03 AM | Train: [125/180] Step 050/312 Loss 1.810 Prec@(1,3) (86.9%, 99.1%), ce_loss 0.622, lat_loss 21.999
09/22 06:12:23 AM | Train: [125/180] Step 100/312 Loss 1.920 Prec@(1,3) (86.8%, 99.0%), ce_loss 0.622, lat_loss 21.999
09/22 06:12:43 AM | Train: [125/180] Step 150/312 Loss 1.945 Prec@(1,3) (86.6%, 99.1%), ce_loss 0.622, lat_loss 21.999
09/22 06:13:03 AM | Train: [125/180] Step 200/312 Loss 1.923 Prec@(1,3) (86.5%, 99.2%), ce_loss 0.622, lat_loss 21.999
09/22 06:13:25 AM | Train: [125/180] Step 250/312 Loss 1.937 Prec@(1,3) (86.3%, 99.2%), ce_loss 0.622, lat_loss 21.999
09/22 06:13:40 AM | Train: [125/180] Step 300/312 Loss 1.940 Prec@(1,3) (86.4%, 99.1%), ce_loss 0.622, lat_loss 21.999
09/22 06:13:43 AM | Train: [125/180] Step 312/312 Loss 1.956 Prec@(1,3) (86.3%, 99.1%), ce_loss 0.622, lat_loss 21.999
09/22 06:13:43 AM | _theta_step_train: [125/180] Final Prec@1 86.2900% Time 119.15
09/22 06:13:48 AM | Valid: [125/180] Step 050/312 Loss 2.244 Prec@(1,3) (82.4%, 98.7%), ce_loss 0.622, lat_loss 21.999
09/22 06:13:53 AM | Valid: [125/180] Step 100/312 Loss 2.226 Prec@(1,3) (83.2%, 98.6%), ce_loss 0.622, lat_loss 21.999
09/22 06:13:58 AM | Valid: [125/180] Step 150/312 Loss 2.191 Prec@(1,3) (83.7%, 98.7%), ce_loss 0.622, lat_loss 21.999
09/22 06:14:02 AM | Valid: [125/180] Step 200/312 Loss 2.111 Prec@(1,3) (84.4%, 98.9%), ce_loss 0.621, lat_loss 21.999
09/22 06:14:07 AM | Valid: [125/180] Step 250/312 Loss 2.112 Prec@(1,3) (84.4%, 98.9%), ce_loss 0.621, lat_loss 21.999
09/22 06:14:12 AM | Valid: [125/180] Step 300/312 Loss 2.078 Prec@(1,3) (84.5%, 99.0%), ce_loss 0.621, lat_loss 21.999
09/22 06:14:13 AM | Valid: [125/180] Step 312/312 Loss 2.065 Prec@(1,3) (84.6%, 99.0%), ce_loss 0.621, lat_loss 21.999
09/22 06:14:13 AM | val: [125/180] Final Prec@1 84.6200% Time 29.87
09/22 06:14:13 AM | Start to train weights for epoch 125
09/22 06:14:38 AM | Train: [126/180] Step 050/1249 Loss 1.007 Prec@(1,3) (92.5%, 99.9%), ce_loss 0.621, lat_loss 21.999
09/22 06:15:00 AM | Train: [126/180] Step 100/1249 Loss 0.982 Prec@(1,3) (92.7%, 99.9%), ce_loss 0.621, lat_loss 21.999
09/22 06:15:25 AM | Train: [126/180] Step 150/1249 Loss 1.017 Prec@(1,3) (92.4%, 99.9%), ce_loss 0.621, lat_loss 21.999
09/22 06:15:49 AM | Train: [126/180] Step 200/1249 Loss 1.038 Prec@(1,3) (92.0%, 99.9%), ce_loss 0.621, lat_loss 21.999
09/22 06:16:14 AM | Train: [126/180] Step 250/1249 Loss 1.080 Prec@(1,3) (91.9%, 99.9%), ce_loss 0.621, lat_loss 21.999
09/22 06:16:39 AM | Train: [126/180] Step 300/1249 Loss 1.092 Prec@(1,3) (91.8%, 99.9%), ce_loss 0.621, lat_loss 21.999
09/22 06:17:04 AM | Train: [126/180] Step 350/1249 Loss 1.089 Prec@(1,3) (91.8%, 99.9%), ce_loss 0.621, lat_loss 21.999
09/22 06:17:29 AM | Train: [126/180] Step 400/1249 Loss 1.078 Prec@(1,3) (91.8%, 99.9%), ce_loss 0.621, lat_loss 21.999
09/22 06:17:54 AM | Train: [126/180] Step 450/1249 Loss 1.113 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.621, lat_loss 21.999
09/22 06:18:19 AM | Train: [126/180] Step 500/1249 Loss 1.104 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.621, lat_loss 21.999
09/22 06:18:44 AM | Train: [126/180] Step 550/1249 Loss 1.106 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.620, lat_loss 21.999
09/22 06:19:09 AM | Train: [126/180] Step 600/1249 Loss 1.149 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.620, lat_loss 21.999
09/22 06:19:34 AM | Train: [126/180] Step 650/1249 Loss 1.152 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.620, lat_loss 21.999
09/22 06:19:59 AM | Train: [126/180] Step 700/1249 Loss 1.143 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.620, lat_loss 21.999
09/22 06:20:22 AM | Train: [126/180] Step 750/1249 Loss 1.131 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.620, lat_loss 21.999
09/22 06:20:45 AM | Train: [126/180] Step 800/1249 Loss 1.129 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.620, lat_loss 21.999
09/22 06:21:09 AM | Train: [126/180] Step 850/1249 Loss 1.129 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.620, lat_loss 21.999
09/22 06:21:33 AM | Train: [126/180] Step 900/1249 Loss 1.130 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.620, lat_loss 21.999
09/22 06:21:56 AM | Train: [126/180] Step 950/1249 Loss 1.125 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.620, lat_loss 21.999
09/22 06:22:19 AM | Train: [126/180] Step 1000/1249 Loss 1.117 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.620, lat_loss 21.999
09/22 06:22:42 AM | Train: [126/180] Step 1050/1249 Loss 1.124 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.620, lat_loss 21.999
09/22 06:23:06 AM | Train: [126/180] Step 1100/1249 Loss 1.126 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.620, lat_loss 21.999
09/22 06:23:28 AM | Train: [126/180] Step 1150/1249 Loss 1.126 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.620, lat_loss 21.999
09/22 06:23:51 AM | Train: [126/180] Step 1200/1249 Loss 1.134 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.619, lat_loss 21.999
09/22 06:24:16 AM | Train: [126/180] Step 1249/1249 Loss 1.123 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.619, lat_loss 21.999
09/22 06:24:16 AM | _w_step_train: [126/180] Final Prec@1 91.4950% Time 603.12
09/22 06:24:16 AM | Start to train theta for epoch 125
09/22 06:24:37 AM | Train: [126/180] Step 050/312 Loss 1.946 Prec@(1,3) (86.2%, 99.1%), ce_loss 0.619, lat_loss 21.999
09/22 06:24:57 AM | Train: [126/180] Step 100/312 Loss 1.988 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.619, lat_loss 21.999
09/22 06:25:18 AM | Train: [126/180] Step 150/312 Loss 1.938 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.619, lat_loss 21.999
09/22 06:25:38 AM | Train: [126/180] Step 200/312 Loss 1.948 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.619, lat_loss 21.999
09/22 06:25:58 AM | Train: [126/180] Step 250/312 Loss 1.956 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.619, lat_loss 21.999
09/22 06:26:19 AM | Train: [126/180] Step 300/312 Loss 1.948 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.619, lat_loss 21.999
09/22 06:26:24 AM | Train: [126/180] Step 312/312 Loss 1.957 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.619, lat_loss 21.999
09/22 06:26:24 AM | _theta_step_train: [126/180] Final Prec@1 85.8800% Time 127.66
09/22 06:26:29 AM | Valid: [126/180] Step 050/312 Loss 1.786 Prec@(1,3) (87.3%, 99.7%), ce_loss 0.619, lat_loss 21.999
09/22 06:26:34 AM | Valid: [126/180] Step 100/312 Loss 2.275 Prec@(1,3) (84.4%, 98.8%), ce_loss 0.619, lat_loss 21.999
09/22 06:26:38 AM | Valid: [126/180] Step 150/312 Loss 2.268 Prec@(1,3) (84.1%, 98.9%), ce_loss 0.619, lat_loss 21.999
09/22 06:26:43 AM | Valid: [126/180] Step 200/312 Loss 2.197 Prec@(1,3) (84.7%, 99.0%), ce_loss 0.619, lat_loss 21.999
09/22 06:26:48 AM | Valid: [126/180] Step 250/312 Loss 2.141 Prec@(1,3) (85.0%, 99.1%), ce_loss 0.619, lat_loss 21.999
09/22 06:26:52 AM | Valid: [126/180] Step 300/312 Loss 2.110 Prec@(1,3) (85.0%, 99.1%), ce_loss 0.619, lat_loss 21.999
09/22 06:26:53 AM | Valid: [126/180] Step 312/312 Loss 2.166 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.619, lat_loss 21.999
09/22 06:26:53 AM | val: [126/180] Final Prec@1 84.7200% Time 29.74
09/22 06:26:53 AM | Start to train weights for epoch 126
09/22 06:27:16 AM | Train: [127/180] Step 050/1249 Loss 1.018 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.619, lat_loss 21.999
09/22 06:27:38 AM | Train: [127/180] Step 100/1249 Loss 1.099 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.619, lat_loss 21.999
09/22 06:28:02 AM | Train: [127/180] Step 150/1249 Loss 1.071 Prec@(1,3) (91.7%, 99.9%), ce_loss 0.619, lat_loss 21.999
09/22 06:28:24 AM | Train: [127/180] Step 200/1249 Loss 1.082 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.619, lat_loss 21.999
09/22 06:28:46 AM | Train: [127/180] Step 250/1249 Loss 1.080 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.619, lat_loss 21.999
09/22 06:29:09 AM | Train: [127/180] Step 300/1249 Loss 1.080 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.618, lat_loss 21.999
09/22 06:29:32 AM | Train: [127/180] Step 350/1249 Loss 1.111 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.618, lat_loss 21.999
09/22 06:29:55 AM | Train: [127/180] Step 400/1249 Loss 1.094 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.618, lat_loss 21.999
09/22 06:30:18 AM | Train: [127/180] Step 450/1249 Loss 1.110 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.618, lat_loss 21.999
09/22 06:30:42 AM | Train: [127/180] Step 500/1249 Loss 1.093 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.618, lat_loss 21.999
09/22 06:31:05 AM | Train: [127/180] Step 550/1249 Loss 1.107 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.618, lat_loss 21.999
09/22 06:31:28 AM | Train: [127/180] Step 600/1249 Loss 1.104 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.618, lat_loss 21.999
09/22 06:31:50 AM | Train: [127/180] Step 650/1249 Loss 1.089 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.618, lat_loss 21.999
09/22 06:32:11 AM | Train: [127/180] Step 700/1249 Loss 1.091 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.618, lat_loss 21.999
09/22 06:32:32 AM | Train: [127/180] Step 750/1249 Loss 1.103 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.618, lat_loss 21.999
09/22 06:32:54 AM | Train: [127/180] Step 800/1249 Loss 1.106 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.618, lat_loss 21.999
09/22 06:33:16 AM | Train: [127/180] Step 850/1249 Loss 1.118 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.618, lat_loss 21.999
09/22 06:33:38 AM | Train: [127/180] Step 900/1249 Loss 1.133 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.618, lat_loss 21.999
09/22 06:34:02 AM | Train: [127/180] Step 950/1249 Loss 1.129 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.617, lat_loss 21.999
09/22 06:34:25 AM | Train: [127/180] Step 1000/1249 Loss 1.131 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.617, lat_loss 21.999
09/22 06:34:49 AM | Train: [127/180] Step 1050/1249 Loss 1.132 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.617, lat_loss 21.999
09/22 06:35:11 AM | Train: [127/180] Step 1100/1249 Loss 1.141 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.617, lat_loss 21.999
09/22 06:35:32 AM | Train: [127/180] Step 1150/1249 Loss 1.167 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.617, lat_loss 21.999
09/22 06:35:57 AM | Train: [127/180] Step 1200/1249 Loss 1.169 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.617, lat_loss 21.999
09/22 06:36:21 AM | Train: [127/180] Step 1249/1249 Loss 1.170 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.617, lat_loss 21.999
09/22 06:36:21 AM | _w_step_train: [127/180] Final Prec@1 91.0800% Time 567.86
09/22 06:36:21 AM | Start to train theta for epoch 126
09/22 06:36:41 AM | Train: [127/180] Step 050/312 Loss 2.062 Prec@(1,3) (85.5%, 99.1%), ce_loss 0.617, lat_loss 21.998
09/22 06:37:00 AM | Train: [127/180] Step 100/312 Loss 2.073 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.617, lat_loss 21.998
09/22 06:37:18 AM | Train: [127/180] Step 150/312 Loss 2.104 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.617, lat_loss 21.998
09/22 06:37:37 AM | Train: [127/180] Step 200/312 Loss 2.023 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.617, lat_loss 21.998
09/22 06:37:57 AM | Train: [127/180] Step 250/312 Loss 2.075 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.617, lat_loss 21.998
09/22 06:38:16 AM | Train: [127/180] Step 300/312 Loss 2.051 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.617, lat_loss 21.998
09/22 06:38:20 AM | Train: [127/180] Step 312/312 Loss 2.060 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.617, lat_loss 21.998
09/22 06:38:20 AM | _theta_step_train: [127/180] Final Prec@1 85.3300% Time 119.19
09/22 06:38:26 AM | Valid: [127/180] Step 050/312 Loss 1.901 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.617, lat_loss 21.998
09/22 06:38:30 AM | Valid: [127/180] Step 100/312 Loss 1.930 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.617, lat_loss 21.998
09/22 06:38:35 AM | Valid: [127/180] Step 150/312 Loss 1.999 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.617, lat_loss 21.998
09/22 06:38:39 AM | Valid: [127/180] Step 200/312 Loss 2.059 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.617, lat_loss 21.998
09/22 06:38:44 AM | Valid: [127/180] Step 250/312 Loss 2.117 Prec@(1,3) (84.4%, 99.0%), ce_loss 0.617, lat_loss 21.998
09/22 06:38:48 AM | Valid: [127/180] Step 300/312 Loss 2.096 Prec@(1,3) (84.2%, 99.1%), ce_loss 0.617, lat_loss 21.998
09/22 06:38:50 AM | Valid: [127/180] Step 312/312 Loss 2.100 Prec@(1,3) (84.2%, 99.1%), ce_loss 0.617, lat_loss 21.998
09/22 06:38:50 AM | val: [127/180] Final Prec@1 84.2300% Time 29.13
09/22 06:38:50 AM | Start to train weights for epoch 127
09/22 06:39:15 AM | Train: [128/180] Step 050/1249 Loss 1.110 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.617, lat_loss 21.998
09/22 06:39:40 AM | Train: [128/180] Step 100/1249 Loss 1.092 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.617, lat_loss 21.998
09/22 06:40:05 AM | Train: [128/180] Step 150/1249 Loss 1.092 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.616, lat_loss 21.998
09/22 06:40:30 AM | Train: [128/180] Step 200/1249 Loss 1.058 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.616, lat_loss 21.998
09/22 06:40:55 AM | Train: [128/180] Step 250/1249 Loss 1.041 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.616, lat_loss 21.998
09/22 06:41:20 AM | Train: [128/180] Step 300/1249 Loss 1.071 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.616, lat_loss 21.998
09/22 06:41:44 AM | Train: [128/180] Step 350/1249 Loss 1.066 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.616, lat_loss 21.998
09/22 06:42:07 AM | Train: [128/180] Step 400/1249 Loss 1.073 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.616, lat_loss 21.998
09/22 06:42:29 AM | Train: [128/180] Step 450/1249 Loss 1.057 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.616, lat_loss 21.998
09/22 06:42:52 AM | Train: [128/180] Step 500/1249 Loss 1.064 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.616, lat_loss 21.998
09/22 06:43:14 AM | Train: [128/180] Step 550/1249 Loss 1.081 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.616, lat_loss 21.998
09/22 06:43:38 AM | Train: [128/180] Step 600/1249 Loss 1.094 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.616, lat_loss 21.998
09/22 06:44:01 AM | Train: [128/180] Step 650/1249 Loss 1.091 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.616, lat_loss 21.998
09/22 06:44:26 AM | Train: [128/180] Step 700/1249 Loss 1.087 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.616, lat_loss 21.998
09/22 06:44:51 AM | Train: [128/180] Step 750/1249 Loss 1.081 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.615, lat_loss 21.998
09/22 06:45:15 AM | Train: [128/180] Step 800/1249 Loss 1.086 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.615, lat_loss 21.998
09/22 06:45:36 AM | Train: [128/180] Step 850/1249 Loss 1.088 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.615, lat_loss 21.998
09/22 06:46:00 AM | Train: [128/180] Step 900/1249 Loss 1.093 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.615, lat_loss 21.998
09/22 06:46:25 AM | Train: [128/180] Step 950/1249 Loss 1.088 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.615, lat_loss 21.998
09/22 06:46:49 AM | Train: [128/180] Step 1000/1249 Loss 1.101 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.615, lat_loss 21.998
09/22 06:47:12 AM | Train: [128/180] Step 1050/1249 Loss 1.100 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.615, lat_loss 21.998
09/22 06:47:35 AM | Train: [128/180] Step 1100/1249 Loss 1.118 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.615, lat_loss 21.998
09/22 06:47:57 AM | Train: [128/180] Step 1150/1249 Loss 1.133 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.615, lat_loss 21.998
09/22 06:48:21 AM | Train: [128/180] Step 1200/1249 Loss 1.143 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.615, lat_loss 21.998
09/22 06:48:45 AM | Train: [128/180] Step 1249/1249 Loss 1.144 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.615, lat_loss 21.998
09/22 06:48:45 AM | _w_step_train: [128/180] Final Prec@1 91.1625% Time 595.40
09/22 06:48:45 AM | Start to train theta for epoch 127
09/22 06:49:05 AM | Train: [128/180] Step 050/312 Loss 1.889 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.615, lat_loss 21.998
09/22 06:49:25 AM | Train: [128/180] Step 100/312 Loss 2.089 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.615, lat_loss 21.998
09/22 06:49:45 AM | Train: [128/180] Step 150/312 Loss 2.177 Prec@(1,3) (84.5%, 98.9%), ce_loss 0.615, lat_loss 21.998
09/22 06:50:06 AM | Train: [128/180] Step 200/312 Loss 2.129 Prec@(1,3) (84.8%, 99.0%), ce_loss 0.615, lat_loss 21.998
09/22 06:50:26 AM | Train: [128/180] Step 250/312 Loss 2.099 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.615, lat_loss 21.998
09/22 06:50:46 AM | Train: [128/180] Step 300/312 Loss 2.072 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.615, lat_loss 21.998
09/22 06:50:51 AM | Train: [128/180] Step 312/312 Loss 2.060 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.615, lat_loss 21.998
09/22 06:50:51 AM | _theta_step_train: [128/180] Final Prec@1 85.2800% Time 125.65
09/22 06:50:56 AM | Valid: [128/180] Step 050/312 Loss 1.754 Prec@(1,3) (86.5%, 99.6%), ce_loss 0.615, lat_loss 21.998
09/22 06:51:01 AM | Valid: [128/180] Step 100/312 Loss 1.808 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.614, lat_loss 21.998
09/22 06:51:05 AM | Valid: [128/180] Step 150/312 Loss 1.964 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.614, lat_loss 21.998
09/22 06:51:10 AM | Valid: [128/180] Step 200/312 Loss 1.995 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.614, lat_loss 21.998
09/22 06:51:14 AM | Valid: [128/180] Step 250/312 Loss 2.047 Prec@(1,3) (84.7%, 98.9%), ce_loss 0.614, lat_loss 21.998
09/22 06:51:19 AM | Valid: [128/180] Step 300/312 Loss 1.994 Prec@(1,3) (85.0%, 99.0%), ce_loss 0.614, lat_loss 21.998
09/22 06:51:20 AM | Valid: [128/180] Step 312/312 Loss 1.992 Prec@(1,3) (85.0%, 99.0%), ce_loss 0.614, lat_loss 21.998
09/22 06:51:20 AM | val: [128/180] Final Prec@1 84.9600% Time 29.67
09/22 06:51:20 AM | Start to train weights for epoch 128
09/22 06:51:46 AM | Train: [129/180] Step 050/1249 Loss 1.318 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.614, lat_loss 21.998
09/22 06:52:10 AM | Train: [129/180] Step 100/1249 Loss 1.197 Prec@(1,3) (90.4%, 99.8%), ce_loss 0.614, lat_loss 21.998
09/22 06:52:34 AM | Train: [129/180] Step 150/1249 Loss 1.148 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.614, lat_loss 21.998
09/22 06:52:58 AM | Train: [129/180] Step 200/1249 Loss 1.098 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.614, lat_loss 21.998
09/22 06:53:21 AM | Train: [129/180] Step 250/1249 Loss 1.147 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.614, lat_loss 21.998
09/22 06:53:45 AM | Train: [129/180] Step 300/1249 Loss 1.128 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.614, lat_loss 21.998
09/22 06:54:09 AM | Train: [129/180] Step 350/1249 Loss 1.127 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.614, lat_loss 21.998
09/22 06:54:33 AM | Train: [129/180] Step 400/1249 Loss 1.133 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.614, lat_loss 21.998
09/22 06:54:56 AM | Train: [129/180] Step 450/1249 Loss 1.121 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.614, lat_loss 21.998
09/22 06:55:20 AM | Train: [129/180] Step 500/1249 Loss 1.115 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.614, lat_loss 21.998
09/22 06:55:44 AM | Train: [129/180] Step 550/1249 Loss 1.137 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.614, lat_loss 21.998
09/22 06:56:07 AM | Train: [129/180] Step 600/1249 Loss 1.141 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.613, lat_loss 21.998
09/22 06:56:31 AM | Train: [129/180] Step 650/1249 Loss 1.139 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.613, lat_loss 21.998
09/22 06:56:54 AM | Train: [129/180] Step 700/1249 Loss 1.138 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.613, lat_loss 21.998
09/22 06:57:19 AM | Train: [129/180] Step 750/1249 Loss 1.138 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.613, lat_loss 21.998
09/22 06:57:43 AM | Train: [129/180] Step 800/1249 Loss 1.133 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.613, lat_loss 21.998
09/22 06:58:07 AM | Train: [129/180] Step 850/1249 Loss 1.144 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.613, lat_loss 21.998
09/22 06:58:31 AM | Train: [129/180] Step 900/1249 Loss 1.147 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.613, lat_loss 21.998
09/22 06:58:55 AM | Train: [129/180] Step 950/1249 Loss 1.146 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.613, lat_loss 21.998
09/22 06:59:19 AM | Train: [129/180] Step 1000/1249 Loss 1.139 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.613, lat_loss 21.998
09/22 06:59:42 AM | Train: [129/180] Step 1050/1249 Loss 1.135 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.613, lat_loss 21.998
09/22 07:00:05 AM | Train: [129/180] Step 1100/1249 Loss 1.135 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.613, lat_loss 21.998
09/22 07:00:29 AM | Train: [129/180] Step 1150/1249 Loss 1.134 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.613, lat_loss 21.998
09/22 07:00:53 AM | Train: [129/180] Step 1200/1249 Loss 1.144 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.613, lat_loss 21.998
09/22 07:01:17 AM | Train: [129/180] Step 1249/1249 Loss 1.142 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.612, lat_loss 21.998
09/22 07:01:17 AM | _w_step_train: [129/180] Final Prec@1 91.1175% Time 596.92
09/22 07:01:17 AM | Start to train theta for epoch 128
09/22 07:01:37 AM | Train: [129/180] Step 050/312 Loss 1.858 Prec@(1,3) (87.1%, 99.3%), ce_loss 0.612, lat_loss 21.998
09/22 07:01:56 AM | Train: [129/180] Step 100/312 Loss 1.873 Prec@(1,3) (86.4%, 99.3%), ce_loss 0.612, lat_loss 21.998
09/22 07:02:13 AM | Train: [129/180] Step 150/312 Loss 2.071 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.612, lat_loss 21.998
09/22 07:02:31 AM | Train: [129/180] Step 200/312 Loss 2.044 Prec@(1,3) (85.5%, 99.1%), ce_loss 0.612, lat_loss 21.998
09/22 07:02:50 AM | Train: [129/180] Step 250/312 Loss 2.101 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.612, lat_loss 21.998
09/22 07:03:10 AM | Train: [129/180] Step 300/312 Loss 2.140 Prec@(1,3) (85.1%, 99.0%), ce_loss 0.612, lat_loss 21.998
09/22 07:03:15 AM | Train: [129/180] Step 312/312 Loss 2.128 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.612, lat_loss 21.998
09/22 07:03:15 AM | _theta_step_train: [129/180] Final Prec@1 85.1300% Time 117.32
09/22 07:03:20 AM | Valid: [129/180] Step 050/312 Loss 2.051 Prec@(1,3) (85.3%, 98.4%), ce_loss 0.612, lat_loss 21.998
09/22 07:03:25 AM | Valid: [129/180] Step 100/312 Loss 2.107 Prec@(1,3) (84.7%, 98.8%), ce_loss 0.612, lat_loss 21.998
09/22 07:03:29 AM | Valid: [129/180] Step 150/312 Loss 2.074 Prec@(1,3) (84.7%, 98.9%), ce_loss 0.612, lat_loss 21.998
09/22 07:03:34 AM | Valid: [129/180] Step 200/312 Loss 2.016 Prec@(1,3) (85.2%, 99.0%), ce_loss 0.612, lat_loss 21.998
09/22 07:03:39 AM | Valid: [129/180] Step 250/312 Loss 2.033 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.612, lat_loss 21.998
09/22 07:03:43 AM | Valid: [129/180] Step 300/312 Loss 2.020 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.612, lat_loss 21.998
09/22 07:03:44 AM | Valid: [129/180] Step 312/312 Loss 2.037 Prec@(1,3) (85.0%, 99.1%), ce_loss 0.612, lat_loss 21.998
09/22 07:03:44 AM | val: [129/180] Final Prec@1 84.9700% Time 29.74
09/22 07:03:44 AM | Start to train weights for epoch 129
09/22 07:04:05 AM | Train: [130/180] Step 050/1249 Loss 0.942 Prec@(1,3) (92.8%, 99.9%), ce_loss 0.612, lat_loss 21.998
09/22 07:04:24 AM | Train: [130/180] Step 100/1249 Loss 1.023 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.612, lat_loss 21.998
09/22 07:04:43 AM | Train: [130/180] Step 150/1249 Loss 1.175 Prec@(1,3) (91.3%, 99.6%), ce_loss 0.612, lat_loss 21.998
09/22 07:05:02 AM | Train: [130/180] Step 200/1249 Loss 1.152 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.612, lat_loss 21.998
09/22 07:05:20 AM | Train: [130/180] Step 250/1249 Loss 1.119 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.612, lat_loss 21.998
09/22 07:05:39 AM | Train: [130/180] Step 300/1249 Loss 1.212 Prec@(1,3) (91.1%, 99.5%), ce_loss 0.612, lat_loss 21.998
09/22 07:05:57 AM | Train: [130/180] Step 350/1249 Loss 1.194 Prec@(1,3) (91.1%, 99.6%), ce_loss 0.612, lat_loss 21.998
09/22 07:06:16 AM | Train: [130/180] Step 400/1249 Loss 1.175 Prec@(1,3) (91.2%, 99.6%), ce_loss 0.612, lat_loss 21.998
09/22 07:06:34 AM | Train: [130/180] Step 450/1249 Loss 1.189 Prec@(1,3) (90.9%, 99.6%), ce_loss 0.611, lat_loss 21.997
09/22 07:06:52 AM | Train: [130/180] Step 500/1249 Loss 1.205 Prec@(1,3) (90.9%, 99.6%), ce_loss 0.611, lat_loss 21.997
09/22 07:07:11 AM | Train: [130/180] Step 550/1249 Loss 1.192 Prec@(1,3) (91.0%, 99.6%), ce_loss 0.611, lat_loss 21.997
09/22 07:07:30 AM | Train: [130/180] Step 600/1249 Loss 1.205 Prec@(1,3) (90.9%, 99.6%), ce_loss 0.611, lat_loss 21.997
09/22 07:07:49 AM | Train: [130/180] Step 650/1249 Loss 1.186 Prec@(1,3) (91.0%, 99.6%), ce_loss 0.611, lat_loss 21.997
09/22 07:08:09 AM | Train: [130/180] Step 700/1249 Loss 1.187 Prec@(1,3) (90.9%, 99.6%), ce_loss 0.611, lat_loss 21.997
09/22 07:08:32 AM | Train: [130/180] Step 750/1249 Loss 1.194 Prec@(1,3) (90.8%, 99.6%), ce_loss 0.611, lat_loss 21.997
09/22 07:08:55 AM | Train: [130/180] Step 800/1249 Loss 1.182 Prec@(1,3) (90.9%, 99.6%), ce_loss 0.611, lat_loss 21.997
09/22 07:09:18 AM | Train: [130/180] Step 850/1249 Loss 1.160 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.611, lat_loss 21.997
09/22 07:09:41 AM | Train: [130/180] Step 900/1249 Loss 1.178 Prec@(1,3) (91.0%, 99.6%), ce_loss 0.611, lat_loss 21.997
09/22 07:10:05 AM | Train: [130/180] Step 950/1249 Loss 1.174 Prec@(1,3) (91.0%, 99.6%), ce_loss 0.611, lat_loss 21.997
09/22 07:10:30 AM | Train: [130/180] Step 1000/1249 Loss 1.169 Prec@(1,3) (91.0%, 99.6%), ce_loss 0.611, lat_loss 21.997
09/22 07:10:54 AM | Train: [130/180] Step 1050/1249 Loss 1.162 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.611, lat_loss 21.997
09/22 07:11:19 AM | Train: [130/180] Step 1100/1249 Loss 1.185 Prec@(1,3) (91.0%, 99.6%), ce_loss 0.611, lat_loss 21.997
09/22 07:11:44 AM | Train: [130/180] Step 1150/1249 Loss 1.181 Prec@(1,3) (91.0%, 99.6%), ce_loss 0.610, lat_loss 21.997
09/22 07:12:09 AM | Train: [130/180] Step 1200/1249 Loss 1.178 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.610, lat_loss 21.997
09/22 07:12:33 AM | Train: [130/180] Step 1249/1249 Loss 1.177 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.610, lat_loss 21.997
09/22 07:12:33 AM | _w_step_train: [130/180] Final Prec@1 90.9450% Time 528.70
09/22 07:12:33 AM | Start to train theta for epoch 129
09/22 07:12:55 AM | Train: [130/180] Step 050/312 Loss 2.054 Prec@(1,3) (85.0%, 99.0%), ce_loss 0.610, lat_loss 21.997
09/22 07:13:15 AM | Train: [130/180] Step 100/312 Loss 2.098 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.610, lat_loss 21.997
09/22 07:13:33 AM | Train: [130/180] Step 150/312 Loss 2.074 Prec@(1,3) (84.9%, 99.2%), ce_loss 0.610, lat_loss 21.997
09/22 07:13:52 AM | Train: [130/180] Step 200/312 Loss 2.085 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.610, lat_loss 21.997
09/22 07:14:10 AM | Train: [130/180] Step 250/312 Loss 2.044 Prec@(1,3) (85.1%, 99.2%), ce_loss 0.610, lat_loss 21.997
09/22 07:14:29 AM | Train: [130/180] Step 300/312 Loss 2.022 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.610, lat_loss 21.997
09/22 07:14:34 AM | Train: [130/180] Step 312/312 Loss 2.026 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.610, lat_loss 21.997
09/22 07:14:34 AM | _theta_step_train: [130/180] Final Prec@1 85.3700% Time 120.69
09/22 07:14:39 AM | Valid: [130/180] Step 050/312 Loss 2.072 Prec@(1,3) (84.4%, 99.3%), ce_loss 0.610, lat_loss 21.997
09/22 07:14:44 AM | Valid: [130/180] Step 100/312 Loss 2.143 Prec@(1,3) (84.5%, 99.1%), ce_loss 0.610, lat_loss 21.997
09/22 07:14:48 AM | Valid: [130/180] Step 150/312 Loss 2.208 Prec@(1,3) (84.3%, 98.8%), ce_loss 0.610, lat_loss 21.997
09/22 07:14:53 AM | Valid: [130/180] Step 200/312 Loss 2.182 Prec@(1,3) (84.5%, 98.8%), ce_loss 0.610, lat_loss 21.997
09/22 07:14:58 AM | Valid: [130/180] Step 250/312 Loss 2.111 Prec@(1,3) (84.9%, 98.9%), ce_loss 0.610, lat_loss 21.997
09/22 07:15:02 AM | Valid: [130/180] Step 300/312 Loss 2.073 Prec@(1,3) (84.9%, 99.0%), ce_loss 0.610, lat_loss 21.997
09/22 07:15:04 AM | Valid: [130/180] Step 312/312 Loss 2.055 Prec@(1,3) (85.1%, 99.0%), ce_loss 0.610, lat_loss 21.997
09/22 07:15:04 AM | val: [130/180] Final Prec@1 85.0600% Time 29.79
09/22 07:15:04 AM | Start to train weights for epoch 130
09/22 07:15:27 AM | Train: [131/180] Step 050/1249 Loss 0.940 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.610, lat_loss 21.997
09/22 07:15:46 AM | Train: [131/180] Step 100/1249 Loss 0.864 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.610, lat_loss 21.997
09/22 07:16:07 AM | Train: [131/180] Step 150/1249 Loss 0.882 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.610, lat_loss 21.997
09/22 07:16:27 AM | Train: [131/180] Step 200/1249 Loss 1.014 Prec@(1,3) (92.4%, 99.7%), ce_loss 0.610, lat_loss 21.997
09/22 07:16:46 AM | Train: [131/180] Step 250/1249 Loss 1.059 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.610, lat_loss 21.997
09/22 07:17:06 AM | Train: [131/180] Step 300/1249 Loss 1.088 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.609, lat_loss 21.997
09/22 07:17:26 AM | Train: [131/180] Step 350/1249 Loss 1.065 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.609, lat_loss 21.997
09/22 07:17:47 AM | Train: [131/180] Step 400/1249 Loss 1.054 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.609, lat_loss 21.997
09/22 07:18:08 AM | Train: [131/180] Step 450/1249 Loss 1.068 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.609, lat_loss 21.997
09/22 07:18:31 AM | Train: [131/180] Step 500/1249 Loss 1.099 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.609, lat_loss 21.997
09/22 07:18:53 AM | Train: [131/180] Step 550/1249 Loss 1.090 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.609, lat_loss 21.997
09/22 07:19:15 AM | Train: [131/180] Step 600/1249 Loss 1.097 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.609, lat_loss 21.997
09/22 07:19:37 AM | Train: [131/180] Step 650/1249 Loss 1.097 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.609, lat_loss 21.997
09/22 07:19:59 AM | Train: [131/180] Step 700/1249 Loss 1.096 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.609, lat_loss 21.997
09/22 07:20:21 AM | Train: [131/180] Step 750/1249 Loss 1.093 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.609, lat_loss 21.997
09/22 07:20:42 AM | Train: [131/180] Step 800/1249 Loss 1.088 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.609, lat_loss 21.997
09/22 07:21:03 AM | Train: [131/180] Step 850/1249 Loss 1.095 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.609, lat_loss 21.997
09/22 07:21:23 AM | Train: [131/180] Step 900/1249 Loss 1.100 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.609, lat_loss 21.997
09/22 07:21:45 AM | Train: [131/180] Step 950/1249 Loss 1.099 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.608, lat_loss 21.997
09/22 07:22:07 AM | Train: [131/180] Step 1000/1249 Loss 1.097 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.608, lat_loss 21.997
09/22 07:22:30 AM | Train: [131/180] Step 1050/1249 Loss 1.097 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.608, lat_loss 21.997
09/22 07:22:52 AM | Train: [131/180] Step 1100/1249 Loss 1.094 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.608, lat_loss 21.997
09/22 07:23:14 AM | Train: [131/180] Step 1150/1249 Loss 1.098 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.608, lat_loss 21.997
09/22 07:23:38 AM | Train: [131/180] Step 1200/1249 Loss 1.093 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.608, lat_loss 21.997
09/22 07:24:02 AM | Train: [131/180] Step 1249/1249 Loss 1.091 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.608, lat_loss 21.997
09/22 07:24:02 AM | _w_step_train: [131/180] Final Prec@1 91.4775% Time 538.50
09/22 07:24:02 AM | Start to train theta for epoch 130
09/22 07:24:22 AM | Train: [131/180] Step 050/312 Loss 2.075 Prec@(1,3) (85.2%, 99.3%), ce_loss 0.608, lat_loss 21.997
09/22 07:24:40 AM | Train: [131/180] Step 100/312 Loss 2.054 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.608, lat_loss 21.997
09/22 07:24:57 AM | Train: [131/180] Step 150/312 Loss 2.052 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.608, lat_loss 21.997
09/22 07:25:14 AM | Train: [131/180] Step 200/312 Loss 2.088 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.608, lat_loss 21.997
09/22 07:25:32 AM | Train: [131/180] Step 250/312 Loss 2.049 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.608, lat_loss 21.997
09/22 07:25:50 AM | Train: [131/180] Step 300/312 Loss 2.030 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.608, lat_loss 21.997
09/22 07:25:55 AM | Train: [131/180] Step 312/312 Loss 2.040 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.608, lat_loss 21.997
09/22 07:25:55 AM | _theta_step_train: [131/180] Final Prec@1 85.7400% Time 113.06
09/22 07:26:00 AM | Valid: [131/180] Step 050/312 Loss 1.835 Prec@(1,3) (86.3%, 99.6%), ce_loss 0.608, lat_loss 21.997
09/22 07:26:04 AM | Valid: [131/180] Step 100/312 Loss 1.971 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.608, lat_loss 21.997
09/22 07:26:09 AM | Valid: [131/180] Step 150/312 Loss 1.978 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.608, lat_loss 21.997
09/22 07:26:13 AM | Valid: [131/180] Step 200/312 Loss 1.917 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.608, lat_loss 21.997
09/22 07:26:17 AM | Valid: [131/180] Step 250/312 Loss 1.927 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.608, lat_loss 21.997
09/22 07:26:21 AM | Valid: [131/180] Step 300/312 Loss 1.927 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.608, lat_loss 21.997
09/22 07:26:23 AM | Valid: [131/180] Step 312/312 Loss 1.926 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.608, lat_loss 21.997
09/22 07:26:23 AM | val: [131/180] Final Prec@1 85.7700% Time 27.35
09/22 07:26:23 AM | Best top1 acc by now. Save model
09/22 07:26:23 AM | Start to train weights for epoch 131
09/22 07:26:45 AM | Train: [132/180] Step 050/1249 Loss 0.883 Prec@(1,3) (92.6%, 100.0%), ce_loss 0.608, lat_loss 21.997
09/22 07:27:09 AM | Train: [132/180] Step 100/1249 Loss 1.034 Prec@(1,3) (91.4%, 99.9%), ce_loss 0.607, lat_loss 21.997
09/22 07:27:34 AM | Train: [132/180] Step 150/1249 Loss 0.989 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.607, lat_loss 21.997
09/22 07:27:59 AM | Train: [132/180] Step 200/1249 Loss 0.982 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.607, lat_loss 21.997
09/22 07:28:23 AM | Train: [132/180] Step 250/1249 Loss 0.985 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.607, lat_loss 21.997
09/22 07:28:47 AM | Train: [132/180] Step 300/1249 Loss 0.982 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.607, lat_loss 21.997
09/22 07:29:12 AM | Train: [132/180] Step 350/1249 Loss 0.973 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.607, lat_loss 21.997
09/22 07:29:36 AM | Train: [132/180] Step 400/1249 Loss 0.983 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.607, lat_loss 21.997
09/22 07:29:59 AM | Train: [132/180] Step 450/1249 Loss 0.994 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.607, lat_loss 21.997
09/22 07:30:21 AM | Train: [132/180] Step 500/1249 Loss 1.023 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.607, lat_loss 21.997
09/22 07:30:45 AM | Train: [132/180] Step 550/1249 Loss 1.059 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.607, lat_loss 21.997
09/22 07:31:09 AM | Train: [132/180] Step 600/1249 Loss 1.079 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.607, lat_loss 21.997
09/22 07:31:33 AM | Train: [132/180] Step 650/1249 Loss 1.073 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.607, lat_loss 21.997
09/22 07:31:57 AM | Train: [132/180] Step 700/1249 Loss 1.076 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.607, lat_loss 21.997
09/22 07:32:21 AM | Train: [132/180] Step 750/1249 Loss 1.081 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.606, lat_loss 21.997
09/22 07:32:45 AM | Train: [132/180] Step 800/1249 Loss 1.073 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.606, lat_loss 21.997
09/22 07:33:11 AM | Train: [132/180] Step 850/1249 Loss 1.073 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.606, lat_loss 21.997
09/22 07:33:35 AM | Train: [132/180] Step 900/1249 Loss 1.068 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.606, lat_loss 21.997
09/22 07:34:00 AM | Train: [132/180] Step 950/1249 Loss 1.066 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.606, lat_loss 21.997
09/22 07:34:26 AM | Train: [132/180] Step 1000/1249 Loss 1.065 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.606, lat_loss 21.997
09/22 07:34:51 AM | Train: [132/180] Step 1050/1249 Loss 1.068 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.606, lat_loss 21.997
09/22 07:35:15 AM | Train: [132/180] Step 1100/1249 Loss 1.067 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.606, lat_loss 21.997
09/22 07:35:39 AM | Train: [132/180] Step 1150/1249 Loss 1.069 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.606, lat_loss 21.997
09/22 07:36:02 AM | Train: [132/180] Step 1200/1249 Loss 1.066 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.606, lat_loss 21.997
09/22 07:36:27 AM | Train: [132/180] Step 1249/1249 Loss 1.069 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.606, lat_loss 21.997
09/22 07:36:27 AM | _w_step_train: [132/180] Final Prec@1 91.6025% Time 603.83
09/22 07:36:27 AM | Start to train theta for epoch 131
09/22 07:36:48 AM | Train: [132/180] Step 050/312 Loss 1.972 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.606, lat_loss 21.997
09/22 07:37:08 AM | Train: [132/180] Step 100/312 Loss 1.962 Prec@(1,3) (86.1%, 99.5%), ce_loss 0.606, lat_loss 21.997
09/22 07:37:28 AM | Train: [132/180] Step 150/312 Loss 1.936 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.606, lat_loss 21.997
09/22 07:37:48 AM | Train: [132/180] Step 200/312 Loss 1.923 Prec@(1,3) (86.8%, 99.3%), ce_loss 0.606, lat_loss 21.997
09/22 07:38:08 AM | Train: [132/180] Step 250/312 Loss 1.926 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.606, lat_loss 21.997
09/22 07:38:28 AM | Train: [132/180] Step 300/312 Loss 1.984 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.606, lat_loss 21.997
09/22 07:38:33 AM | Train: [132/180] Step 312/312 Loss 1.989 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.606, lat_loss 21.997
09/22 07:38:33 AM | _theta_step_train: [132/180] Final Prec@1 86.1200% Time 126.07
09/22 07:38:38 AM | Valid: [132/180] Step 050/312 Loss 2.245 Prec@(1,3) (83.6%, 98.8%), ce_loss 0.606, lat_loss 21.997
09/22 07:38:43 AM | Valid: [132/180] Step 100/312 Loss 2.168 Prec@(1,3) (84.7%, 98.9%), ce_loss 0.605, lat_loss 21.997
09/22 07:38:47 AM | Valid: [132/180] Step 150/312 Loss 2.172 Prec@(1,3) (84.7%, 99.0%), ce_loss 0.605, lat_loss 21.997
09/22 07:38:52 AM | Valid: [132/180] Step 200/312 Loss 2.082 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.605, lat_loss 21.997
09/22 07:38:57 AM | Valid: [132/180] Step 250/312 Loss 2.084 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.605, lat_loss 21.997
09/22 07:39:01 AM | Valid: [132/180] Step 300/312 Loss 2.076 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.605, lat_loss 21.997
09/22 07:39:03 AM | Valid: [132/180] Step 312/312 Loss 2.113 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.605, lat_loss 21.997
09/22 07:39:03 AM | val: [132/180] Final Prec@1 84.6700% Time 30.43
09/22 07:39:03 AM | Start to train weights for epoch 132
09/22 07:39:20 AM | Train: [133/180] Step 050/1249 Loss 0.875 Prec@(1,3) (92.6%, 99.9%), ce_loss 0.605, lat_loss 21.997
09/22 07:39:36 AM | Train: [133/180] Step 100/1249 Loss 0.904 Prec@(1,3) (92.5%, 99.9%), ce_loss 0.605, lat_loss 21.997
09/22 07:40:01 AM | Train: [133/180] Step 150/1249 Loss 1.030 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.605, lat_loss 21.997
09/22 07:40:28 AM | Train: [133/180] Step 200/1249 Loss 1.091 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.605, lat_loss 21.997
09/22 07:40:54 AM | Train: [133/180] Step 250/1249 Loss 1.070 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.605, lat_loss 21.997
09/22 07:41:21 AM | Train: [133/180] Step 300/1249 Loss 1.114 Prec@(1,3) (91.5%, 99.6%), ce_loss 0.605, lat_loss 21.997
09/22 07:41:47 AM | Train: [133/180] Step 350/1249 Loss 1.094 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.605, lat_loss 21.997
09/22 07:42:14 AM | Train: [133/180] Step 400/1249 Loss 1.113 Prec@(1,3) (91.5%, 99.6%), ce_loss 0.605, lat_loss 21.997
09/22 07:42:39 AM | Train: [133/180] Step 450/1249 Loss 1.113 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.605, lat_loss 21.997
09/22 07:43:05 AM | Train: [133/180] Step 500/1249 Loss 1.091 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.605, lat_loss 21.997
09/22 07:43:32 AM | Train: [133/180] Step 550/1249 Loss 1.091 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.605, lat_loss 21.997
09/22 07:43:59 AM | Train: [133/180] Step 600/1249 Loss 1.075 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.604, lat_loss 21.997
09/22 07:44:26 AM | Train: [133/180] Step 650/1249 Loss 1.063 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.604, lat_loss 21.997
09/22 07:44:52 AM | Train: [133/180] Step 700/1249 Loss 1.069 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.604, lat_loss 21.997
09/22 07:45:19 AM | Train: [133/180] Step 750/1249 Loss 1.063 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.604, lat_loss 21.997
09/22 07:45:46 AM | Train: [133/180] Step 800/1249 Loss 1.054 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.604, lat_loss 21.997
09/22 07:46:13 AM | Train: [133/180] Step 850/1249 Loss 1.045 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.604, lat_loss 21.997
09/22 07:46:40 AM | Train: [133/180] Step 900/1249 Loss 1.048 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.604, lat_loss 21.997
09/22 07:47:06 AM | Train: [133/180] Step 950/1249 Loss 1.057 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.604, lat_loss 21.997
09/22 07:47:23 AM | Train: [133/180] Step 1000/1249 Loss 1.053 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.604, lat_loss 21.997
09/22 07:47:39 AM | Train: [133/180] Step 1050/1249 Loss 1.052 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.604, lat_loss 21.997
09/22 07:47:55 AM | Train: [133/180] Step 1100/1249 Loss 1.053 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.604, lat_loss 21.997
09/22 07:48:11 AM | Train: [133/180] Step 1150/1249 Loss 1.051 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.604, lat_loss 21.997
09/22 07:48:27 AM | Train: [133/180] Step 1200/1249 Loss 1.050 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.604, lat_loss 21.997
09/22 07:48:43 AM | Train: [133/180] Step 1249/1249 Loss 1.049 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.603, lat_loss 21.997
09/22 07:48:43 AM | _w_step_train: [133/180] Final Prec@1 91.7850% Time 579.45
09/22 07:48:43 AM | Start to train theta for epoch 132
09/22 07:49:04 AM | Train: [133/180] Step 050/312 Loss 1.962 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.603, lat_loss 21.997
09/22 07:49:25 AM | Train: [133/180] Step 100/312 Loss 2.031 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.603, lat_loss 21.997
09/22 07:49:46 AM | Train: [133/180] Step 150/312 Loss 2.010 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.603, lat_loss 21.997
09/22 07:50:05 AM | Train: [133/180] Step 200/312 Loss 2.001 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.603, lat_loss 21.997
09/22 07:50:25 AM | Train: [133/180] Step 250/312 Loss 2.023 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.603, lat_loss 21.997
09/22 07:50:43 AM | Train: [133/180] Step 300/312 Loss 2.088 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.603, lat_loss 21.997
09/22 07:50:48 AM | Train: [133/180] Step 312/312 Loss 2.074 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.603, lat_loss 21.997
09/22 07:50:48 AM | _theta_step_train: [133/180] Final Prec@1 85.4400% Time 125.23
09/22 07:50:53 AM | Valid: [133/180] Step 050/312 Loss 2.201 Prec@(1,3) (83.3%, 99.0%), ce_loss 0.603, lat_loss 21.997
09/22 07:50:58 AM | Valid: [133/180] Step 100/312 Loss 2.109 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.603, lat_loss 21.997
09/22 07:51:03 AM | Valid: [133/180] Step 150/312 Loss 2.272 Prec@(1,3) (83.3%, 98.9%), ce_loss 0.603, lat_loss 21.997
09/22 07:51:07 AM | Valid: [133/180] Step 200/312 Loss 2.251 Prec@(1,3) (83.7%, 99.0%), ce_loss 0.603, lat_loss 21.997
09/22 07:51:12 AM | Valid: [133/180] Step 250/312 Loss 2.226 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.603, lat_loss 21.997
09/22 07:51:17 AM | Valid: [133/180] Step 300/312 Loss 2.177 Prec@(1,3) (84.0%, 99.2%), ce_loss 0.603, lat_loss 21.997
09/22 07:51:18 AM | Valid: [133/180] Step 312/312 Loss 2.179 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.603, lat_loss 21.997
09/22 07:51:18 AM | val: [133/180] Final Prec@1 83.9300% Time 30.03
09/22 07:51:18 AM | Start to train weights for epoch 133
09/22 07:51:42 AM | Train: [134/180] Step 050/1249 Loss 1.146 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.603, lat_loss 21.997
09/22 07:52:06 AM | Train: [134/180] Step 100/1249 Loss 1.072 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.603, lat_loss 21.997
09/22 07:52:29 AM | Train: [134/180] Step 150/1249 Loss 1.064 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.603, lat_loss 21.997
09/22 07:52:54 AM | Train: [134/180] Step 200/1249 Loss 1.073 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.603, lat_loss 21.997
09/22 07:53:18 AM | Train: [134/180] Step 250/1249 Loss 1.026 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.603, lat_loss 21.997
09/22 07:53:41 AM | Train: [134/180] Step 300/1249 Loss 1.029 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.603, lat_loss 21.997
09/22 07:54:01 AM | Train: [134/180] Step 350/1249 Loss 1.015 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.603, lat_loss 21.997
09/22 07:54:24 AM | Train: [134/180] Step 400/1249 Loss 1.017 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.603, lat_loss 21.997
09/22 07:54:48 AM | Train: [134/180] Step 450/1249 Loss 1.025 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.602, lat_loss 21.997
09/22 07:55:12 AM | Train: [134/180] Step 500/1249 Loss 1.017 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.602, lat_loss 21.997
09/22 07:55:36 AM | Train: [134/180] Step 550/1249 Loss 1.020 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.602, lat_loss 21.997
09/22 07:56:00 AM | Train: [134/180] Step 600/1249 Loss 1.018 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.602, lat_loss 21.997
09/22 07:56:24 AM | Train: [134/180] Step 650/1249 Loss 1.010 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.602, lat_loss 21.997
09/22 07:56:47 AM | Train: [134/180] Step 700/1249 Loss 1.016 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.602, lat_loss 21.997
09/22 07:57:11 AM | Train: [134/180] Step 750/1249 Loss 1.010 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.602, lat_loss 21.997
09/22 07:57:34 AM | Train: [134/180] Step 800/1249 Loss 1.013 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.602, lat_loss 21.997
09/22 07:57:57 AM | Train: [134/180] Step 850/1249 Loss 1.014 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.602, lat_loss 21.997
09/22 07:58:20 AM | Train: [134/180] Step 900/1249 Loss 1.015 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.602, lat_loss 21.997
09/22 07:58:43 AM | Train: [134/180] Step 950/1249 Loss 1.033 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.602, lat_loss 21.997
09/22 07:59:08 AM | Train: [134/180] Step 1000/1249 Loss 1.035 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.602, lat_loss 21.997
09/22 07:59:33 AM | Train: [134/180] Step 1050/1249 Loss 1.028 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.602, lat_loss 21.997
09/22 07:59:58 AM | Train: [134/180] Step 1100/1249 Loss 1.032 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.602, lat_loss 21.997
09/22 08:00:23 AM | Train: [134/180] Step 1150/1249 Loss 1.033 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.601, lat_loss 21.997
09/22 08:00:48 AM | Train: [134/180] Step 1200/1249 Loss 1.041 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.601, lat_loss 21.997
09/22 08:01:12 AM | Train: [134/180] Step 1249/1249 Loss 1.057 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.601, lat_loss 21.997
09/22 08:01:12 AM | _w_step_train: [134/180] Final Prec@1 91.7900% Time 594.16
09/22 08:01:12 AM | Start to train theta for epoch 133
09/22 08:01:34 AM | Train: [134/180] Step 050/312 Loss 2.044 Prec@(1,3) (85.1%, 98.8%), ce_loss 0.601, lat_loss 21.997
09/22 08:01:54 AM | Train: [134/180] Step 100/312 Loss 1.998 Prec@(1,3) (85.4%, 98.9%), ce_loss 0.601, lat_loss 21.997
09/22 08:02:14 AM | Train: [134/180] Step 150/312 Loss 2.019 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.601, lat_loss 21.997
09/22 08:02:35 AM | Train: [134/180] Step 200/312 Loss 1.974 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.601, lat_loss 21.997
09/22 08:02:56 AM | Train: [134/180] Step 250/312 Loss 1.958 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.601, lat_loss 21.997
09/22 08:03:16 AM | Train: [134/180] Step 300/312 Loss 1.948 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.601, lat_loss 21.997
09/22 08:03:21 AM | Train: [134/180] Step 312/312 Loss 1.939 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.601, lat_loss 21.997
09/22 08:03:21 AM | _theta_step_train: [134/180] Final Prec@1 85.8600% Time 129.19
09/22 08:03:27 AM | Valid: [134/180] Step 050/312 Loss 2.049 Prec@(1,3) (84.4%, 98.7%), ce_loss 0.601, lat_loss 21.997
09/22 08:03:31 AM | Valid: [134/180] Step 100/312 Loss 2.171 Prec@(1,3) (83.8%, 98.7%), ce_loss 0.601, lat_loss 21.997
09/22 08:03:36 AM | Valid: [134/180] Step 150/312 Loss 2.150 Prec@(1,3) (84.4%, 98.8%), ce_loss 0.601, lat_loss 21.997
09/22 08:03:40 AM | Valid: [134/180] Step 200/312 Loss 2.053 Prec@(1,3) (85.2%, 98.9%), ce_loss 0.601, lat_loss 21.997
09/22 08:03:45 AM | Valid: [134/180] Step 250/312 Loss 2.054 Prec@(1,3) (84.9%, 99.0%), ce_loss 0.601, lat_loss 21.997
09/22 08:03:50 AM | Valid: [134/180] Step 300/312 Loss 1.998 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.601, lat_loss 21.997
09/22 08:03:51 AM | Valid: [134/180] Step 312/312 Loss 2.010 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.601, lat_loss 21.997
09/22 08:03:51 AM | val: [134/180] Final Prec@1 85.1700% Time 29.52
09/22 08:03:51 AM | Start to train weights for epoch 134
09/22 08:04:15 AM | Train: [135/180] Step 050/1249 Loss 1.039 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.601, lat_loss 21.997
09/22 08:04:39 AM | Train: [135/180] Step 100/1249 Loss 1.037 Prec@(1,3) (92.0%, 99.6%), ce_loss 0.601, lat_loss 21.997
09/22 08:05:04 AM | Train: [135/180] Step 150/1249 Loss 1.085 Prec@(1,3) (91.8%, 99.6%), ce_loss 0.601, lat_loss 21.997
09/22 08:05:27 AM | Train: [135/180] Step 200/1249 Loss 1.070 Prec@(1,3) (92.0%, 99.6%), ce_loss 0.601, lat_loss 21.997
09/22 08:05:51 AM | Train: [135/180] Step 250/1249 Loss 1.027 Prec@(1,3) (92.4%, 99.6%), ce_loss 0.601, lat_loss 21.997
09/22 08:06:14 AM | Train: [135/180] Step 300/1249 Loss 1.020 Prec@(1,3) (92.4%, 99.7%), ce_loss 0.600, lat_loss 21.997
09/22 08:06:38 AM | Train: [135/180] Step 350/1249 Loss 1.017 Prec@(1,3) (92.4%, 99.7%), ce_loss 0.600, lat_loss 21.997
09/22 08:07:00 AM | Train: [135/180] Step 400/1249 Loss 1.007 Prec@(1,3) (92.3%, 99.7%), ce_loss 0.600, lat_loss 21.997
09/22 08:07:22 AM | Train: [135/180] Step 450/1249 Loss 0.994 Prec@(1,3) (92.4%, 99.7%), ce_loss 0.600, lat_loss 21.997
09/22 08:07:46 AM | Train: [135/180] Step 500/1249 Loss 0.995 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.600, lat_loss 21.997
09/22 08:08:06 AM | Train: [135/180] Step 550/1249 Loss 1.014 Prec@(1,3) (92.2%, 99.7%), ce_loss 0.600, lat_loss 21.997
09/22 08:08:29 AM | Train: [135/180] Step 600/1249 Loss 1.019 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.600, lat_loss 21.997
09/22 08:08:52 AM | Train: [135/180] Step 650/1249 Loss 1.020 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.600, lat_loss 21.997
09/22 08:09:14 AM | Train: [135/180] Step 700/1249 Loss 1.007 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.600, lat_loss 21.997
09/22 08:09:38 AM | Train: [135/180] Step 750/1249 Loss 1.001 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.600, lat_loss 21.997
09/22 08:10:01 AM | Train: [135/180] Step 800/1249 Loss 1.008 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.600, lat_loss 21.997
09/22 08:10:24 AM | Train: [135/180] Step 850/1249 Loss 1.011 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.600, lat_loss 21.997
09/22 08:10:46 AM | Train: [135/180] Step 900/1249 Loss 1.028 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.600, lat_loss 21.996
09/22 08:11:11 AM | Train: [135/180] Step 950/1249 Loss 1.028 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.600, lat_loss 21.996
09/22 08:11:36 AM | Train: [135/180] Step 1000/1249 Loss 1.027 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.599, lat_loss 21.996
09/22 08:12:00 AM | Train: [135/180] Step 1050/1249 Loss 1.021 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.599, lat_loss 21.996
09/22 08:12:25 AM | Train: [135/180] Step 1100/1249 Loss 1.033 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.599, lat_loss 21.996
09/22 08:12:50 AM | Train: [135/180] Step 1150/1249 Loss 1.044 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.599, lat_loss 21.996
09/22 08:13:14 AM | Train: [135/180] Step 1200/1249 Loss 1.046 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.599, lat_loss 21.996
09/22 08:13:39 AM | Train: [135/180] Step 1249/1249 Loss 1.045 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.599, lat_loss 21.996
09/22 08:13:39 AM | _w_step_train: [135/180] Final Prec@1 92.0150% Time 587.90
09/22 08:13:39 AM | Start to train theta for epoch 134
09/22 08:14:00 AM | Train: [135/180] Step 050/312 Loss 2.148 Prec@(1,3) (84.7%, 99.0%), ce_loss 0.599, lat_loss 21.996
09/22 08:14:21 AM | Train: [135/180] Step 100/312 Loss 2.201 Prec@(1,3) (84.5%, 98.8%), ce_loss 0.599, lat_loss 21.996
09/22 08:14:41 AM | Train: [135/180] Step 150/312 Loss 2.119 Prec@(1,3) (84.9%, 98.9%), ce_loss 0.599, lat_loss 21.996
09/22 08:15:01 AM | Train: [135/180] Step 200/312 Loss 2.136 Prec@(1,3) (84.7%, 99.0%), ce_loss 0.599, lat_loss 21.996
09/22 08:15:20 AM | Train: [135/180] Step 250/312 Loss 2.097 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.599, lat_loss 21.996
09/22 08:15:38 AM | Train: [135/180] Step 300/312 Loss 2.060 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.599, lat_loss 21.996
09/22 08:15:42 AM | Train: [135/180] Step 312/312 Loss 2.054 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.599, lat_loss 21.996
09/22 08:15:43 AM | _theta_step_train: [135/180] Final Prec@1 85.3200% Time 123.80
09/22 08:15:48 AM | Valid: [135/180] Step 050/312 Loss 1.866 Prec@(1,3) (86.5%, 99.6%), ce_loss 0.599, lat_loss 21.996
09/22 08:15:52 AM | Valid: [135/180] Step 100/312 Loss 2.080 Prec@(1,3) (84.9%, 99.2%), ce_loss 0.599, lat_loss 21.996
09/22 08:15:57 AM | Valid: [135/180] Step 150/312 Loss 2.165 Prec@(1,3) (84.4%, 99.0%), ce_loss 0.599, lat_loss 21.996
09/22 08:16:02 AM | Valid: [135/180] Step 200/312 Loss 2.205 Prec@(1,3) (84.3%, 99.0%), ce_loss 0.599, lat_loss 21.996
09/22 08:16:06 AM | Valid: [135/180] Step 250/312 Loss 2.149 Prec@(1,3) (84.4%, 99.1%), ce_loss 0.599, lat_loss 21.996
09/22 08:16:11 AM | Valid: [135/180] Step 300/312 Loss 2.147 Prec@(1,3) (84.4%, 99.1%), ce_loss 0.599, lat_loss 21.996
09/22 08:16:12 AM | Valid: [135/180] Step 312/312 Loss 2.128 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.599, lat_loss 21.996
09/22 08:16:12 AM | val: [135/180] Final Prec@1 84.6200% Time 29.53
09/22 08:16:12 AM | Start to train weights for epoch 135
09/22 08:16:29 AM | Train: [136/180] Step 050/1249 Loss 1.130 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.599, lat_loss 21.996
09/22 08:16:50 AM | Train: [136/180] Step 100/1249 Loss 1.001 Prec@(1,3) (92.5%, 99.9%), ce_loss 0.599, lat_loss 21.996
09/22 08:17:15 AM | Train: [136/180] Step 150/1249 Loss 0.943 Prec@(1,3) (92.8%, 99.9%), ce_loss 0.599, lat_loss 21.996
09/22 08:17:40 AM | Train: [136/180] Step 200/1249 Loss 0.962 Prec@(1,3) (92.5%, 99.9%), ce_loss 0.598, lat_loss 21.996
09/22 08:18:03 AM | Train: [136/180] Step 250/1249 Loss 0.958 Prec@(1,3) (92.6%, 99.9%), ce_loss 0.598, lat_loss 21.996
09/22 08:18:26 AM | Train: [136/180] Step 300/1249 Loss 0.943 Prec@(1,3) (92.7%, 99.9%), ce_loss 0.598, lat_loss 21.996
09/22 08:18:49 AM | Train: [136/180] Step 350/1249 Loss 0.956 Prec@(1,3) (92.5%, 99.9%), ce_loss 0.598, lat_loss 21.996
09/22 08:19:12 AM | Train: [136/180] Step 400/1249 Loss 0.984 Prec@(1,3) (92.5%, 99.8%), ce_loss 0.598, lat_loss 21.996
09/22 08:19:36 AM | Train: [136/180] Step 450/1249 Loss 0.966 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.598, lat_loss 21.996
09/22 08:20:01 AM | Train: [136/180] Step 500/1249 Loss 0.968 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.598, lat_loss 21.996
09/22 08:20:25 AM | Train: [136/180] Step 550/1249 Loss 0.960 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.598, lat_loss 21.996
09/22 08:20:50 AM | Train: [136/180] Step 600/1249 Loss 0.977 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.598, lat_loss 21.996
09/22 08:21:14 AM | Train: [136/180] Step 650/1249 Loss 1.000 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.598, lat_loss 21.996
09/22 08:21:39 AM | Train: [136/180] Step 700/1249 Loss 0.999 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.598, lat_loss 21.996
09/22 08:22:03 AM | Train: [136/180] Step 750/1249 Loss 1.006 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.598, lat_loss 21.996
09/22 08:22:28 AM | Train: [136/180] Step 800/1249 Loss 0.996 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.598, lat_loss 21.996
09/22 08:22:50 AM | Train: [136/180] Step 850/1249 Loss 1.001 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.597, lat_loss 21.996
09/22 08:23:14 AM | Train: [136/180] Step 900/1249 Loss 0.999 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.597, lat_loss 21.996
09/22 08:23:38 AM | Train: [136/180] Step 950/1249 Loss 0.998 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.597, lat_loss 21.996
09/22 08:24:03 AM | Train: [136/180] Step 1000/1249 Loss 0.993 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.597, lat_loss 21.996
09/22 08:24:26 AM | Train: [136/180] Step 1050/1249 Loss 0.991 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.597, lat_loss 21.996
09/22 08:24:51 AM | Train: [136/180] Step 1100/1249 Loss 0.990 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.597, lat_loss 21.996
09/22 08:25:15 AM | Train: [136/180] Step 1150/1249 Loss 1.003 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.597, lat_loss 21.996
09/22 08:25:38 AM | Train: [136/180] Step 1200/1249 Loss 1.008 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.597, lat_loss 21.996
09/22 08:26:02 AM | Train: [136/180] Step 1249/1249 Loss 1.011 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.597, lat_loss 21.996
09/22 08:26:02 AM | _w_step_train: [136/180] Final Prec@1 92.1750% Time 590.05
09/22 08:26:02 AM | Start to train theta for epoch 135
09/22 08:26:19 AM | Train: [136/180] Step 050/312 Loss 2.049 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.597, lat_loss 21.996
09/22 08:26:40 AM | Train: [136/180] Step 100/312 Loss 1.941 Prec@(1,3) (87.7%, 99.4%), ce_loss 0.597, lat_loss 21.996
09/22 08:26:59 AM | Train: [136/180] Step 150/312 Loss 1.914 Prec@(1,3) (87.2%, 99.5%), ce_loss 0.597, lat_loss 21.996
09/22 08:27:18 AM | Train: [136/180] Step 200/312 Loss 1.976 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.597, lat_loss 21.996
09/22 08:27:38 AM | Train: [136/180] Step 250/312 Loss 1.963 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.597, lat_loss 21.996
09/22 08:27:59 AM | Train: [136/180] Step 300/312 Loss 1.936 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.597, lat_loss 21.996
09/22 08:28:04 AM | Train: [136/180] Step 312/312 Loss 1.946 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.597, lat_loss 21.996
09/22 08:28:04 AM | _theta_step_train: [136/180] Final Prec@1 86.5500% Time 121.94
09/22 08:28:09 AM | Valid: [136/180] Step 050/312 Loss 2.385 Prec@(1,3) (83.6%, 97.6%), ce_loss 0.597, lat_loss 21.996
09/22 08:28:14 AM | Valid: [136/180] Step 100/312 Loss 2.318 Prec@(1,3) (83.2%, 98.2%), ce_loss 0.597, lat_loss 21.996
09/22 08:28:18 AM | Valid: [136/180] Step 150/312 Loss 2.291 Prec@(1,3) (83.3%, 98.3%), ce_loss 0.597, lat_loss 21.996
09/22 08:28:23 AM | Valid: [136/180] Step 200/312 Loss 2.248 Prec@(1,3) (83.7%, 98.5%), ce_loss 0.597, lat_loss 21.996
09/22 08:28:28 AM | Valid: [136/180] Step 250/312 Loss 2.293 Prec@(1,3) (83.4%, 98.4%), ce_loss 0.597, lat_loss 21.996
09/22 08:28:32 AM | Valid: [136/180] Step 300/312 Loss 2.315 Prec@(1,3) (83.1%, 98.4%), ce_loss 0.597, lat_loss 21.996
09/22 08:28:33 AM | Valid: [136/180] Step 312/312 Loss 2.302 Prec@(1,3) (83.1%, 98.4%), ce_loss 0.597, lat_loss 21.996
09/22 08:28:33 AM | val: [136/180] Final Prec@1 83.1100% Time 29.22
09/22 08:28:33 AM | Start to train weights for epoch 136
09/22 08:29:00 AM | Train: [137/180] Step 050/1249 Loss 0.856 Prec@(1,3) (93.3%, 99.9%), ce_loss 0.597, lat_loss 21.996
09/22 08:29:23 AM | Train: [137/180] Step 100/1249 Loss 0.871 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.596, lat_loss 21.996
09/22 08:29:48 AM | Train: [137/180] Step 150/1249 Loss 0.887 Prec@(1,3) (92.9%, 99.9%), ce_loss 0.596, lat_loss 21.996
09/22 08:30:13 AM | Train: [137/180] Step 200/1249 Loss 0.897 Prec@(1,3) (92.7%, 99.9%), ce_loss 0.596, lat_loss 21.996
09/22 08:30:39 AM | Train: [137/180] Step 250/1249 Loss 0.900 Prec@(1,3) (92.7%, 99.9%), ce_loss 0.596, lat_loss 21.996
09/22 08:31:03 AM | Train: [137/180] Step 300/1249 Loss 0.921 Prec@(1,3) (92.6%, 99.9%), ce_loss 0.596, lat_loss 21.996
09/22 08:31:28 AM | Train: [137/180] Step 350/1249 Loss 0.954 Prec@(1,3) (92.4%, 99.9%), ce_loss 0.596, lat_loss 21.996
09/22 08:31:52 AM | Train: [137/180] Step 400/1249 Loss 0.964 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.596, lat_loss 21.996
09/22 08:32:17 AM | Train: [137/180] Step 450/1249 Loss 0.976 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.596, lat_loss 21.996
09/22 08:32:40 AM | Train: [137/180] Step 500/1249 Loss 0.972 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.596, lat_loss 21.996
09/22 08:33:02 AM | Train: [137/180] Step 550/1249 Loss 0.969 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.596, lat_loss 21.996
09/22 08:33:26 AM | Train: [137/180] Step 600/1249 Loss 0.963 Prec@(1,3) (92.4%, 99.9%), ce_loss 0.596, lat_loss 21.996
09/22 08:33:51 AM | Train: [137/180] Step 650/1249 Loss 0.967 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.596, lat_loss 21.996
09/22 08:34:13 AM | Train: [137/180] Step 700/1249 Loss 0.983 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.596, lat_loss 21.996
09/22 08:34:35 AM | Train: [137/180] Step 750/1249 Loss 0.980 Prec@(1,3) (92.2%, 99.9%), ce_loss 0.596, lat_loss 21.996
09/22 08:34:57 AM | Train: [137/180] Step 800/1249 Loss 0.975 Prec@(1,3) (92.3%, 99.9%), ce_loss 0.595, lat_loss 21.996
09/22 08:35:21 AM | Train: [137/180] Step 850/1249 Loss 0.997 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.595, lat_loss 21.996
09/22 08:35:44 AM | Train: [137/180] Step 900/1249 Loss 0.994 Prec@(1,3) (92.1%, 99.9%), ce_loss 0.595, lat_loss 21.996
09/22 08:36:09 AM | Train: [137/180] Step 950/1249 Loss 1.009 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.595, lat_loss 21.996
09/22 08:36:33 AM | Train: [137/180] Step 1000/1249 Loss 1.021 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.595, lat_loss 21.996
09/22 08:36:57 AM | Train: [137/180] Step 1050/1249 Loss 1.017 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.595, lat_loss 21.996
09/22 08:37:21 AM | Train: [137/180] Step 1100/1249 Loss 1.024 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.595, lat_loss 21.996
09/22 08:37:44 AM | Train: [137/180] Step 1150/1249 Loss 1.022 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.595, lat_loss 21.996
09/22 08:38:07 AM | Train: [137/180] Step 1200/1249 Loss 1.029 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.595, lat_loss 21.996
09/22 08:38:32 AM | Train: [137/180] Step 1249/1249 Loss 1.025 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.595, lat_loss 21.996
09/22 08:38:32 AM | _w_step_train: [137/180] Final Prec@1 91.9475% Time 598.29
09/22 08:38:32 AM | Start to train theta for epoch 136
09/22 08:38:52 AM | Train: [137/180] Step 050/312 Loss 1.840 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.595, lat_loss 21.996
09/22 08:39:12 AM | Train: [137/180] Step 100/312 Loss 1.921 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.595, lat_loss 21.996
09/22 08:39:30 AM | Train: [137/180] Step 150/312 Loss 1.880 Prec@(1,3) (86.7%, 99.4%), ce_loss 0.595, lat_loss 21.996
09/22 08:39:47 AM | Train: [137/180] Step 200/312 Loss 1.922 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.595, lat_loss 21.996
09/22 08:40:07 AM | Train: [137/180] Step 250/312 Loss 1.956 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.595, lat_loss 21.996
09/22 08:40:27 AM | Train: [137/180] Step 300/312 Loss 1.974 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.595, lat_loss 21.996
09/22 08:40:32 AM | Train: [137/180] Step 312/312 Loss 1.979 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.595, lat_loss 21.996
09/22 08:40:32 AM | _theta_step_train: [137/180] Final Prec@1 86.0700% Time 120.55
09/22 08:40:37 AM | Valid: [137/180] Step 050/312 Loss 2.157 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.595, lat_loss 21.996
09/22 08:40:42 AM | Valid: [137/180] Step 100/312 Loss 2.198 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.595, lat_loss 21.996
09/22 08:40:47 AM | Valid: [137/180] Step 150/312 Loss 2.163 Prec@(1,3) (85.0%, 99.0%), ce_loss 0.595, lat_loss 21.996
09/22 08:40:51 AM | Valid: [137/180] Step 200/312 Loss 2.116 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.595, lat_loss 21.996
09/22 08:40:56 AM | Valid: [137/180] Step 250/312 Loss 2.093 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.595, lat_loss 21.996
09/22 08:41:01 AM | Valid: [137/180] Step 300/312 Loss 2.071 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.594, lat_loss 21.996
09/22 08:41:02 AM | Valid: [137/180] Step 312/312 Loss 2.068 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.594, lat_loss 21.996
09/22 08:41:02 AM | val: [137/180] Final Prec@1 85.2900% Time 29.59
09/22 08:41:02 AM | Start to train weights for epoch 137
09/22 08:41:30 AM | Train: [138/180] Step 050/1249 Loss 0.922 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.594, lat_loss 21.996
09/22 08:41:56 AM | Train: [138/180] Step 100/1249 Loss 0.914 Prec@(1,3) (92.9%, 99.9%), ce_loss 0.594, lat_loss 21.996
09/22 08:42:22 AM | Train: [138/180] Step 150/1249 Loss 0.923 Prec@(1,3) (92.7%, 99.9%), ce_loss 0.594, lat_loss 21.996
09/22 08:42:47 AM | Train: [138/180] Step 200/1249 Loss 0.954 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.594, lat_loss 21.996
09/22 08:43:13 AM | Train: [138/180] Step 250/1249 Loss 0.993 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.594, lat_loss 21.996
09/22 08:43:40 AM | Train: [138/180] Step 300/1249 Loss 0.956 Prec@(1,3) (92.5%, 99.9%), ce_loss 0.594, lat_loss 21.996
09/22 08:44:06 AM | Train: [138/180] Step 350/1249 Loss 0.986 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.594, lat_loss 21.996
09/22 08:44:32 AM | Train: [138/180] Step 400/1249 Loss 0.993 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.594, lat_loss 21.996
09/22 08:44:59 AM | Train: [138/180] Step 450/1249 Loss 0.994 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.594, lat_loss 21.996
09/22 08:45:25 AM | Train: [138/180] Step 500/1249 Loss 0.980 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.594, lat_loss 21.996
09/22 08:45:51 AM | Train: [138/180] Step 550/1249 Loss 0.980 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.594, lat_loss 21.996
09/22 08:46:17 AM | Train: [138/180] Step 600/1249 Loss 0.987 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.594, lat_loss 21.996
09/22 08:46:44 AM | Train: [138/180] Step 650/1249 Loss 0.983 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.594, lat_loss 21.996
09/22 08:47:07 AM | Train: [138/180] Step 700/1249 Loss 0.978 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.593, lat_loss 21.996
09/22 08:47:30 AM | Train: [138/180] Step 750/1249 Loss 0.970 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.593, lat_loss 21.996
09/22 08:47:51 AM | Train: [138/180] Step 800/1249 Loss 0.964 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.593, lat_loss 21.996
09/22 08:48:14 AM | Train: [138/180] Step 850/1249 Loss 0.970 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.593, lat_loss 21.996
09/22 08:48:37 AM | Train: [138/180] Step 900/1249 Loss 0.974 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.593, lat_loss 21.996
09/22 08:49:01 AM | Train: [138/180] Step 950/1249 Loss 0.972 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.593, lat_loss 21.996
09/22 08:49:25 AM | Train: [138/180] Step 1000/1249 Loss 0.976 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.593, lat_loss 21.996
09/22 08:49:48 AM | Train: [138/180] Step 1050/1249 Loss 0.978 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.593, lat_loss 21.996
09/22 08:50:13 AM | Train: [138/180] Step 1100/1249 Loss 0.986 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.593, lat_loss 21.996
09/22 08:50:39 AM | Train: [138/180] Step 1150/1249 Loss 0.986 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.593, lat_loss 21.996
09/22 08:51:05 AM | Train: [138/180] Step 1200/1249 Loss 0.989 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.593, lat_loss 21.996
09/22 08:51:29 AM | Train: [138/180] Step 1249/1249 Loss 0.995 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.593, lat_loss 21.996
09/22 08:51:29 AM | _w_step_train: [138/180] Final Prec@1 92.2625% Time 626.83
09/22 08:51:29 AM | Start to train theta for epoch 137
09/22 08:51:50 AM | Train: [138/180] Step 050/312 Loss 2.179 Prec@(1,3) (84.6%, 99.4%), ce_loss 0.593, lat_loss 21.996
09/22 08:52:10 AM | Train: [138/180] Step 100/312 Loss 2.065 Prec@(1,3) (85.4%, 99.4%), ce_loss 0.593, lat_loss 21.996
09/22 08:52:30 AM | Train: [138/180] Step 150/312 Loss 2.009 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.593, lat_loss 21.996
09/22 08:52:50 AM | Train: [138/180] Step 200/312 Loss 1.986 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.593, lat_loss 21.996
09/22 08:53:10 AM | Train: [138/180] Step 250/312 Loss 2.033 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.593, lat_loss 21.996
09/22 08:53:28 AM | Train: [138/180] Step 300/312 Loss 2.030 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.592, lat_loss 21.996
09/22 08:53:33 AM | Train: [138/180] Step 312/312 Loss 2.002 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.592, lat_loss 21.996
09/22 08:53:33 AM | _theta_step_train: [138/180] Final Prec@1 85.9800% Time 123.92
09/22 08:53:38 AM | Valid: [138/180] Step 050/312 Loss 1.864 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.592, lat_loss 21.996
09/22 08:53:43 AM | Valid: [138/180] Step 100/312 Loss 1.927 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.592, lat_loss 21.996
09/22 08:53:47 AM | Valid: [138/180] Step 150/312 Loss 2.005 Prec@(1,3) (85.1%, 99.2%), ce_loss 0.592, lat_loss 21.996
09/22 08:53:52 AM | Valid: [138/180] Step 200/312 Loss 1.983 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.592, lat_loss 21.996
09/22 08:53:57 AM | Valid: [138/180] Step 250/312 Loss 1.993 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.592, lat_loss 21.996
09/22 08:54:01 AM | Valid: [138/180] Step 300/312 Loss 1.993 Prec@(1,3) (85.2%, 99.3%), ce_loss 0.592, lat_loss 21.996
09/22 08:54:03 AM | Valid: [138/180] Step 312/312 Loss 1.981 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.592, lat_loss 21.996
09/22 08:54:03 AM | val: [138/180] Final Prec@1 85.2600% Time 30.03
09/22 08:54:03 AM | Start to train weights for epoch 138
09/22 08:54:26 AM | Train: [139/180] Step 050/1249 Loss 0.993 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.592, lat_loss 21.996
09/22 08:54:50 AM | Train: [139/180] Step 100/1249 Loss 0.955 Prec@(1,3) (92.5%, 99.8%), ce_loss 0.592, lat_loss 21.996
09/22 08:55:14 AM | Train: [139/180] Step 150/1249 Loss 0.940 Prec@(1,3) (92.7%, 99.7%), ce_loss 0.592, lat_loss 21.996
09/22 08:55:37 AM | Train: [139/180] Step 200/1249 Loss 0.930 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.592, lat_loss 21.996
09/22 08:56:00 AM | Train: [139/180] Step 250/1249 Loss 0.896 Prec@(1,3) (92.9%, 99.8%), ce_loss 0.592, lat_loss 21.996
09/22 08:56:24 AM | Train: [139/180] Step 300/1249 Loss 0.881 Prec@(1,3) (93.0%, 99.8%), ce_loss 0.592, lat_loss 21.996
09/22 08:56:49 AM | Train: [139/180] Step 350/1249 Loss 0.931 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.592, lat_loss 21.996
09/22 08:57:12 AM | Train: [139/180] Step 400/1249 Loss 0.959 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.592, lat_loss 21.996
09/22 08:57:36 AM | Train: [139/180] Step 450/1249 Loss 0.955 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.592, lat_loss 21.996
09/22 08:57:59 AM | Train: [139/180] Step 500/1249 Loss 0.964 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.592, lat_loss 21.996
09/22 08:58:23 AM | Train: [139/180] Step 550/1249 Loss 0.961 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.591, lat_loss 21.996
09/22 08:58:47 AM | Train: [139/180] Step 600/1249 Loss 0.964 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.591, lat_loss 21.996
09/22 08:59:11 AM | Train: [139/180] Step 650/1249 Loss 0.955 Prec@(1,3) (92.5%, 99.9%), ce_loss 0.591, lat_loss 21.996
09/22 08:59:35 AM | Train: [139/180] Step 700/1249 Loss 0.986 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.591, lat_loss 21.996
09/22 08:59:57 AM | Train: [139/180] Step 750/1249 Loss 0.984 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.591, lat_loss 21.996
09/22 09:00:15 AM | Train: [139/180] Step 800/1249 Loss 0.980 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.591, lat_loss 21.996
09/22 09:00:31 AM | Train: [139/180] Step 850/1249 Loss 0.994 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.591, lat_loss 21.996
09/22 09:00:47 AM | Train: [139/180] Step 900/1249 Loss 0.990 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.591, lat_loss 21.996
09/22 09:01:03 AM | Train: [139/180] Step 950/1249 Loss 0.987 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.591, lat_loss 21.996
09/22 09:01:19 AM | Train: [139/180] Step 1000/1249 Loss 1.007 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.591, lat_loss 21.996
09/22 09:01:35 AM | Train: [139/180] Step 1050/1249 Loss 1.000 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.591, lat_loss 21.996
09/22 09:01:55 AM | Train: [139/180] Step 1100/1249 Loss 0.996 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.591, lat_loss 21.996
09/22 09:02:20 AM | Train: [139/180] Step 1150/1249 Loss 0.996 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.591, lat_loss 21.996
09/22 09:02:44 AM | Train: [139/180] Step 1200/1249 Loss 0.994 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.591, lat_loss 21.996
09/22 09:03:08 AM | Train: [139/180] Step 1249/1249 Loss 0.995 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.591, lat_loss 21.996
09/22 09:03:08 AM | _w_step_train: [139/180] Final Prec@1 92.2000% Time 545.81
09/22 09:03:08 AM | Start to train theta for epoch 138
09/22 09:03:30 AM | Train: [139/180] Step 050/312 Loss 1.955 Prec@(1,3) (85.8%, 99.0%), ce_loss 0.590, lat_loss 21.996
09/22 09:03:50 AM | Train: [139/180] Step 100/312 Loss 1.941 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.590, lat_loss 21.996
09/22 09:04:11 AM | Train: [139/180] Step 150/312 Loss 1.915 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.590, lat_loss 21.996
09/22 09:04:32 AM | Train: [139/180] Step 200/312 Loss 1.891 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.590, lat_loss 21.996
09/22 09:04:52 AM | Train: [139/180] Step 250/312 Loss 1.952 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.590, lat_loss 21.996
09/22 09:05:12 AM | Train: [139/180] Step 300/312 Loss 2.015 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.590, lat_loss 21.996
09/22 09:05:16 AM | Train: [139/180] Step 312/312 Loss 2.030 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.590, lat_loss 21.996
09/22 09:05:16 AM | _theta_step_train: [139/180] Final Prec@1 85.7900% Time 127.91
09/22 09:05:22 AM | Valid: [139/180] Step 050/312 Loss 1.953 Prec@(1,3) (85.7%, 99.0%), ce_loss 0.590, lat_loss 21.996
09/22 09:05:27 AM | Valid: [139/180] Step 100/312 Loss 2.412 Prec@(1,3) (83.8%, 98.1%), ce_loss 0.590, lat_loss 21.996
09/22 09:05:32 AM | Valid: [139/180] Step 150/312 Loss 2.391 Prec@(1,3) (83.3%, 98.4%), ce_loss 0.590, lat_loss 21.996
09/22 09:05:36 AM | Valid: [139/180] Step 200/312 Loss 2.336 Prec@(1,3) (83.7%, 98.5%), ce_loss 0.590, lat_loss 21.996
09/22 09:05:41 AM | Valid: [139/180] Step 250/312 Loss 2.314 Prec@(1,3) (83.8%, 98.5%), ce_loss 0.590, lat_loss 21.996
09/22 09:05:46 AM | Valid: [139/180] Step 300/312 Loss 2.221 Prec@(1,3) (84.3%, 98.7%), ce_loss 0.590, lat_loss 21.996
09/22 09:05:47 AM | Valid: [139/180] Step 312/312 Loss 2.210 Prec@(1,3) (84.3%, 98.7%), ce_loss 0.590, lat_loss 21.996
09/22 09:05:47 AM | val: [139/180] Final Prec@1 84.2800% Time 30.43
09/22 09:05:47 AM | Start to train weights for epoch 139
09/22 09:06:11 AM | Train: [140/180] Step 050/1249 Loss 0.837 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.590, lat_loss 21.996
09/22 09:06:33 AM | Train: [140/180] Step 100/1249 Loss 0.813 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.590, lat_loss 21.996
09/22 09:06:54 AM | Train: [140/180] Step 150/1249 Loss 0.883 Prec@(1,3) (93.1%, 99.8%), ce_loss 0.590, lat_loss 21.996
09/22 09:07:15 AM | Train: [140/180] Step 200/1249 Loss 0.876 Prec@(1,3) (93.0%, 99.8%), ce_loss 0.590, lat_loss 21.996
09/22 09:07:40 AM | Train: [140/180] Step 250/1249 Loss 0.898 Prec@(1,3) (93.0%, 99.8%), ce_loss 0.590, lat_loss 21.996
09/22 09:08:04 AM | Train: [140/180] Step 300/1249 Loss 0.896 Prec@(1,3) (92.9%, 99.9%), ce_loss 0.590, lat_loss 21.996
09/22 09:08:29 AM | Train: [140/180] Step 350/1249 Loss 0.903 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.590, lat_loss 21.996
09/22 09:08:53 AM | Train: [140/180] Step 400/1249 Loss 0.890 Prec@(1,3) (93.0%, 99.8%), ce_loss 0.590, lat_loss 21.996
09/22 09:09:18 AM | Train: [140/180] Step 450/1249 Loss 0.885 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.590, lat_loss 21.996
09/22 09:09:41 AM | Train: [140/180] Step 500/1249 Loss 0.930 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.589, lat_loss 21.996
09/22 09:10:06 AM | Train: [140/180] Step 550/1249 Loss 0.938 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.589, lat_loss 21.996
09/22 09:10:30 AM | Train: [140/180] Step 600/1249 Loss 0.967 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.589, lat_loss 21.996
09/22 09:10:55 AM | Train: [140/180] Step 650/1249 Loss 0.981 Prec@(1,3) (92.5%, 99.8%), ce_loss 0.589, lat_loss 21.996
09/22 09:11:18 AM | Train: [140/180] Step 700/1249 Loss 0.972 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.589, lat_loss 21.996
09/22 09:11:42 AM | Train: [140/180] Step 750/1249 Loss 0.967 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.589, lat_loss 21.996
09/22 09:12:06 AM | Train: [140/180] Step 800/1249 Loss 0.951 Prec@(1,3) (92.7%, 99.8%), ce_loss 0.589, lat_loss 21.996
09/22 09:12:30 AM | Train: [140/180] Step 850/1249 Loss 0.946 Prec@(1,3) (92.7%, 99.8%), ce_loss 0.589, lat_loss 21.996
09/22 09:12:54 AM | Train: [140/180] Step 900/1249 Loss 0.944 Prec@(1,3) (92.7%, 99.8%), ce_loss 0.589, lat_loss 21.996
09/22 09:13:19 AM | Train: [140/180] Step 950/1249 Loss 0.944 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.589, lat_loss 21.996
09/22 09:13:43 AM | Train: [140/180] Step 1000/1249 Loss 0.957 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.589, lat_loss 21.996
09/22 09:14:08 AM | Train: [140/180] Step 1050/1249 Loss 0.950 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.589, lat_loss 21.996
09/22 09:14:29 AM | Train: [140/180] Step 1100/1249 Loss 0.952 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.589, lat_loss 21.996
09/22 09:14:53 AM | Train: [140/180] Step 1150/1249 Loss 0.947 Prec@(1,3) (92.7%, 99.8%), ce_loss 0.589, lat_loss 21.996
09/22 09:15:17 AM | Train: [140/180] Step 1200/1249 Loss 0.945 Prec@(1,3) (92.7%, 99.8%), ce_loss 0.588, lat_loss 21.996
09/22 09:15:41 AM | Train: [140/180] Step 1249/1249 Loss 0.943 Prec@(1,3) (92.7%, 99.8%), ce_loss 0.588, lat_loss 21.996
09/22 09:15:42 AM | _w_step_train: [140/180] Final Prec@1 92.6500% Time 594.69
09/22 09:15:42 AM | Start to train theta for epoch 139
09/22 09:16:03 AM | Train: [140/180] Step 050/312 Loss 1.806 Prec@(1,3) (88.0%, 99.1%), ce_loss 0.588, lat_loss 21.996
09/22 09:16:24 AM | Train: [140/180] Step 100/312 Loss 1.963 Prec@(1,3) (86.9%, 99.0%), ce_loss 0.588, lat_loss 21.996
09/22 09:16:45 AM | Train: [140/180] Step 150/312 Loss 2.057 Prec@(1,3) (86.1%, 99.0%), ce_loss 0.588, lat_loss 21.996
09/22 09:17:05 AM | Train: [140/180] Step 200/312 Loss 2.012 Prec@(1,3) (86.4%, 99.1%), ce_loss 0.588, lat_loss 21.996
09/22 09:17:27 AM | Train: [140/180] Step 250/312 Loss 2.021 Prec@(1,3) (86.2%, 99.1%), ce_loss 0.588, lat_loss 21.996
09/22 09:17:47 AM | Train: [140/180] Step 300/312 Loss 2.005 Prec@(1,3) (86.2%, 99.1%), ce_loss 0.588, lat_loss 21.996
09/22 09:17:52 AM | Train: [140/180] Step 312/312 Loss 2.054 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.588, lat_loss 21.996
09/22 09:17:52 AM | _theta_step_train: [140/180] Final Prec@1 85.9700% Time 130.62
09/22 09:17:57 AM | Valid: [140/180] Step 050/312 Loss 1.921 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.588, lat_loss 21.996
09/22 09:18:02 AM | Valid: [140/180] Step 100/312 Loss 1.975 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.588, lat_loss 21.996
09/22 09:18:07 AM | Valid: [140/180] Step 150/312 Loss 2.122 Prec@(1,3) (85.2%, 98.8%), ce_loss 0.588, lat_loss 21.996
09/22 09:18:11 AM | Valid: [140/180] Step 200/312 Loss 2.133 Prec@(1,3) (85.2%, 98.9%), ce_loss 0.588, lat_loss 21.996
09/22 09:18:16 AM | Valid: [140/180] Step 250/312 Loss 2.113 Prec@(1,3) (85.1%, 99.0%), ce_loss 0.588, lat_loss 21.996
09/22 09:18:20 AM | Valid: [140/180] Step 300/312 Loss 2.064 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.588, lat_loss 21.996
09/22 09:18:22 AM | Valid: [140/180] Step 312/312 Loss 2.052 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.588, lat_loss 21.996
09/22 09:18:22 AM | val: [140/180] Final Prec@1 85.3700% Time 29.43
09/22 09:18:22 AM | Start to train weights for epoch 140
09/22 09:18:48 AM | Train: [141/180] Step 050/1249 Loss 0.909 Prec@(1,3) (92.8%, 99.9%), ce_loss 0.588, lat_loss 21.996
09/22 09:19:15 AM | Train: [141/180] Step 100/1249 Loss 1.110 Prec@(1,3) (91.7%, 99.5%), ce_loss 0.588, lat_loss 21.996
09/22 09:19:42 AM | Train: [141/180] Step 150/1249 Loss 1.009 Prec@(1,3) (92.3%, 99.6%), ce_loss 0.588, lat_loss 21.996
09/22 09:20:08 AM | Train: [141/180] Step 200/1249 Loss 0.983 Prec@(1,3) (92.4%, 99.7%), ce_loss 0.588, lat_loss 21.996
09/22 09:20:35 AM | Train: [141/180] Step 250/1249 Loss 0.992 Prec@(1,3) (92.3%, 99.7%), ce_loss 0.588, lat_loss 21.996
09/22 09:21:01 AM | Train: [141/180] Step 300/1249 Loss 0.981 Prec@(1,3) (92.5%, 99.8%), ce_loss 0.588, lat_loss 21.996
09/22 09:21:27 AM | Train: [141/180] Step 350/1249 Loss 0.967 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.588, lat_loss 21.996
09/22 09:21:51 AM | Train: [141/180] Step 400/1249 Loss 0.973 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.588, lat_loss 21.996
09/22 09:22:09 AM | Train: [141/180] Step 450/1249 Loss 0.967 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.587, lat_loss 21.996
09/22 09:22:26 AM | Train: [141/180] Step 500/1249 Loss 0.951 Prec@(1,3) (92.7%, 99.8%), ce_loss 0.587, lat_loss 21.996
09/22 09:22:42 AM | Train: [141/180] Step 550/1249 Loss 0.943 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.587, lat_loss 21.996
09/22 09:22:58 AM | Train: [141/180] Step 600/1249 Loss 0.938 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.587, lat_loss 21.996
09/22 09:23:14 AM | Train: [141/180] Step 650/1249 Loss 0.943 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.587, lat_loss 21.996
09/22 09:23:30 AM | Train: [141/180] Step 700/1249 Loss 0.935 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.587, lat_loss 21.996
09/22 09:23:46 AM | Train: [141/180] Step 750/1249 Loss 0.940 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.587, lat_loss 21.996
09/22 09:24:02 AM | Train: [141/180] Step 800/1249 Loss 0.930 Prec@(1,3) (92.9%, 99.8%), ce_loss 0.587, lat_loss 21.996
09/22 09:24:18 AM | Train: [141/180] Step 850/1249 Loss 0.934 Prec@(1,3) (92.9%, 99.8%), ce_loss 0.587, lat_loss 21.996
09/22 09:24:34 AM | Train: [141/180] Step 900/1249 Loss 0.943 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.587, lat_loss 21.996
09/22 09:24:50 AM | Train: [141/180] Step 950/1249 Loss 0.946 Prec@(1,3) (92.7%, 99.8%), ce_loss 0.587, lat_loss 21.996
09/22 09:25:06 AM | Train: [141/180] Step 1000/1249 Loss 0.947 Prec@(1,3) (92.7%, 99.8%), ce_loss 0.587, lat_loss 21.996
09/22 09:25:22 AM | Train: [141/180] Step 1050/1249 Loss 0.955 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.587, lat_loss 21.996
09/22 09:25:38 AM | Train: [141/180] Step 1100/1249 Loss 0.956 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.587, lat_loss 21.996
09/22 09:25:54 AM | Train: [141/180] Step 1150/1249 Loss 0.955 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.586, lat_loss 21.996
09/22 09:26:10 AM | Train: [141/180] Step 1200/1249 Loss 0.950 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.586, lat_loss 21.996
09/22 09:26:26 AM | Train: [141/180] Step 1249/1249 Loss 0.947 Prec@(1,3) (92.7%, 99.8%), ce_loss 0.586, lat_loss 21.996
09/22 09:26:26 AM | _w_step_train: [141/180] Final Prec@1 92.6975% Time 484.17
09/22 09:26:26 AM | Start to train theta for epoch 140
09/22 09:26:46 AM | Train: [141/180] Step 050/312 Loss 1.996 Prec@(1,3) (87.3%, 99.1%), ce_loss 0.586, lat_loss 21.996
09/22 09:27:06 AM | Train: [141/180] Step 100/312 Loss 2.023 Prec@(1,3) (86.7%, 99.2%), ce_loss 0.586, lat_loss 21.996
09/22 09:27:27 AM | Train: [141/180] Step 150/312 Loss 2.014 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.586, lat_loss 21.996
09/22 09:27:48 AM | Train: [141/180] Step 200/312 Loss 2.017 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.586, lat_loss 21.996
09/22 09:28:08 AM | Train: [141/180] Step 250/312 Loss 2.035 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.586, lat_loss 21.996
09/22 09:28:28 AM | Train: [141/180] Step 300/312 Loss 2.016 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.586, lat_loss 21.996
09/22 09:28:33 AM | Train: [141/180] Step 312/312 Loss 2.025 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.586, lat_loss 21.996
09/22 09:28:34 AM | _theta_step_train: [141/180] Final Prec@1 85.8100% Time 127.96
09/22 09:28:39 AM | Valid: [141/180] Step 050/312 Loss 2.153 Prec@(1,3) (85.2%, 98.4%), ce_loss 0.586, lat_loss 21.996
09/22 09:28:44 AM | Valid: [141/180] Step 100/312 Loss 2.147 Prec@(1,3) (84.5%, 98.7%), ce_loss 0.586, lat_loss 21.996
09/22 09:28:48 AM | Valid: [141/180] Step 150/312 Loss 2.371 Prec@(1,3) (83.7%, 98.4%), ce_loss 0.586, lat_loss 21.996
09/22 09:28:53 AM | Valid: [141/180] Step 200/312 Loss 2.272 Prec@(1,3) (84.5%, 98.6%), ce_loss 0.586, lat_loss 21.996
09/22 09:28:58 AM | Valid: [141/180] Step 250/312 Loss 2.218 Prec@(1,3) (84.7%, 98.7%), ce_loss 0.586, lat_loss 21.996
09/22 09:29:02 AM | Valid: [141/180] Step 300/312 Loss 2.193 Prec@(1,3) (84.8%, 98.8%), ce_loss 0.586, lat_loss 21.996
09/22 09:29:04 AM | Valid: [141/180] Step 312/312 Loss 2.176 Prec@(1,3) (84.9%, 98.8%), ce_loss 0.586, lat_loss 21.996
09/22 09:29:04 AM | val: [141/180] Final Prec@1 84.9200% Time 30.26
09/22 09:29:04 AM | Start to train weights for epoch 141
09/22 09:29:28 AM | Train: [142/180] Step 050/1249 Loss 0.881 Prec@(1,3) (92.9%, 99.9%), ce_loss 0.586, lat_loss 21.996
09/22 09:29:51 AM | Train: [142/180] Step 100/1249 Loss 0.867 Prec@(1,3) (92.7%, 99.9%), ce_loss 0.586, lat_loss 21.996
09/22 09:30:13 AM | Train: [142/180] Step 150/1249 Loss 0.883 Prec@(1,3) (92.8%, 99.9%), ce_loss 0.586, lat_loss 21.996
09/22 09:30:33 AM | Train: [142/180] Step 200/1249 Loss 0.926 Prec@(1,3) (92.6%, 99.9%), ce_loss 0.586, lat_loss 21.996
09/22 09:30:56 AM | Train: [142/180] Step 250/1249 Loss 0.888 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.586, lat_loss 21.996
09/22 09:31:18 AM | Train: [142/180] Step 300/1249 Loss 0.869 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.586, lat_loss 21.996
09/22 09:31:41 AM | Train: [142/180] Step 350/1249 Loss 0.876 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.586, lat_loss 21.996
09/22 09:32:04 AM | Train: [142/180] Step 400/1249 Loss 0.872 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.585, lat_loss 21.996
09/22 09:32:26 AM | Train: [142/180] Step 450/1249 Loss 0.865 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.585, lat_loss 21.996
09/22 09:32:48 AM | Train: [142/180] Step 500/1249 Loss 0.865 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.585, lat_loss 21.996
09/22 09:33:09 AM | Train: [142/180] Step 550/1249 Loss 0.884 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.585, lat_loss 21.996
09/22 09:33:31 AM | Train: [142/180] Step 600/1249 Loss 0.890 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.585, lat_loss 21.996
09/22 09:33:53 AM | Train: [142/180] Step 650/1249 Loss 0.894 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.585, lat_loss 21.996
09/22 09:34:15 AM | Train: [142/180] Step 700/1249 Loss 0.923 Prec@(1,3) (92.9%, 99.8%), ce_loss 0.585, lat_loss 21.996
09/22 09:34:37 AM | Train: [142/180] Step 750/1249 Loss 0.918 Prec@(1,3) (92.9%, 99.8%), ce_loss 0.585, lat_loss 21.996
09/22 09:34:59 AM | Train: [142/180] Step 800/1249 Loss 0.921 Prec@(1,3) (92.9%, 99.8%), ce_loss 0.585, lat_loss 21.996
09/22 09:35:21 AM | Train: [142/180] Step 850/1249 Loss 0.924 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.585, lat_loss 21.996
09/22 09:35:43 AM | Train: [142/180] Step 900/1249 Loss 0.921 Prec@(1,3) (92.9%, 99.8%), ce_loss 0.585, lat_loss 21.996
09/22 09:36:07 AM | Train: [142/180] Step 950/1249 Loss 0.919 Prec@(1,3) (92.9%, 99.8%), ce_loss 0.585, lat_loss 21.996
09/22 09:36:28 AM | Train: [142/180] Step 1000/1249 Loss 0.919 Prec@(1,3) (92.9%, 99.8%), ce_loss 0.585, lat_loss 21.996
09/22 09:36:48 AM | Train: [142/180] Step 1050/1249 Loss 0.922 Prec@(1,3) (92.9%, 99.8%), ce_loss 0.584, lat_loss 21.996
09/22 09:37:07 AM | Train: [142/180] Step 1100/1249 Loss 0.919 Prec@(1,3) (92.9%, 99.8%), ce_loss 0.584, lat_loss 21.996
09/22 09:37:27 AM | Train: [142/180] Step 1150/1249 Loss 0.929 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.584, lat_loss 21.996
09/22 09:37:47 AM | Train: [142/180] Step 1200/1249 Loss 0.935 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.584, lat_loss 21.996
09/22 09:38:10 AM | Train: [142/180] Step 1249/1249 Loss 0.932 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.584, lat_loss 21.996
09/22 09:38:10 AM | _w_step_train: [142/180] Final Prec@1 92.8200% Time 545.99
09/22 09:38:10 AM | Start to train theta for epoch 141
09/22 09:38:23 AM | Train: [142/180] Step 050/312 Loss 1.871 Prec@(1,3) (86.4%, 99.1%), ce_loss 0.584, lat_loss 21.996
09/22 09:38:39 AM | Train: [142/180] Step 100/312 Loss 1.886 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.584, lat_loss 21.996
09/22 09:39:00 AM | Train: [142/180] Step 150/312 Loss 1.879 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.584, lat_loss 21.996
09/22 09:39:21 AM | Train: [142/180] Step 200/312 Loss 2.003 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.584, lat_loss 21.996
09/22 09:39:42 AM | Train: [142/180] Step 250/312 Loss 1.971 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.584, lat_loss 21.996
09/22 09:40:02 AM | Train: [142/180] Step 300/312 Loss 1.972 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.584, lat_loss 21.996
09/22 09:40:07 AM | Train: [142/180] Step 312/312 Loss 1.976 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.584, lat_loss 21.996
09/22 09:40:08 AM | _theta_step_train: [142/180] Final Prec@1 85.9700% Time 117.85
09/22 09:40:13 AM | Valid: [142/180] Step 050/312 Loss 1.803 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.584, lat_loss 21.996
09/22 09:40:18 AM | Valid: [142/180] Step 100/312 Loss 1.902 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.584, lat_loss 21.996
09/22 09:40:23 AM | Valid: [142/180] Step 150/312 Loss 1.972 Prec@(1,3) (85.8%, 99.1%), ce_loss 0.584, lat_loss 21.996
09/22 09:40:27 AM | Valid: [142/180] Step 200/312 Loss 1.923 Prec@(1,3) (86.3%, 99.2%), ce_loss 0.584, lat_loss 21.996
09/22 09:40:32 AM | Valid: [142/180] Step 250/312 Loss 1.912 Prec@(1,3) (86.3%, 99.2%), ce_loss 0.584, lat_loss 21.996
09/22 09:40:37 AM | Valid: [142/180] Step 300/312 Loss 1.911 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.584, lat_loss 21.996
09/22 09:40:38 AM | Valid: [142/180] Step 312/312 Loss 1.908 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.584, lat_loss 21.996
09/22 09:40:38 AM | val: [142/180] Final Prec@1 86.1500% Time 30.22
09/22 09:40:38 AM | Best top1 acc by now. Save model
09/22 09:40:38 AM | Start to train weights for epoch 142
09/22 09:41:04 AM | Train: [143/180] Step 050/1249 Loss 0.832 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.584, lat_loss 21.996
09/22 09:41:26 AM | Train: [143/180] Step 100/1249 Loss 0.833 Prec@(1,3) (93.3%, 99.9%), ce_loss 0.584, lat_loss 21.996
09/22 09:41:50 AM | Train: [143/180] Step 150/1249 Loss 0.822 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.584, lat_loss 21.996
09/22 09:42:14 AM | Train: [143/180] Step 200/1249 Loss 0.840 Prec@(1,3) (93.3%, 99.9%), ce_loss 0.584, lat_loss 21.996
09/22 09:42:38 AM | Train: [143/180] Step 250/1249 Loss 0.830 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.583, lat_loss 21.997
09/22 09:43:01 AM | Train: [143/180] Step 300/1249 Loss 0.846 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.583, lat_loss 21.997
09/22 09:43:24 AM | Train: [143/180] Step 350/1249 Loss 0.843 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.583, lat_loss 21.997
09/22 09:43:47 AM | Train: [143/180] Step 400/1249 Loss 0.861 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.583, lat_loss 21.997
09/22 09:44:11 AM | Train: [143/180] Step 450/1249 Loss 0.870 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.583, lat_loss 21.997
09/22 09:44:35 AM | Train: [143/180] Step 500/1249 Loss 0.866 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.583, lat_loss 21.997
09/22 09:44:58 AM | Train: [143/180] Step 550/1249 Loss 0.865 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.583, lat_loss 21.997
09/22 09:45:22 AM | Train: [143/180] Step 600/1249 Loss 0.860 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.583, lat_loss 21.997
09/22 09:45:44 AM | Train: [143/180] Step 650/1249 Loss 0.867 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.583, lat_loss 21.997
09/22 09:46:08 AM | Train: [143/180] Step 700/1249 Loss 0.867 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.583, lat_loss 21.997
09/22 09:46:32 AM | Train: [143/180] Step 750/1249 Loss 0.863 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.583, lat_loss 21.997
09/22 09:46:55 AM | Train: [143/180] Step 800/1249 Loss 0.856 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.583, lat_loss 21.997
09/22 09:47:18 AM | Train: [143/180] Step 850/1249 Loss 0.858 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.583, lat_loss 21.997
09/22 09:47:42 AM | Train: [143/180] Step 900/1249 Loss 0.861 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.583, lat_loss 21.997
09/22 09:48:06 AM | Train: [143/180] Step 950/1249 Loss 0.866 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.582, lat_loss 21.997
09/22 09:48:31 AM | Train: [143/180] Step 1000/1249 Loss 0.873 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.582, lat_loss 21.997
09/22 09:48:54 AM | Train: [143/180] Step 1050/1249 Loss 0.874 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.582, lat_loss 21.997
09/22 09:49:17 AM | Train: [143/180] Step 1100/1249 Loss 0.877 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.582, lat_loss 21.997
09/22 09:49:41 AM | Train: [143/180] Step 1150/1249 Loss 0.876 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.582, lat_loss 21.997
09/22 09:50:05 AM | Train: [143/180] Step 1200/1249 Loss 0.880 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.582, lat_loss 21.997
09/22 09:50:30 AM | Train: [143/180] Step 1249/1249 Loss 0.875 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.582, lat_loss 21.997
09/22 09:50:30 AM | _w_step_train: [143/180] Final Prec@1 93.1425% Time 591.27
09/22 09:50:30 AM | Start to train theta for epoch 142
09/22 09:50:51 AM | Train: [143/180] Step 050/312 Loss 1.844 Prec@(1,3) (87.6%, 99.4%), ce_loss 0.582, lat_loss 21.997
09/22 09:51:12 AM | Train: [143/180] Step 100/312 Loss 1.904 Prec@(1,3) (87.6%, 99.3%), ce_loss 0.582, lat_loss 21.997
09/22 09:51:33 AM | Train: [143/180] Step 150/312 Loss 1.972 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.582, lat_loss 21.997
09/22 09:51:53 AM | Train: [143/180] Step 200/312 Loss 1.949 Prec@(1,3) (86.9%, 99.3%), ce_loss 0.582, lat_loss 21.997
09/22 09:52:14 AM | Train: [143/180] Step 250/312 Loss 1.974 Prec@(1,3) (86.7%, 99.3%), ce_loss 0.582, lat_loss 21.997
09/22 09:52:35 AM | Train: [143/180] Step 300/312 Loss 1.973 Prec@(1,3) (86.7%, 99.3%), ce_loss 0.582, lat_loss 21.997
09/22 09:52:40 AM | Train: [143/180] Step 312/312 Loss 1.974 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.582, lat_loss 21.997
09/22 09:52:41 AM | _theta_step_train: [143/180] Final Prec@1 86.6400% Time 130.99
09/22 09:52:46 AM | Valid: [143/180] Step 050/312 Loss 1.830 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.582, lat_loss 21.997
09/22 09:52:51 AM | Valid: [143/180] Step 100/312 Loss 2.182 Prec@(1,3) (85.0%, 98.8%), ce_loss 0.582, lat_loss 21.997
09/22 09:52:55 AM | Valid: [143/180] Step 150/312 Loss 2.274 Prec@(1,3) (84.3%, 98.7%), ce_loss 0.582, lat_loss 21.997
09/22 09:53:00 AM | Valid: [143/180] Step 200/312 Loss 2.246 Prec@(1,3) (84.6%, 98.8%), ce_loss 0.582, lat_loss 21.997
09/22 09:53:05 AM | Valid: [143/180] Step 250/312 Loss 2.397 Prec@(1,3) (83.6%, 98.6%), ce_loss 0.582, lat_loss 21.997
09/22 09:53:09 AM | Valid: [143/180] Step 300/312 Loss 2.321 Prec@(1,3) (83.9%, 98.7%), ce_loss 0.582, lat_loss 21.997
09/22 09:53:10 AM | Valid: [143/180] Step 312/312 Loss 2.303 Prec@(1,3) (84.0%, 98.8%), ce_loss 0.582, lat_loss 21.997
09/22 09:53:10 AM | val: [143/180] Final Prec@1 84.0000% Time 29.83
09/22 09:53:10 AM | Start to train weights for epoch 143
09/22 09:53:36 AM | Train: [144/180] Step 050/1249 Loss 0.784 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.582, lat_loss 21.997
09/22 09:54:01 AM | Train: [144/180] Step 100/1249 Loss 0.920 Prec@(1,3) (92.7%, 99.8%), ce_loss 0.582, lat_loss 21.997
09/22 09:54:26 AM | Train: [144/180] Step 150/1249 Loss 0.935 Prec@(1,3) (92.5%, 99.9%), ce_loss 0.582, lat_loss 21.997
09/22 09:54:51 AM | Train: [144/180] Step 200/1249 Loss 0.905 Prec@(1,3) (92.9%, 99.8%), ce_loss 0.582, lat_loss 21.997
09/22 09:55:16 AM | Train: [144/180] Step 250/1249 Loss 0.901 Prec@(1,3) (92.9%, 99.9%), ce_loss 0.581, lat_loss 21.997
09/22 09:55:41 AM | Train: [144/180] Step 300/1249 Loss 0.916 Prec@(1,3) (92.7%, 99.9%), ce_loss 0.581, lat_loss 21.997
09/22 09:56:05 AM | Train: [144/180] Step 350/1249 Loss 0.913 Prec@(1,3) (92.8%, 99.9%), ce_loss 0.581, lat_loss 21.997
09/22 09:56:29 AM | Train: [144/180] Step 400/1249 Loss 0.898 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.581, lat_loss 21.997
09/22 09:56:53 AM | Train: [144/180] Step 450/1249 Loss 0.886 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.581, lat_loss 21.997
09/22 09:57:18 AM | Train: [144/180] Step 500/1249 Loss 0.889 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.581, lat_loss 21.997
09/22 09:57:43 AM | Train: [144/180] Step 550/1249 Loss 0.900 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.581, lat_loss 21.997
09/22 09:58:08 AM | Train: [144/180] Step 600/1249 Loss 0.894 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.581, lat_loss 21.997
09/22 09:58:33 AM | Train: [144/180] Step 650/1249 Loss 0.888 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.581, lat_loss 21.997
09/22 09:58:58 AM | Train: [144/180] Step 700/1249 Loss 0.885 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.581, lat_loss 21.997
09/22 09:59:24 AM | Train: [144/180] Step 750/1249 Loss 0.894 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.581, lat_loss 21.997
09/22 09:59:48 AM | Train: [144/180] Step 800/1249 Loss 0.910 Prec@(1,3) (92.9%, 99.9%), ce_loss 0.581, lat_loss 21.997
09/22 10:00:11 AM | Train: [144/180] Step 850/1249 Loss 0.903 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.581, lat_loss 21.997
09/22 10:00:33 AM | Train: [144/180] Step 900/1249 Loss 0.902 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.581, lat_loss 21.997
09/22 10:00:58 AM | Train: [144/180] Step 950/1249 Loss 0.909 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.580, lat_loss 21.997
09/22 10:01:21 AM | Train: [144/180] Step 1000/1249 Loss 0.902 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.580, lat_loss 21.997
09/22 10:01:44 AM | Train: [144/180] Step 1050/1249 Loss 0.901 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.580, lat_loss 21.997
09/22 10:02:08 AM | Train: [144/180] Step 1100/1249 Loss 0.896 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.580, lat_loss 21.997
09/22 10:02:32 AM | Train: [144/180] Step 1150/1249 Loss 0.898 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.580, lat_loss 21.997
09/22 10:02:56 AM | Train: [144/180] Step 1200/1249 Loss 0.895 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.580, lat_loss 21.997
09/22 10:03:21 AM | Train: [144/180] Step 1249/1249 Loss 0.892 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.580, lat_loss 21.997
09/22 10:03:21 AM | _w_step_train: [144/180] Final Prec@1 93.0125% Time 610.38
09/22 10:03:21 AM | Start to train theta for epoch 143
09/22 10:03:42 AM | Train: [144/180] Step 050/312 Loss 1.843 Prec@(1,3) (87.4%, 99.4%), ce_loss 0.580, lat_loss 21.997
09/22 10:04:01 AM | Train: [144/180] Step 100/312 Loss 1.919 Prec@(1,3) (87.0%, 99.3%), ce_loss 0.580, lat_loss 21.997
09/22 10:04:19 AM | Train: [144/180] Step 150/312 Loss 1.995 Prec@(1,3) (86.7%, 99.2%), ce_loss 0.580, lat_loss 21.997
09/22 10:04:39 AM | Train: [144/180] Step 200/312 Loss 1.974 Prec@(1,3) (86.5%, 99.2%), ce_loss 0.580, lat_loss 21.997
09/22 10:05:00 AM | Train: [144/180] Step 250/312 Loss 2.066 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.580, lat_loss 21.997
09/22 10:05:20 AM | Train: [144/180] Step 300/312 Loss 2.095 Prec@(1,3) (85.8%, 99.0%), ce_loss 0.580, lat_loss 21.997
09/22 10:05:25 AM | Train: [144/180] Step 312/312 Loss 2.088 Prec@(1,3) (85.9%, 99.0%), ce_loss 0.580, lat_loss 21.997
09/22 10:05:25 AM | _theta_step_train: [144/180] Final Prec@1 85.9000% Time 124.52
09/22 10:05:31 AM | Valid: [144/180] Step 050/312 Loss 2.119 Prec@(1,3) (84.3%, 99.1%), ce_loss 0.580, lat_loss 21.997
09/22 10:05:36 AM | Valid: [144/180] Step 100/312 Loss 2.399 Prec@(1,3) (83.4%, 98.7%), ce_loss 0.580, lat_loss 21.997
09/22 10:05:40 AM | Valid: [144/180] Step 150/312 Loss 2.340 Prec@(1,3) (83.8%, 98.7%), ce_loss 0.580, lat_loss 21.997
09/22 10:05:45 AM | Valid: [144/180] Step 200/312 Loss 2.311 Prec@(1,3) (83.9%, 98.8%), ce_loss 0.580, lat_loss 21.997
09/22 10:05:50 AM | Valid: [144/180] Step 250/312 Loss 2.285 Prec@(1,3) (83.8%, 98.9%), ce_loss 0.580, lat_loss 21.997
09/22 10:05:54 AM | Valid: [144/180] Step 300/312 Loss 2.232 Prec@(1,3) (84.0%, 99.0%), ce_loss 0.580, lat_loss 21.997
09/22 10:05:55 AM | Valid: [144/180] Step 312/312 Loss 2.226 Prec@(1,3) (84.1%, 99.0%), ce_loss 0.580, lat_loss 21.997
09/22 10:05:55 AM | val: [144/180] Final Prec@1 84.1200% Time 30.06
09/22 10:05:55 AM | Start to train weights for epoch 144
09/22 10:06:17 AM | Train: [145/180] Step 050/1249 Loss 0.759 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.580, lat_loss 21.997
09/22 10:06:37 AM | Train: [145/180] Step 100/1249 Loss 0.785 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.580, lat_loss 21.997
09/22 10:06:59 AM | Train: [145/180] Step 150/1249 Loss 0.776 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.580, lat_loss 21.997
09/22 10:07:21 AM | Train: [145/180] Step 200/1249 Loss 0.783 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.579, lat_loss 21.997
09/22 10:07:45 AM | Train: [145/180] Step 250/1249 Loss 0.834 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.579, lat_loss 21.997
09/22 10:08:08 AM | Train: [145/180] Step 300/1249 Loss 0.847 Prec@(1,3) (93.3%, 99.9%), ce_loss 0.579, lat_loss 21.997
09/22 10:08:30 AM | Train: [145/180] Step 350/1249 Loss 0.834 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.579, lat_loss 21.997
09/22 10:08:54 AM | Train: [145/180] Step 400/1249 Loss 0.883 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.579, lat_loss 21.997
09/22 10:09:19 AM | Train: [145/180] Step 450/1249 Loss 0.881 Prec@(1,3) (93.1%, 99.8%), ce_loss 0.579, lat_loss 21.997
09/22 10:09:42 AM | Train: [145/180] Step 500/1249 Loss 0.870 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.579, lat_loss 21.997
09/22 10:10:07 AM | Train: [145/180] Step 550/1249 Loss 0.875 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.579, lat_loss 21.997
09/22 10:10:31 AM | Train: [145/180] Step 600/1249 Loss 0.868 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.579, lat_loss 21.997
09/22 10:10:55 AM | Train: [145/180] Step 650/1249 Loss 0.864 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.579, lat_loss 21.997
09/22 10:11:18 AM | Train: [145/180] Step 700/1249 Loss 0.864 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.579, lat_loss 21.997
09/22 10:11:40 AM | Train: [145/180] Step 750/1249 Loss 0.868 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.579, lat_loss 21.997
09/22 10:12:06 AM | Train: [145/180] Step 800/1249 Loss 0.866 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.579, lat_loss 21.997
09/22 10:12:31 AM | Train: [145/180] Step 850/1249 Loss 0.871 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.579, lat_loss 21.997
09/22 10:12:56 AM | Train: [145/180] Step 900/1249 Loss 0.874 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.578, lat_loss 21.997
09/22 10:13:21 AM | Train: [145/180] Step 950/1249 Loss 0.867 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.578, lat_loss 21.997
09/22 10:13:47 AM | Train: [145/180] Step 1000/1249 Loss 0.875 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.578, lat_loss 21.997
09/22 10:14:12 AM | Train: [145/180] Step 1050/1249 Loss 0.878 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.578, lat_loss 21.997
09/22 10:14:37 AM | Train: [145/180] Step 1100/1249 Loss 0.878 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.578, lat_loss 21.997
09/22 10:15:02 AM | Train: [145/180] Step 1150/1249 Loss 0.880 Prec@(1,3) (93.1%, 99.9%), ce_loss 0.578, lat_loss 21.997
09/22 10:15:27 AM | Train: [145/180] Step 1200/1249 Loss 0.893 Prec@(1,3) (93.0%, 99.8%), ce_loss 0.578, lat_loss 21.997
09/22 10:15:51 AM | Train: [145/180] Step 1249/1249 Loss 0.888 Prec@(1,3) (93.1%, 99.8%), ce_loss 0.578, lat_loss 21.997
09/22 10:15:52 AM | _w_step_train: [145/180] Final Prec@1 93.0575% Time 596.13
09/22 10:15:52 AM | Start to train theta for epoch 144
09/22 10:16:13 AM | Train: [145/180] Step 050/312 Loss 2.176 Prec@(1,3) (86.0%, 98.9%), ce_loss 0.578, lat_loss 21.997
09/22 10:16:34 AM | Train: [145/180] Step 100/312 Loss 2.345 Prec@(1,3) (85.2%, 98.6%), ce_loss 0.578, lat_loss 21.997
09/22 10:16:53 AM | Train: [145/180] Step 150/312 Loss 2.196 Prec@(1,3) (85.8%, 98.8%), ce_loss 0.578, lat_loss 21.997
09/22 10:17:12 AM | Train: [145/180] Step 200/312 Loss 2.144 Prec@(1,3) (85.9%, 99.0%), ce_loss 0.578, lat_loss 21.997
09/22 10:17:31 AM | Train: [145/180] Step 250/312 Loss 2.116 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.578, lat_loss 21.997
09/22 10:17:50 AM | Train: [145/180] Step 300/312 Loss 2.111 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.578, lat_loss 21.997
09/22 10:17:55 AM | Train: [145/180] Step 312/312 Loss 2.094 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.578, lat_loss 21.997
09/22 10:17:55 AM | _theta_step_train: [145/180] Final Prec@1 86.0900% Time 123.25
09/22 10:18:00 AM | Valid: [145/180] Step 050/312 Loss 2.265 Prec@(1,3) (82.9%, 99.1%), ce_loss 0.578, lat_loss 21.997
09/22 10:18:05 AM | Valid: [145/180] Step 100/312 Loss 2.207 Prec@(1,3) (83.8%, 99.3%), ce_loss 0.578, lat_loss 21.997
09/22 10:18:09 AM | Valid: [145/180] Step 150/312 Loss 2.494 Prec@(1,3) (82.6%, 98.5%), ce_loss 0.578, lat_loss 21.997
09/22 10:18:14 AM | Valid: [145/180] Step 200/312 Loss 2.327 Prec@(1,3) (83.8%, 98.7%), ce_loss 0.578, lat_loss 21.997
09/22 10:18:19 AM | Valid: [145/180] Step 250/312 Loss 2.245 Prec@(1,3) (84.3%, 98.9%), ce_loss 0.578, lat_loss 21.997
09/22 10:18:23 AM | Valid: [145/180] Step 300/312 Loss 2.226 Prec@(1,3) (84.3%, 98.9%), ce_loss 0.578, lat_loss 21.997
09/22 10:18:24 AM | Valid: [145/180] Step 312/312 Loss 2.211 Prec@(1,3) (84.4%, 99.0%), ce_loss 0.578, lat_loss 21.997
09/22 10:18:24 AM | val: [145/180] Final Prec@1 84.3500% Time 29.61
09/22 10:18:24 AM | Start to train weights for epoch 145
09/22 10:18:49 AM | Train: [146/180] Step 050/1249 Loss 0.725 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.578, lat_loss 21.997
09/22 10:19:11 AM | Train: [146/180] Step 100/1249 Loss 0.753 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.578, lat_loss 21.998
09/22 10:19:34 AM | Train: [146/180] Step 150/1249 Loss 0.794 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.578, lat_loss 21.998
09/22 10:19:58 AM | Train: [146/180] Step 200/1249 Loss 0.786 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.577, lat_loss 21.998
09/22 10:20:22 AM | Train: [146/180] Step 250/1249 Loss 0.814 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.577, lat_loss 21.998
09/22 10:20:46 AM | Train: [146/180] Step 300/1249 Loss 0.819 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.577, lat_loss 21.998
09/22 10:21:08 AM | Train: [146/180] Step 350/1249 Loss 0.837 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.577, lat_loss 21.998
09/22 10:21:30 AM | Train: [146/180] Step 400/1249 Loss 0.847 Prec@(1,3) (93.3%, 99.9%), ce_loss 0.577, lat_loss 21.998
09/22 10:21:52 AM | Train: [146/180] Step 450/1249 Loss 0.840 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.577, lat_loss 21.998
09/22 10:22:15 AM | Train: [146/180] Step 500/1249 Loss 0.841 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.577, lat_loss 21.998
09/22 10:22:39 AM | Train: [146/180] Step 550/1249 Loss 0.846 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.577, lat_loss 21.998
09/22 10:23:04 AM | Train: [146/180] Step 600/1249 Loss 0.856 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.577, lat_loss 21.998
09/22 10:23:28 AM | Train: [146/180] Step 650/1249 Loss 0.892 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.577, lat_loss 21.998
09/22 10:23:52 AM | Train: [146/180] Step 700/1249 Loss 0.894 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.577, lat_loss 21.998
09/22 10:24:15 AM | Train: [146/180] Step 750/1249 Loss 0.895 Prec@(1,3) (93.1%, 99.8%), ce_loss 0.577, lat_loss 21.998
09/22 10:24:39 AM | Train: [146/180] Step 800/1249 Loss 0.886 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.577, lat_loss 21.998
09/22 10:25:02 AM | Train: [146/180] Step 850/1249 Loss 0.877 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.577, lat_loss 21.998
09/22 10:25:23 AM | Train: [146/180] Step 900/1249 Loss 0.879 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.577, lat_loss 21.998
09/22 10:25:46 AM | Train: [146/180] Step 950/1249 Loss 0.878 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.576, lat_loss 21.998
09/22 10:26:09 AM | Train: [146/180] Step 1000/1249 Loss 0.878 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.576, lat_loss 21.998
09/22 10:26:33 AM | Train: [146/180] Step 1050/1249 Loss 0.878 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.576, lat_loss 21.998
09/22 10:26:56 AM | Train: [146/180] Step 1100/1249 Loss 0.881 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.576, lat_loss 21.998
09/22 10:27:20 AM | Train: [146/180] Step 1150/1249 Loss 0.878 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.576, lat_loss 21.998
09/22 10:27:44 AM | Train: [146/180] Step 1200/1249 Loss 0.874 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.576, lat_loss 21.998
09/22 10:28:08 AM | Train: [146/180] Step 1249/1249 Loss 0.876 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.576, lat_loss 21.998
09/22 10:28:08 AM | _w_step_train: [146/180] Final Prec@1 93.3050% Time 584.00
09/22 10:28:08 AM | Start to train theta for epoch 145
09/22 10:28:30 AM | Train: [146/180] Step 050/312 Loss 1.764 Prec@(1,3) (87.9%, 99.2%), ce_loss 0.576, lat_loss 21.998
09/22 10:28:51 AM | Train: [146/180] Step 100/312 Loss 1.841 Prec@(1,3) (87.5%, 99.1%), ce_loss 0.576, lat_loss 21.998
09/22 10:29:10 AM | Train: [146/180] Step 150/312 Loss 1.855 Prec@(1,3) (87.3%, 99.2%), ce_loss 0.576, lat_loss 21.998
09/22 10:29:29 AM | Train: [146/180] Step 200/312 Loss 1.920 Prec@(1,3) (86.9%, 99.2%), ce_loss 0.576, lat_loss 21.998
09/22 10:29:48 AM | Train: [146/180] Step 250/312 Loss 1.904 Prec@(1,3) (87.1%, 99.3%), ce_loss 0.576, lat_loss 21.998
09/22 10:30:07 AM | Train: [146/180] Step 300/312 Loss 1.910 Prec@(1,3) (86.9%, 99.3%), ce_loss 0.576, lat_loss 21.998
09/22 10:30:11 AM | Train: [146/180] Step 312/312 Loss 1.916 Prec@(1,3) (86.9%, 99.3%), ce_loss 0.576, lat_loss 21.998
09/22 10:30:11 AM | _theta_step_train: [146/180] Final Prec@1 86.8600% Time 122.90
09/22 10:30:17 AM | Valid: [146/180] Step 050/312 Loss 2.018 Prec@(1,3) (85.5%, 99.2%), ce_loss 0.576, lat_loss 21.998
09/22 10:30:22 AM | Valid: [146/180] Step 100/312 Loss 2.064 Prec@(1,3) (86.2%, 99.1%), ce_loss 0.576, lat_loss 21.998
09/22 10:30:27 AM | Valid: [146/180] Step 150/312 Loss 2.118 Prec@(1,3) (86.3%, 99.0%), ce_loss 0.576, lat_loss 21.998
09/22 10:30:31 AM | Valid: [146/180] Step 200/312 Loss 2.050 Prec@(1,3) (86.7%, 99.1%), ce_loss 0.576, lat_loss 21.998
09/22 10:30:36 AM | Valid: [146/180] Step 250/312 Loss 2.058 Prec@(1,3) (86.5%, 99.2%), ce_loss 0.576, lat_loss 21.998
09/22 10:30:41 AM | Valid: [146/180] Step 300/312 Loss 2.093 Prec@(1,3) (86.2%, 99.1%), ce_loss 0.576, lat_loss 21.998
09/22 10:30:42 AM | Valid: [146/180] Step 312/312 Loss 2.080 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.576, lat_loss 21.998
09/22 10:30:42 AM | val: [146/180] Final Prec@1 86.2500% Time 30.71
09/22 10:30:42 AM | Best top1 acc by now. Save model
09/22 10:30:42 AM | Start to train weights for epoch 146
09/22 10:31:07 AM | Train: [147/180] Step 050/1249 Loss 0.818 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.576, lat_loss 21.998
09/22 10:31:31 AM | Train: [147/180] Step 100/1249 Loss 0.787 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.576, lat_loss 21.998
09/22 10:31:54 AM | Train: [147/180] Step 150/1249 Loss 0.902 Prec@(1,3) (93.2%, 99.7%), ce_loss 0.576, lat_loss 21.998
09/22 10:32:15 AM | Train: [147/180] Step 200/1249 Loss 0.975 Prec@(1,3) (92.5%, 99.7%), ce_loss 0.575, lat_loss 21.998
09/22 10:32:37 AM | Train: [147/180] Step 250/1249 Loss 0.974 Prec@(1,3) (92.5%, 99.7%), ce_loss 0.575, lat_loss 21.998
09/22 10:33:02 AM | Train: [147/180] Step 300/1249 Loss 0.952 Prec@(1,3) (92.6%, 99.7%), ce_loss 0.575, lat_loss 21.998
09/22 10:33:27 AM | Train: [147/180] Step 350/1249 Loss 0.925 Prec@(1,3) (92.8%, 99.7%), ce_loss 0.575, lat_loss 21.998
09/22 10:33:51 AM | Train: [147/180] Step 400/1249 Loss 0.906 Prec@(1,3) (92.9%, 99.7%), ce_loss 0.575, lat_loss 21.998
09/22 10:34:16 AM | Train: [147/180] Step 450/1249 Loss 0.889 Prec@(1,3) (93.0%, 99.8%), ce_loss 0.575, lat_loss 21.998
09/22 10:34:41 AM | Train: [147/180] Step 500/1249 Loss 0.885 Prec@(1,3) (93.1%, 99.8%), ce_loss 0.575, lat_loss 21.998
09/22 10:35:05 AM | Train: [147/180] Step 550/1249 Loss 0.879 Prec@(1,3) (93.1%, 99.8%), ce_loss 0.575, lat_loss 21.998
09/22 10:35:30 AM | Train: [147/180] Step 600/1249 Loss 0.889 Prec@(1,3) (93.1%, 99.8%), ce_loss 0.575, lat_loss 21.998
09/22 10:35:55 AM | Train: [147/180] Step 650/1249 Loss 0.889 Prec@(1,3) (93.1%, 99.8%), ce_loss 0.575, lat_loss 21.998
09/22 10:36:20 AM | Train: [147/180] Step 700/1249 Loss 0.884 Prec@(1,3) (93.1%, 99.8%), ce_loss 0.575, lat_loss 21.998
09/22 10:36:44 AM | Train: [147/180] Step 750/1249 Loss 0.877 Prec@(1,3) (93.1%, 99.8%), ce_loss 0.575, lat_loss 21.998
09/22 10:37:09 AM | Train: [147/180] Step 800/1249 Loss 0.870 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.575, lat_loss 21.998
09/22 10:37:34 AM | Train: [147/180] Step 850/1249 Loss 0.861 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.575, lat_loss 21.998
09/22 10:37:58 AM | Train: [147/180] Step 900/1249 Loss 0.866 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.574, lat_loss 21.998
09/22 10:38:23 AM | Train: [147/180] Step 950/1249 Loss 0.869 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.574, lat_loss 21.998
09/22 10:38:48 AM | Train: [147/180] Step 1000/1249 Loss 0.872 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.574, lat_loss 21.998
09/22 10:39:12 AM | Train: [147/180] Step 1050/1249 Loss 0.871 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.574, lat_loss 21.998
09/22 10:39:37 AM | Train: [147/180] Step 1100/1249 Loss 0.874 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.574, lat_loss 21.998
09/22 10:40:01 AM | Train: [147/180] Step 1150/1249 Loss 0.868 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.574, lat_loss 21.998
09/22 10:40:25 AM | Train: [147/180] Step 1200/1249 Loss 0.870 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.574, lat_loss 21.998
09/22 10:40:49 AM | Train: [147/180] Step 1249/1249 Loss 0.864 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.574, lat_loss 21.998
09/22 10:40:50 AM | _w_step_train: [147/180] Final Prec@1 93.2300% Time 607.11
09/22 10:40:50 AM | Start to train theta for epoch 146
09/22 10:41:09 AM | Train: [147/180] Step 050/312 Loss 1.833 Prec@(1,3) (87.1%, 99.3%), ce_loss 0.574, lat_loss 21.998
09/22 10:41:27 AM | Train: [147/180] Step 100/312 Loss 2.068 Prec@(1,3) (86.1%, 99.0%), ce_loss 0.574, lat_loss 21.998
09/22 10:41:48 AM | Train: [147/180] Step 150/312 Loss 2.024 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.574, lat_loss 21.998
09/22 10:42:08 AM | Train: [147/180] Step 200/312 Loss 2.034 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.574, lat_loss 21.998
09/22 10:42:28 AM | Train: [147/180] Step 250/312 Loss 2.034 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.574, lat_loss 21.998
09/22 10:42:49 AM | Train: [147/180] Step 300/312 Loss 2.068 Prec@(1,3) (85.9%, 99.1%), ce_loss 0.574, lat_loss 21.998
09/22 10:42:54 AM | Train: [147/180] Step 312/312 Loss 2.054 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.574, lat_loss 21.998
09/22 10:42:54 AM | _theta_step_train: [147/180] Final Prec@1 85.9700% Time 124.55
09/22 10:42:59 AM | Valid: [147/180] Step 050/312 Loss 1.835 Prec@(1,3) (86.2%, 99.5%), ce_loss 0.574, lat_loss 21.998
09/22 10:43:04 AM | Valid: [147/180] Step 100/312 Loss 1.999 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.574, lat_loss 21.998
09/22 10:43:09 AM | Valid: [147/180] Step 150/312 Loss 2.128 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.574, lat_loss 21.998
09/22 10:43:13 AM | Valid: [147/180] Step 200/312 Loss 2.067 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.574, lat_loss 21.998
09/22 10:43:18 AM | Valid: [147/180] Step 250/312 Loss 2.082 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.574, lat_loss 21.998
09/22 10:43:23 AM | Valid: [147/180] Step 300/312 Loss 2.021 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.574, lat_loss 21.998
09/22 10:43:24 AM | Valid: [147/180] Step 312/312 Loss 2.010 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.574, lat_loss 21.998
09/22 10:43:24 AM | val: [147/180] Final Prec@1 85.6400% Time 29.67
09/22 10:43:24 AM | Start to train weights for epoch 147
09/22 10:43:49 AM | Train: [148/180] Step 050/1249 Loss 0.859 Prec@(1,3) (93.9%, 99.6%), ce_loss 0.574, lat_loss 21.998
09/22 10:44:13 AM | Train: [148/180] Step 100/1249 Loss 0.821 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.574, lat_loss 21.998
09/22 10:44:34 AM | Train: [148/180] Step 150/1249 Loss 0.827 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.573, lat_loss 21.998
09/22 10:44:55 AM | Train: [148/180] Step 200/1249 Loss 0.854 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.573, lat_loss 21.998
09/22 10:45:20 AM | Train: [148/180] Step 250/1249 Loss 0.865 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.573, lat_loss 21.998
09/22 10:45:38 AM | Train: [148/180] Step 300/1249 Loss 0.854 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.573, lat_loss 21.998
09/22 10:45:54 AM | Train: [148/180] Step 350/1249 Loss 0.855 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.573, lat_loss 21.998
09/22 10:46:10 AM | Train: [148/180] Step 400/1249 Loss 0.903 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.573, lat_loss 21.998
09/22 10:46:35 AM | Train: [148/180] Step 450/1249 Loss 0.895 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.573, lat_loss 21.998
09/22 10:47:00 AM | Train: [148/180] Step 500/1249 Loss 0.878 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.573, lat_loss 21.998
09/22 10:47:25 AM | Train: [148/180] Step 550/1249 Loss 0.879 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.573, lat_loss 21.998
09/22 10:47:51 AM | Train: [148/180] Step 600/1249 Loss 0.877 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.573, lat_loss 21.998
09/22 10:48:16 AM | Train: [148/180] Step 650/1249 Loss 0.866 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.573, lat_loss 21.998
09/22 10:48:41 AM | Train: [148/180] Step 700/1249 Loss 0.854 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.573, lat_loss 21.998
09/22 10:49:07 AM | Train: [148/180] Step 750/1249 Loss 0.866 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.573, lat_loss 21.998
09/22 10:49:32 AM | Train: [148/180] Step 800/1249 Loss 0.866 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.573, lat_loss 21.998
09/22 10:49:58 AM | Train: [148/180] Step 850/1249 Loss 0.868 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.573, lat_loss 21.998
09/22 10:50:24 AM | Train: [148/180] Step 900/1249 Loss 0.860 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.572, lat_loss 21.998
09/22 10:50:49 AM | Train: [148/180] Step 950/1249 Loss 0.855 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.572, lat_loss 21.998
09/22 10:51:14 AM | Train: [148/180] Step 1000/1249 Loss 0.856 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.572, lat_loss 21.998
09/22 10:51:40 AM | Train: [148/180] Step 1050/1249 Loss 0.858 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.572, lat_loss 21.998
09/22 10:52:05 AM | Train: [148/180] Step 1100/1249 Loss 0.865 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.572, lat_loss 21.998
09/22 10:52:30 AM | Train: [148/180] Step 1150/1249 Loss 0.867 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.572, lat_loss 21.998
09/22 10:52:56 AM | Train: [148/180] Step 1200/1249 Loss 0.864 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.572, lat_loss 21.998
09/22 10:53:20 AM | Train: [148/180] Step 1249/1249 Loss 0.860 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.572, lat_loss 21.998
09/22 10:53:20 AM | _w_step_train: [148/180] Final Prec@1 93.3350% Time 596.40
09/22 10:53:20 AM | Start to train theta for epoch 147
09/22 10:53:42 AM | Train: [148/180] Step 050/312 Loss 1.993 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.572, lat_loss 21.998
09/22 10:54:03 AM | Train: [148/180] Step 100/312 Loss 2.007 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.572, lat_loss 21.998
09/22 10:54:23 AM | Train: [148/180] Step 150/312 Loss 2.044 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.572, lat_loss 21.998
09/22 10:54:42 AM | Train: [148/180] Step 200/312 Loss 1.987 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.572, lat_loss 21.998
09/22 10:55:03 AM | Train: [148/180] Step 250/312 Loss 2.020 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.572, lat_loss 21.998
09/22 10:55:23 AM | Train: [148/180] Step 300/312 Loss 2.005 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.572, lat_loss 21.998
09/22 10:55:28 AM | Train: [148/180] Step 312/312 Loss 2.006 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.572, lat_loss 21.998
09/22 10:55:28 AM | _theta_step_train: [148/180] Final Prec@1 86.2300% Time 128.11
09/22 10:55:34 AM | Valid: [148/180] Step 050/312 Loss 2.042 Prec@(1,3) (85.0%, 98.6%), ce_loss 0.572, lat_loss 21.998
09/22 10:55:38 AM | Valid: [148/180] Step 100/312 Loss 2.040 Prec@(1,3) (85.3%, 98.7%), ce_loss 0.572, lat_loss 21.998
09/22 10:55:43 AM | Valid: [148/180] Step 150/312 Loss 2.097 Prec@(1,3) (85.2%, 98.8%), ce_loss 0.572, lat_loss 21.998
09/22 10:55:48 AM | Valid: [148/180] Step 200/312 Loss 2.180 Prec@(1,3) (85.0%, 98.6%), ce_loss 0.572, lat_loss 21.998
09/22 10:55:52 AM | Valid: [148/180] Step 250/312 Loss 2.168 Prec@(1,3) (84.9%, 98.7%), ce_loss 0.572, lat_loss 21.998
09/22 10:55:57 AM | Valid: [148/180] Step 300/312 Loss 2.093 Prec@(1,3) (85.4%, 98.8%), ce_loss 0.572, lat_loss 21.998
09/22 10:55:58 AM | Valid: [148/180] Step 312/312 Loss 2.082 Prec@(1,3) (85.5%, 98.9%), ce_loss 0.572, lat_loss 21.998
09/22 10:55:58 AM | val: [148/180] Final Prec@1 85.4700% Time 29.78
09/22 10:55:58 AM | Start to train weights for epoch 148
09/22 10:56:24 AM | Train: [149/180] Step 050/1249 Loss 0.990 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.572, lat_loss 21.998
09/22 10:56:49 AM | Train: [149/180] Step 100/1249 Loss 0.903 Prec@(1,3) (93.0%, 99.8%), ce_loss 0.572, lat_loss 21.998
09/22 10:57:13 AM | Train: [149/180] Step 150/1249 Loss 0.876 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.571, lat_loss 21.998
09/22 10:57:37 AM | Train: [149/180] Step 200/1249 Loss 0.876 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.571, lat_loss 21.998
09/22 10:58:00 AM | Train: [149/180] Step 250/1249 Loss 0.854 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.571, lat_loss 21.998
09/22 10:58:23 AM | Train: [149/180] Step 300/1249 Loss 0.854 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.571, lat_loss 21.998
09/22 10:58:47 AM | Train: [149/180] Step 350/1249 Loss 0.838 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.571, lat_loss 21.998
09/22 10:59:06 AM | Train: [149/180] Step 400/1249 Loss 0.967 Prec@(1,3) (93.1%, 99.7%), ce_loss 0.571, lat_loss 21.998
09/22 10:59:22 AM | Train: [149/180] Step 450/1249 Loss 0.943 Prec@(1,3) (93.2%, 99.7%), ce_loss 0.571, lat_loss 21.998
09/22 10:59:38 AM | Train: [149/180] Step 500/1249 Loss 0.931 Prec@(1,3) (93.2%, 99.7%), ce_loss 0.571, lat_loss 21.998
09/22 10:59:54 AM | Train: [149/180] Step 550/1249 Loss 0.913 Prec@(1,3) (93.3%, 99.7%), ce_loss 0.571, lat_loss 21.998
09/22 11:00:10 AM | Train: [149/180] Step 600/1249 Loss 0.914 Prec@(1,3) (93.3%, 99.7%), ce_loss 0.571, lat_loss 21.998
09/22 11:00:26 AM | Train: [149/180] Step 650/1249 Loss 0.915 Prec@(1,3) (93.3%, 99.7%), ce_loss 0.571, lat_loss 21.998
09/22 11:00:42 AM | Train: [149/180] Step 700/1249 Loss 0.909 Prec@(1,3) (93.3%, 99.7%), ce_loss 0.571, lat_loss 21.998
09/22 11:00:59 AM | Train: [149/180] Step 750/1249 Loss 0.905 Prec@(1,3) (93.3%, 99.7%), ce_loss 0.571, lat_loss 21.999
09/22 11:01:15 AM | Train: [149/180] Step 800/1249 Loss 0.901 Prec@(1,3) (93.3%, 99.7%), ce_loss 0.571, lat_loss 21.999
09/22 11:01:31 AM | Train: [149/180] Step 850/1249 Loss 0.898 Prec@(1,3) (93.3%, 99.7%), ce_loss 0.571, lat_loss 21.999
09/22 11:01:55 AM | Train: [149/180] Step 900/1249 Loss 0.897 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.570, lat_loss 21.999
09/22 11:02:20 AM | Train: [149/180] Step 950/1249 Loss 0.892 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.570, lat_loss 21.999
09/22 11:02:45 AM | Train: [149/180] Step 1000/1249 Loss 0.893 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.570, lat_loss 21.999
09/22 11:03:11 AM | Train: [149/180] Step 1050/1249 Loss 0.886 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.570, lat_loss 21.999
09/22 11:03:35 AM | Train: [149/180] Step 1100/1249 Loss 0.888 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.570, lat_loss 21.999
09/22 11:04:00 AM | Train: [149/180] Step 1150/1249 Loss 0.880 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.570, lat_loss 21.999
09/22 11:04:25 AM | Train: [149/180] Step 1200/1249 Loss 0.876 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.570, lat_loss 21.999
09/22 11:04:50 AM | Train: [149/180] Step 1249/1249 Loss 0.869 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.570, lat_loss 21.999
09/22 11:04:50 AM | _w_step_train: [149/180] Final Prec@1 93.4650% Time 531.61
09/22 11:04:50 AM | Start to train theta for epoch 148
09/22 11:05:10 AM | Train: [149/180] Step 050/312 Loss 1.912 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.570, lat_loss 21.999
09/22 11:05:31 AM | Train: [149/180] Step 100/312 Loss 1.965 Prec@(1,3) (86.7%, 99.2%), ce_loss 0.570, lat_loss 21.999
09/22 11:05:51 AM | Train: [149/180] Step 150/312 Loss 1.949 Prec@(1,3) (86.7%, 99.1%), ce_loss 0.570, lat_loss 21.999
09/22 11:06:12 AM | Train: [149/180] Step 200/312 Loss 1.982 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.570, lat_loss 21.999
09/22 11:06:32 AM | Train: [149/180] Step 250/312 Loss 1.973 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.570, lat_loss 21.999
09/22 11:06:53 AM | Train: [149/180] Step 300/312 Loss 2.008 Prec@(1,3) (86.3%, 99.2%), ce_loss 0.570, lat_loss 21.999
09/22 11:06:58 AM | Train: [149/180] Step 312/312 Loss 2.014 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.570, lat_loss 21.999
09/22 11:06:58 AM | _theta_step_train: [149/180] Final Prec@1 86.2500% Time 128.52
09/22 11:07:03 AM | Valid: [149/180] Step 050/312 Loss 2.094 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.570, lat_loss 21.999
09/22 11:07:08 AM | Valid: [149/180] Step 100/312 Loss 1.976 Prec@(1,3) (86.4%, 99.3%), ce_loss 0.570, lat_loss 21.999
09/22 11:07:13 AM | Valid: [149/180] Step 150/312 Loss 2.102 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.570, lat_loss 21.999
09/22 11:07:17 AM | Valid: [149/180] Step 200/312 Loss 2.092 Prec@(1,3) (85.6%, 99.1%), ce_loss 0.570, lat_loss 21.999
09/22 11:07:22 AM | Valid: [149/180] Step 250/312 Loss 2.167 Prec@(1,3) (85.0%, 99.0%), ce_loss 0.570, lat_loss 21.999
09/22 11:07:27 AM | Valid: [149/180] Step 300/312 Loss 2.153 Prec@(1,3) (84.8%, 99.0%), ce_loss 0.570, lat_loss 21.999
09/22 11:07:28 AM | Valid: [149/180] Step 312/312 Loss 2.141 Prec@(1,3) (84.9%, 99.0%), ce_loss 0.570, lat_loss 21.999
09/22 11:07:28 AM | val: [149/180] Final Prec@1 84.8900% Time 29.40
09/22 11:07:28 AM | Start to train weights for epoch 149
09/22 11:07:53 AM | Train: [150/180] Step 050/1249 Loss 0.906 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.570, lat_loss 21.999
09/22 11:08:19 AM | Train: [150/180] Step 100/1249 Loss 0.943 Prec@(1,3) (92.9%, 99.8%), ce_loss 0.570, lat_loss 21.999
09/22 11:08:44 AM | Train: [150/180] Step 150/1249 Loss 0.876 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.570, lat_loss 21.999
09/22 11:09:09 AM | Train: [150/180] Step 200/1249 Loss 0.873 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.569, lat_loss 21.999
09/22 11:09:34 AM | Train: [150/180] Step 250/1249 Loss 0.874 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.569, lat_loss 21.999
09/22 11:09:59 AM | Train: [150/180] Step 300/1249 Loss 0.859 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.569, lat_loss 21.999
09/22 11:10:24 AM | Train: [150/180] Step 350/1249 Loss 0.829 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.569, lat_loss 21.999
09/22 11:10:48 AM | Train: [150/180] Step 400/1249 Loss 0.818 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.569, lat_loss 21.999
09/22 11:11:13 AM | Train: [150/180] Step 450/1249 Loss 0.853 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.569, lat_loss 21.999
09/22 11:11:37 AM | Train: [150/180] Step 500/1249 Loss 0.846 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.569, lat_loss 21.999
09/22 11:12:02 AM | Train: [150/180] Step 550/1249 Loss 0.843 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.569, lat_loss 21.999
09/22 11:12:27 AM | Train: [150/180] Step 600/1249 Loss 0.839 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.569, lat_loss 21.999
09/22 11:12:52 AM | Train: [150/180] Step 650/1249 Loss 0.861 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.569, lat_loss 21.999
09/22 11:13:17 AM | Train: [150/180] Step 700/1249 Loss 0.850 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.569, lat_loss 21.999
09/22 11:13:42 AM | Train: [150/180] Step 750/1249 Loss 0.852 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.569, lat_loss 21.999
09/22 11:14:06 AM | Train: [150/180] Step 800/1249 Loss 0.852 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.569, lat_loss 21.999
09/22 11:14:30 AM | Train: [150/180] Step 850/1249 Loss 0.844 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.569, lat_loss 21.999
09/22 11:14:54 AM | Train: [150/180] Step 900/1249 Loss 0.865 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.569, lat_loss 21.999
09/22 11:15:18 AM | Train: [150/180] Step 950/1249 Loss 0.859 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.568, lat_loss 21.999
09/22 11:15:42 AM | Train: [150/180] Step 1000/1249 Loss 0.864 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.568, lat_loss 21.999
09/22 11:16:05 AM | Train: [150/180] Step 1050/1249 Loss 0.868 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.568, lat_loss 21.999
09/22 11:16:29 AM | Train: [150/180] Step 1100/1249 Loss 0.863 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.568, lat_loss 21.999
09/22 11:16:53 AM | Train: [150/180] Step 1150/1249 Loss 0.864 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.568, lat_loss 21.999
09/22 11:17:17 AM | Train: [150/180] Step 1200/1249 Loss 0.853 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.568, lat_loss 21.999
09/22 11:17:42 AM | Train: [150/180] Step 1249/1249 Loss 0.853 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.568, lat_loss 21.999
09/22 11:17:42 AM | _w_step_train: [150/180] Final Prec@1 93.6700% Time 614.34
09/22 11:17:42 AM | Start to train theta for epoch 149
09/22 11:18:04 AM | Train: [150/180] Step 050/312 Loss 1.775 Prec@(1,3) (88.1%, 99.3%), ce_loss 0.568, lat_loss 21.999
09/22 11:18:24 AM | Train: [150/180] Step 100/312 Loss 1.832 Prec@(1,3) (87.7%, 99.4%), ce_loss 0.568, lat_loss 21.999
09/22 11:18:45 AM | Train: [150/180] Step 150/312 Loss 1.853 Prec@(1,3) (87.5%, 99.3%), ce_loss 0.568, lat_loss 21.999
09/22 11:19:05 AM | Train: [150/180] Step 200/312 Loss 1.914 Prec@(1,3) (87.1%, 99.3%), ce_loss 0.568, lat_loss 21.999
09/22 11:19:25 AM | Train: [150/180] Step 250/312 Loss 1.921 Prec@(1,3) (87.0%, 99.3%), ce_loss 0.568, lat_loss 21.999
09/22 11:19:46 AM | Train: [150/180] Step 300/312 Loss 1.925 Prec@(1,3) (87.0%, 99.3%), ce_loss 0.568, lat_loss 21.999
09/22 11:19:51 AM | Train: [150/180] Step 312/312 Loss 1.921 Prec@(1,3) (87.1%, 99.3%), ce_loss 0.568, lat_loss 21.999
09/22 11:19:51 AM | _theta_step_train: [150/180] Final Prec@1 87.0600% Time 128.85
09/22 11:19:56 AM | Valid: [150/180] Step 050/312 Loss 1.952 Prec@(1,3) (85.4%, 99.3%), ce_loss 0.568, lat_loss 21.999
09/22 11:20:01 AM | Valid: [150/180] Step 100/312 Loss 2.124 Prec@(1,3) (84.9%, 98.9%), ce_loss 0.568, lat_loss 21.999
09/22 11:20:06 AM | Valid: [150/180] Step 150/312 Loss 2.231 Prec@(1,3) (84.1%, 98.7%), ce_loss 0.568, lat_loss 21.999
09/22 11:20:10 AM | Valid: [150/180] Step 200/312 Loss 2.117 Prec@(1,3) (85.1%, 98.9%), ce_loss 0.568, lat_loss 21.999
09/22 11:20:15 AM | Valid: [150/180] Step 250/312 Loss 2.126 Prec@(1,3) (85.0%, 98.9%), ce_loss 0.568, lat_loss 21.999
09/22 11:20:20 AM | Valid: [150/180] Step 300/312 Loss 2.078 Prec@(1,3) (85.2%, 99.0%), ce_loss 0.568, lat_loss 21.999
09/22 11:20:21 AM | Valid: [150/180] Step 312/312 Loss 2.077 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.568, lat_loss 21.999
09/22 11:20:21 AM | val: [150/180] Final Prec@1 85.1700% Time 29.85
09/22 11:20:21 AM | Start to train weights for epoch 150
09/22 11:20:47 AM | Train: [151/180] Step 050/1249 Loss 0.779 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.568, lat_loss 21.999
09/22 11:21:11 AM | Train: [151/180] Step 100/1249 Loss 0.792 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.568, lat_loss 21.999
09/22 11:21:35 AM | Train: [151/180] Step 150/1249 Loss 0.807 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.568, lat_loss 21.999
09/22 11:22:00 AM | Train: [151/180] Step 200/1249 Loss 0.777 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.568, lat_loss 21.999
09/22 11:22:25 AM | Train: [151/180] Step 250/1249 Loss 0.772 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.567, lat_loss 21.999
09/22 11:22:49 AM | Train: [151/180] Step 300/1249 Loss 0.771 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.567, lat_loss 21.999
09/22 11:23:14 AM | Train: [151/180] Step 350/1249 Loss 0.760 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.567, lat_loss 21.999
09/22 11:23:37 AM | Train: [151/180] Step 400/1249 Loss 0.760 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.567, lat_loss 21.999
09/22 11:24:01 AM | Train: [151/180] Step 450/1249 Loss 0.753 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.567, lat_loss 21.999
09/22 11:24:24 AM | Train: [151/180] Step 500/1249 Loss 0.765 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.567, lat_loss 21.999
09/22 11:24:47 AM | Train: [151/180] Step 550/1249 Loss 0.770 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.567, lat_loss 21.999
09/22 11:25:12 AM | Train: [151/180] Step 600/1249 Loss 0.778 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.567, lat_loss 21.999
09/22 11:25:35 AM | Train: [151/180] Step 650/1249 Loss 0.777 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.567, lat_loss 21.999
09/22 11:25:57 AM | Train: [151/180] Step 700/1249 Loss 0.781 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.567, lat_loss 21.999
09/22 11:26:20 AM | Train: [151/180] Step 750/1249 Loss 0.791 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.567, lat_loss 21.999
09/22 11:26:43 AM | Train: [151/180] Step 800/1249 Loss 0.796 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.567, lat_loss 21.999
09/22 11:27:07 AM | Train: [151/180] Step 850/1249 Loss 0.820 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.567, lat_loss 21.999
09/22 11:27:30 AM | Train: [151/180] Step 900/1249 Loss 0.822 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.567, lat_loss 21.999
09/22 11:27:52 AM | Train: [151/180] Step 950/1249 Loss 0.822 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.566, lat_loss 21.999
09/22 11:28:16 AM | Train: [151/180] Step 1000/1249 Loss 0.816 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.566, lat_loss 21.999
09/22 11:28:39 AM | Train: [151/180] Step 1050/1249 Loss 0.812 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.566, lat_loss 21.999
09/22 11:29:02 AM | Train: [151/180] Step 1100/1249 Loss 0.811 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.566, lat_loss 21.999
09/22 11:29:26 AM | Train: [151/180] Step 1150/1249 Loss 0.811 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.566, lat_loss 21.999
09/22 11:29:48 AM | Train: [151/180] Step 1200/1249 Loss 0.806 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.566, lat_loss 21.999
09/22 11:30:13 AM | Train: [151/180] Step 1249/1249 Loss 0.805 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.566, lat_loss 21.999
09/22 11:30:13 AM | _w_step_train: [151/180] Final Prec@1 93.7050% Time 592.40
09/22 11:30:13 AM | Start to train theta for epoch 150
09/22 11:30:34 AM | Train: [151/180] Step 050/312 Loss 1.906 Prec@(1,3) (87.3%, 99.3%), ce_loss 0.566, lat_loss 21.999
09/22 11:30:54 AM | Train: [151/180] Step 100/312 Loss 1.915 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.566, lat_loss 21.999
09/22 11:31:15 AM | Train: [151/180] Step 150/312 Loss 1.940 Prec@(1,3) (86.7%, 99.4%), ce_loss 0.566, lat_loss 21.999
09/22 11:31:35 AM | Train: [151/180] Step 200/312 Loss 1.962 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.566, lat_loss 21.999
09/22 11:31:55 AM | Train: [151/180] Step 250/312 Loss 1.966 Prec@(1,3) (86.8%, 99.3%), ce_loss 0.566, lat_loss 21.999
09/22 11:32:16 AM | Train: [151/180] Step 300/312 Loss 1.944 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.566, lat_loss 21.999
09/22 11:32:21 AM | Train: [151/180] Step 312/312 Loss 1.949 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.566, lat_loss 21.999
09/22 11:32:22 AM | _theta_step_train: [151/180] Final Prec@1 86.8200% Time 128.40
09/22 11:32:27 AM | Valid: [151/180] Step 050/312 Loss 2.140 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.566, lat_loss 21.999
09/22 11:32:31 AM | Valid: [151/180] Step 100/312 Loss 2.134 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.566, lat_loss 21.999
09/22 11:32:36 AM | Valid: [151/180] Step 150/312 Loss 2.219 Prec@(1,3) (84.3%, 98.8%), ce_loss 0.566, lat_loss 21.999
09/22 11:32:41 AM | Valid: [151/180] Step 200/312 Loss 2.138 Prec@(1,3) (84.9%, 98.9%), ce_loss 0.566, lat_loss 21.999
09/22 11:32:46 AM | Valid: [151/180] Step 250/312 Loss 2.149 Prec@(1,3) (84.8%, 99.0%), ce_loss 0.566, lat_loss 21.999
09/22 11:32:50 AM | Valid: [151/180] Step 300/312 Loss 2.127 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.566, lat_loss 21.999
09/22 11:32:51 AM | Valid: [151/180] Step 312/312 Loss 2.132 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.566, lat_loss 21.999
09/22 11:32:51 AM | val: [151/180] Final Prec@1 84.8500% Time 29.82
09/22 11:32:51 AM | Start to train weights for epoch 151
09/22 11:33:16 AM | Train: [152/180] Step 050/1249 Loss 0.646 Prec@(1,3) (95.0%, 99.9%), ce_loss 0.566, lat_loss 21.999
09/22 11:33:39 AM | Train: [152/180] Step 100/1249 Loss 0.787 Prec@(1,3) (94.2%, 99.7%), ce_loss 0.566, lat_loss 21.999
09/22 11:34:01 AM | Train: [152/180] Step 150/1249 Loss 0.745 Prec@(1,3) (94.0%, 99.8%), ce_loss 0.566, lat_loss 21.999
09/22 11:34:24 AM | Train: [152/180] Step 200/1249 Loss 0.771 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.566, lat_loss 21.999
09/22 11:34:47 AM | Train: [152/180] Step 250/1249 Loss 0.808 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.565, lat_loss 21.999
09/22 11:35:10 AM | Train: [152/180] Step 300/1249 Loss 0.790 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.565, lat_loss 21.999
09/22 11:35:32 AM | Train: [152/180] Step 350/1249 Loss 0.789 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.565, lat_loss 21.999
09/22 11:35:54 AM | Train: [152/180] Step 400/1249 Loss 0.787 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.565, lat_loss 21.999
09/22 11:36:17 AM | Train: [152/180] Step 450/1249 Loss 0.786 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.565, lat_loss 21.999
09/22 11:36:40 AM | Train: [152/180] Step 500/1249 Loss 0.783 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.565, lat_loss 21.999
09/22 11:37:05 AM | Train: [152/180] Step 550/1249 Loss 0.786 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.565, lat_loss 21.999
09/22 11:37:32 AM | Train: [152/180] Step 600/1249 Loss 0.788 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.565, lat_loss 21.999
09/22 11:38:00 AM | Train: [152/180] Step 650/1249 Loss 0.785 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.565, lat_loss 21.999
09/22 11:38:27 AM | Train: [152/180] Step 700/1249 Loss 0.840 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.565, lat_loss 21.999
09/22 11:38:54 AM | Train: [152/180] Step 750/1249 Loss 0.842 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.565, lat_loss 21.999
09/22 11:39:20 AM | Train: [152/180] Step 800/1249 Loss 0.836 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.565, lat_loss 21.999
09/22 11:39:45 AM | Train: [152/180] Step 850/1249 Loss 0.833 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.565, lat_loss 21.999
09/22 11:40:10 AM | Train: [152/180] Step 900/1249 Loss 0.837 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.565, lat_loss 21.999
09/22 11:40:35 AM | Train: [152/180] Step 950/1249 Loss 0.835 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.565, lat_loss 21.999
09/22 11:41:00 AM | Train: [152/180] Step 1000/1249 Loss 0.840 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.564, lat_loss 21.999
09/22 11:41:25 AM | Train: [152/180] Step 1050/1249 Loss 0.840 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.564, lat_loss 21.999
09/22 11:41:49 AM | Train: [152/180] Step 1100/1249 Loss 0.840 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.564, lat_loss 21.999
09/22 11:42:13 AM | Train: [152/180] Step 1150/1249 Loss 0.840 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.564, lat_loss 21.999
09/22 11:42:36 AM | Train: [152/180] Step 1200/1249 Loss 0.841 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.564, lat_loss 21.999
09/22 11:43:00 AM | Train: [152/180] Step 1249/1249 Loss 0.832 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.564, lat_loss 21.999
09/22 11:43:01 AM | _w_step_train: [152/180] Final Prec@1 93.5150% Time 609.10
09/22 11:43:01 AM | Start to train theta for epoch 151
09/22 11:43:22 AM | Train: [152/180] Step 050/312 Loss 2.093 Prec@(1,3) (85.5%, 99.2%), ce_loss 0.564, lat_loss 21.999
09/22 11:43:43 AM | Train: [152/180] Step 100/312 Loss 1.947 Prec@(1,3) (86.7%, 99.2%), ce_loss 0.564, lat_loss 21.999
09/22 11:44:04 AM | Train: [152/180] Step 150/312 Loss 1.994 Prec@(1,3) (86.6%, 99.2%), ce_loss 0.564, lat_loss 21.999
09/22 11:44:25 AM | Train: [152/180] Step 200/312 Loss 1.967 Prec@(1,3) (86.6%, 99.2%), ce_loss 0.564, lat_loss 21.999
09/22 11:44:46 AM | Train: [152/180] Step 250/312 Loss 1.935 Prec@(1,3) (86.8%, 99.3%), ce_loss 0.564, lat_loss 21.999
09/22 11:45:07 AM | Train: [152/180] Step 300/312 Loss 1.953 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.564, lat_loss 21.999
09/22 11:45:12 AM | Train: [152/180] Step 312/312 Loss 1.961 Prec@(1,3) (86.6%, 99.2%), ce_loss 0.564, lat_loss 21.999
09/22 11:45:12 AM | _theta_step_train: [152/180] Final Prec@1 86.5600% Time 131.49
09/22 11:45:17 AM | Valid: [152/180] Step 050/312 Loss 1.831 Prec@(1,3) (86.0%, 99.6%), ce_loss 0.564, lat_loss 21.999
09/22 11:45:22 AM | Valid: [152/180] Step 100/312 Loss 2.195 Prec@(1,3) (84.8%, 98.9%), ce_loss 0.564, lat_loss 21.999
09/22 11:45:27 AM | Valid: [152/180] Step 150/312 Loss 2.247 Prec@(1,3) (84.7%, 98.8%), ce_loss 0.564, lat_loss 21.999
09/22 11:45:31 AM | Valid: [152/180] Step 200/312 Loss 2.230 Prec@(1,3) (84.7%, 98.8%), ce_loss 0.564, lat_loss 21.999
09/22 11:45:36 AM | Valid: [152/180] Step 250/312 Loss 2.346 Prec@(1,3) (84.5%, 98.6%), ce_loss 0.564, lat_loss 21.999
09/22 11:45:41 AM | Valid: [152/180] Step 300/312 Loss 2.304 Prec@(1,3) (84.6%, 98.7%), ce_loss 0.564, lat_loss 21.999
09/22 11:45:42 AM | Valid: [152/180] Step 312/312 Loss 2.302 Prec@(1,3) (84.5%, 98.7%), ce_loss 0.564, lat_loss 21.999
09/22 11:45:42 AM | val: [152/180] Final Prec@1 84.5300% Time 29.82
09/22 11:45:42 AM | Start to train weights for epoch 152
09/22 11:46:05 AM | Train: [153/180] Step 050/1249 Loss 1.030 Prec@(1,3) (92.0%, 99.9%), ce_loss 0.564, lat_loss 21.999
09/22 11:46:25 AM | Train: [153/180] Step 100/1249 Loss 0.947 Prec@(1,3) (92.7%, 99.9%), ce_loss 0.564, lat_loss 21.999
09/22 11:46:46 AM | Train: [153/180] Step 150/1249 Loss 0.885 Prec@(1,3) (93.0%, 99.9%), ce_loss 0.564, lat_loss 21.999
09/22 11:47:08 AM | Train: [153/180] Step 200/1249 Loss 0.876 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.564, lat_loss 21.999
09/22 11:47:31 AM | Train: [153/180] Step 250/1249 Loss 0.854 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.564, lat_loss 21.999
09/22 11:47:54 AM | Train: [153/180] Step 300/1249 Loss 0.841 Prec@(1,3) (93.3%, 99.9%), ce_loss 0.564, lat_loss 21.999
09/22 11:48:18 AM | Train: [153/180] Step 350/1249 Loss 0.823 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.563, lat_loss 21.999
09/22 11:48:42 AM | Train: [153/180] Step 400/1249 Loss 0.813 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.563, lat_loss 21.999
09/22 11:49:03 AM | Train: [153/180] Step 450/1249 Loss 0.809 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.563, lat_loss 21.999
09/22 11:49:27 AM | Train: [153/180] Step 500/1249 Loss 0.806 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.563, lat_loss 21.999
09/22 11:49:50 AM | Train: [153/180] Step 550/1249 Loss 0.798 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.563, lat_loss 21.999
09/22 11:50:15 AM | Train: [153/180] Step 600/1249 Loss 0.795 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.563, lat_loss 21.999
09/22 11:50:39 AM | Train: [153/180] Step 650/1249 Loss 0.791 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.563, lat_loss 21.999
09/22 11:51:04 AM | Train: [153/180] Step 700/1249 Loss 0.790 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.563, lat_loss 21.999
09/22 11:51:29 AM | Train: [153/180] Step 750/1249 Loss 0.791 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.563, lat_loss 21.999
09/22 11:51:54 AM | Train: [153/180] Step 800/1249 Loss 0.795 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.563, lat_loss 21.999
09/22 11:52:19 AM | Train: [153/180] Step 850/1249 Loss 0.801 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.563, lat_loss 21.999
09/22 11:52:44 AM | Train: [153/180] Step 900/1249 Loss 0.799 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.563, lat_loss 21.999
09/22 11:53:09 AM | Train: [153/180] Step 950/1249 Loss 0.803 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.563, lat_loss 21.999
09/22 11:53:34 AM | Train: [153/180] Step 1000/1249 Loss 0.813 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.563, lat_loss 21.999
09/22 11:53:59 AM | Train: [153/180] Step 1050/1249 Loss 0.811 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.563, lat_loss 21.999
09/22 11:54:24 AM | Train: [153/180] Step 1100/1249 Loss 0.821 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.562, lat_loss 21.999
09/22 11:54:49 AM | Train: [153/180] Step 1150/1249 Loss 0.823 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.562, lat_loss 21.999
09/22 11:55:13 AM | Train: [153/180] Step 1200/1249 Loss 0.827 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.562, lat_loss 21.999
09/22 11:55:38 AM | Train: [153/180] Step 1249/1249 Loss 0.832 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.562, lat_loss 21.999
09/22 11:55:38 AM | _w_step_train: [153/180] Final Prec@1 93.5025% Time 595.74
09/22 11:55:38 AM | Start to train theta for epoch 152
09/22 11:55:59 AM | Train: [153/180] Step 050/312 Loss 1.992 Prec@(1,3) (86.7%, 99.0%), ce_loss 0.562, lat_loss 22.000
09/22 11:56:19 AM | Train: [153/180] Step 100/312 Loss 2.099 Prec@(1,3) (86.0%, 99.0%), ce_loss 0.562, lat_loss 22.000
09/22 11:56:40 AM | Train: [153/180] Step 150/312 Loss 2.021 Prec@(1,3) (86.3%, 99.0%), ce_loss 0.562, lat_loss 22.000
09/22 11:57:00 AM | Train: [153/180] Step 200/312 Loss 2.022 Prec@(1,3) (86.2%, 99.1%), ce_loss 0.562, lat_loss 22.000
09/22 11:57:22 AM | Train: [153/180] Step 250/312 Loss 2.000 Prec@(1,3) (86.3%, 99.1%), ce_loss 0.562, lat_loss 22.000
09/22 11:57:42 AM | Train: [153/180] Step 300/312 Loss 1.992 Prec@(1,3) (86.2%, 99.1%), ce_loss 0.562, lat_loss 22.000
09/22 11:57:47 AM | Train: [153/180] Step 312/312 Loss 2.004 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.562, lat_loss 22.000
09/22 11:57:47 AM | _theta_step_train: [153/180] Final Prec@1 86.1200% Time 129.74
09/22 11:57:53 AM | Valid: [153/180] Step 050/312 Loss 2.029 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.562, lat_loss 22.000
09/22 11:57:57 AM | Valid: [153/180] Step 100/312 Loss 2.164 Prec@(1,3) (84.8%, 98.9%), ce_loss 0.562, lat_loss 22.000
09/22 11:58:02 AM | Valid: [153/180] Step 150/312 Loss 2.166 Prec@(1,3) (84.6%, 98.9%), ce_loss 0.562, lat_loss 22.000
09/22 11:58:07 AM | Valid: [153/180] Step 200/312 Loss 2.114 Prec@(1,3) (85.1%, 99.0%), ce_loss 0.562, lat_loss 22.000
09/22 11:58:12 AM | Valid: [153/180] Step 250/312 Loss 2.098 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.562, lat_loss 22.000
09/22 11:58:16 AM | Valid: [153/180] Step 300/312 Loss 2.065 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.562, lat_loss 22.000
09/22 11:58:17 AM | Valid: [153/180] Step 312/312 Loss 2.055 Prec@(1,3) (85.5%, 99.2%), ce_loss 0.562, lat_loss 22.000
09/22 11:58:17 AM | val: [153/180] Final Prec@1 85.4500% Time 29.94
09/22 11:58:17 AM | Start to train weights for epoch 153
09/22 11:58:44 AM | Train: [154/180] Step 050/1249 Loss 0.842 Prec@(1,3) (93.3%, 99.9%), ce_loss 0.562, lat_loss 22.000
09/22 11:59:08 AM | Train: [154/180] Step 100/1249 Loss 0.963 Prec@(1,3) (92.9%, 99.8%), ce_loss 0.562, lat_loss 22.000
09/22 11:59:29 AM | Train: [154/180] Step 150/1249 Loss 0.892 Prec@(1,3) (93.0%, 99.8%), ce_loss 0.562, lat_loss 22.000
09/22 11:59:52 AM | Train: [154/180] Step 200/1249 Loss 0.843 Prec@(1,3) (93.3%, 99.9%), ce_loss 0.562, lat_loss 22.000
09/22 12:00:16 PM | Train: [154/180] Step 250/1249 Loss 0.828 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.562, lat_loss 22.000
09/22 12:00:40 PM | Train: [154/180] Step 300/1249 Loss 0.839 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.562, lat_loss 22.000
09/22 12:01:05 PM | Train: [154/180] Step 350/1249 Loss 0.818 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.562, lat_loss 22.000
09/22 12:01:30 PM | Train: [154/180] Step 400/1249 Loss 0.828 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.562, lat_loss 22.000
09/22 12:01:54 PM | Train: [154/180] Step 450/1249 Loss 0.822 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.561, lat_loss 22.000
09/22 12:02:19 PM | Train: [154/180] Step 500/1249 Loss 0.817 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.561, lat_loss 22.000
09/22 12:02:43 PM | Train: [154/180] Step 550/1249 Loss 0.828 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.561, lat_loss 22.000
09/22 12:03:05 PM | Train: [154/180] Step 600/1249 Loss 0.826 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.561, lat_loss 22.000
09/22 12:03:29 PM | Train: [154/180] Step 650/1249 Loss 0.825 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.561, lat_loss 22.000
09/22 12:03:54 PM | Train: [154/180] Step 700/1249 Loss 0.825 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.561, lat_loss 22.000
09/22 12:04:18 PM | Train: [154/180] Step 750/1249 Loss 0.812 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.561, lat_loss 22.000
09/22 12:04:41 PM | Train: [154/180] Step 800/1249 Loss 0.811 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.561, lat_loss 22.000
09/22 12:05:03 PM | Train: [154/180] Step 850/1249 Loss 0.814 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.561, lat_loss 22.000
09/22 12:05:27 PM | Train: [154/180] Step 900/1249 Loss 0.828 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.561, lat_loss 22.000
09/22 12:05:51 PM | Train: [154/180] Step 950/1249 Loss 0.821 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.561, lat_loss 22.000
09/22 12:06:14 PM | Train: [154/180] Step 1000/1249 Loss 0.821 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.561, lat_loss 22.000
09/22 12:06:38 PM | Train: [154/180] Step 1050/1249 Loss 0.839 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.561, lat_loss 22.000
09/22 12:07:02 PM | Train: [154/180] Step 1100/1249 Loss 0.829 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.561, lat_loss 22.000
09/22 12:07:27 PM | Train: [154/180] Step 1150/1249 Loss 0.830 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.561, lat_loss 22.000
09/22 12:07:51 PM | Train: [154/180] Step 1200/1249 Loss 0.827 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.560, lat_loss 22.000
09/22 12:08:15 PM | Train: [154/180] Step 1249/1249 Loss 0.830 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.560, lat_loss 22.000
09/22 12:08:15 PM | _w_step_train: [154/180] Final Prec@1 93.4775% Time 598.13
09/22 12:08:15 PM | Start to train theta for epoch 153
09/22 12:08:37 PM | Train: [154/180] Step 050/312 Loss 2.051 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.560, lat_loss 22.000
09/22 12:08:57 PM | Train: [154/180] Step 100/312 Loss 1.889 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.560, lat_loss 22.000
09/22 12:09:18 PM | Train: [154/180] Step 150/312 Loss 1.963 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.560, lat_loss 22.000
09/22 12:09:39 PM | Train: [154/180] Step 200/312 Loss 1.943 Prec@(1,3) (86.8%, 99.3%), ce_loss 0.560, lat_loss 22.000
09/22 12:09:59 PM | Train: [154/180] Step 250/312 Loss 1.952 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.560, lat_loss 22.000
09/22 12:10:20 PM | Train: [154/180] Step 300/312 Loss 1.955 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.560, lat_loss 22.000
09/22 12:10:25 PM | Train: [154/180] Step 312/312 Loss 1.992 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.560, lat_loss 22.000
09/22 12:10:25 PM | _theta_step_train: [154/180] Final Prec@1 86.5100% Time 129.90
09/22 12:10:31 PM | Valid: [154/180] Step 050/312 Loss 2.234 Prec@(1,3) (84.4%, 98.3%), ce_loss 0.560, lat_loss 22.000
09/22 12:10:35 PM | Valid: [154/180] Step 100/312 Loss 2.395 Prec@(1,3) (83.2%, 98.6%), ce_loss 0.560, lat_loss 22.000
09/22 12:10:40 PM | Valid: [154/180] Step 150/312 Loss 2.287 Prec@(1,3) (84.0%, 98.8%), ce_loss 0.560, lat_loss 22.000
09/22 12:10:44 PM | Valid: [154/180] Step 200/312 Loss 2.178 Prec@(1,3) (84.7%, 98.8%), ce_loss 0.560, lat_loss 22.000
09/22 12:10:49 PM | Valid: [154/180] Step 250/312 Loss 2.134 Prec@(1,3) (84.9%, 99.0%), ce_loss 0.560, lat_loss 22.000
09/22 12:10:54 PM | Valid: [154/180] Step 300/312 Loss 2.052 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.560, lat_loss 22.000
09/22 12:10:55 PM | Valid: [154/180] Step 312/312 Loss 2.043 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.560, lat_loss 22.000
09/22 12:10:55 PM | val: [154/180] Final Prec@1 85.3400% Time 29.75
09/22 12:10:55 PM | Start to train weights for epoch 154
09/22 12:11:18 PM | Train: [155/180] Step 050/1249 Loss 0.851 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.560, lat_loss 22.000
09/22 12:11:39 PM | Train: [155/180] Step 100/1249 Loss 0.823 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.560, lat_loss 22.000
09/22 12:12:01 PM | Train: [155/180] Step 150/1249 Loss 0.810 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.560, lat_loss 22.000
09/22 12:12:22 PM | Train: [155/180] Step 200/1249 Loss 0.846 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.560, lat_loss 22.000
09/22 12:12:43 PM | Train: [155/180] Step 250/1249 Loss 0.845 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.560, lat_loss 22.000
09/22 12:13:04 PM | Train: [155/180] Step 300/1249 Loss 0.859 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.560, lat_loss 22.000
09/22 12:13:26 PM | Train: [155/180] Step 350/1249 Loss 0.854 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.560, lat_loss 22.000
09/22 12:13:47 PM | Train: [155/180] Step 400/1249 Loss 0.829 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.560, lat_loss 22.000
09/22 12:14:09 PM | Train: [155/180] Step 450/1249 Loss 0.826 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.560, lat_loss 22.000
09/22 12:14:30 PM | Train: [155/180] Step 500/1249 Loss 0.818 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.559, lat_loss 22.000
09/22 12:14:51 PM | Train: [155/180] Step 550/1249 Loss 0.804 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.559, lat_loss 22.000
09/22 12:15:13 PM | Train: [155/180] Step 600/1249 Loss 0.798 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.559, lat_loss 22.000
09/22 12:15:35 PM | Train: [155/180] Step 650/1249 Loss 0.814 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.559, lat_loss 22.000
09/22 12:16:00 PM | Train: [155/180] Step 700/1249 Loss 0.817 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.559, lat_loss 22.000
09/22 12:16:25 PM | Train: [155/180] Step 750/1249 Loss 0.809 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.559, lat_loss 22.000
09/22 12:16:50 PM | Train: [155/180] Step 800/1249 Loss 0.820 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.559, lat_loss 22.000
09/22 12:17:15 PM | Train: [155/180] Step 850/1249 Loss 0.813 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.559, lat_loss 22.000
09/22 12:17:39 PM | Train: [155/180] Step 900/1249 Loss 0.816 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.559, lat_loss 22.000
09/22 12:18:03 PM | Train: [155/180] Step 950/1249 Loss 0.813 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.559, lat_loss 22.000
09/22 12:18:25 PM | Train: [155/180] Step 1000/1249 Loss 0.815 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.559, lat_loss 22.000
09/22 12:18:47 PM | Train: [155/180] Step 1050/1249 Loss 0.818 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.559, lat_loss 22.000
09/22 12:19:09 PM | Train: [155/180] Step 1100/1249 Loss 0.818 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.559, lat_loss 22.000
09/22 12:19:31 PM | Train: [155/180] Step 1150/1249 Loss 0.829 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.559, lat_loss 22.000
09/22 12:19:54 PM | Train: [155/180] Step 1200/1249 Loss 0.826 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.559, lat_loss 22.000
09/22 12:20:19 PM | Train: [155/180] Step 1249/1249 Loss 0.822 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.559, lat_loss 22.000
09/22 12:20:19 PM | _w_step_train: [155/180] Final Prec@1 93.6000% Time 563.47
09/22 12:20:19 PM | Start to train theta for epoch 154
09/22 12:20:40 PM | Train: [155/180] Step 050/312 Loss 1.977 Prec@(1,3) (86.8%, 99.6%), ce_loss 0.558, lat_loss 22.000
09/22 12:21:00 PM | Train: [155/180] Step 100/312 Loss 2.098 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.558, lat_loss 22.001
09/22 12:21:18 PM | Train: [155/180] Step 150/312 Loss 2.041 Prec@(1,3) (86.3%, 99.2%), ce_loss 0.558, lat_loss 22.001
09/22 12:21:39 PM | Train: [155/180] Step 200/312 Loss 1.988 Prec@(1,3) (86.5%, 99.2%), ce_loss 0.558, lat_loss 22.001
09/22 12:21:58 PM | Train: [155/180] Step 250/312 Loss 1.979 Prec@(1,3) (86.6%, 99.2%), ce_loss 0.558, lat_loss 22.001
09/22 12:22:17 PM | Train: [155/180] Step 300/312 Loss 1.996 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.558, lat_loss 22.001
09/22 12:22:22 PM | Train: [155/180] Step 312/312 Loss 2.009 Prec@(1,3) (86.5%, 99.2%), ce_loss 0.558, lat_loss 22.001
09/22 12:22:22 PM | _theta_step_train: [155/180] Final Prec@1 86.5200% Time 123.56
09/22 12:22:28 PM | Valid: [155/180] Step 050/312 Loss 2.184 Prec@(1,3) (84.2%, 98.7%), ce_loss 0.558, lat_loss 22.001
09/22 12:22:32 PM | Valid: [155/180] Step 100/312 Loss 2.241 Prec@(1,3) (83.9%, 98.6%), ce_loss 0.558, lat_loss 22.001
09/22 12:22:37 PM | Valid: [155/180] Step 150/312 Loss 2.296 Prec@(1,3) (83.9%, 98.7%), ce_loss 0.558, lat_loss 22.001
09/22 12:22:42 PM | Valid: [155/180] Step 200/312 Loss 2.303 Prec@(1,3) (84.0%, 98.6%), ce_loss 0.558, lat_loss 22.001
09/22 12:22:47 PM | Valid: [155/180] Step 250/312 Loss 2.282 Prec@(1,3) (84.2%, 98.6%), ce_loss 0.558, lat_loss 22.001
09/22 12:22:51 PM | Valid: [155/180] Step 300/312 Loss 2.184 Prec@(1,3) (84.6%, 98.8%), ce_loss 0.558, lat_loss 22.001
09/22 12:22:52 PM | Valid: [155/180] Step 312/312 Loss 2.179 Prec@(1,3) (84.6%, 98.8%), ce_loss 0.558, lat_loss 22.001
09/22 12:22:52 PM | val: [155/180] Final Prec@1 84.6400% Time 30.17
09/22 12:22:52 PM | Start to train weights for epoch 155
09/22 12:23:10 PM | Train: [156/180] Step 050/1249 Loss 0.755 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.558, lat_loss 22.001
09/22 12:23:26 PM | Train: [156/180] Step 100/1249 Loss 0.721 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.558, lat_loss 22.001
09/22 12:23:42 PM | Train: [156/180] Step 150/1249 Loss 0.720 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.558, lat_loss 22.001
09/22 12:23:58 PM | Train: [156/180] Step 200/1249 Loss 0.736 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.558, lat_loss 22.001
09/22 12:24:14 PM | Train: [156/180] Step 250/1249 Loss 0.769 Prec@(1,3) (93.9%, 100.0%), ce_loss 0.558, lat_loss 22.001
09/22 12:24:31 PM | Train: [156/180] Step 300/1249 Loss 0.750 Prec@(1,3) (94.0%, 100.0%), ce_loss 0.558, lat_loss 22.001
09/22 12:24:47 PM | Train: [156/180] Step 350/1249 Loss 0.746 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.558, lat_loss 22.001
09/22 12:25:03 PM | Train: [156/180] Step 400/1249 Loss 0.743 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.558, lat_loss 22.001
09/22 12:25:19 PM | Train: [156/180] Step 450/1249 Loss 0.760 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.558, lat_loss 22.001
09/22 12:25:35 PM | Train: [156/180] Step 500/1249 Loss 0.753 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.558, lat_loss 22.001
09/22 12:25:51 PM | Train: [156/180] Step 550/1249 Loss 0.746 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.558, lat_loss 22.001
09/22 12:26:07 PM | Train: [156/180] Step 600/1249 Loss 0.750 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:26:23 PM | Train: [156/180] Step 650/1249 Loss 0.743 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:26:39 PM | Train: [156/180] Step 700/1249 Loss 0.737 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:27:03 PM | Train: [156/180] Step 750/1249 Loss 0.742 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:27:28 PM | Train: [156/180] Step 800/1249 Loss 0.754 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:27:54 PM | Train: [156/180] Step 850/1249 Loss 0.760 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:28:19 PM | Train: [156/180] Step 900/1249 Loss 0.774 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:28:44 PM | Train: [156/180] Step 950/1249 Loss 0.770 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:29:09 PM | Train: [156/180] Step 1000/1249 Loss 0.774 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:29:35 PM | Train: [156/180] Step 1050/1249 Loss 0.779 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:30:00 PM | Train: [156/180] Step 1100/1249 Loss 0.784 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:30:25 PM | Train: [156/180] Step 1150/1249 Loss 0.789 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:30:51 PM | Train: [156/180] Step 1200/1249 Loss 0.796 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:31:15 PM | Train: [156/180] Step 1249/1249 Loss 0.813 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:31:15 PM | _w_step_train: [156/180] Final Prec@1 93.7925% Time 502.77
09/22 12:31:15 PM | Start to train theta for epoch 155
09/22 12:31:28 PM | Train: [156/180] Step 050/312 Loss 2.209 Prec@(1,3) (85.7%, 98.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:31:41 PM | Train: [156/180] Step 100/312 Loss 2.070 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.557, lat_loss 22.001
09/22 12:31:53 PM | Train: [156/180] Step 150/312 Loss 1.991 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.557, lat_loss 22.001
09/22 12:32:05 PM | Train: [156/180] Step 200/312 Loss 2.065 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.557, lat_loss 22.001
09/22 12:32:17 PM | Train: [156/180] Step 250/312 Loss 2.069 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.557, lat_loss 22.001
09/22 12:32:33 PM | Train: [156/180] Step 300/312 Loss 2.040 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.557, lat_loss 22.001
09/22 12:32:38 PM | Train: [156/180] Step 312/312 Loss 2.035 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.557, lat_loss 22.001
09/22 12:32:38 PM | _theta_step_train: [156/180] Final Prec@1 86.2400% Time 83.22
09/22 12:32:44 PM | Valid: [156/180] Step 050/312 Loss 1.888 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.557, lat_loss 22.001
09/22 12:32:48 PM | Valid: [156/180] Step 100/312 Loss 2.029 Prec@(1,3) (85.6%, 99.0%), ce_loss 0.557, lat_loss 22.001
09/22 12:32:53 PM | Valid: [156/180] Step 150/312 Loss 2.157 Prec@(1,3) (84.7%, 98.9%), ce_loss 0.557, lat_loss 22.001
09/22 12:32:58 PM | Valid: [156/180] Step 200/312 Loss 2.112 Prec@(1,3) (85.2%, 99.0%), ce_loss 0.557, lat_loss 22.001
09/22 12:33:02 PM | Valid: [156/180] Step 250/312 Loss 2.105 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.557, lat_loss 22.001
09/22 12:33:07 PM | Valid: [156/180] Step 300/312 Loss 2.056 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.556, lat_loss 22.001
09/22 12:33:08 PM | Valid: [156/180] Step 312/312 Loss 2.042 Prec@(1,3) (85.5%, 99.2%), ce_loss 0.556, lat_loss 22.001
09/22 12:33:08 PM | val: [156/180] Final Prec@1 85.5000% Time 29.77
09/22 12:33:08 PM | Start to train weights for epoch 156
09/22 12:33:34 PM | Train: [157/180] Step 050/1249 Loss 0.791 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.556, lat_loss 22.001
09/22 12:33:58 PM | Train: [157/180] Step 100/1249 Loss 0.799 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.556, lat_loss 22.001
09/22 12:34:22 PM | Train: [157/180] Step 150/1249 Loss 0.775 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.556, lat_loss 22.001
09/22 12:34:46 PM | Train: [157/180] Step 200/1249 Loss 0.782 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.556, lat_loss 22.001
09/22 12:35:10 PM | Train: [157/180] Step 250/1249 Loss 0.762 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.556, lat_loss 22.001
09/22 12:35:33 PM | Train: [157/180] Step 300/1249 Loss 0.788 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.556, lat_loss 22.001
09/22 12:35:57 PM | Train: [157/180] Step 350/1249 Loss 0.804 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.556, lat_loss 22.001
09/22 12:36:20 PM | Train: [157/180] Step 400/1249 Loss 0.787 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.556, lat_loss 22.001
09/22 12:36:44 PM | Train: [157/180] Step 450/1249 Loss 0.792 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.556, lat_loss 22.001
09/22 12:37:08 PM | Train: [157/180] Step 500/1249 Loss 0.792 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.556, lat_loss 22.001
09/22 12:37:32 PM | Train: [157/180] Step 550/1249 Loss 0.804 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.556, lat_loss 22.001
09/22 12:37:55 PM | Train: [157/180] Step 600/1249 Loss 0.830 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.556, lat_loss 22.001
09/22 12:38:20 PM | Train: [157/180] Step 650/1249 Loss 0.824 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.556, lat_loss 22.001
09/22 12:38:44 PM | Train: [157/180] Step 700/1249 Loss 0.822 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.556, lat_loss 22.001
09/22 12:39:08 PM | Train: [157/180] Step 750/1249 Loss 0.828 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.556, lat_loss 22.001
09/22 12:39:32 PM | Train: [157/180] Step 800/1249 Loss 0.823 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.555, lat_loss 22.001
09/22 12:39:56 PM | Train: [157/180] Step 850/1249 Loss 0.821 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.555, lat_loss 22.001
09/22 12:40:20 PM | Train: [157/180] Step 900/1249 Loss 0.816 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.555, lat_loss 22.001
09/22 12:40:45 PM | Train: [157/180] Step 950/1249 Loss 0.814 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.555, lat_loss 22.001
09/22 12:41:09 PM | Train: [157/180] Step 1000/1249 Loss 0.814 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.555, lat_loss 22.001
09/22 12:41:33 PM | Train: [157/180] Step 1050/1249 Loss 0.809 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.555, lat_loss 22.001
09/22 12:41:57 PM | Train: [157/180] Step 1100/1249 Loss 0.803 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.555, lat_loss 22.001
09/22 12:42:19 PM | Train: [157/180] Step 1150/1249 Loss 0.807 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.555, lat_loss 22.001
09/22 12:42:42 PM | Train: [157/180] Step 1200/1249 Loss 0.807 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.555, lat_loss 22.001
09/22 12:43:06 PM | Train: [157/180] Step 1249/1249 Loss 0.805 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.555, lat_loss 22.001
09/22 12:43:06 PM | _w_step_train: [157/180] Final Prec@1 93.7150% Time 598.14
09/22 12:43:06 PM | Start to train theta for epoch 156
09/22 12:43:28 PM | Train: [157/180] Step 050/312 Loss 1.906 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.555, lat_loss 22.001
09/22 12:43:49 PM | Train: [157/180] Step 100/312 Loss 1.877 Prec@(1,3) (87.4%, 99.4%), ce_loss 0.555, lat_loss 22.002
09/22 12:44:10 PM | Train: [157/180] Step 150/312 Loss 1.845 Prec@(1,3) (87.8%, 99.3%), ce_loss 0.555, lat_loss 22.002
09/22 12:44:30 PM | Train: [157/180] Step 200/312 Loss 1.881 Prec@(1,3) (87.3%, 99.4%), ce_loss 0.555, lat_loss 22.002
09/22 12:44:51 PM | Train: [157/180] Step 250/312 Loss 1.940 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.555, lat_loss 22.002
09/22 12:45:12 PM | Train: [157/180] Step 300/312 Loss 1.943 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.555, lat_loss 22.002
09/22 12:45:17 PM | Train: [157/180] Step 312/312 Loss 1.944 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.555, lat_loss 22.002
09/22 12:45:17 PM | _theta_step_train: [157/180] Final Prec@1 86.8300% Time 130.56
09/22 12:45:22 PM | Valid: [157/180] Step 050/312 Loss 1.828 Prec@(1,3) (86.8%, 99.3%), ce_loss 0.555, lat_loss 22.002
09/22 12:45:26 PM | Valid: [157/180] Step 100/312 Loss 1.982 Prec@(1,3) (85.9%, 99.0%), ce_loss 0.555, lat_loss 22.002
09/22 12:45:30 PM | Valid: [157/180] Step 150/312 Loss 2.229 Prec@(1,3) (84.5%, 98.6%), ce_loss 0.555, lat_loss 22.002
09/22 12:45:34 PM | Valid: [157/180] Step 200/312 Loss 2.116 Prec@(1,3) (85.3%, 98.7%), ce_loss 0.555, lat_loss 22.002
09/22 12:45:39 PM | Valid: [157/180] Step 250/312 Loss 2.168 Prec@(1,3) (85.0%, 98.7%), ce_loss 0.555, lat_loss 22.002
09/22 12:45:44 PM | Valid: [157/180] Step 300/312 Loss 2.162 Prec@(1,3) (84.9%, 98.7%), ce_loss 0.555, lat_loss 22.002
09/22 12:45:45 PM | Valid: [157/180] Step 312/312 Loss 2.160 Prec@(1,3) (84.9%, 98.7%), ce_loss 0.555, lat_loss 22.002
09/22 12:45:45 PM | val: [157/180] Final Prec@1 84.8700% Time 28.12
09/22 12:45:45 PM | Start to train weights for epoch 157
09/22 12:46:11 PM | Train: [158/180] Step 050/1249 Loss 0.761 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.555, lat_loss 22.002
09/22 12:46:37 PM | Train: [158/180] Step 100/1249 Loss 0.722 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.555, lat_loss 22.002
09/22 12:47:03 PM | Train: [158/180] Step 150/1249 Loss 0.724 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.554, lat_loss 22.002
09/22 12:47:29 PM | Train: [158/180] Step 200/1249 Loss 0.771 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.554, lat_loss 22.002
09/22 12:47:56 PM | Train: [158/180] Step 250/1249 Loss 0.768 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.554, lat_loss 22.002
09/22 12:48:22 PM | Train: [158/180] Step 300/1249 Loss 0.744 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.554, lat_loss 22.002
09/22 12:48:48 PM | Train: [158/180] Step 350/1249 Loss 0.752 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.554, lat_loss 22.002
09/22 12:49:13 PM | Train: [158/180] Step 400/1249 Loss 0.749 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.554, lat_loss 22.002
09/22 12:49:39 PM | Train: [158/180] Step 450/1249 Loss 0.760 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.554, lat_loss 22.002
09/22 12:50:04 PM | Train: [158/180] Step 500/1249 Loss 0.753 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.554, lat_loss 22.002
09/22 12:50:29 PM | Train: [158/180] Step 550/1249 Loss 0.788 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.554, lat_loss 22.002
09/22 12:50:54 PM | Train: [158/180] Step 600/1249 Loss 0.791 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.554, lat_loss 22.002
09/22 12:51:21 PM | Train: [158/180] Step 650/1249 Loss 0.799 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.554, lat_loss 22.002
09/22 12:51:47 PM | Train: [158/180] Step 700/1249 Loss 0.798 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.554, lat_loss 22.002
09/22 12:52:14 PM | Train: [158/180] Step 750/1249 Loss 0.812 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.554, lat_loss 22.002
09/22 12:52:40 PM | Train: [158/180] Step 800/1249 Loss 0.815 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.554, lat_loss 22.002
09/22 12:53:07 PM | Train: [158/180] Step 850/1249 Loss 0.805 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.554, lat_loss 22.002
09/22 12:53:33 PM | Train: [158/180] Step 900/1249 Loss 0.804 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.553, lat_loss 22.002
09/22 12:53:59 PM | Train: [158/180] Step 950/1249 Loss 0.822 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.553, lat_loss 22.002
09/22 12:54:26 PM | Train: [158/180] Step 1000/1249 Loss 0.819 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.553, lat_loss 22.002
09/22 12:54:53 PM | Train: [158/180] Step 1050/1249 Loss 0.820 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.553, lat_loss 22.002
09/22 12:55:19 PM | Train: [158/180] Step 1100/1249 Loss 0.825 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.553, lat_loss 22.002
09/22 12:55:46 PM | Train: [158/180] Step 1150/1249 Loss 0.827 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.553, lat_loss 22.002
09/22 12:56:12 PM | Train: [158/180] Step 1200/1249 Loss 0.822 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.553, lat_loss 22.002
09/22 12:56:36 PM | Train: [158/180] Step 1249/1249 Loss 0.821 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.553, lat_loss 22.002
09/22 12:56:36 PM | _w_step_train: [158/180] Final Prec@1 93.7100% Time 651.25
09/22 12:56:36 PM | Start to train theta for epoch 157
09/22 12:56:58 PM | Train: [158/180] Step 050/312 Loss 2.279 Prec@(1,3) (85.3%, 98.8%), ce_loss 0.553, lat_loss 22.002
09/22 12:57:18 PM | Train: [158/180] Step 100/312 Loss 2.124 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.553, lat_loss 22.002
09/22 12:57:39 PM | Train: [158/180] Step 150/312 Loss 2.132 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.553, lat_loss 22.002
09/22 12:58:00 PM | Train: [158/180] Step 200/312 Loss 2.032 Prec@(1,3) (86.4%, 99.3%), ce_loss 0.553, lat_loss 22.002
09/22 12:58:20 PM | Train: [158/180] Step 250/312 Loss 2.013 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.553, lat_loss 22.002
09/22 12:58:40 PM | Train: [158/180] Step 300/312 Loss 2.028 Prec@(1,3) (86.4%, 99.3%), ce_loss 0.553, lat_loss 22.002
09/22 12:58:46 PM | Train: [158/180] Step 312/312 Loss 2.012 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.553, lat_loss 22.002
09/22 12:58:46 PM | _theta_step_train: [158/180] Final Prec@1 86.4800% Time 129.23
09/22 12:58:51 PM | Valid: [158/180] Step 050/312 Loss 1.974 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.553, lat_loss 22.002
09/22 12:58:56 PM | Valid: [158/180] Step 100/312 Loss 2.147 Prec@(1,3) (84.8%, 98.9%), ce_loss 0.553, lat_loss 22.002
09/22 12:59:00 PM | Valid: [158/180] Step 150/312 Loss 2.235 Prec@(1,3) (84.5%, 98.8%), ce_loss 0.553, lat_loss 22.002
09/22 12:59:05 PM | Valid: [158/180] Step 200/312 Loss 2.117 Prec@(1,3) (85.4%, 99.0%), ce_loss 0.553, lat_loss 22.002
09/22 12:59:10 PM | Valid: [158/180] Step 250/312 Loss 2.132 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.553, lat_loss 22.002
09/22 12:59:14 PM | Valid: [158/180] Step 300/312 Loss 2.075 Prec@(1,3) (85.5%, 99.1%), ce_loss 0.553, lat_loss 22.002
09/22 12:59:15 PM | Valid: [158/180] Step 312/312 Loss 2.065 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.553, lat_loss 22.002
09/22 12:59:15 PM | val: [158/180] Final Prec@1 85.6300% Time 29.88
09/22 12:59:16 PM | Start to train weights for epoch 158
09/22 12:59:42 PM | Train: [159/180] Step 050/1249 Loss 0.696 Prec@(1,3) (95.0%, 99.9%), ce_loss 0.553, lat_loss 22.002
09/22 01:00:06 PM | Train: [159/180] Step 100/1249 Loss 0.748 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.553, lat_loss 22.002
09/22 01:00:30 PM | Train: [159/180] Step 150/1249 Loss 0.738 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.553, lat_loss 22.002
09/22 01:00:55 PM | Train: [159/180] Step 200/1249 Loss 0.748 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.553, lat_loss 22.002
09/22 01:01:19 PM | Train: [159/180] Step 250/1249 Loss 0.718 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.553, lat_loss 22.002
09/22 01:01:43 PM | Train: [159/180] Step 300/1249 Loss 0.722 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:02:07 PM | Train: [159/180] Step 350/1249 Loss 0.760 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:02:31 PM | Train: [159/180] Step 400/1249 Loss 0.759 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:02:55 PM | Train: [159/180] Step 450/1249 Loss 0.753 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:03:18 PM | Train: [159/180] Step 500/1249 Loss 0.741 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:03:42 PM | Train: [159/180] Step 550/1249 Loss 0.754 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:04:05 PM | Train: [159/180] Step 600/1249 Loss 0.757 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:04:29 PM | Train: [159/180] Step 650/1249 Loss 0.786 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:04:54 PM | Train: [159/180] Step 700/1249 Loss 0.788 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:05:18 PM | Train: [159/180] Step 750/1249 Loss 0.798 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:05:42 PM | Train: [159/180] Step 800/1249 Loss 0.785 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:06:05 PM | Train: [159/180] Step 850/1249 Loss 0.790 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:06:29 PM | Train: [159/180] Step 900/1249 Loss 0.786 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:06:54 PM | Train: [159/180] Step 950/1249 Loss 0.787 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:07:18 PM | Train: [159/180] Step 1000/1249 Loss 0.786 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:07:42 PM | Train: [159/180] Step 1050/1249 Loss 0.783 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.552, lat_loss 22.002
09/22 01:08:05 PM | Train: [159/180] Step 1100/1249 Loss 0.786 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.551, lat_loss 22.002
09/22 01:08:29 PM | Train: [159/180] Step 1150/1249 Loss 0.787 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.551, lat_loss 22.002
09/22 01:08:53 PM | Train: [159/180] Step 1200/1249 Loss 0.787 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.551, lat_loss 22.002
09/22 01:09:17 PM | Train: [159/180] Step 1249/1249 Loss 0.791 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.551, lat_loss 22.002
09/22 01:09:17 PM | _w_step_train: [159/180] Final Prec@1 93.9375% Time 601.25
09/22 01:09:17 PM | Start to train theta for epoch 158
09/22 01:09:39 PM | Train: [159/180] Step 050/312 Loss 1.839 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.551, lat_loss 22.002
09/22 01:09:59 PM | Train: [159/180] Step 100/312 Loss 1.878 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.551, lat_loss 22.002
09/22 01:10:20 PM | Train: [159/180] Step 150/312 Loss 1.952 Prec@(1,3) (86.9%, 99.5%), ce_loss 0.551, lat_loss 22.002
09/22 01:10:40 PM | Train: [159/180] Step 200/312 Loss 1.891 Prec@(1,3) (87.2%, 99.5%), ce_loss 0.551, lat_loss 22.002
09/22 01:11:00 PM | Train: [159/180] Step 250/312 Loss 1.892 Prec@(1,3) (87.2%, 99.5%), ce_loss 0.551, lat_loss 22.002
09/22 01:11:21 PM | Train: [159/180] Step 300/312 Loss 1.935 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.551, lat_loss 22.002
09/22 01:11:26 PM | Train: [159/180] Step 312/312 Loss 1.948 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.551, lat_loss 22.002
09/22 01:11:26 PM | _theta_step_train: [159/180] Final Prec@1 86.9800% Time 128.92
09/22 01:11:32 PM | Valid: [159/180] Step 050/312 Loss 2.010 Prec@(1,3) (85.0%, 99.1%), ce_loss 0.551, lat_loss 22.002
09/22 01:11:37 PM | Valid: [159/180] Step 100/312 Loss 2.022 Prec@(1,3) (85.7%, 99.0%), ce_loss 0.551, lat_loss 22.002
09/22 01:11:41 PM | Valid: [159/180] Step 150/312 Loss 2.187 Prec@(1,3) (85.1%, 99.0%), ce_loss 0.551, lat_loss 22.002
09/22 01:11:46 PM | Valid: [159/180] Step 200/312 Loss 2.133 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.551, lat_loss 22.002
09/22 01:11:51 PM | Valid: [159/180] Step 250/312 Loss 2.154 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.551, lat_loss 22.002
09/22 01:11:55 PM | Valid: [159/180] Step 300/312 Loss 2.107 Prec@(1,3) (85.5%, 99.1%), ce_loss 0.551, lat_loss 22.002
09/22 01:11:56 PM | Valid: [159/180] Step 312/312 Loss 2.161 Prec@(1,3) (85.2%, 99.0%), ce_loss 0.551, lat_loss 22.002
09/22 01:11:56 PM | val: [159/180] Final Prec@1 85.1700% Time 30.37
09/22 01:11:56 PM | Start to train weights for epoch 159
09/22 01:12:23 PM | Train: [160/180] Step 050/1249 Loss 0.698 Prec@(1,3) (94.4%, 100.0%), ce_loss 0.551, lat_loss 22.002
09/22 01:12:47 PM | Train: [160/180] Step 100/1249 Loss 0.700 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.551, lat_loss 22.002
09/22 01:13:11 PM | Train: [160/180] Step 150/1249 Loss 0.764 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.551, lat_loss 22.002
09/22 01:13:34 PM | Train: [160/180] Step 200/1249 Loss 0.756 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.551, lat_loss 22.003
09/22 01:13:59 PM | Train: [160/180] Step 250/1249 Loss 0.752 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.551, lat_loss 22.003
09/22 01:14:23 PM | Train: [160/180] Step 300/1249 Loss 0.731 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.551, lat_loss 22.003
09/22 01:14:46 PM | Train: [160/180] Step 350/1249 Loss 0.748 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.551, lat_loss 22.003
09/22 01:15:08 PM | Train: [160/180] Step 400/1249 Loss 0.728 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.551, lat_loss 22.003
09/22 01:15:31 PM | Train: [160/180] Step 450/1249 Loss 0.739 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:15:52 PM | Train: [160/180] Step 500/1249 Loss 0.732 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:16:14 PM | Train: [160/180] Step 550/1249 Loss 0.742 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:16:36 PM | Train: [160/180] Step 600/1249 Loss 0.730 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:16:57 PM | Train: [160/180] Step 650/1249 Loss 0.731 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:17:20 PM | Train: [160/180] Step 700/1249 Loss 0.733 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:17:42 PM | Train: [160/180] Step 750/1249 Loss 0.742 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:18:05 PM | Train: [160/180] Step 800/1249 Loss 0.743 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:18:27 PM | Train: [160/180] Step 850/1249 Loss 0.758 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:18:50 PM | Train: [160/180] Step 900/1249 Loss 0.758 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:19:11 PM | Train: [160/180] Step 950/1249 Loss 0.768 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:19:33 PM | Train: [160/180] Step 1000/1249 Loss 0.773 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:19:54 PM | Train: [160/180] Step 1050/1249 Loss 0.770 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:20:16 PM | Train: [160/180] Step 1100/1249 Loss 0.767 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:20:37 PM | Train: [160/180] Step 1150/1249 Loss 0.762 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:21:00 PM | Train: [160/180] Step 1200/1249 Loss 0.759 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.550, lat_loss 22.003
09/22 01:21:24 PM | Train: [160/180] Step 1249/1249 Loss 0.753 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.549, lat_loss 22.003
09/22 01:21:24 PM | _w_step_train: [160/180] Final Prec@1 94.1525% Time 567.96
09/22 01:21:24 PM | Start to train theta for epoch 159
09/22 01:21:43 PM | Train: [160/180] Step 050/312 Loss 2.042 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.549, lat_loss 22.003
09/22 01:21:59 PM | Train: [160/180] Step 100/312 Loss 2.026 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.549, lat_loss 22.003
09/22 01:22:15 PM | Train: [160/180] Step 150/312 Loss 1.946 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.549, lat_loss 22.003
09/22 01:22:32 PM | Train: [160/180] Step 200/312 Loss 1.959 Prec@(1,3) (86.7%, 99.3%), ce_loss 0.549, lat_loss 22.003
09/22 01:22:50 PM | Train: [160/180] Step 250/312 Loss 1.994 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.549, lat_loss 22.003
09/22 01:23:09 PM | Train: [160/180] Step 300/312 Loss 1.996 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.549, lat_loss 22.003
09/22 01:23:14 PM | Train: [160/180] Step 312/312 Loss 1.966 Prec@(1,3) (86.8%, 99.3%), ce_loss 0.549, lat_loss 22.003
09/22 01:23:14 PM | _theta_step_train: [160/180] Final Prec@1 86.7500% Time 109.82
09/22 01:23:19 PM | Valid: [160/180] Step 050/312 Loss 1.936 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.549, lat_loss 22.003
09/22 01:23:24 PM | Valid: [160/180] Step 100/312 Loss 2.027 Prec@(1,3) (85.5%, 99.2%), ce_loss 0.549, lat_loss 22.003
09/22 01:23:29 PM | Valid: [160/180] Step 150/312 Loss 2.061 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.549, lat_loss 22.003
09/22 01:23:33 PM | Valid: [160/180] Step 200/312 Loss 1.989 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.549, lat_loss 22.003
09/22 01:23:38 PM | Valid: [160/180] Step 250/312 Loss 2.001 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.549, lat_loss 22.003
09/22 01:23:43 PM | Valid: [160/180] Step 300/312 Loss 1.984 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.549, lat_loss 22.003
09/22 01:23:44 PM | Valid: [160/180] Step 312/312 Loss 1.977 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.549, lat_loss 22.003
09/22 01:23:44 PM | val: [160/180] Final Prec@1 85.9400% Time 29.56
09/22 01:23:44 PM | Start to train weights for epoch 160
09/22 01:24:07 PM | Train: [161/180] Step 050/1249 Loss 0.778 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.549, lat_loss 22.003
09/22 01:24:28 PM | Train: [161/180] Step 100/1249 Loss 0.806 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.549, lat_loss 22.003
09/22 01:24:49 PM | Train: [161/180] Step 150/1249 Loss 0.766 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.549, lat_loss 22.003
09/22 01:25:12 PM | Train: [161/180] Step 200/1249 Loss 0.735 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.549, lat_loss 22.003
09/22 01:25:36 PM | Train: [161/180] Step 250/1249 Loss 0.717 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.549, lat_loss 22.003
09/22 01:26:01 PM | Train: [161/180] Step 300/1249 Loss 0.734 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.549, lat_loss 22.003
09/22 01:26:25 PM | Train: [161/180] Step 350/1249 Loss 0.719 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.549, lat_loss 22.003
09/22 01:26:50 PM | Train: [161/180] Step 400/1249 Loss 0.718 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.549, lat_loss 22.003
09/22 01:27:15 PM | Train: [161/180] Step 450/1249 Loss 0.716 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.549, lat_loss 22.003
09/22 01:27:40 PM | Train: [161/180] Step 500/1249 Loss 0.720 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.549, lat_loss 22.003
09/22 01:28:05 PM | Train: [161/180] Step 550/1249 Loss 0.719 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.549, lat_loss 22.003
09/22 01:28:30 PM | Train: [161/180] Step 600/1249 Loss 0.714 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.548, lat_loss 22.003
09/22 01:28:55 PM | Train: [161/180] Step 650/1249 Loss 0.724 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.548, lat_loss 22.003
09/22 01:29:20 PM | Train: [161/180] Step 700/1249 Loss 0.745 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.548, lat_loss 22.003
09/22 01:29:44 PM | Train: [161/180] Step 750/1249 Loss 0.751 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.548, lat_loss 22.003
09/22 01:30:09 PM | Train: [161/180] Step 800/1249 Loss 0.751 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.548, lat_loss 22.003
09/22 01:30:34 PM | Train: [161/180] Step 850/1249 Loss 0.745 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.548, lat_loss 22.003
09/22 01:30:59 PM | Train: [161/180] Step 900/1249 Loss 0.740 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.548, lat_loss 22.003
09/22 01:31:24 PM | Train: [161/180] Step 950/1249 Loss 0.743 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.548, lat_loss 22.003
09/22 01:31:49 PM | Train: [161/180] Step 1000/1249 Loss 0.754 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.548, lat_loss 22.003
09/22 01:32:13 PM | Train: [161/180] Step 1050/1249 Loss 0.754 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.548, lat_loss 22.003
09/22 01:32:37 PM | Train: [161/180] Step 1100/1249 Loss 0.750 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.548, lat_loss 22.003
09/22 01:33:02 PM | Train: [161/180] Step 1150/1249 Loss 0.751 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.548, lat_loss 22.003
09/22 01:33:26 PM | Train: [161/180] Step 1200/1249 Loss 0.776 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.548, lat_loss 22.003
09/22 01:33:50 PM | Train: [161/180] Step 1249/1249 Loss 0.776 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.548, lat_loss 22.003
09/22 01:33:51 PM | _w_step_train: [161/180] Final Prec@1 94.0525% Time 606.64
09/22 01:33:51 PM | Start to train theta for epoch 160
09/22 01:34:09 PM | Train: [161/180] Step 050/312 Loss 2.022 Prec@(1,3) (87.1%, 99.0%), ce_loss 0.548, lat_loss 22.003
09/22 01:34:27 PM | Train: [161/180] Step 100/312 Loss 1.968 Prec@(1,3) (87.0%, 99.2%), ce_loss 0.548, lat_loss 22.003
09/22 01:34:43 PM | Train: [161/180] Step 150/312 Loss 1.947 Prec@(1,3) (86.9%, 99.3%), ce_loss 0.548, lat_loss 22.003
09/22 01:35:00 PM | Train: [161/180] Step 200/312 Loss 2.034 Prec@(1,3) (86.6%, 99.2%), ce_loss 0.548, lat_loss 22.003
09/22 01:35:20 PM | Train: [161/180] Step 250/312 Loss 2.019 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.548, lat_loss 22.003
09/22 01:35:41 PM | Train: [161/180] Step 300/312 Loss 2.003 Prec@(1,3) (86.7%, 99.3%), ce_loss 0.548, lat_loss 22.003
09/22 01:35:46 PM | Train: [161/180] Step 312/312 Loss 1.987 Prec@(1,3) (86.8%, 99.3%), ce_loss 0.548, lat_loss 22.003
09/22 01:35:46 PM | _theta_step_train: [161/180] Final Prec@1 86.7900% Time 115.19
09/22 01:35:51 PM | Valid: [161/180] Step 050/312 Loss 1.754 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.548, lat_loss 22.003
09/22 01:35:56 PM | Valid: [161/180] Step 100/312 Loss 2.035 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.548, lat_loss 22.003
09/22 01:36:00 PM | Valid: [161/180] Step 150/312 Loss 2.081 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.548, lat_loss 22.003
09/22 01:36:05 PM | Valid: [161/180] Step 200/312 Loss 2.067 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.547, lat_loss 22.003
09/22 01:36:10 PM | Valid: [161/180] Step 250/312 Loss 2.143 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.548, lat_loss 22.003
09/22 01:36:14 PM | Valid: [161/180] Step 300/312 Loss 2.113 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.547, lat_loss 22.003
09/22 01:36:15 PM | Valid: [161/180] Step 312/312 Loss 2.107 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.547, lat_loss 22.003
09/22 01:36:15 PM | val: [161/180] Final Prec@1 85.2900% Time 29.61
09/22 01:36:15 PM | Start to train weights for epoch 161
09/22 01:36:41 PM | Train: [162/180] Step 050/1249 Loss 1.069 Prec@(1,3) (92.5%, 99.4%), ce_loss 0.547, lat_loss 22.003
09/22 01:37:06 PM | Train: [162/180] Step 100/1249 Loss 0.986 Prec@(1,3) (92.9%, 99.6%), ce_loss 0.547, lat_loss 22.003
09/22 01:37:30 PM | Train: [162/180] Step 150/1249 Loss 0.855 Prec@(1,3) (93.8%, 99.7%), ce_loss 0.547, lat_loss 22.003
09/22 01:37:55 PM | Train: [162/180] Step 200/1249 Loss 0.824 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.547, lat_loss 22.003
09/22 01:38:20 PM | Train: [162/180] Step 250/1249 Loss 0.813 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.547, lat_loss 22.003
09/22 01:38:45 PM | Train: [162/180] Step 300/1249 Loss 0.800 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.547, lat_loss 22.003
09/22 01:39:09 PM | Train: [162/180] Step 350/1249 Loss 0.770 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.547, lat_loss 22.003
09/22 01:39:34 PM | Train: [162/180] Step 400/1249 Loss 0.770 Prec@(1,3) (94.2%, 99.8%), ce_loss 0.547, lat_loss 22.003
09/22 01:39:59 PM | Train: [162/180] Step 450/1249 Loss 0.761 Prec@(1,3) (94.2%, 99.8%), ce_loss 0.547, lat_loss 22.003
09/22 01:40:23 PM | Train: [162/180] Step 500/1249 Loss 0.751 Prec@(1,3) (94.3%, 99.8%), ce_loss 0.547, lat_loss 22.003
09/22 01:40:49 PM | Train: [162/180] Step 550/1249 Loss 0.753 Prec@(1,3) (94.3%, 99.8%), ce_loss 0.547, lat_loss 22.003
09/22 01:41:14 PM | Train: [162/180] Step 600/1249 Loss 0.744 Prec@(1,3) (94.3%, 99.8%), ce_loss 0.547, lat_loss 22.003
09/22 01:41:39 PM | Train: [162/180] Step 650/1249 Loss 0.743 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.547, lat_loss 22.003
09/22 01:42:04 PM | Train: [162/180] Step 700/1249 Loss 0.740 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.547, lat_loss 22.003
09/22 01:42:28 PM | Train: [162/180] Step 750/1249 Loss 0.744 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.547, lat_loss 22.003
09/22 01:42:44 PM | Train: [162/180] Step 800/1249 Loss 0.744 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.546, lat_loss 22.003
09/22 01:43:00 PM | Train: [162/180] Step 850/1249 Loss 0.742 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.546, lat_loss 22.003
09/22 01:43:16 PM | Train: [162/180] Step 900/1249 Loss 0.740 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.546, lat_loss 22.003
09/22 01:43:32 PM | Train: [162/180] Step 950/1249 Loss 0.739 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.546, lat_loss 22.003
09/22 01:43:48 PM | Train: [162/180] Step 1000/1249 Loss 0.735 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.546, lat_loss 22.003
09/22 01:44:04 PM | Train: [162/180] Step 1050/1249 Loss 0.738 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.546, lat_loss 22.003
09/22 01:44:20 PM | Train: [162/180] Step 1100/1249 Loss 0.737 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.546, lat_loss 22.003
09/22 01:44:36 PM | Train: [162/180] Step 1150/1249 Loss 0.738 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.546, lat_loss 22.003
09/22 01:44:52 PM | Train: [162/180] Step 1200/1249 Loss 0.736 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.546, lat_loss 22.003
09/22 01:45:08 PM | Train: [162/180] Step 1249/1249 Loss 0.740 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.546, lat_loss 22.003
09/22 01:45:08 PM | _w_step_train: [162/180] Final Prec@1 94.3250% Time 532.58
09/22 01:45:08 PM | Start to train theta for epoch 161
09/22 01:45:29 PM | Train: [162/180] Step 050/312 Loss 2.160 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.546, lat_loss 22.003
09/22 01:45:48 PM | Train: [162/180] Step 100/312 Loss 2.129 Prec@(1,3) (86.3%, 99.2%), ce_loss 0.546, lat_loss 22.003
09/22 01:46:08 PM | Train: [162/180] Step 150/312 Loss 2.209 Prec@(1,3) (85.5%, 99.0%), ce_loss 0.546, lat_loss 22.003
09/22 01:46:28 PM | Train: [162/180] Step 200/312 Loss 2.131 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.546, lat_loss 22.003
09/22 01:46:46 PM | Train: [162/180] Step 250/312 Loss 2.077 Prec@(1,3) (86.2%, 99.1%), ce_loss 0.546, lat_loss 22.003
09/22 01:47:06 PM | Train: [162/180] Step 300/312 Loss 2.033 Prec@(1,3) (86.6%, 99.2%), ce_loss 0.546, lat_loss 22.003
09/22 01:47:11 PM | Train: [162/180] Step 312/312 Loss 2.027 Prec@(1,3) (86.7%, 99.2%), ce_loss 0.546, lat_loss 22.003
09/22 01:47:11 PM | _theta_step_train: [162/180] Final Prec@1 86.6600% Time 123.13
09/22 01:47:16 PM | Valid: [162/180] Step 050/312 Loss 2.174 Prec@(1,3) (84.4%, 98.9%), ce_loss 0.546, lat_loss 22.003
09/22 01:47:21 PM | Valid: [162/180] Step 100/312 Loss 2.200 Prec@(1,3) (84.8%, 98.8%), ce_loss 0.546, lat_loss 22.003
09/22 01:47:26 PM | Valid: [162/180] Step 150/312 Loss 2.214 Prec@(1,3) (84.8%, 98.9%), ce_loss 0.546, lat_loss 22.003
09/22 01:47:30 PM | Valid: [162/180] Step 200/312 Loss 2.124 Prec@(1,3) (85.4%, 99.0%), ce_loss 0.546, lat_loss 22.003
09/22 01:47:35 PM | Valid: [162/180] Step 250/312 Loss 2.084 Prec@(1,3) (85.5%, 99.1%), ce_loss 0.546, lat_loss 22.003
09/22 01:47:40 PM | Valid: [162/180] Step 300/312 Loss 2.038 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.546, lat_loss 22.004
09/22 01:47:41 PM | Valid: [162/180] Step 312/312 Loss 2.024 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.546, lat_loss 22.004
09/22 01:47:41 PM | val: [162/180] Final Prec@1 85.7800% Time 30.03
09/22 01:47:41 PM | Start to train weights for epoch 162
09/22 01:48:06 PM | Train: [163/180] Step 050/1249 Loss 0.639 Prec@(1,3) (94.7%, 99.9%), ce_loss 0.546, lat_loss 22.004
09/22 01:48:27 PM | Train: [163/180] Step 100/1249 Loss 0.654 Prec@(1,3) (94.7%, 99.9%), ce_loss 0.546, lat_loss 22.004
09/22 01:48:52 PM | Train: [163/180] Step 150/1249 Loss 0.665 Prec@(1,3) (94.6%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:49:16 PM | Train: [163/180] Step 200/1249 Loss 0.729 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:49:40 PM | Train: [163/180] Step 250/1249 Loss 0.760 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:50:04 PM | Train: [163/180] Step 300/1249 Loss 0.741 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:50:29 PM | Train: [163/180] Step 350/1249 Loss 0.740 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:50:53 PM | Train: [163/180] Step 400/1249 Loss 0.740 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:51:17 PM | Train: [163/180] Step 450/1249 Loss 0.735 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:51:41 PM | Train: [163/180] Step 500/1249 Loss 0.730 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:52:04 PM | Train: [163/180] Step 550/1249 Loss 0.735 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:52:26 PM | Train: [163/180] Step 600/1249 Loss 0.741 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:52:50 PM | Train: [163/180] Step 650/1249 Loss 0.735 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:53:14 PM | Train: [163/180] Step 700/1249 Loss 0.742 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:53:38 PM | Train: [163/180] Step 750/1249 Loss 0.737 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:54:02 PM | Train: [163/180] Step 800/1249 Loss 0.735 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:54:27 PM | Train: [163/180] Step 850/1249 Loss 0.739 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:54:52 PM | Train: [163/180] Step 900/1249 Loss 0.737 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.545, lat_loss 22.004
09/22 01:55:17 PM | Train: [163/180] Step 950/1249 Loss 0.738 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.544, lat_loss 22.004
09/22 01:55:42 PM | Train: [163/180] Step 1000/1249 Loss 0.736 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.544, lat_loss 22.004
09/22 01:56:07 PM | Train: [163/180] Step 1050/1249 Loss 0.740 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.544, lat_loss 22.004
09/22 01:56:32 PM | Train: [163/180] Step 1100/1249 Loss 0.741 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.544, lat_loss 22.004
09/22 01:56:56 PM | Train: [163/180] Step 1150/1249 Loss 0.737 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.544, lat_loss 22.004
09/22 01:57:21 PM | Train: [163/180] Step 1200/1249 Loss 0.738 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.544, lat_loss 22.004
09/22 01:57:46 PM | Train: [163/180] Step 1249/1249 Loss 0.744 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.544, lat_loss 22.004
09/22 01:57:46 PM | _w_step_train: [163/180] Final Prec@1 94.1625% Time 605.30
09/22 01:57:46 PM | Start to train theta for epoch 162
09/22 01:58:08 PM | Train: [163/180] Step 050/312 Loss 2.064 Prec@(1,3) (87.9%, 99.3%), ce_loss 0.544, lat_loss 22.004
09/22 01:58:29 PM | Train: [163/180] Step 100/312 Loss 2.114 Prec@(1,3) (86.7%, 99.2%), ce_loss 0.544, lat_loss 22.004
09/22 01:58:50 PM | Train: [163/180] Step 150/312 Loss 2.163 Prec@(1,3) (86.3%, 99.2%), ce_loss 0.544, lat_loss 22.004
09/22 01:59:11 PM | Train: [163/180] Step 200/312 Loss 2.150 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.544, lat_loss 22.004
09/22 01:59:32 PM | Train: [163/180] Step 250/312 Loss 2.094 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.544, lat_loss 22.004
09/22 01:59:53 PM | Train: [163/180] Step 300/312 Loss 2.041 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.544, lat_loss 22.004
09/22 01:59:58 PM | Train: [163/180] Step 312/312 Loss 2.034 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.544, lat_loss 22.004
09/22 01:59:58 PM | _theta_step_train: [163/180] Final Prec@1 86.5000% Time 131.18
09/22 02:00:03 PM | Valid: [163/180] Step 050/312 Loss 2.165 Prec@(1,3) (85.0%, 99.1%), ce_loss 0.544, lat_loss 22.004
09/22 02:00:08 PM | Valid: [163/180] Step 100/312 Loss 2.417 Prec@(1,3) (83.3%, 98.5%), ce_loss 0.544, lat_loss 22.004
09/22 02:00:12 PM | Valid: [163/180] Step 150/312 Loss 2.497 Prec@(1,3) (83.4%, 98.4%), ce_loss 0.544, lat_loss 22.004
09/22 02:00:17 PM | Valid: [163/180] Step 200/312 Loss 2.425 Prec@(1,3) (84.1%, 98.4%), ce_loss 0.544, lat_loss 22.004
09/22 02:00:22 PM | Valid: [163/180] Step 250/312 Loss 2.372 Prec@(1,3) (84.4%, 98.6%), ce_loss 0.544, lat_loss 22.004
09/22 02:00:26 PM | Valid: [163/180] Step 300/312 Loss 2.306 Prec@(1,3) (84.5%, 98.8%), ce_loss 0.544, lat_loss 22.004
09/22 02:00:27 PM | Valid: [163/180] Step 312/312 Loss 2.305 Prec@(1,3) (84.5%, 98.8%), ce_loss 0.544, lat_loss 22.004
09/22 02:00:27 PM | val: [163/180] Final Prec@1 84.5500% Time 29.80
09/22 02:00:27 PM | Start to train weights for epoch 163
09/22 02:00:52 PM | Train: [164/180] Step 050/1249 Loss 1.084 Prec@(1,3) (92.6%, 99.5%), ce_loss 0.544, lat_loss 22.004
09/22 02:01:15 PM | Train: [164/180] Step 100/1249 Loss 0.929 Prec@(1,3) (93.1%, 99.7%), ce_loss 0.544, lat_loss 22.004
09/22 02:01:39 PM | Train: [164/180] Step 150/1249 Loss 0.857 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.544, lat_loss 22.004
09/22 02:02:04 PM | Train: [164/180] Step 200/1249 Loss 0.835 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.544, lat_loss 22.004
09/22 02:02:29 PM | Train: [164/180] Step 250/1249 Loss 0.831 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.544, lat_loss 22.004
09/22 02:02:54 PM | Train: [164/180] Step 300/1249 Loss 0.823 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.544, lat_loss 22.004
09/22 02:03:19 PM | Train: [164/180] Step 350/1249 Loss 0.797 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.544, lat_loss 22.004
09/22 02:03:43 PM | Train: [164/180] Step 400/1249 Loss 0.795 Prec@(1,3) (94.0%, 99.8%), ce_loss 0.544, lat_loss 22.004
09/22 02:04:05 PM | Train: [164/180] Step 450/1249 Loss 0.797 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.543, lat_loss 22.004
09/22 02:04:28 PM | Train: [164/180] Step 500/1249 Loss 0.800 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.543, lat_loss 22.004
09/22 02:04:51 PM | Train: [164/180] Step 550/1249 Loss 0.786 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.543, lat_loss 22.004
09/22 02:05:13 PM | Train: [164/180] Step 600/1249 Loss 0.778 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.543, lat_loss 22.004
09/22 02:05:34 PM | Train: [164/180] Step 650/1249 Loss 0.775 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.543, lat_loss 22.004
09/22 02:05:56 PM | Train: [164/180] Step 700/1249 Loss 0.785 Prec@(1,3) (94.0%, 99.8%), ce_loss 0.543, lat_loss 22.004
09/22 02:06:19 PM | Train: [164/180] Step 750/1249 Loss 0.789 Prec@(1,3) (94.0%, 99.8%), ce_loss 0.543, lat_loss 22.004
09/22 02:06:41 PM | Train: [164/180] Step 800/1249 Loss 0.784 Prec@(1,3) (94.0%, 99.8%), ce_loss 0.543, lat_loss 22.004
09/22 02:07:04 PM | Train: [164/180] Step 850/1249 Loss 0.782 Prec@(1,3) (94.0%, 99.8%), ce_loss 0.543, lat_loss 22.004
09/22 02:07:27 PM | Train: [164/180] Step 900/1249 Loss 0.776 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.543, lat_loss 22.004
09/22 02:07:50 PM | Train: [164/180] Step 950/1249 Loss 0.782 Prec@(1,3) (94.0%, 99.8%), ce_loss 0.543, lat_loss 22.004
09/22 02:08:13 PM | Train: [164/180] Step 1000/1249 Loss 0.802 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.543, lat_loss 22.004
09/22 02:08:32 PM | Train: [164/180] Step 1050/1249 Loss 0.816 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.543, lat_loss 22.004
09/22 02:08:53 PM | Train: [164/180] Step 1100/1249 Loss 0.818 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.543, lat_loss 22.004
09/22 02:09:14 PM | Train: [164/180] Step 1150/1249 Loss 0.822 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.543, lat_loss 22.004
09/22 02:09:38 PM | Train: [164/180] Step 1200/1249 Loss 0.816 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.543, lat_loss 22.004
09/22 02:10:02 PM | Train: [164/180] Step 1249/1249 Loss 0.815 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.543, lat_loss 22.004
09/22 02:10:02 PM | _w_step_train: [164/180] Final Prec@1 93.8300% Time 574.80
09/22 02:10:02 PM | Start to train theta for epoch 163
09/22 02:10:24 PM | Train: [164/180] Step 050/312 Loss 1.929 Prec@(1,3) (87.4%, 99.4%), ce_loss 0.543, lat_loss 22.004
09/22 02:10:44 PM | Train: [164/180] Step 100/312 Loss 2.019 Prec@(1,3) (87.1%, 99.3%), ce_loss 0.542, lat_loss 22.004
09/22 02:11:03 PM | Train: [164/180] Step 150/312 Loss 1.957 Prec@(1,3) (87.1%, 99.3%), ce_loss 0.542, lat_loss 22.004
09/22 02:11:24 PM | Train: [164/180] Step 200/312 Loss 2.123 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.542, lat_loss 22.004
09/22 02:11:45 PM | Train: [164/180] Step 250/312 Loss 2.094 Prec@(1,3) (86.4%, 99.2%), ce_loss 0.542, lat_loss 22.004
09/22 02:12:06 PM | Train: [164/180] Step 300/312 Loss 2.060 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.542, lat_loss 22.004
09/22 02:12:11 PM | Train: [164/180] Step 312/312 Loss 2.070 Prec@(1,3) (86.5%, 99.2%), ce_loss 0.542, lat_loss 22.004
09/22 02:12:11 PM | _theta_step_train: [164/180] Final Prec@1 86.4500% Time 128.65
09/22 02:12:16 PM | Valid: [164/180] Step 050/312 Loss 1.939 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.542, lat_loss 22.004
09/22 02:12:21 PM | Valid: [164/180] Step 100/312 Loss 2.088 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.542, lat_loss 22.004
09/22 02:12:25 PM | Valid: [164/180] Step 150/312 Loss 2.232 Prec@(1,3) (85.3%, 98.7%), ce_loss 0.542, lat_loss 22.004
09/22 02:12:30 PM | Valid: [164/180] Step 200/312 Loss 2.256 Prec@(1,3) (84.9%, 98.6%), ce_loss 0.542, lat_loss 22.004
09/22 02:12:35 PM | Valid: [164/180] Step 250/312 Loss 2.215 Prec@(1,3) (85.1%, 98.8%), ce_loss 0.542, lat_loss 22.004
09/22 02:12:39 PM | Valid: [164/180] Step 300/312 Loss 2.149 Prec@(1,3) (85.3%, 98.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:12:40 PM | Valid: [164/180] Step 312/312 Loss 2.138 Prec@(1,3) (85.3%, 98.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:12:41 PM | val: [164/180] Final Prec@1 85.3400% Time 29.59
09/22 02:12:41 PM | Start to train weights for epoch 164
09/22 02:13:07 PM | Train: [165/180] Step 050/1249 Loss 0.738 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:13:31 PM | Train: [165/180] Step 100/1249 Loss 0.726 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:13:54 PM | Train: [165/180] Step 150/1249 Loss 0.736 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:14:16 PM | Train: [165/180] Step 200/1249 Loss 0.747 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:14:39 PM | Train: [165/180] Step 250/1249 Loss 0.722 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:15:03 PM | Train: [165/180] Step 300/1249 Loss 0.741 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:15:27 PM | Train: [165/180] Step 350/1249 Loss 0.745 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:15:51 PM | Train: [165/180] Step 400/1249 Loss 0.726 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:16:16 PM | Train: [165/180] Step 450/1249 Loss 0.729 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:16:40 PM | Train: [165/180] Step 500/1249 Loss 0.736 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:17:04 PM | Train: [165/180] Step 550/1249 Loss 0.736 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:17:29 PM | Train: [165/180] Step 600/1249 Loss 0.731 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:17:53 PM | Train: [165/180] Step 650/1249 Loss 0.735 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:18:18 PM | Train: [165/180] Step 700/1249 Loss 0.732 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.542, lat_loss 22.004
09/22 02:18:42 PM | Train: [165/180] Step 750/1249 Loss 0.738 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.541, lat_loss 22.004
09/22 02:19:07 PM | Train: [165/180] Step 800/1249 Loss 0.737 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.541, lat_loss 22.004
09/22 02:19:32 PM | Train: [165/180] Step 850/1249 Loss 0.735 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.541, lat_loss 22.004
09/22 02:19:57 PM | Train: [165/180] Step 900/1249 Loss 0.738 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.541, lat_loss 22.004
09/22 02:20:22 PM | Train: [165/180] Step 950/1249 Loss 0.734 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.541, lat_loss 22.004
09/22 02:20:46 PM | Train: [165/180] Step 1000/1249 Loss 0.733 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.541, lat_loss 22.004
09/22 02:21:11 PM | Train: [165/180] Step 1050/1249 Loss 0.735 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.541, lat_loss 22.005
09/22 02:21:36 PM | Train: [165/180] Step 1100/1249 Loss 0.731 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.541, lat_loss 22.005
09/22 02:22:00 PM | Train: [165/180] Step 1150/1249 Loss 0.740 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.541, lat_loss 22.005
09/22 02:22:24 PM | Train: [165/180] Step 1200/1249 Loss 0.737 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.541, lat_loss 22.005
09/22 02:22:47 PM | Train: [165/180] Step 1249/1249 Loss 0.742 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.541, lat_loss 22.005
09/22 02:22:48 PM | _w_step_train: [165/180] Final Prec@1 94.1275% Time 606.64
09/22 02:22:48 PM | Start to train theta for epoch 164
09/22 02:23:09 PM | Train: [165/180] Step 050/312 Loss 2.045 Prec@(1,3) (86.2%, 99.5%), ce_loss 0.541, lat_loss 22.005
09/22 02:23:29 PM | Train: [165/180] Step 100/312 Loss 2.111 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.541, lat_loss 22.005
09/22 02:23:50 PM | Train: [165/180] Step 150/312 Loss 2.115 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.541, lat_loss 22.005
09/22 02:24:10 PM | Train: [165/180] Step 200/312 Loss 2.030 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.541, lat_loss 22.005
09/22 02:24:30 PM | Train: [165/180] Step 250/312 Loss 1.997 Prec@(1,3) (86.7%, 99.3%), ce_loss 0.541, lat_loss 22.005
09/22 02:24:48 PM | Train: [165/180] Step 300/312 Loss 1.988 Prec@(1,3) (86.8%, 99.3%), ce_loss 0.541, lat_loss 22.005
09/22 02:24:53 PM | Train: [165/180] Step 312/312 Loss 1.999 Prec@(1,3) (86.7%, 99.4%), ce_loss 0.541, lat_loss 22.005
09/22 02:24:53 PM | _theta_step_train: [165/180] Final Prec@1 86.6900% Time 125.19
09/22 02:24:58 PM | Valid: [165/180] Step 050/312 Loss 1.876 Prec@(1,3) (86.2%, 99.5%), ce_loss 0.541, lat_loss 22.005
09/22 02:25:03 PM | Valid: [165/180] Step 100/312 Loss 2.040 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.541, lat_loss 22.005
09/22 02:25:08 PM | Valid: [165/180] Step 150/312 Loss 2.040 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.541, lat_loss 22.005
09/22 02:25:12 PM | Valid: [165/180] Step 200/312 Loss 1.983 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.541, lat_loss 22.005
09/22 02:25:17 PM | Valid: [165/180] Step 250/312 Loss 2.030 Prec@(1,3) (85.8%, 99.1%), ce_loss 0.541, lat_loss 22.005
09/22 02:25:22 PM | Valid: [165/180] Step 300/312 Loss 2.062 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.541, lat_loss 22.005
09/22 02:25:23 PM | Valid: [165/180] Step 312/312 Loss 2.047 Prec@(1,3) (85.5%, 99.1%), ce_loss 0.541, lat_loss 22.005
09/22 02:25:23 PM | val: [165/180] Final Prec@1 85.4900% Time 30.20
09/22 02:25:23 PM | Start to train weights for epoch 165
09/22 02:25:47 PM | Train: [166/180] Step 050/1249 Loss 0.823 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.541, lat_loss 22.005
09/22 02:26:11 PM | Train: [166/180] Step 100/1249 Loss 0.802 Prec@(1,3) (93.8%, 100.0%), ce_loss 0.541, lat_loss 22.005
09/22 02:26:34 PM | Train: [166/180] Step 150/1249 Loss 0.776 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:26:57 PM | Train: [166/180] Step 200/1249 Loss 0.719 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:27:19 PM | Train: [166/180] Step 250/1249 Loss 0.723 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:27:42 PM | Train: [166/180] Step 300/1249 Loss 0.724 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:28:06 PM | Train: [166/180] Step 350/1249 Loss 0.755 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:28:27 PM | Train: [166/180] Step 400/1249 Loss 0.759 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:28:48 PM | Train: [166/180] Step 450/1249 Loss 0.756 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:29:10 PM | Train: [166/180] Step 500/1249 Loss 0.777 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:29:33 PM | Train: [166/180] Step 550/1249 Loss 0.772 Prec@(1,3) (94.0%, 99.8%), ce_loss 0.540, lat_loss 22.005
09/22 02:29:56 PM | Train: [166/180] Step 600/1249 Loss 0.766 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:30:19 PM | Train: [166/180] Step 650/1249 Loss 0.765 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:30:42 PM | Train: [166/180] Step 700/1249 Loss 0.758 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:31:04 PM | Train: [166/180] Step 750/1249 Loss 0.759 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:31:24 PM | Train: [166/180] Step 800/1249 Loss 0.777 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:31:45 PM | Train: [166/180] Step 850/1249 Loss 0.783 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:32:08 PM | Train: [166/180] Step 900/1249 Loss 0.788 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:32:31 PM | Train: [166/180] Step 950/1249 Loss 0.785 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.540, lat_loss 22.005
09/22 02:32:55 PM | Train: [166/180] Step 1000/1249 Loss 0.783 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.539, lat_loss 22.005
09/22 02:33:19 PM | Train: [166/180] Step 1050/1249 Loss 0.773 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.539, lat_loss 22.005
09/22 02:33:41 PM | Train: [166/180] Step 1100/1249 Loss 0.780 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.539, lat_loss 22.005
09/22 02:34:04 PM | Train: [166/180] Step 1150/1249 Loss 0.793 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.539, lat_loss 22.005
09/22 02:34:27 PM | Train: [166/180] Step 1200/1249 Loss 0.790 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.539, lat_loss 22.005
09/22 02:34:51 PM | Train: [166/180] Step 1249/1249 Loss 0.788 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.539, lat_loss 22.005
09/22 02:34:52 PM | _w_step_train: [166/180] Final Prec@1 93.9400% Time 568.54
09/22 02:34:52 PM | Start to train theta for epoch 165
09/22 02:35:13 PM | Train: [166/180] Step 050/312 Loss 2.104 Prec@(1,3) (86.5%, 99.2%), ce_loss 0.539, lat_loss 22.005
09/22 02:35:34 PM | Train: [166/180] Step 100/312 Loss 2.115 Prec@(1,3) (86.4%, 99.0%), ce_loss 0.539, lat_loss 22.005
09/22 02:35:55 PM | Train: [166/180] Step 150/312 Loss 2.056 Prec@(1,3) (86.5%, 99.1%), ce_loss 0.539, lat_loss 22.005
09/22 02:36:16 PM | Train: [166/180] Step 200/312 Loss 2.059 Prec@(1,3) (86.6%, 99.2%), ce_loss 0.539, lat_loss 22.005
09/22 02:36:37 PM | Train: [166/180] Step 250/312 Loss 2.031 Prec@(1,3) (86.7%, 99.2%), ce_loss 0.539, lat_loss 22.005
09/22 02:36:57 PM | Train: [166/180] Step 300/312 Loss 2.037 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.539, lat_loss 22.005
09/22 02:37:02 PM | Train: [166/180] Step 312/312 Loss 2.048 Prec@(1,3) (86.5%, 99.2%), ce_loss 0.539, lat_loss 22.005
09/22 02:37:02 PM | _theta_step_train: [166/180] Final Prec@1 86.5400% Time 130.76
09/22 02:37:08 PM | Valid: [166/180] Step 050/312 Loss 2.048 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.539, lat_loss 22.005
09/22 02:37:12 PM | Valid: [166/180] Step 100/312 Loss 2.087 Prec@(1,3) (86.2%, 99.1%), ce_loss 0.539, lat_loss 22.005
09/22 02:37:17 PM | Valid: [166/180] Step 150/312 Loss 2.361 Prec@(1,3) (84.9%, 98.8%), ce_loss 0.539, lat_loss 22.005
09/22 02:37:21 PM | Valid: [166/180] Step 200/312 Loss 2.293 Prec@(1,3) (85.3%, 98.9%), ce_loss 0.539, lat_loss 22.005
09/22 02:37:26 PM | Valid: [166/180] Step 250/312 Loss 2.251 Prec@(1,3) (85.4%, 99.0%), ce_loss 0.539, lat_loss 22.005
09/22 02:37:31 PM | Valid: [166/180] Step 300/312 Loss 2.228 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.539, lat_loss 22.005
09/22 02:37:32 PM | Valid: [166/180] Step 312/312 Loss 2.228 Prec@(1,3) (85.2%, 99.0%), ce_loss 0.539, lat_loss 22.005
09/22 02:37:32 PM | val: [166/180] Final Prec@1 85.2400% Time 29.88
09/22 02:37:32 PM | Start to train weights for epoch 166
09/22 02:37:58 PM | Train: [167/180] Step 050/1249 Loss 0.747 Prec@(1,3) (94.2%, 99.8%), ce_loss 0.539, lat_loss 22.005
09/22 02:38:20 PM | Train: [167/180] Step 100/1249 Loss 0.669 Prec@(1,3) (94.6%, 99.9%), ce_loss 0.539, lat_loss 22.005
09/22 02:38:42 PM | Train: [167/180] Step 150/1249 Loss 0.666 Prec@(1,3) (94.6%, 99.9%), ce_loss 0.539, lat_loss 22.005
09/22 02:39:03 PM | Train: [167/180] Step 200/1249 Loss 0.702 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.539, lat_loss 22.005
09/22 02:39:26 PM | Train: [167/180] Step 250/1249 Loss 0.677 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.539, lat_loss 22.005
09/22 02:39:48 PM | Train: [167/180] Step 300/1249 Loss 0.699 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.539, lat_loss 22.005
09/22 02:40:12 PM | Train: [167/180] Step 350/1249 Loss 0.694 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.539, lat_loss 22.005
09/22 02:40:34 PM | Train: [167/180] Step 400/1249 Loss 0.686 Prec@(1,3) (94.6%, 99.9%), ce_loss 0.539, lat_loss 22.005
09/22 02:40:56 PM | Train: [167/180] Step 450/1249 Loss 0.696 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.539, lat_loss 22.005
09/22 02:41:12 PM | Train: [167/180] Step 500/1249 Loss 0.697 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:41:28 PM | Train: [167/180] Step 550/1249 Loss 0.693 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:41:44 PM | Train: [167/180] Step 600/1249 Loss 0.688 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:42:00 PM | Train: [167/180] Step 650/1249 Loss 0.691 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:42:16 PM | Train: [167/180] Step 700/1249 Loss 0.688 Prec@(1,3) (94.6%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:42:32 PM | Train: [167/180] Step 750/1249 Loss 0.686 Prec@(1,3) (94.6%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:42:48 PM | Train: [167/180] Step 800/1249 Loss 0.689 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:43:04 PM | Train: [167/180] Step 850/1249 Loss 0.694 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:43:20 PM | Train: [167/180] Step 900/1249 Loss 0.693 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:43:36 PM | Train: [167/180] Step 950/1249 Loss 0.691 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:43:52 PM | Train: [167/180] Step 1000/1249 Loss 0.704 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:44:09 PM | Train: [167/180] Step 1050/1249 Loss 0.698 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:44:25 PM | Train: [167/180] Step 1100/1249 Loss 0.700 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:44:41 PM | Train: [167/180] Step 1150/1249 Loss 0.699 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:44:57 PM | Train: [167/180] Step 1200/1249 Loss 0.703 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:45:12 PM | Train: [167/180] Step 1249/1249 Loss 0.696 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.538, lat_loss 22.005
09/22 02:45:13 PM | _w_step_train: [167/180] Final Prec@1 94.5350% Time 460.38
09/22 02:45:13 PM | Start to train theta for epoch 166
09/22 02:45:33 PM | Train: [167/180] Step 050/312 Loss 1.849 Prec@(1,3) (87.7%, 99.1%), ce_loss 0.537, lat_loss 22.006
09/22 02:45:52 PM | Train: [167/180] Step 100/312 Loss 2.058 Prec@(1,3) (86.5%, 98.9%), ce_loss 0.537, lat_loss 22.006
09/22 02:46:11 PM | Train: [167/180] Step 150/312 Loss 2.014 Prec@(1,3) (86.4%, 99.1%), ce_loss 0.537, lat_loss 22.006
09/22 02:46:29 PM | Train: [167/180] Step 200/312 Loss 2.062 Prec@(1,3) (86.2%, 99.1%), ce_loss 0.537, lat_loss 22.006
09/22 02:46:49 PM | Train: [167/180] Step 250/312 Loss 2.073 Prec@(1,3) (86.2%, 99.0%), ce_loss 0.537, lat_loss 22.006
09/22 02:47:10 PM | Train: [167/180] Step 300/312 Loss 2.091 Prec@(1,3) (86.3%, 99.0%), ce_loss 0.537, lat_loss 22.006
09/22 02:47:15 PM | Train: [167/180] Step 312/312 Loss 2.107 Prec@(1,3) (86.2%, 99.0%), ce_loss 0.537, lat_loss 22.006
09/22 02:47:15 PM | _theta_step_train: [167/180] Final Prec@1 86.2500% Time 122.32
09/22 02:47:20 PM | Valid: [167/180] Step 050/312 Loss 2.059 Prec@(1,3) (85.8%, 98.3%), ce_loss 0.537, lat_loss 22.006
09/22 02:47:24 PM | Valid: [167/180] Step 100/312 Loss 2.059 Prec@(1,3) (85.9%, 98.8%), ce_loss 0.537, lat_loss 22.006
09/22 02:47:29 PM | Valid: [167/180] Step 150/312 Loss 2.154 Prec@(1,3) (85.4%, 98.9%), ce_loss 0.537, lat_loss 22.006
09/22 02:47:33 PM | Valid: [167/180] Step 200/312 Loss 2.122 Prec@(1,3) (85.5%, 98.9%), ce_loss 0.537, lat_loss 22.006
09/22 02:47:38 PM | Valid: [167/180] Step 250/312 Loss 2.138 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.537, lat_loss 22.006
09/22 02:47:43 PM | Valid: [167/180] Step 300/312 Loss 2.072 Prec@(1,3) (85.5%, 99.1%), ce_loss 0.537, lat_loss 22.006
09/22 02:47:44 PM | Valid: [167/180] Step 312/312 Loss 2.077 Prec@(1,3) (85.5%, 99.1%), ce_loss 0.537, lat_loss 22.006
09/22 02:47:44 PM | val: [167/180] Final Prec@1 85.4500% Time 29.27
09/22 02:47:44 PM | Start to train weights for epoch 167
09/22 02:48:09 PM | Train: [168/180] Step 050/1249 Loss 0.694 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.537, lat_loss 22.006
09/22 02:48:32 PM | Train: [168/180] Step 100/1249 Loss 0.698 Prec@(1,3) (94.5%, 100.0%), ce_loss 0.537, lat_loss 22.006
09/22 02:48:56 PM | Train: [168/180] Step 150/1249 Loss 0.720 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.537, lat_loss 22.006
09/22 02:49:19 PM | Train: [168/180] Step 200/1249 Loss 0.698 Prec@(1,3) (94.8%, 99.9%), ce_loss 0.537, lat_loss 22.006
09/22 02:49:41 PM | Train: [168/180] Step 250/1249 Loss 0.698 Prec@(1,3) (94.7%, 99.9%), ce_loss 0.537, lat_loss 22.006
09/22 02:50:04 PM | Train: [168/180] Step 300/1249 Loss 0.695 Prec@(1,3) (94.7%, 99.9%), ce_loss 0.537, lat_loss 22.006
09/22 02:50:27 PM | Train: [168/180] Step 350/1249 Loss 0.697 Prec@(1,3) (94.7%, 99.9%), ce_loss 0.537, lat_loss 22.006
09/22 02:50:49 PM | Train: [168/180] Step 400/1249 Loss 0.691 Prec@(1,3) (94.7%, 99.9%), ce_loss 0.537, lat_loss 22.006
09/22 02:51:10 PM | Train: [168/180] Step 450/1249 Loss 0.700 Prec@(1,3) (94.6%, 100.0%), ce_loss 0.537, lat_loss 22.006
09/22 02:51:30 PM | Train: [168/180] Step 500/1249 Loss 0.691 Prec@(1,3) (94.6%, 100.0%), ce_loss 0.537, lat_loss 22.006
09/22 02:51:52 PM | Train: [168/180] Step 550/1249 Loss 0.699 Prec@(1,3) (94.6%, 99.9%), ce_loss 0.537, lat_loss 22.006
09/22 02:52:12 PM | Train: [168/180] Step 600/1249 Loss 0.728 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.537, lat_loss 22.006
09/22 02:52:33 PM | Train: [168/180] Step 650/1249 Loss 0.723 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.537, lat_loss 22.006
09/22 02:52:54 PM | Train: [168/180] Step 700/1249 Loss 0.719 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.537, lat_loss 22.006
09/22 02:53:15 PM | Train: [168/180] Step 750/1249 Loss 0.722 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 02:53:35 PM | Train: [168/180] Step 800/1249 Loss 0.734 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 02:53:56 PM | Train: [168/180] Step 850/1249 Loss 0.732 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 02:54:17 PM | Train: [168/180] Step 900/1249 Loss 0.730 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 02:54:40 PM | Train: [168/180] Step 950/1249 Loss 0.736 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 02:55:03 PM | Train: [168/180] Step 1000/1249 Loss 0.732 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 02:55:26 PM | Train: [168/180] Step 1050/1249 Loss 0.729 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 02:55:49 PM | Train: [168/180] Step 1100/1249 Loss 0.728 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 02:56:12 PM | Train: [168/180] Step 1150/1249 Loss 0.728 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 02:56:36 PM | Train: [168/180] Step 1200/1249 Loss 0.733 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 02:57:00 PM | Train: [168/180] Step 1249/1249 Loss 0.736 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 02:57:00 PM | _w_step_train: [168/180] Final Prec@1 94.3100% Time 556.03
09/22 02:57:00 PM | Start to train theta for epoch 167
09/22 02:57:22 PM | Train: [168/180] Step 050/312 Loss 1.966 Prec@(1,3) (86.5%, 99.1%), ce_loss 0.536, lat_loss 22.006
09/22 02:57:42 PM | Train: [168/180] Step 100/312 Loss 1.974 Prec@(1,3) (86.8%, 99.2%), ce_loss 0.536, lat_loss 22.006
09/22 02:58:03 PM | Train: [168/180] Step 150/312 Loss 2.029 Prec@(1,3) (86.6%, 99.2%), ce_loss 0.536, lat_loss 22.006
09/22 02:58:23 PM | Train: [168/180] Step 200/312 Loss 2.043 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.536, lat_loss 22.006
09/22 02:58:43 PM | Train: [168/180] Step 250/312 Loss 2.079 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.536, lat_loss 22.006
09/22 02:59:04 PM | Train: [168/180] Step 300/312 Loss 2.105 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.536, lat_loss 22.006
09/22 02:59:09 PM | Train: [168/180] Step 312/312 Loss 2.093 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.536, lat_loss 22.006
09/22 02:59:09 PM | _theta_step_train: [168/180] Final Prec@1 85.8900% Time 128.75
09/22 02:59:14 PM | Valid: [168/180] Step 050/312 Loss 2.244 Prec@(1,3) (84.1%, 98.8%), ce_loss 0.536, lat_loss 22.006
09/22 02:59:19 PM | Valid: [168/180] Step 100/312 Loss 2.490 Prec@(1,3) (83.0%, 98.4%), ce_loss 0.536, lat_loss 22.006
09/22 02:59:23 PM | Valid: [168/180] Step 150/312 Loss 2.541 Prec@(1,3) (82.8%, 98.3%), ce_loss 0.536, lat_loss 22.006
09/22 02:59:28 PM | Valid: [168/180] Step 200/312 Loss 2.486 Prec@(1,3) (83.3%, 98.4%), ce_loss 0.536, lat_loss 22.006
09/22 02:59:33 PM | Valid: [168/180] Step 250/312 Loss 2.408 Prec@(1,3) (83.8%, 98.5%), ce_loss 0.536, lat_loss 22.006
09/22 02:59:37 PM | Valid: [168/180] Step 300/312 Loss 2.314 Prec@(1,3) (84.2%, 98.7%), ce_loss 0.536, lat_loss 22.006
09/22 02:59:38 PM | Valid: [168/180] Step 312/312 Loss 2.299 Prec@(1,3) (84.3%, 98.7%), ce_loss 0.536, lat_loss 22.006
09/22 02:59:38 PM | val: [168/180] Final Prec@1 84.3100% Time 29.43
09/22 02:59:38 PM | Start to train weights for epoch 168
09/22 03:00:05 PM | Train: [169/180] Step 050/1249 Loss 0.761 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 03:00:28 PM | Train: [169/180] Step 100/1249 Loss 0.875 Prec@(1,3) (93.3%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 03:00:53 PM | Train: [169/180] Step 150/1249 Loss 0.838 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 03:01:18 PM | Train: [169/180] Step 200/1249 Loss 0.816 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 03:01:42 PM | Train: [169/180] Step 250/1249 Loss 0.778 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.536, lat_loss 22.006
09/22 03:02:07 PM | Train: [169/180] Step 300/1249 Loss 0.783 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.535, lat_loss 22.006
09/22 03:02:32 PM | Train: [169/180] Step 350/1249 Loss 0.751 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.535, lat_loss 22.006
09/22 03:02:55 PM | Train: [169/180] Step 400/1249 Loss 0.747 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.535, lat_loss 22.006
09/22 03:03:19 PM | Train: [169/180] Step 450/1249 Loss 0.756 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.535, lat_loss 22.006
09/22 03:03:41 PM | Train: [169/180] Step 500/1249 Loss 0.762 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.535, lat_loss 22.006
09/22 03:04:06 PM | Train: [169/180] Step 550/1249 Loss 0.758 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.535, lat_loss 22.006
09/22 03:04:31 PM | Train: [169/180] Step 600/1249 Loss 0.797 Prec@(1,3) (94.2%, 99.8%), ce_loss 0.535, lat_loss 22.006
09/22 03:04:55 PM | Train: [169/180] Step 650/1249 Loss 0.786 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.535, lat_loss 22.006
09/22 03:05:20 PM | Train: [169/180] Step 700/1249 Loss 0.803 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.535, lat_loss 22.006
09/22 03:05:45 PM | Train: [169/180] Step 750/1249 Loss 0.812 Prec@(1,3) (94.0%, 99.8%), ce_loss 0.535, lat_loss 22.006
09/22 03:06:10 PM | Train: [169/180] Step 800/1249 Loss 0.807 Prec@(1,3) (94.0%, 99.8%), ce_loss 0.535, lat_loss 22.006
09/22 03:06:35 PM | Train: [169/180] Step 850/1249 Loss 0.798 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.535, lat_loss 22.006
09/22 03:07:00 PM | Train: [169/180] Step 900/1249 Loss 0.795 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.535, lat_loss 22.006
09/22 03:07:24 PM | Train: [169/180] Step 950/1249 Loss 0.785 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.535, lat_loss 22.006
09/22 03:07:45 PM | Train: [169/180] Step 1000/1249 Loss 0.795 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.535, lat_loss 22.007
09/22 03:08:10 PM | Train: [169/180] Step 1050/1249 Loss 0.789 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.535, lat_loss 22.007
09/22 03:08:35 PM | Train: [169/180] Step 1100/1249 Loss 0.791 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.535, lat_loss 22.007
09/22 03:09:00 PM | Train: [169/180] Step 1150/1249 Loss 0.795 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.534, lat_loss 22.007
09/22 03:09:25 PM | Train: [169/180] Step 1200/1249 Loss 0.800 Prec@(1,3) (94.0%, 99.8%), ce_loss 0.534, lat_loss 22.007
09/22 03:09:49 PM | Train: [169/180] Step 1249/1249 Loss 0.794 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.534, lat_loss 22.007
09/22 03:09:49 PM | _w_step_train: [169/180] Final Prec@1 94.0600% Time 610.72
09/22 03:09:49 PM | Start to train theta for epoch 168
09/22 03:10:09 PM | Train: [169/180] Step 050/312 Loss 1.897 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.534, lat_loss 22.007
09/22 03:10:27 PM | Train: [169/180] Step 100/312 Loss 1.918 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.534, lat_loss 22.007
09/22 03:10:46 PM | Train: [169/180] Step 150/312 Loss 1.887 Prec@(1,3) (87.3%, 99.4%), ce_loss 0.534, lat_loss 22.007
09/22 03:11:04 PM | Train: [169/180] Step 200/312 Loss 1.988 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.534, lat_loss 22.007
09/22 03:11:23 PM | Train: [169/180] Step 250/312 Loss 2.019 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.534, lat_loss 22.007
09/22 03:11:42 PM | Train: [169/180] Step 300/312 Loss 2.046 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.534, lat_loss 22.007
09/22 03:11:46 PM | Train: [169/180] Step 312/312 Loss 2.049 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.534, lat_loss 22.007
09/22 03:11:47 PM | _theta_step_train: [169/180] Final Prec@1 86.3100% Time 117.35
09/22 03:11:52 PM | Valid: [169/180] Step 050/312 Loss 2.110 Prec@(1,3) (85.4%, 98.8%), ce_loss 0.534, lat_loss 22.007
09/22 03:11:57 PM | Valid: [169/180] Step 100/312 Loss 2.230 Prec@(1,3) (84.7%, 98.7%), ce_loss 0.534, lat_loss 22.007
09/22 03:12:02 PM | Valid: [169/180] Step 150/312 Loss 2.332 Prec@(1,3) (83.9%, 98.6%), ce_loss 0.534, lat_loss 22.007
09/22 03:12:06 PM | Valid: [169/180] Step 200/312 Loss 2.331 Prec@(1,3) (83.8%, 98.6%), ce_loss 0.534, lat_loss 22.007
09/22 03:12:11 PM | Valid: [169/180] Step 250/312 Loss 2.350 Prec@(1,3) (83.8%, 98.6%), ce_loss 0.534, lat_loss 22.007
09/22 03:12:16 PM | Valid: [169/180] Step 300/312 Loss 2.245 Prec@(1,3) (84.3%, 98.8%), ce_loss 0.534, lat_loss 22.007
09/22 03:12:17 PM | Valid: [169/180] Step 312/312 Loss 2.241 Prec@(1,3) (84.3%, 98.8%), ce_loss 0.534, lat_loss 22.007
09/22 03:12:17 PM | val: [169/180] Final Prec@1 84.3400% Time 30.68
09/22 03:12:17 PM | Start to train weights for epoch 169
09/22 03:12:43 PM | Train: [170/180] Step 050/1249 Loss 0.789 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.534, lat_loss 22.007
09/22 03:13:08 PM | Train: [170/180] Step 100/1249 Loss 0.842 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.534, lat_loss 22.007
09/22 03:13:26 PM | Train: [170/180] Step 150/1249 Loss 0.806 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.534, lat_loss 22.007
09/22 03:13:42 PM | Train: [170/180] Step 200/1249 Loss 0.823 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.534, lat_loss 22.007
09/22 03:13:58 PM | Train: [170/180] Step 250/1249 Loss 0.798 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.534, lat_loss 22.007
09/22 03:14:14 PM | Train: [170/180] Step 300/1249 Loss 0.794 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.534, lat_loss 22.007
09/22 03:14:30 PM | Train: [170/180] Step 350/1249 Loss 0.766 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.534, lat_loss 22.007
09/22 03:14:46 PM | Train: [170/180] Step 400/1249 Loss 0.764 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.534, lat_loss 22.007
09/22 03:15:02 PM | Train: [170/180] Step 450/1249 Loss 0.779 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.534, lat_loss 22.007
09/22 03:15:18 PM | Train: [170/180] Step 500/1249 Loss 0.778 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.534, lat_loss 22.007
09/22 03:15:34 PM | Train: [170/180] Step 550/1249 Loss 0.761 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.534, lat_loss 22.007
09/22 03:15:50 PM | Train: [170/180] Step 600/1249 Loss 0.755 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.534, lat_loss 22.007
09/22 03:16:07 PM | Train: [170/180] Step 650/1249 Loss 0.759 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.534, lat_loss 22.007
09/22 03:16:33 PM | Train: [170/180] Step 700/1249 Loss 0.763 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.533, lat_loss 22.007
09/22 03:16:56 PM | Train: [170/180] Step 750/1249 Loss 0.762 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.533, lat_loss 22.007
09/22 03:17:20 PM | Train: [170/180] Step 800/1249 Loss 0.755 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.533, lat_loss 22.007
09/22 03:17:43 PM | Train: [170/180] Step 850/1249 Loss 0.752 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.533, lat_loss 22.007
09/22 03:18:03 PM | Train: [170/180] Step 900/1249 Loss 0.748 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.533, lat_loss 22.007
09/22 03:18:23 PM | Train: [170/180] Step 950/1249 Loss 0.747 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.533, lat_loss 22.007
09/22 03:18:43 PM | Train: [170/180] Step 1000/1249 Loss 0.748 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.533, lat_loss 22.007
09/22 03:19:02 PM | Train: [170/180] Step 1050/1249 Loss 0.748 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.533, lat_loss 22.007
09/22 03:19:22 PM | Train: [170/180] Step 1100/1249 Loss 0.744 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.533, lat_loss 22.007
09/22 03:19:42 PM | Train: [170/180] Step 1150/1249 Loss 0.751 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.533, lat_loss 22.007
09/22 03:20:03 PM | Train: [170/180] Step 1200/1249 Loss 0.761 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.533, lat_loss 22.007
09/22 03:20:26 PM | Train: [170/180] Step 1249/1249 Loss 0.757 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.533, lat_loss 22.007
09/22 03:20:27 PM | _w_step_train: [170/180] Final Prec@1 94.1775% Time 489.30
09/22 03:20:27 PM | Start to train theta for epoch 169
09/22 03:20:48 PM | Train: [170/180] Step 050/312 Loss 2.114 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.533, lat_loss 22.007
09/22 03:21:08 PM | Train: [170/180] Step 100/312 Loss 2.100 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.533, lat_loss 22.007
09/22 03:21:28 PM | Train: [170/180] Step 150/312 Loss 2.095 Prec@(1,3) (85.9%, 99.1%), ce_loss 0.533, lat_loss 22.007
09/22 03:21:49 PM | Train: [170/180] Step 200/312 Loss 2.088 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.533, lat_loss 22.007
09/22 03:22:09 PM | Train: [170/180] Step 250/312 Loss 2.043 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.533, lat_loss 22.007
09/22 03:22:29 PM | Train: [170/180] Step 300/312 Loss 2.052 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.533, lat_loss 22.007
09/22 03:22:34 PM | Train: [170/180] Step 312/312 Loss 2.048 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.533, lat_loss 22.007
09/22 03:22:34 PM | _theta_step_train: [170/180] Final Prec@1 86.2500% Time 127.51
09/22 03:22:39 PM | Valid: [170/180] Step 050/312 Loss 2.267 Prec@(1,3) (84.9%, 98.8%), ce_loss 0.533, lat_loss 22.007
09/22 03:22:44 PM | Valid: [170/180] Step 100/312 Loss 2.425 Prec@(1,3) (84.3%, 98.3%), ce_loss 0.533, lat_loss 22.007
09/22 03:22:49 PM | Valid: [170/180] Step 150/312 Loss 2.394 Prec@(1,3) (84.5%, 98.5%), ce_loss 0.533, lat_loss 22.007
09/22 03:22:53 PM | Valid: [170/180] Step 200/312 Loss 2.459 Prec@(1,3) (83.9%, 98.6%), ce_loss 0.533, lat_loss 22.007
09/22 03:22:58 PM | Valid: [170/180] Step 250/312 Loss 2.386 Prec@(1,3) (84.3%, 98.8%), ce_loss 0.533, lat_loss 22.007
09/22 03:23:03 PM | Valid: [170/180] Step 300/312 Loss 2.344 Prec@(1,3) (84.4%, 98.8%), ce_loss 0.533, lat_loss 22.007
09/22 03:23:04 PM | Valid: [170/180] Step 312/312 Loss 2.329 Prec@(1,3) (84.5%, 98.8%), ce_loss 0.533, lat_loss 22.007
09/22 03:23:04 PM | val: [170/180] Final Prec@1 84.4700% Time 30.00
09/22 03:23:04 PM | Start to train weights for epoch 170
09/22 03:23:26 PM | Train: [171/180] Step 050/1249 Loss 0.798 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.533, lat_loss 22.007
09/22 03:23:47 PM | Train: [171/180] Step 100/1249 Loss 0.782 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.533, lat_loss 22.007
09/22 03:24:08 PM | Train: [171/180] Step 150/1249 Loss 0.819 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.533, lat_loss 22.007
09/22 03:24:28 PM | Train: [171/180] Step 200/1249 Loss 0.766 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.533, lat_loss 22.007
09/22 03:24:50 PM | Train: [171/180] Step 250/1249 Loss 0.744 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.532, lat_loss 22.007
09/22 03:25:10 PM | Train: [171/180] Step 300/1249 Loss 0.751 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.532, lat_loss 22.007
09/22 03:25:31 PM | Train: [171/180] Step 350/1249 Loss 0.747 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.532, lat_loss 22.008
09/22 03:25:51 PM | Train: [171/180] Step 400/1249 Loss 0.758 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.532, lat_loss 22.008
09/22 03:26:12 PM | Train: [171/180] Step 450/1249 Loss 0.765 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.532, lat_loss 22.008
09/22 03:26:34 PM | Train: [171/180] Step 500/1249 Loss 0.760 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.532, lat_loss 22.008
09/22 03:26:54 PM | Train: [171/180] Step 550/1249 Loss 0.764 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.532, lat_loss 22.008
09/22 03:27:18 PM | Train: [171/180] Step 600/1249 Loss 0.766 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.532, lat_loss 22.008
09/22 03:27:38 PM | Train: [171/180] Step 650/1249 Loss 0.767 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.532, lat_loss 22.008
09/22 03:28:02 PM | Train: [171/180] Step 700/1249 Loss 0.757 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.532, lat_loss 22.008
09/22 03:28:25 PM | Train: [171/180] Step 750/1249 Loss 0.758 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.532, lat_loss 22.008
09/22 03:28:47 PM | Train: [171/180] Step 800/1249 Loss 0.764 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.532, lat_loss 22.008
09/22 03:29:08 PM | Train: [171/180] Step 850/1249 Loss 0.768 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.532, lat_loss 22.008
09/22 03:29:31 PM | Train: [171/180] Step 900/1249 Loss 0.767 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.532, lat_loss 22.008
09/22 03:29:52 PM | Train: [171/180] Step 950/1249 Loss 0.762 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.532, lat_loss 22.008
09/22 03:30:14 PM | Train: [171/180] Step 1000/1249 Loss 0.770 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.532, lat_loss 22.008
09/22 03:30:37 PM | Train: [171/180] Step 1050/1249 Loss 0.777 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.532, lat_loss 22.008
09/22 03:30:57 PM | Train: [171/180] Step 1100/1249 Loss 0.782 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:31:18 PM | Train: [171/180] Step 1150/1249 Loss 0.779 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:31:43 PM | Train: [171/180] Step 1200/1249 Loss 0.780 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:32:07 PM | Train: [171/180] Step 1249/1249 Loss 0.778 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:32:07 PM | _w_step_train: [171/180] Final Prec@1 93.9925% Time 543.00
09/22 03:32:07 PM | Start to train theta for epoch 170
09/22 03:32:29 PM | Train: [171/180] Step 050/312 Loss 2.005 Prec@(1,3) (87.0%, 99.1%), ce_loss 0.531, lat_loss 22.008
09/22 03:32:48 PM | Train: [171/180] Step 100/312 Loss 2.084 Prec@(1,3) (86.3%, 99.2%), ce_loss 0.531, lat_loss 22.008
09/22 03:33:01 PM | Train: [171/180] Step 150/312 Loss 2.059 Prec@(1,3) (86.4%, 99.2%), ce_loss 0.531, lat_loss 22.008
09/22 03:33:13 PM | Train: [171/180] Step 200/312 Loss 2.332 Prec@(1,3) (85.2%, 98.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:33:25 PM | Train: [171/180] Step 250/312 Loss 2.283 Prec@(1,3) (85.2%, 99.0%), ce_loss 0.531, lat_loss 22.008
09/22 03:33:37 PM | Train: [171/180] Step 300/312 Loss 2.250 Prec@(1,3) (85.3%, 98.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:33:40 PM | Train: [171/180] Step 312/312 Loss 2.226 Prec@(1,3) (85.4%, 99.0%), ce_loss 0.531, lat_loss 22.008
09/22 03:33:40 PM | _theta_step_train: [171/180] Final Prec@1 85.4200% Time 93.21
09/22 03:33:46 PM | Valid: [171/180] Step 050/312 Loss 2.286 Prec@(1,3) (83.6%, 98.8%), ce_loss 0.531, lat_loss 22.008
09/22 03:33:50 PM | Valid: [171/180] Step 100/312 Loss 2.405 Prec@(1,3) (83.1%, 98.6%), ce_loss 0.531, lat_loss 22.008
09/22 03:33:55 PM | Valid: [171/180] Step 150/312 Loss 2.481 Prec@(1,3) (83.0%, 98.6%), ce_loss 0.531, lat_loss 22.008
09/22 03:33:59 PM | Valid: [171/180] Step 200/312 Loss 2.409 Prec@(1,3) (83.6%, 98.7%), ce_loss 0.531, lat_loss 22.008
09/22 03:34:04 PM | Valid: [171/180] Step 250/312 Loss 2.377 Prec@(1,3) (83.9%, 98.7%), ce_loss 0.531, lat_loss 22.008
09/22 03:34:09 PM | Valid: [171/180] Step 300/312 Loss 2.339 Prec@(1,3) (84.0%, 98.8%), ce_loss 0.531, lat_loss 22.008
09/22 03:34:10 PM | Valid: [171/180] Step 312/312 Loss 2.322 Prec@(1,3) (84.1%, 98.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:34:10 PM | val: [171/180] Final Prec@1 84.1400% Time 29.76
09/22 03:34:10 PM | Start to train weights for epoch 171
09/22 03:34:36 PM | Train: [172/180] Step 050/1249 Loss 0.895 Prec@(1,3) (93.2%, 99.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:35:01 PM | Train: [172/180] Step 100/1249 Loss 0.790 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:35:24 PM | Train: [172/180] Step 150/1249 Loss 0.809 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:35:47 PM | Train: [172/180] Step 200/1249 Loss 0.859 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:36:12 PM | Train: [172/180] Step 250/1249 Loss 0.881 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.531, lat_loss 22.008
09/22 03:36:35 PM | Train: [172/180] Step 300/1249 Loss 0.867 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.531, lat_loss 22.008
09/22 03:36:59 PM | Train: [172/180] Step 350/1249 Loss 0.843 Prec@(1,3) (93.4%, 99.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:37:24 PM | Train: [172/180] Step 400/1249 Loss 0.830 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:37:49 PM | Train: [172/180] Step 450/1249 Loss 0.826 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:38:13 PM | Train: [172/180] Step 500/1249 Loss 0.812 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:38:37 PM | Train: [172/180] Step 550/1249 Loss 0.802 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:39:00 PM | Train: [172/180] Step 600/1249 Loss 0.797 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.531, lat_loss 22.008
09/22 03:39:25 PM | Train: [172/180] Step 650/1249 Loss 0.795 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.531, lat_loss 22.008
09/22 03:39:49 PM | Train: [172/180] Step 700/1249 Loss 0.796 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.530, lat_loss 22.008
09/22 03:40:15 PM | Train: [172/180] Step 750/1249 Loss 0.793 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.530, lat_loss 22.008
09/22 03:40:39 PM | Train: [172/180] Step 800/1249 Loss 0.814 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.530, lat_loss 22.008
09/22 03:41:04 PM | Train: [172/180] Step 850/1249 Loss 0.815 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.530, lat_loss 22.008
09/22 03:41:29 PM | Train: [172/180] Step 900/1249 Loss 0.815 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.530, lat_loss 22.008
09/22 03:41:54 PM | Train: [172/180] Step 950/1249 Loss 0.813 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.530, lat_loss 22.008
09/22 03:42:19 PM | Train: [172/180] Step 1000/1249 Loss 0.810 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.530, lat_loss 22.008
09/22 03:42:43 PM | Train: [172/180] Step 1050/1249 Loss 0.819 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.530, lat_loss 22.008
09/22 03:43:08 PM | Train: [172/180] Step 1100/1249 Loss 0.818 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.530, lat_loss 22.008
09/22 03:43:32 PM | Train: [172/180] Step 1150/1249 Loss 0.830 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.530, lat_loss 22.008
09/22 03:43:57 PM | Train: [172/180] Step 1200/1249 Loss 0.829 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.530, lat_loss 22.008
09/22 03:44:21 PM | Train: [172/180] Step 1249/1249 Loss 0.827 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.530, lat_loss 22.008
09/22 03:44:22 PM | _w_step_train: [172/180] Final Prec@1 93.5850% Time 611.45
09/22 03:44:22 PM | Start to train theta for epoch 171
09/22 03:44:42 PM | Train: [172/180] Step 050/312 Loss 1.959 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.530, lat_loss 22.008
09/22 03:45:03 PM | Train: [172/180] Step 100/312 Loss 1.877 Prec@(1,3) (86.8%, 99.3%), ce_loss 0.530, lat_loss 22.008
09/22 03:45:24 PM | Train: [172/180] Step 150/312 Loss 1.875 Prec@(1,3) (87.0%, 99.3%), ce_loss 0.530, lat_loss 22.008
09/22 03:45:44 PM | Train: [172/180] Step 200/312 Loss 1.902 Prec@(1,3) (87.0%, 99.3%), ce_loss 0.530, lat_loss 22.008
09/22 03:46:04 PM | Train: [172/180] Step 250/312 Loss 1.910 Prec@(1,3) (87.1%, 99.2%), ce_loss 0.530, lat_loss 22.009
09/22 03:46:25 PM | Train: [172/180] Step 300/312 Loss 1.956 Prec@(1,3) (86.9%, 99.2%), ce_loss 0.530, lat_loss 22.009
09/22 03:46:30 PM | Train: [172/180] Step 312/312 Loss 1.967 Prec@(1,3) (86.8%, 99.2%), ce_loss 0.530, lat_loss 22.009
09/22 03:46:31 PM | _theta_step_train: [172/180] Final Prec@1 86.7500% Time 128.91
09/22 03:46:36 PM | Valid: [172/180] Step 050/312 Loss 2.127 Prec@(1,3) (85.3%, 98.7%), ce_loss 0.530, lat_loss 22.009
09/22 03:46:41 PM | Valid: [172/180] Step 100/312 Loss 2.186 Prec@(1,3) (85.3%, 98.9%), ce_loss 0.530, lat_loss 22.009
09/22 03:46:45 PM | Valid: [172/180] Step 150/312 Loss 2.352 Prec@(1,3) (84.2%, 98.7%), ce_loss 0.530, lat_loss 22.009
09/22 03:46:50 PM | Valid: [172/180] Step 200/312 Loss 2.364 Prec@(1,3) (84.3%, 98.7%), ce_loss 0.530, lat_loss 22.009
09/22 03:46:55 PM | Valid: [172/180] Step 250/312 Loss 2.335 Prec@(1,3) (84.5%, 98.8%), ce_loss 0.530, lat_loss 22.009
09/22 03:46:59 PM | Valid: [172/180] Step 300/312 Loss 2.292 Prec@(1,3) (84.7%, 98.9%), ce_loss 0.530, lat_loss 22.009
09/22 03:47:01 PM | Valid: [172/180] Step 312/312 Loss 2.297 Prec@(1,3) (84.6%, 98.9%), ce_loss 0.530, lat_loss 22.009
09/22 03:47:01 PM | val: [172/180] Final Prec@1 84.6300% Time 30.11
09/22 03:47:01 PM | Start to train weights for epoch 172
09/22 03:47:27 PM | Train: [173/180] Step 050/1249 Loss 0.905 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.530, lat_loss 22.009
09/22 03:47:51 PM | Train: [173/180] Step 100/1249 Loss 0.899 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.530, lat_loss 22.009
09/22 03:48:16 PM | Train: [173/180] Step 150/1249 Loss 0.820 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.530, lat_loss 22.009
09/22 03:48:40 PM | Train: [173/180] Step 200/1249 Loss 0.902 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.530, lat_loss 22.009
09/22 03:49:05 PM | Train: [173/180] Step 250/1249 Loss 0.884 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.530, lat_loss 22.009
09/22 03:49:30 PM | Train: [173/180] Step 300/1249 Loss 0.861 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.530, lat_loss 22.009
09/22 03:49:55 PM | Train: [173/180] Step 350/1249 Loss 0.841 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.529, lat_loss 22.009
09/22 03:50:21 PM | Train: [173/180] Step 400/1249 Loss 0.832 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.529, lat_loss 22.009
09/22 03:50:44 PM | Train: [173/180] Step 450/1249 Loss 0.827 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.529, lat_loss 22.009
09/22 03:51:00 PM | Train: [173/180] Step 500/1249 Loss 0.827 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.529, lat_loss 22.009
09/22 03:51:16 PM | Train: [173/180] Step 550/1249 Loss 0.843 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.529, lat_loss 22.009
09/22 03:51:32 PM | Train: [173/180] Step 600/1249 Loss 0.847 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.529, lat_loss 22.009
09/22 03:51:48 PM | Train: [173/180] Step 650/1249 Loss 0.851 Prec@(1,3) (93.5%, 99.9%), ce_loss 0.529, lat_loss 22.009
09/22 03:52:04 PM | Train: [173/180] Step 700/1249 Loss 0.840 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.529, lat_loss 22.009
09/22 03:52:20 PM | Train: [173/180] Step 750/1249 Loss 0.829 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.529, lat_loss 22.009
09/22 03:52:36 PM | Train: [173/180] Step 800/1249 Loss 0.836 Prec@(1,3) (93.6%, 99.9%), ce_loss 0.529, lat_loss 22.009
09/22 03:52:51 PM | Train: [173/180] Step 850/1249 Loss 0.834 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.529, lat_loss 22.009
09/22 03:53:07 PM | Train: [173/180] Step 900/1249 Loss 0.823 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.529, lat_loss 22.009
09/22 03:53:23 PM | Train: [173/180] Step 950/1249 Loss 0.821 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.529, lat_loss 22.009
09/22 03:53:39 PM | Train: [173/180] Step 1000/1249 Loss 0.812 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.529, lat_loss 22.009
09/22 03:53:55 PM | Train: [173/180] Step 1050/1249 Loss 0.802 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.529, lat_loss 22.009
09/22 03:54:11 PM | Train: [173/180] Step 1100/1249 Loss 0.800 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.529, lat_loss 22.009
09/22 03:54:27 PM | Train: [173/180] Step 1150/1249 Loss 0.796 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.529, lat_loss 22.009
09/22 03:54:43 PM | Train: [173/180] Step 1200/1249 Loss 0.800 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.529, lat_loss 22.009
09/22 03:54:58 PM | Train: [173/180] Step 1249/1249 Loss 0.797 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.528, lat_loss 22.009
09/22 03:54:59 PM | _w_step_train: [173/180] Final Prec@1 93.8625% Time 477.94
09/22 03:54:59 PM | Start to train theta for epoch 172
09/22 03:55:20 PM | Train: [173/180] Step 050/312 Loss 1.863 Prec@(1,3) (87.9%, 99.3%), ce_loss 0.528, lat_loss 22.009
09/22 03:55:40 PM | Train: [173/180] Step 100/312 Loss 1.934 Prec@(1,3) (87.3%, 99.4%), ce_loss 0.528, lat_loss 22.009
09/22 03:55:59 PM | Train: [173/180] Step 150/312 Loss 2.001 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.528, lat_loss 22.009
09/22 03:56:20 PM | Train: [173/180] Step 200/312 Loss 1.995 Prec@(1,3) (87.1%, 99.3%), ce_loss 0.528, lat_loss 22.009
09/22 03:56:40 PM | Train: [173/180] Step 250/312 Loss 2.052 Prec@(1,3) (86.8%, 99.2%), ce_loss 0.528, lat_loss 22.009
09/22 03:57:00 PM | Train: [173/180] Step 300/312 Loss 2.011 Prec@(1,3) (86.8%, 99.2%), ce_loss 0.528, lat_loss 22.009
09/22 03:57:05 PM | Train: [173/180] Step 312/312 Loss 2.027 Prec@(1,3) (86.7%, 99.2%), ce_loss 0.528, lat_loss 22.009
09/22 03:57:05 PM | _theta_step_train: [173/180] Final Prec@1 86.7200% Time 126.10
09/22 03:57:10 PM | Valid: [173/180] Step 050/312 Loss 2.710 Prec@(1,3) (81.1%, 98.6%), ce_loss 0.528, lat_loss 22.009
09/22 03:57:14 PM | Valid: [173/180] Step 100/312 Loss 2.532 Prec@(1,3) (83.0%, 98.9%), ce_loss 0.528, lat_loss 22.009
09/22 03:57:18 PM | Valid: [173/180] Step 150/312 Loss 2.587 Prec@(1,3) (82.7%, 98.8%), ce_loss 0.528, lat_loss 22.009
09/22 03:57:22 PM | Valid: [173/180] Step 200/312 Loss 2.459 Prec@(1,3) (83.8%, 98.9%), ce_loss 0.528, lat_loss 22.009
09/22 03:57:27 PM | Valid: [173/180] Step 250/312 Loss 2.396 Prec@(1,3) (83.9%, 99.0%), ce_loss 0.528, lat_loss 22.009
09/22 03:57:31 PM | Valid: [173/180] Step 300/312 Loss 2.291 Prec@(1,3) (84.5%, 99.1%), ce_loss 0.528, lat_loss 22.009
09/22 03:57:32 PM | Valid: [173/180] Step 312/312 Loss 2.276 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.528, lat_loss 22.009
09/22 03:57:32 PM | val: [173/180] Final Prec@1 84.5800% Time 27.10
09/22 03:57:32 PM | Start to train weights for epoch 173
09/22 03:57:54 PM | Train: [174/180] Step 050/1249 Loss 0.605 Prec@(1,3) (94.9%, 99.9%), ce_loss 0.528, lat_loss 22.009
09/22 03:58:14 PM | Train: [174/180] Step 100/1249 Loss 0.669 Prec@(1,3) (94.8%, 99.9%), ce_loss 0.528, lat_loss 22.009
09/22 03:58:38 PM | Train: [174/180] Step 150/1249 Loss 0.672 Prec@(1,3) (94.7%, 99.9%), ce_loss 0.528, lat_loss 22.009
09/22 03:59:02 PM | Train: [174/180] Step 200/1249 Loss 0.683 Prec@(1,3) (94.6%, 99.9%), ce_loss 0.528, lat_loss 22.009
09/22 03:59:25 PM | Train: [174/180] Step 250/1249 Loss 0.693 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.528, lat_loss 22.009
09/22 03:59:48 PM | Train: [174/180] Step 300/1249 Loss 0.751 Prec@(1,3) (94.0%, 99.8%), ce_loss 0.528, lat_loss 22.010
09/22 04:00:12 PM | Train: [174/180] Step 350/1249 Loss 0.731 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.528, lat_loss 22.010
09/22 04:00:37 PM | Train: [174/180] Step 400/1249 Loss 0.740 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.528, lat_loss 22.010
09/22 04:01:01 PM | Train: [174/180] Step 450/1249 Loss 0.753 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.528, lat_loss 22.010
09/22 04:01:26 PM | Train: [174/180] Step 500/1249 Loss 0.754 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.528, lat_loss 22.010
09/22 04:01:51 PM | Train: [174/180] Step 550/1249 Loss 0.754 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.528, lat_loss 22.010
09/22 04:02:16 PM | Train: [174/180] Step 600/1249 Loss 0.783 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.528, lat_loss 22.010
09/22 04:02:41 PM | Train: [174/180] Step 650/1249 Loss 0.781 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.528, lat_loss 22.010
09/22 04:03:06 PM | Train: [174/180] Step 700/1249 Loss 0.774 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.528, lat_loss 22.010
09/22 04:03:30 PM | Train: [174/180] Step 750/1249 Loss 0.792 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.528, lat_loss 22.010
09/22 04:03:55 PM | Train: [174/180] Step 800/1249 Loss 0.797 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.527, lat_loss 22.010
09/22 04:04:19 PM | Train: [174/180] Step 850/1249 Loss 0.794 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.527, lat_loss 22.010
09/22 04:04:38 PM | Train: [174/180] Step 900/1249 Loss 0.799 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.527, lat_loss 22.010
09/22 04:04:54 PM | Train: [174/180] Step 950/1249 Loss 0.795 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.527, lat_loss 22.010
09/22 04:05:10 PM | Train: [174/180] Step 1000/1249 Loss 0.807 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.527, lat_loss 22.010
09/22 04:05:25 PM | Train: [174/180] Step 1050/1249 Loss 0.807 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.527, lat_loss 22.010
09/22 04:05:41 PM | Train: [174/180] Step 1100/1249 Loss 0.807 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.527, lat_loss 22.010
09/22 04:05:57 PM | Train: [174/180] Step 1150/1249 Loss 0.799 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.527, lat_loss 22.010
09/22 04:06:13 PM | Train: [174/180] Step 1200/1249 Loss 0.810 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.527, lat_loss 22.010
09/22 04:06:28 PM | Train: [174/180] Step 1249/1249 Loss 0.828 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.527, lat_loss 22.010
09/22 04:06:29 PM | _w_step_train: [174/180] Final Prec@1 93.7500% Time 537.18
09/22 04:06:29 PM | Start to train theta for epoch 173
09/22 04:06:49 PM | Train: [174/180] Step 050/312 Loss 1.884 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.527, lat_loss 22.010
09/22 04:07:07 PM | Train: [174/180] Step 100/312 Loss 1.923 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.527, lat_loss 22.010
09/22 04:07:25 PM | Train: [174/180] Step 150/312 Loss 1.957 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.527, lat_loss 22.010
09/22 04:07:44 PM | Train: [174/180] Step 200/312 Loss 2.013 Prec@(1,3) (86.0%, 99.5%), ce_loss 0.527, lat_loss 22.010
09/22 04:08:02 PM | Train: [174/180] Step 250/312 Loss 2.016 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.527, lat_loss 22.010
09/22 04:08:20 PM | Train: [174/180] Step 300/312 Loss 1.994 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.527, lat_loss 22.010
09/22 04:08:24 PM | Train: [174/180] Step 312/312 Loss 2.009 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.527, lat_loss 22.010
09/22 04:08:24 PM | _theta_step_train: [174/180] Final Prec@1 86.1500% Time 115.41
09/22 04:08:30 PM | Valid: [174/180] Step 050/312 Loss 2.024 Prec@(1,3) (84.7%, 99.7%), ce_loss 0.527, lat_loss 22.010
09/22 04:08:35 PM | Valid: [174/180] Step 100/312 Loss 2.197 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.527, lat_loss 22.010
09/22 04:08:39 PM | Valid: [174/180] Step 150/312 Loss 2.343 Prec@(1,3) (83.7%, 98.9%), ce_loss 0.527, lat_loss 22.010
09/22 04:08:44 PM | Valid: [174/180] Step 200/312 Loss 2.300 Prec@(1,3) (83.9%, 99.0%), ce_loss 0.527, lat_loss 22.010
09/22 04:08:49 PM | Valid: [174/180] Step 250/312 Loss 2.281 Prec@(1,3) (83.9%, 99.0%), ce_loss 0.527, lat_loss 22.010
09/22 04:08:53 PM | Valid: [174/180] Step 300/312 Loss 2.198 Prec@(1,3) (84.5%, 99.1%), ce_loss 0.527, lat_loss 22.010
09/22 04:08:55 PM | Valid: [174/180] Step 312/312 Loss 2.194 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.527, lat_loss 22.010
09/22 04:08:55 PM | val: [174/180] Final Prec@1 84.6000% Time 30.66
09/22 04:08:55 PM | Start to train weights for epoch 174
09/22 04:09:20 PM | Train: [175/180] Step 050/1249 Loss 0.915 Prec@(1,3) (93.1%, 99.7%), ce_loss 0.527, lat_loss 22.010
09/22 04:09:43 PM | Train: [175/180] Step 100/1249 Loss 0.833 Prec@(1,3) (93.4%, 99.8%), ce_loss 0.527, lat_loss 22.010
09/22 04:10:05 PM | Train: [175/180] Step 150/1249 Loss 0.794 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.527, lat_loss 22.010
09/22 04:10:28 PM | Train: [175/180] Step 200/1249 Loss 0.762 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.527, lat_loss 22.010
09/22 04:10:50 PM | Train: [175/180] Step 250/1249 Loss 0.773 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.527, lat_loss 22.010
09/22 04:11:13 PM | Train: [175/180] Step 300/1249 Loss 0.785 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.527, lat_loss 22.010
09/22 04:11:36 PM | Train: [175/180] Step 350/1249 Loss 0.776 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.527, lat_loss 22.010
09/22 04:12:00 PM | Train: [175/180] Step 400/1249 Loss 0.781 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.526, lat_loss 22.010
09/22 04:12:24 PM | Train: [175/180] Step 450/1249 Loss 0.776 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.526, lat_loss 22.010
09/22 04:12:49 PM | Train: [175/180] Step 500/1249 Loss 0.798 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.526, lat_loss 22.010
09/22 04:13:14 PM | Train: [175/180] Step 550/1249 Loss 0.794 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.526, lat_loss 22.010
09/22 04:13:38 PM | Train: [175/180] Step 600/1249 Loss 0.784 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.526, lat_loss 22.010
09/22 04:14:02 PM | Train: [175/180] Step 650/1249 Loss 0.775 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.526, lat_loss 22.010
09/22 04:14:24 PM | Train: [175/180] Step 700/1249 Loss 0.772 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.526, lat_loss 22.010
09/22 04:14:45 PM | Train: [175/180] Step 750/1249 Loss 0.775 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.526, lat_loss 22.010
09/22 04:15:07 PM | Train: [175/180] Step 800/1249 Loss 0.777 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.526, lat_loss 22.010
09/22 04:15:31 PM | Train: [175/180] Step 850/1249 Loss 0.772 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.526, lat_loss 22.011
09/22 04:15:55 PM | Train: [175/180] Step 900/1249 Loss 0.764 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.526, lat_loss 22.011
09/22 04:16:19 PM | Train: [175/180] Step 950/1249 Loss 0.763 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.526, lat_loss 22.011
09/22 04:16:43 PM | Train: [175/180] Step 1000/1249 Loss 0.763 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.526, lat_loss 22.011
09/22 04:17:06 PM | Train: [175/180] Step 1050/1249 Loss 0.764 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.526, lat_loss 22.011
09/22 04:17:30 PM | Train: [175/180] Step 1100/1249 Loss 0.762 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.526, lat_loss 22.011
09/22 04:17:53 PM | Train: [175/180] Step 1150/1249 Loss 0.754 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.526, lat_loss 22.011
09/22 04:18:18 PM | Train: [175/180] Step 1200/1249 Loss 0.753 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.526, lat_loss 22.011
09/22 04:18:42 PM | Train: [175/180] Step 1249/1249 Loss 0.749 Prec@(1,3) (94.3%, 99.9%), ce_loss 0.526, lat_loss 22.011
09/22 04:18:42 PM | _w_step_train: [175/180] Final Prec@1 94.2750% Time 587.23
09/22 04:18:42 PM | Start to train theta for epoch 174
09/22 04:19:03 PM | Train: [175/180] Step 050/312 Loss 2.055 Prec@(1,3) (86.6%, 99.6%), ce_loss 0.526, lat_loss 22.011
09/22 04:19:22 PM | Train: [175/180] Step 100/312 Loss 2.127 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.526, lat_loss 22.011
09/22 04:19:42 PM | Train: [175/180] Step 150/312 Loss 2.199 Prec@(1,3) (85.6%, 99.1%), ce_loss 0.526, lat_loss 22.011
09/22 04:20:03 PM | Train: [175/180] Step 200/312 Loss 2.158 Prec@(1,3) (85.8%, 99.1%), ce_loss 0.526, lat_loss 22.011
09/22 04:20:23 PM | Train: [175/180] Step 250/312 Loss 2.219 Prec@(1,3) (85.5%, 98.9%), ce_loss 0.526, lat_loss 22.011
09/22 04:20:43 PM | Train: [175/180] Step 300/312 Loss 2.165 Prec@(1,3) (85.6%, 99.0%), ce_loss 0.526, lat_loss 22.011
09/22 04:20:48 PM | Train: [175/180] Step 312/312 Loss 2.140 Prec@(1,3) (85.8%, 99.0%), ce_loss 0.525, lat_loss 22.011
09/22 04:20:48 PM | _theta_step_train: [175/180] Final Prec@1 85.7900% Time 125.36
09/22 04:20:53 PM | Valid: [175/180] Step 050/312 Loss 2.213 Prec@(1,3) (84.4%, 98.8%), ce_loss 0.525, lat_loss 22.011
09/22 04:20:58 PM | Valid: [175/180] Step 100/312 Loss 2.233 Prec@(1,3) (84.8%, 98.9%), ce_loss 0.525, lat_loss 22.011
09/22 04:21:02 PM | Valid: [175/180] Step 150/312 Loss 2.360 Prec@(1,3) (84.0%, 98.7%), ce_loss 0.525, lat_loss 22.011
09/22 04:21:07 PM | Valid: [175/180] Step 200/312 Loss 2.241 Prec@(1,3) (84.9%, 98.9%), ce_loss 0.525, lat_loss 22.011
09/22 04:21:12 PM | Valid: [175/180] Step 250/312 Loss 2.206 Prec@(1,3) (85.0%, 98.9%), ce_loss 0.525, lat_loss 22.011
09/22 04:21:16 PM | Valid: [175/180] Step 300/312 Loss 2.163 Prec@(1,3) (85.2%, 99.0%), ce_loss 0.525, lat_loss 22.011
09/22 04:21:18 PM | Valid: [175/180] Step 312/312 Loss 2.204 Prec@(1,3) (84.8%, 99.0%), ce_loss 0.525, lat_loss 22.011
09/22 04:21:18 PM | val: [175/180] Final Prec@1 84.8400% Time 29.86
09/22 04:21:18 PM | Start to train weights for epoch 175
09/22 04:21:35 PM | Train: [176/180] Step 050/1249 Loss 0.785 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.525, lat_loss 22.011
09/22 04:21:51 PM | Train: [176/180] Step 100/1249 Loss 0.746 Prec@(1,3) (94.2%, 99.8%), ce_loss 0.525, lat_loss 22.011
09/22 04:22:12 PM | Train: [176/180] Step 150/1249 Loss 0.765 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.525, lat_loss 22.011
09/22 04:22:35 PM | Train: [176/180] Step 200/1249 Loss 0.731 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.525, lat_loss 22.011
09/22 04:22:59 PM | Train: [176/180] Step 250/1249 Loss 0.734 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.525, lat_loss 22.011
09/22 04:23:23 PM | Train: [176/180] Step 300/1249 Loss 0.774 Prec@(1,3) (94.0%, 99.8%), ce_loss 0.525, lat_loss 22.011
09/22 04:23:46 PM | Train: [176/180] Step 350/1249 Loss 0.758 Prec@(1,3) (94.2%, 99.8%), ce_loss 0.525, lat_loss 22.011
09/22 04:24:09 PM | Train: [176/180] Step 400/1249 Loss 0.746 Prec@(1,3) (94.3%, 99.8%), ce_loss 0.525, lat_loss 22.011
09/22 04:24:31 PM | Train: [176/180] Step 450/1249 Loss 0.737 Prec@(1,3) (94.4%, 99.8%), ce_loss 0.525, lat_loss 22.011
09/22 04:24:55 PM | Train: [176/180] Step 500/1249 Loss 0.739 Prec@(1,3) (94.4%, 99.8%), ce_loss 0.525, lat_loss 22.011
09/22 04:25:19 PM | Train: [176/180] Step 550/1249 Loss 0.733 Prec@(1,3) (94.4%, 99.8%), ce_loss 0.525, lat_loss 22.011
09/22 04:25:44 PM | Train: [176/180] Step 600/1249 Loss 0.719 Prec@(1,3) (94.5%, 99.8%), ce_loss 0.525, lat_loss 22.011
09/22 04:26:08 PM | Train: [176/180] Step 650/1249 Loss 0.718 Prec@(1,3) (94.5%, 99.8%), ce_loss 0.525, lat_loss 22.011
09/22 04:26:33 PM | Train: [176/180] Step 700/1249 Loss 0.714 Prec@(1,3) (94.6%, 99.8%), ce_loss 0.525, lat_loss 22.011
09/22 04:26:57 PM | Train: [176/180] Step 750/1249 Loss 0.717 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.525, lat_loss 22.011
09/22 04:27:22 PM | Train: [176/180] Step 800/1249 Loss 0.722 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.525, lat_loss 22.011
09/22 04:27:46 PM | Train: [176/180] Step 850/1249 Loss 0.733 Prec@(1,3) (94.4%, 99.8%), ce_loss 0.525, lat_loss 22.011
09/22 04:28:11 PM | Train: [176/180] Step 900/1249 Loss 0.756 Prec@(1,3) (94.3%, 99.8%), ce_loss 0.524, lat_loss 22.011
09/22 04:28:35 PM | Train: [176/180] Step 950/1249 Loss 0.757 Prec@(1,3) (94.3%, 99.8%), ce_loss 0.524, lat_loss 22.011
09/22 04:29:00 PM | Train: [176/180] Step 1000/1249 Loss 0.759 Prec@(1,3) (94.3%, 99.8%), ce_loss 0.524, lat_loss 22.011
09/22 04:29:23 PM | Train: [176/180] Step 1050/1249 Loss 0.782 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.524, lat_loss 22.011
09/22 04:29:48 PM | Train: [176/180] Step 1100/1249 Loss 0.777 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.524, lat_loss 22.011
09/22 04:30:12 PM | Train: [176/180] Step 1150/1249 Loss 0.776 Prec@(1,3) (94.1%, 99.8%), ce_loss 0.524, lat_loss 22.011
09/22 04:30:37 PM | Train: [176/180] Step 1200/1249 Loss 0.766 Prec@(1,3) (94.2%, 99.8%), ce_loss 0.524, lat_loss 22.011
09/22 04:31:01 PM | Train: [176/180] Step 1249/1249 Loss 0.763 Prec@(1,3) (94.2%, 99.8%), ce_loss 0.524, lat_loss 22.011
09/22 04:31:01 PM | _w_step_train: [176/180] Final Prec@1 94.2325% Time 583.80
09/22 04:31:01 PM | Start to train theta for epoch 175
09/22 04:31:20 PM | Train: [176/180] Step 050/312 Loss 1.730 Prec@(1,3) (87.7%, 99.5%), ce_loss 0.524, lat_loss 22.011
09/22 04:31:38 PM | Train: [176/180] Step 100/312 Loss 1.801 Prec@(1,3) (87.6%, 99.4%), ce_loss 0.524, lat_loss 22.012
09/22 04:31:54 PM | Train: [176/180] Step 150/312 Loss 1.847 Prec@(1,3) (87.4%, 99.4%), ce_loss 0.524, lat_loss 22.012
09/22 04:32:12 PM | Train: [176/180] Step 200/312 Loss 1.903 Prec@(1,3) (87.2%, 99.3%), ce_loss 0.524, lat_loss 22.012
09/22 04:32:31 PM | Train: [176/180] Step 250/312 Loss 1.917 Prec@(1,3) (87.1%, 99.3%), ce_loss 0.524, lat_loss 22.012
09/22 04:32:50 PM | Train: [176/180] Step 300/312 Loss 1.931 Prec@(1,3) (87.0%, 99.3%), ce_loss 0.524, lat_loss 22.012
09/22 04:32:54 PM | Train: [176/180] Step 312/312 Loss 1.920 Prec@(1,3) (87.1%, 99.3%), ce_loss 0.524, lat_loss 22.012
09/22 04:32:55 PM | _theta_step_train: [176/180] Final Prec@1 87.1000% Time 113.12
09/22 04:33:00 PM | Valid: [176/180] Step 050/312 Loss 2.312 Prec@(1,3) (83.0%, 98.7%), ce_loss 0.524, lat_loss 22.012
09/22 04:33:05 PM | Valid: [176/180] Step 100/312 Loss 2.460 Prec@(1,3) (82.7%, 98.5%), ce_loss 0.524, lat_loss 22.012
09/22 04:33:10 PM | Valid: [176/180] Step 150/312 Loss 2.403 Prec@(1,3) (83.2%, 98.5%), ce_loss 0.524, lat_loss 22.012
09/22 04:33:14 PM | Valid: [176/180] Step 200/312 Loss 2.377 Prec@(1,3) (83.7%, 98.5%), ce_loss 0.524, lat_loss 22.012
09/22 04:33:19 PM | Valid: [176/180] Step 250/312 Loss 2.273 Prec@(1,3) (84.5%, 98.7%), ce_loss 0.524, lat_loss 22.012
09/22 04:33:24 PM | Valid: [176/180] Step 300/312 Loss 2.179 Prec@(1,3) (84.9%, 98.8%), ce_loss 0.524, lat_loss 22.012
09/22 04:33:25 PM | Valid: [176/180] Step 312/312 Loss 2.211 Prec@(1,3) (84.7%, 98.7%), ce_loss 0.524, lat_loss 22.012
09/22 04:33:25 PM | val: [176/180] Final Prec@1 84.6600% Time 30.22
09/22 04:33:25 PM | Start to train weights for epoch 176
09/22 04:33:50 PM | Train: [177/180] Step 050/1249 Loss 0.773 Prec@(1,3) (94.3%, 99.8%), ce_loss 0.524, lat_loss 22.012
09/22 04:34:14 PM | Train: [177/180] Step 100/1249 Loss 0.897 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.524, lat_loss 22.012
09/22 04:34:36 PM | Train: [177/180] Step 150/1249 Loss 0.851 Prec@(1,3) (94.0%, 99.8%), ce_loss 0.524, lat_loss 22.012
09/22 04:35:00 PM | Train: [177/180] Step 200/1249 Loss 0.847 Prec@(1,3) (94.0%, 99.8%), ce_loss 0.524, lat_loss 22.012
09/22 04:35:25 PM | Train: [177/180] Step 250/1249 Loss 0.819 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.524, lat_loss 22.012
09/22 04:35:47 PM | Train: [177/180] Step 300/1249 Loss 0.817 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.524, lat_loss 22.012
09/22 04:36:11 PM | Train: [177/180] Step 350/1249 Loss 0.794 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.524, lat_loss 22.012
09/22 04:36:34 PM | Train: [177/180] Step 400/1249 Loss 0.854 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.524, lat_loss 22.012
09/22 04:36:59 PM | Train: [177/180] Step 450/1249 Loss 0.837 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.524, lat_loss 22.012
09/22 04:37:22 PM | Train: [177/180] Step 500/1249 Loss 0.825 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.523, lat_loss 22.012
09/22 04:37:45 PM | Train: [177/180] Step 550/1249 Loss 0.822 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.523, lat_loss 22.012
09/22 04:38:08 PM | Train: [177/180] Step 600/1249 Loss 0.815 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.523, lat_loss 22.012
09/22 04:38:32 PM | Train: [177/180] Step 650/1249 Loss 0.810 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.523, lat_loss 22.012
09/22 04:38:56 PM | Train: [177/180] Step 700/1249 Loss 0.813 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.523, lat_loss 22.012
09/22 04:39:20 PM | Train: [177/180] Step 750/1249 Loss 0.803 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.523, lat_loss 22.012
09/22 04:39:43 PM | Train: [177/180] Step 800/1249 Loss 0.825 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.523, lat_loss 22.012
09/22 04:40:04 PM | Train: [177/180] Step 850/1249 Loss 0.846 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.523, lat_loss 22.012
09/22 04:40:24 PM | Train: [177/180] Step 900/1249 Loss 0.850 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.523, lat_loss 22.012
09/22 04:40:43 PM | Train: [177/180] Step 950/1249 Loss 0.849 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.523, lat_loss 22.012
09/22 04:41:02 PM | Train: [177/180] Step 1000/1249 Loss 0.839 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.523, lat_loss 22.012
09/22 04:41:21 PM | Train: [177/180] Step 1050/1249 Loss 0.845 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.523, lat_loss 22.012
09/22 04:41:41 PM | Train: [177/180] Step 1100/1249 Loss 0.853 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.523, lat_loss 22.012
09/22 04:42:00 PM | Train: [177/180] Step 1150/1249 Loss 0.852 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.523, lat_loss 22.012
09/22 04:42:20 PM | Train: [177/180] Step 1200/1249 Loss 0.846 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.523, lat_loss 22.012
09/22 04:42:44 PM | Train: [177/180] Step 1249/1249 Loss 0.845 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.523, lat_loss 22.012
09/22 04:42:44 PM | _w_step_train: [177/180] Final Prec@1 93.8325% Time 559.20
09/22 04:42:44 PM | Start to train theta for epoch 176
09/22 04:43:05 PM | Train: [177/180] Step 050/312 Loss 2.321 Prec@(1,3) (84.9%, 98.8%), ce_loss 0.523, lat_loss 22.012
09/22 04:43:26 PM | Train: [177/180] Step 100/312 Loss 2.075 Prec@(1,3) (86.2%, 99.1%), ce_loss 0.523, lat_loss 22.012
09/22 04:43:44 PM | Train: [177/180] Step 150/312 Loss 1.997 Prec@(1,3) (86.7%, 99.2%), ce_loss 0.523, lat_loss 22.012
09/22 04:44:05 PM | Train: [177/180] Step 200/312 Loss 2.068 Prec@(1,3) (86.4%, 99.3%), ce_loss 0.523, lat_loss 22.012
09/22 04:44:25 PM | Train: [177/180] Step 250/312 Loss 2.065 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.523, lat_loss 22.013
09/22 04:44:45 PM | Train: [177/180] Step 300/312 Loss 2.075 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.523, lat_loss 22.013
09/22 04:44:50 PM | Train: [177/180] Step 312/312 Loss 2.080 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.523, lat_loss 22.013
09/22 04:44:50 PM | _theta_step_train: [177/180] Final Prec@1 86.5200% Time 125.60
09/22 04:44:55 PM | Valid: [177/180] Step 050/312 Loss 2.106 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.523, lat_loss 22.013
09/22 04:45:00 PM | Valid: [177/180] Step 100/312 Loss 2.243 Prec@(1,3) (84.8%, 99.1%), ce_loss 0.523, lat_loss 22.013
09/22 04:45:05 PM | Valid: [177/180] Step 150/312 Loss 2.286 Prec@(1,3) (84.3%, 99.1%), ce_loss 0.523, lat_loss 22.013
09/22 04:45:09 PM | Valid: [177/180] Step 200/312 Loss 2.318 Prec@(1,3) (84.2%, 98.9%), ce_loss 0.523, lat_loss 22.013
09/22 04:45:14 PM | Valid: [177/180] Step 250/312 Loss 2.238 Prec@(1,3) (84.7%, 99.0%), ce_loss 0.523, lat_loss 22.013
09/22 04:45:19 PM | Valid: [177/180] Step 300/312 Loss 2.239 Prec@(1,3) (84.6%, 99.0%), ce_loss 0.523, lat_loss 22.013
09/22 04:45:20 PM | Valid: [177/180] Step 312/312 Loss 2.233 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.523, lat_loss 22.013
09/22 04:45:20 PM | val: [177/180] Final Prec@1 84.6200% Time 30.34
09/22 04:45:20 PM | Start to train weights for epoch 177
09/22 04:45:45 PM | Train: [178/180] Step 050/1249 Loss 0.641 Prec@(1,3) (94.4%, 99.9%), ce_loss 0.523, lat_loss 22.013
09/22 04:46:10 PM | Train: [178/180] Step 100/1249 Loss 0.680 Prec@(1,3) (94.3%, 100.0%), ce_loss 0.523, lat_loss 22.013
09/22 04:46:33 PM | Train: [178/180] Step 150/1249 Loss 0.729 Prec@(1,3) (93.8%, 100.0%), ce_loss 0.522, lat_loss 22.013
09/22 04:46:57 PM | Train: [178/180] Step 200/1249 Loss 0.730 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.522, lat_loss 22.013
09/22 04:47:22 PM | Train: [178/180] Step 250/1249 Loss 0.740 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.522, lat_loss 22.013
09/22 04:47:46 PM | Train: [178/180] Step 300/1249 Loss 0.775 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.522, lat_loss 22.013
09/22 04:48:11 PM | Train: [178/180] Step 350/1249 Loss 0.782 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.522, lat_loss 22.013
09/22 04:48:35 PM | Train: [178/180] Step 400/1249 Loss 0.823 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.522, lat_loss 22.013
09/22 04:49:00 PM | Train: [178/180] Step 450/1249 Loss 0.813 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.522, lat_loss 22.013
09/22 04:49:24 PM | Train: [178/180] Step 500/1249 Loss 0.806 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.522, lat_loss 22.013
09/22 04:49:49 PM | Train: [178/180] Step 550/1249 Loss 0.804 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.522, lat_loss 22.013
09/22 04:50:13 PM | Train: [178/180] Step 600/1249 Loss 0.822 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.522, lat_loss 22.013
09/22 04:50:38 PM | Train: [178/180] Step 650/1249 Loss 0.819 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.522, lat_loss 22.013
09/22 04:51:02 PM | Train: [178/180] Step 700/1249 Loss 0.811 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.522, lat_loss 22.013
09/22 04:51:27 PM | Train: [178/180] Step 750/1249 Loss 0.804 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.522, lat_loss 22.013
09/22 04:51:51 PM | Train: [178/180] Step 800/1249 Loss 0.811 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.522, lat_loss 22.013
09/22 04:52:15 PM | Train: [178/180] Step 850/1249 Loss 0.815 Prec@(1,3) (93.7%, 99.9%), ce_loss 0.522, lat_loss 22.013
09/22 04:52:40 PM | Train: [178/180] Step 900/1249 Loss 0.807 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.522, lat_loss 22.013
09/22 04:53:05 PM | Train: [178/180] Step 950/1249 Loss 0.796 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.522, lat_loss 22.013
09/22 04:53:30 PM | Train: [178/180] Step 1000/1249 Loss 0.796 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.522, lat_loss 22.013
09/22 04:53:54 PM | Train: [178/180] Step 1050/1249 Loss 0.796 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.522, lat_loss 22.013
09/22 04:54:18 PM | Train: [178/180] Step 1100/1249 Loss 0.800 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.521, lat_loss 22.013
09/22 04:54:43 PM | Train: [178/180] Step 1150/1249 Loss 0.797 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.521, lat_loss 22.013
09/22 04:55:07 PM | Train: [178/180] Step 1200/1249 Loss 0.802 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.521, lat_loss 22.013
09/22 04:55:32 PM | Train: [178/180] Step 1249/1249 Loss 0.802 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.521, lat_loss 22.013
09/22 04:55:32 PM | _w_step_train: [178/180] Final Prec@1 93.7975% Time 612.11
09/22 04:55:32 PM | Start to train theta for epoch 177
09/22 04:55:53 PM | Train: [178/180] Step 050/312 Loss 1.910 Prec@(1,3) (86.8%, 99.5%), ce_loss 0.521, lat_loss 22.013
09/22 04:56:13 PM | Train: [178/180] Step 100/312 Loss 1.971 Prec@(1,3) (86.7%, 99.2%), ce_loss 0.521, lat_loss 22.013
09/22 04:56:33 PM | Train: [178/180] Step 150/312 Loss 1.980 Prec@(1,3) (86.8%, 99.1%), ce_loss 0.521, lat_loss 22.013
09/22 04:56:54 PM | Train: [178/180] Step 200/312 Loss 1.974 Prec@(1,3) (86.8%, 99.1%), ce_loss 0.521, lat_loss 22.013
09/22 04:57:13 PM | Train: [178/180] Step 250/312 Loss 1.954 Prec@(1,3) (87.0%, 99.2%), ce_loss 0.521, lat_loss 22.013
09/22 04:57:31 PM | Train: [178/180] Step 300/312 Loss 1.990 Prec@(1,3) (86.8%, 99.2%), ce_loss 0.521, lat_loss 22.013
09/22 04:57:36 PM | Train: [178/180] Step 312/312 Loss 1.993 Prec@(1,3) (86.8%, 99.2%), ce_loss 0.521, lat_loss 22.013
09/22 04:57:36 PM | _theta_step_train: [178/180] Final Prec@1 86.7700% Time 123.66
09/22 04:57:42 PM | Valid: [178/180] Step 050/312 Loss 2.184 Prec@(1,3) (84.0%, 99.3%), ce_loss 0.521, lat_loss 22.014
09/22 04:57:46 PM | Valid: [178/180] Step 100/312 Loss 2.279 Prec@(1,3) (83.9%, 98.9%), ce_loss 0.521, lat_loss 22.014
09/22 04:57:51 PM | Valid: [178/180] Step 150/312 Loss 2.287 Prec@(1,3) (83.9%, 98.9%), ce_loss 0.521, lat_loss 22.014
09/22 04:57:56 PM | Valid: [178/180] Step 200/312 Loss 2.271 Prec@(1,3) (84.0%, 98.8%), ce_loss 0.521, lat_loss 22.014
09/22 04:58:00 PM | Valid: [178/180] Step 250/312 Loss 2.326 Prec@(1,3) (83.7%, 98.8%), ce_loss 0.521, lat_loss 22.014
09/22 04:58:05 PM | Valid: [178/180] Step 300/312 Loss 2.269 Prec@(1,3) (83.9%, 98.9%), ce_loss 0.521, lat_loss 22.014
09/22 04:58:06 PM | Valid: [178/180] Step 312/312 Loss 2.263 Prec@(1,3) (84.0%, 98.9%), ce_loss 0.521, lat_loss 22.014
09/22 04:58:06 PM | val: [178/180] Final Prec@1 83.9700% Time 30.39
09/22 04:58:06 PM | Start to train weights for epoch 178
09/22 04:58:31 PM | Train: [179/180] Step 050/1249 Loss 0.795 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.521, lat_loss 22.014
09/22 04:58:55 PM | Train: [179/180] Step 100/1249 Loss 0.823 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.521, lat_loss 22.014
09/22 04:59:18 PM | Train: [179/180] Step 150/1249 Loss 0.787 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.521, lat_loss 22.014
09/22 04:59:42 PM | Train: [179/180] Step 200/1249 Loss 0.778 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.521, lat_loss 22.014
09/22 05:00:04 PM | Train: [179/180] Step 250/1249 Loss 0.775 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.521, lat_loss 22.014
09/22 05:00:27 PM | Train: [179/180] Step 300/1249 Loss 0.799 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.521, lat_loss 22.014
09/22 05:00:50 PM | Train: [179/180] Step 350/1249 Loss 0.774 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.521, lat_loss 22.014
09/22 05:01:13 PM | Train: [179/180] Step 400/1249 Loss 0.774 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.521, lat_loss 22.014
09/22 05:01:37 PM | Train: [179/180] Step 450/1249 Loss 0.802 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.521, lat_loss 22.014
09/22 05:02:01 PM | Train: [179/180] Step 500/1249 Loss 0.801 Prec@(1,3) (93.9%, 99.9%), ce_loss 0.521, lat_loss 22.014
09/22 05:02:24 PM | Train: [179/180] Step 550/1249 Loss 0.778 Prec@(1,3) (94.0%, 99.9%), ce_loss 0.521, lat_loss 22.014
09/22 05:02:48 PM | Train: [179/180] Step 600/1249 Loss 0.771 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.521, lat_loss 22.014
09/22 05:03:12 PM | Train: [179/180] Step 650/1249 Loss 0.762 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.521, lat_loss 22.014
09/22 05:03:34 PM | Train: [179/180] Step 700/1249 Loss 0.768 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.521, lat_loss 22.014
09/22 05:03:55 PM | Train: [179/180] Step 750/1249 Loss 0.762 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.520, lat_loss 22.014
09/22 05:04:17 PM | Train: [179/180] Step 800/1249 Loss 0.786 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.520, lat_loss 22.014
09/22 05:04:38 PM | Train: [179/180] Step 850/1249 Loss 0.785 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.520, lat_loss 22.014
09/22 05:05:01 PM | Train: [179/180] Step 900/1249 Loss 0.780 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.520, lat_loss 22.014
09/22 05:05:24 PM | Train: [179/180] Step 950/1249 Loss 0.774 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.520, lat_loss 22.014
09/22 05:05:48 PM | Train: [179/180] Step 1000/1249 Loss 0.772 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.520, lat_loss 22.014
09/22 05:06:13 PM | Train: [179/180] Step 1050/1249 Loss 0.768 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.520, lat_loss 22.014
09/22 05:06:38 PM | Train: [179/180] Step 1100/1249 Loss 0.780 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.520, lat_loss 22.014
09/22 05:07:03 PM | Train: [179/180] Step 1150/1249 Loss 0.782 Prec@(1,3) (94.2%, 99.9%), ce_loss 0.520, lat_loss 22.014
09/22 05:07:28 PM | Train: [179/180] Step 1200/1249 Loss 0.785 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.520, lat_loss 22.014
09/22 05:07:53 PM | Train: [179/180] Step 1249/1249 Loss 0.796 Prec@(1,3) (94.1%, 99.9%), ce_loss 0.520, lat_loss 22.014
09/22 05:07:53 PM | _w_step_train: [179/180] Final Prec@1 94.0875% Time 586.47
09/22 05:07:53 PM | Start to train theta for epoch 178
09/22 05:08:14 PM | Train: [179/180] Step 050/312 Loss 2.115 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.520, lat_loss 22.014
09/22 05:08:35 PM | Train: [179/180] Step 100/312 Loss 2.182 Prec@(1,3) (85.8%, 99.0%), ce_loss 0.520, lat_loss 22.014
09/22 05:08:55 PM | Train: [179/180] Step 150/312 Loss 2.054 Prec@(1,3) (86.2%, 99.1%), ce_loss 0.520, lat_loss 22.014
09/22 05:09:14 PM | Train: [179/180] Step 200/312 Loss 2.045 Prec@(1,3) (86.5%, 99.2%), ce_loss 0.520, lat_loss 22.014
09/22 05:09:35 PM | Train: [179/180] Step 250/312 Loss 1.997 Prec@(1,3) (86.7%, 99.2%), ce_loss 0.520, lat_loss 22.014
09/22 05:09:55 PM | Train: [179/180] Step 300/312 Loss 2.011 Prec@(1,3) (86.6%, 99.2%), ce_loss 0.520, lat_loss 22.014
09/22 05:10:00 PM | Train: [179/180] Step 312/312 Loss 2.011 Prec@(1,3) (86.6%, 99.2%), ce_loss 0.520, lat_loss 22.014
09/22 05:10:00 PM | _theta_step_train: [179/180] Final Prec@1 86.6300% Time 127.19
09/22 05:10:05 PM | Valid: [179/180] Step 050/312 Loss 2.007 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.520, lat_loss 22.014
09/22 05:10:10 PM | Valid: [179/180] Step 100/312 Loss 2.276 Prec@(1,3) (84.3%, 98.8%), ce_loss 0.520, lat_loss 22.014
09/22 05:10:14 PM | Valid: [179/180] Step 150/312 Loss 2.267 Prec@(1,3) (84.3%, 98.8%), ce_loss 0.520, lat_loss 22.015
09/22 05:10:19 PM | Valid: [179/180] Step 200/312 Loss 2.176 Prec@(1,3) (84.7%, 98.9%), ce_loss 0.520, lat_loss 22.015
09/22 05:10:24 PM | Valid: [179/180] Step 250/312 Loss 2.219 Prec@(1,3) (84.2%, 98.9%), ce_loss 0.520, lat_loss 22.015
09/22 05:10:28 PM | Valid: [179/180] Step 300/312 Loss 2.171 Prec@(1,3) (84.3%, 98.9%), ce_loss 0.520, lat_loss 22.015
09/22 05:10:29 PM | Valid: [179/180] Step 312/312 Loss 2.182 Prec@(1,3) (84.3%, 98.9%), ce_loss 0.520, lat_loss 22.015
09/22 05:10:30 PM | val: [179/180] Final Prec@1 84.2700% Time 29.65
09/22 05:10:30 PM | Start to train weights for epoch 179
09/22 05:10:55 PM | Train: [180/180] Step 050/1249 Loss 0.732 Prec@(1,3) (94.5%, 99.9%), ce_loss 0.520, lat_loss 22.015
09/22 05:11:19 PM | Train: [180/180] Step 100/1249 Loss 0.748 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.520, lat_loss 22.015
09/22 05:11:42 PM | Train: [180/180] Step 150/1249 Loss 0.979 Prec@(1,3) (93.0%, 99.7%), ce_loss 0.520, lat_loss 22.015
09/22 05:12:05 PM | Train: [180/180] Step 200/1249 Loss 0.907 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.520, lat_loss 22.015
09/22 05:12:28 PM | Train: [180/180] Step 250/1249 Loss 0.918 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.520, lat_loss 22.015
09/22 05:12:52 PM | Train: [180/180] Step 300/1249 Loss 0.892 Prec@(1,3) (93.5%, 99.8%), ce_loss 0.520, lat_loss 22.015
09/22 05:13:16 PM | Train: [180/180] Step 350/1249 Loss 0.855 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.520, lat_loss 22.015
09/22 05:13:40 PM | Train: [180/180] Step 400/1249 Loss 0.847 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.519, lat_loss 22.015
09/22 05:14:04 PM | Train: [180/180] Step 450/1249 Loss 0.853 Prec@(1,3) (93.6%, 99.8%), ce_loss 0.519, lat_loss 22.015
09/22 05:14:28 PM | Train: [180/180] Step 500/1249 Loss 0.839 Prec@(1,3) (93.7%, 99.8%), ce_loss 0.519, lat_loss 22.015
09/22 05:14:52 PM | Train: [180/180] Step 550/1249 Loss 0.832 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.519, lat_loss 22.015
09/22 05:15:15 PM | Train: [180/180] Step 600/1249 Loss 0.828 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.519, lat_loss 22.015
09/22 05:15:39 PM | Train: [180/180] Step 650/1249 Loss 0.822 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.519, lat_loss 22.015
09/22 05:16:03 PM | Train: [180/180] Step 700/1249 Loss 0.806 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.519, lat_loss 22.015
09/22 05:16:26 PM | Train: [180/180] Step 750/1249 Loss 0.808 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.519, lat_loss 22.015
09/22 05:16:51 PM | Train: [180/180] Step 800/1249 Loss 0.811 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.519, lat_loss 22.015
09/22 05:17:14 PM | Train: [180/180] Step 850/1249 Loss 0.803 Prec@(1,3) (93.9%, 99.8%), ce_loss 0.519, lat_loss 22.015
09/22 05:17:34 PM | Train: [180/180] Step 900/1249 Loss 0.807 Prec@(1,3) (93.8%, 99.8%), ce_loss 0.519, lat_loss 22.015
09/22 05:17:58 PM | Train: [180/180] Step 950/1249 Loss 0.805 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.519, lat_loss 22.015
09/22 05:18:21 PM | Train: [180/180] Step 1000/1249 Loss 0.807 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.519, lat_loss 22.015
09/22 05:18:44 PM | Train: [180/180] Step 1050/1249 Loss 0.809 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.519, lat_loss 22.015
09/22 05:19:08 PM | Train: [180/180] Step 1100/1249 Loss 0.810 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.519, lat_loss 22.015
09/22 05:19:33 PM | Train: [180/180] Step 1150/1249 Loss 0.812 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.519, lat_loss 22.015
09/22 05:19:58 PM | Train: [180/180] Step 1200/1249 Loss 0.812 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.519, lat_loss 22.015
09/22 05:20:17 PM | Train: [180/180] Step 1249/1249 Loss 0.809 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.519, lat_loss 22.015
09/22 05:20:17 PM | _w_step_train: [180/180] Final Prec@1 93.8350% Time 587.68
09/22 05:20:17 PM | Start to train theta for epoch 179
09/22 05:20:30 PM | Train: [180/180] Step 050/312 Loss 2.111 Prec@(1,3) (86.6%, 99.1%), ce_loss 0.519, lat_loss 22.015
09/22 05:20:49 PM | Train: [180/180] Step 100/312 Loss 2.164 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.519, lat_loss 22.015
09/22 05:21:10 PM | Train: [180/180] Step 150/312 Loss 2.170 Prec@(1,3) (85.8%, 99.0%), ce_loss 0.519, lat_loss 22.015
09/22 05:21:32 PM | Train: [180/180] Step 200/312 Loss 2.085 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.519, lat_loss 22.015
09/22 05:21:53 PM | Train: [180/180] Step 250/312 Loss 2.077 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.519, lat_loss 22.015
09/22 05:22:13 PM | Train: [180/180] Step 300/312 Loss 2.088 Prec@(1,3) (85.9%, 99.1%), ce_loss 0.519, lat_loss 22.015
09/22 05:22:18 PM | Train: [180/180] Step 312/312 Loss 2.088 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.519, lat_loss 22.015
09/22 05:22:19 PM | _theta_step_train: [180/180] Final Prec@1 85.8600% Time 121.74
09/22 05:22:24 PM | Valid: [180/180] Step 050/312 Loss 2.654 Prec@(1,3) (80.9%, 98.0%), ce_loss 0.519, lat_loss 22.015
09/22 05:22:29 PM | Valid: [180/180] Step 100/312 Loss 2.427 Prec@(1,3) (82.7%, 98.5%), ce_loss 0.519, lat_loss 22.015
09/22 05:22:33 PM | Valid: [180/180] Step 150/312 Loss 2.322 Prec@(1,3) (83.7%, 98.7%), ce_loss 0.519, lat_loss 22.015
09/22 05:22:38 PM | Valid: [180/180] Step 200/312 Loss 2.298 Prec@(1,3) (83.8%, 98.8%), ce_loss 0.519, lat_loss 22.015
09/22 05:22:43 PM | Valid: [180/180] Step 250/312 Loss 2.308 Prec@(1,3) (83.5%, 98.8%), ce_loss 0.519, lat_loss 22.015
09/22 05:22:47 PM | Valid: [180/180] Step 300/312 Loss 2.247 Prec@(1,3) (83.9%, 98.9%), ce_loss 0.519, lat_loss 22.016
09/22 05:22:48 PM | Valid: [180/180] Step 312/312 Loss 2.249 Prec@(1,3) (84.0%, 98.9%), ce_loss 0.519, lat_loss 22.016
09/22 05:22:48 PM | val: [180/180] Final Prec@1 83.9600% Time 29.37
