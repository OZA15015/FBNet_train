09/18 04:15:56 PM | Firstly, start to train weights for epoch 0
Files already downloaded and verified
Files already downloaded and verified
09/18 04:16:21 PM | Train: [  1/180] Step 050/1249 Loss 3.274 Prec@(1,3) (10.3%, 50.9%), ce_loss 2.459, lat_loss 6.658
09/18 04:16:45 PM | Train: [  1/180] Step 100/1249 Loss 3.329 Prec@(1,3) (11.3%, 54.5%), ce_loss 2.500, lat_loss 6.657
09/18 04:17:09 PM | Train: [  1/180] Step 150/1249 Loss 3.352 Prec@(1,3) (12.5%, 55.6%), ce_loss 2.518, lat_loss 6.658
09/18 04:17:34 PM | Train: [  1/180] Step 200/1249 Loss 3.320 Prec@(1,3) (13.6%, 57.6%), ce_loss 2.493, lat_loss 6.658
09/18 04:17:59 PM | Train: [  1/180] Step 250/1249 Loss 3.290 Prec@(1,3) (14.1%, 59.2%), ce_loss 2.471, lat_loss 6.658
09/18 04:18:24 PM | Train: [  1/180] Step 300/1249 Loss 3.255 Prec@(1,3) (15.0%, 60.7%), ce_loss 2.444, lat_loss 6.658
09/18 04:18:47 PM | Train: [  1/180] Step 350/1249 Loss 3.227 Prec@(1,3) (15.5%, 61.9%), ce_loss 2.424, lat_loss 6.658
09/18 04:19:12 PM | Train: [  1/180] Step 400/1249 Loss 3.199 Prec@(1,3) (16.2%, 63.0%), ce_loss 2.402, lat_loss 6.658
09/18 04:19:37 PM | Train: [  1/180] Step 450/1249 Loss 3.162 Prec@(1,3) (16.7%, 64.2%), ce_loss 2.374, lat_loss 6.658
09/18 04:20:02 PM | Train: [  1/180] Step 500/1249 Loss 3.132 Prec@(1,3) (17.2%, 65.4%), ce_loss 2.352, lat_loss 6.658
09/18 04:20:25 PM | Train: [  1/180] Step 550/1249 Loss 3.100 Prec@(1,3) (17.8%, 66.5%), ce_loss 2.328, lat_loss 6.658
09/18 04:20:50 PM | Train: [  1/180] Step 600/1249 Loss 3.070 Prec@(1,3) (18.4%, 67.5%), ce_loss 2.305, lat_loss 6.658
09/18 04:21:14 PM | Train: [  1/180] Step 650/1249 Loss 3.044 Prec@(1,3) (19.1%, 68.4%), ce_loss 2.286, lat_loss 6.658
09/18 04:21:37 PM | Train: [  1/180] Step 700/1249 Loss 3.017 Prec@(1,3) (19.5%, 69.4%), ce_loss 2.266, lat_loss 6.658
09/18 04:22:01 PM | Train: [  1/180] Step 750/1249 Loss 2.996 Prec@(1,3) (19.9%, 70.1%), ce_loss 2.250, lat_loss 6.658
09/18 04:22:24 PM | Train: [  1/180] Step 800/1249 Loss 2.972 Prec@(1,3) (20.5%, 70.9%), ce_loss 2.232, lat_loss 6.658
09/18 04:22:47 PM | Train: [  1/180] Step 850/1249 Loss 2.952 Prec@(1,3) (20.9%, 71.4%), ce_loss 2.217, lat_loss 6.658
09/18 04:23:09 PM | Train: [  1/180] Step 900/1249 Loss 2.929 Prec@(1,3) (21.3%, 72.1%), ce_loss 2.200, lat_loss 6.658
09/18 04:23:33 PM | Train: [  1/180] Step 950/1249 Loss 2.911 Prec@(1,3) (21.7%, 72.6%), ce_loss 2.186, lat_loss 6.658
09/18 04:23:55 PM | Train: [  1/180] Step 1000/1249 Loss 2.893 Prec@(1,3) (22.0%, 73.1%), ce_loss 2.172, lat_loss 6.658
09/18 04:24:18 PM | Train: [  1/180] Step 1050/1249 Loss 2.874 Prec@(1,3) (22.5%, 73.7%), ce_loss 2.158, lat_loss 6.658
09/18 04:24:42 PM | Train: [  1/180] Step 1100/1249 Loss 2.857 Prec@(1,3) (22.9%, 74.1%), ce_loss 2.145, lat_loss 6.658
09/18 04:25:06 PM | Train: [  1/180] Step 1150/1249 Loss 2.840 Prec@(1,3) (23.3%, 74.6%), ce_loss 2.133, lat_loss 6.658
09/18 04:25:29 PM | Train: [  1/180] Step 1200/1249 Loss 2.824 Prec@(1,3) (23.6%, 74.9%), ce_loss 2.120, lat_loss 6.658
09/18 04:25:53 PM | Train: [  1/180] Step 1249/1249 Loss 2.812 Prec@(1,3) (23.9%, 75.2%), ce_loss 2.112, lat_loss 6.658
09/18 04:25:53 PM | _w_step_train: [  1/180] Final Prec@1 23.8925% Time 597.67
09/18 04:25:53 PM | Firstly, start to train weights for epoch 1
09/18 04:26:11 PM | Train: [  2/180] Step 050/1249 Loss 2.487 Prec@(1,3) (30.8%, 84.2%), ce_loss 2.102, lat_loss 6.658
09/18 04:26:27 PM | Train: [  2/180] Step 100/1249 Loss 2.460 Prec@(1,3) (31.6%, 85.2%), ce_loss 2.092, lat_loss 6.658
09/18 04:26:43 PM | Train: [  2/180] Step 150/1249 Loss 2.463 Prec@(1,3) (31.5%, 85.3%), ce_loss 2.084, lat_loss 6.658
09/18 04:26:58 PM | Train: [  2/180] Step 200/1249 Loss 2.451 Prec@(1,3) (31.8%, 85.2%), ce_loss 2.074, lat_loss 6.658
09/18 04:27:14 PM | Train: [  2/180] Step 250/1249 Loss 2.443 Prec@(1,3) (32.2%, 85.1%), ce_loss 2.065, lat_loss 6.658
09/18 04:27:30 PM | Train: [  2/180] Step 300/1249 Loss 2.432 Prec@(1,3) (32.6%, 85.3%), ce_loss 2.056, lat_loss 6.658
09/18 04:27:46 PM | Train: [  2/180] Step 350/1249 Loss 2.434 Prec@(1,3) (32.7%, 85.3%), ce_loss 2.050, lat_loss 6.658
09/18 04:28:02 PM | Train: [  2/180] Step 400/1249 Loss 2.427 Prec@(1,3) (32.9%, 85.4%), ce_loss 2.042, lat_loss 6.658
09/18 04:28:18 PM | Train: [  2/180] Step 450/1249 Loss 2.419 Prec@(1,3) (33.1%, 85.4%), ce_loss 2.034, lat_loss 6.658
09/18 04:28:34 PM | Train: [  2/180] Step 500/1249 Loss 2.422 Prec@(1,3) (33.0%, 85.5%), ce_loss 2.028, lat_loss 6.658
09/18 04:28:50 PM | Train: [  2/180] Step 550/1249 Loss 2.416 Prec@(1,3) (33.1%, 85.5%), ce_loss 2.021, lat_loss 6.658
09/18 04:29:06 PM | Train: [  2/180] Step 600/1249 Loss 2.407 Prec@(1,3) (33.3%, 85.7%), ce_loss 2.013, lat_loss 6.658
09/18 04:29:22 PM | Train: [  2/180] Step 650/1249 Loss 2.403 Prec@(1,3) (33.3%, 85.7%), ce_loss 2.007, lat_loss 6.658
09/18 04:29:38 PM | Train: [  2/180] Step 700/1249 Loss 2.397 Prec@(1,3) (33.5%, 85.8%), ce_loss 2.000, lat_loss 6.658
09/18 04:29:54 PM | Train: [  2/180] Step 750/1249 Loss 2.394 Prec@(1,3) (33.7%, 85.9%), ce_loss 1.994, lat_loss 6.658
09/18 04:30:10 PM | Train: [  2/180] Step 800/1249 Loss 2.393 Prec@(1,3) (33.8%, 85.8%), ce_loss 1.989, lat_loss 6.658
09/18 04:30:26 PM | Train: [  2/180] Step 850/1249 Loss 2.387 Prec@(1,3) (33.9%, 86.0%), ce_loss 1.982, lat_loss 6.658
09/18 04:30:42 PM | Train: [  2/180] Step 900/1249 Loss 2.383 Prec@(1,3) (34.0%, 86.0%), ce_loss 1.977, lat_loss 6.658
09/18 04:31:02 PM | Train: [  2/180] Step 950/1249 Loss 2.382 Prec@(1,3) (34.0%, 86.1%), ce_loss 1.972, lat_loss 6.658
09/18 04:31:26 PM | Train: [  2/180] Step 1000/1249 Loss 2.376 Prec@(1,3) (34.2%, 86.2%), ce_loss 1.966, lat_loss 6.658
09/18 04:31:51 PM | Train: [  2/180] Step 1050/1249 Loss 2.373 Prec@(1,3) (34.2%, 86.3%), ce_loss 1.961, lat_loss 6.658
09/18 04:32:15 PM | Train: [  2/180] Step 1100/1249 Loss 2.370 Prec@(1,3) (34.3%, 86.4%), ce_loss 1.956, lat_loss 6.658
09/18 04:32:39 PM | Train: [  2/180] Step 1150/1249 Loss 2.369 Prec@(1,3) (34.4%, 86.3%), ce_loss 1.952, lat_loss 6.658
09/18 04:33:04 PM | Train: [  2/180] Step 1200/1249 Loss 2.366 Prec@(1,3) (34.4%, 86.4%), ce_loss 1.948, lat_loss 6.658
09/18 04:33:28 PM | Train: [  2/180] Step 1249/1249 Loss 2.362 Prec@(1,3) (34.6%, 86.5%), ce_loss 1.943, lat_loss 6.658
09/18 04:33:28 PM | _w_step_train: [  2/180] Final Prec@1 34.5575% Time 455.01
09/18 04:33:28 PM | Firstly, start to train weights for epoch 2
09/18 04:33:55 PM | Train: [  3/180] Step 050/1249 Loss 2.287 Prec@(1,3) (36.4%, 87.3%), ce_loss 1.938, lat_loss 6.658
09/18 04:34:20 PM | Train: [  3/180] Step 100/1249 Loss 2.256 Prec@(1,3) (36.9%, 88.4%), ce_loss 1.933, lat_loss 6.658
09/18 04:34:45 PM | Train: [  3/180] Step 150/1249 Loss 2.257 Prec@(1,3) (37.0%, 88.4%), ce_loss 1.929, lat_loss 6.658
09/18 04:35:09 PM | Train: [  3/180] Step 200/1249 Loss 2.243 Prec@(1,3) (37.9%, 88.5%), ce_loss 1.924, lat_loss 6.658
09/18 04:35:33 PM | Train: [  3/180] Step 250/1249 Loss 2.237 Prec@(1,3) (38.0%, 88.4%), ce_loss 1.919, lat_loss 6.658
09/18 04:35:56 PM | Train: [  3/180] Step 300/1249 Loss 2.230 Prec@(1,3) (38.0%, 88.5%), ce_loss 1.914, lat_loss 6.658
09/18 04:36:18 PM | Train: [  3/180] Step 350/1249 Loss 2.223 Prec@(1,3) (38.4%, 88.5%), ce_loss 1.909, lat_loss 6.658
09/18 04:36:40 PM | Train: [  3/180] Step 400/1249 Loss 2.216 Prec@(1,3) (38.7%, 88.6%), ce_loss 1.904, lat_loss 6.658
09/18 04:36:59 PM | Train: [  3/180] Step 450/1249 Loss 2.212 Prec@(1,3) (38.7%, 88.6%), ce_loss 1.900, lat_loss 6.658
09/18 04:37:20 PM | Train: [  3/180] Step 500/1249 Loss 2.215 Prec@(1,3) (38.7%, 88.6%), ce_loss 1.896, lat_loss 6.658
09/18 04:37:40 PM | Train: [  3/180] Step 550/1249 Loss 2.210 Prec@(1,3) (38.9%, 88.6%), ce_loss 1.892, lat_loss 6.658
09/18 04:38:03 PM | Train: [  3/180] Step 600/1249 Loss 2.212 Prec@(1,3) (38.7%, 88.7%), ce_loss 1.888, lat_loss 6.658
09/18 04:38:25 PM | Train: [  3/180] Step 650/1249 Loss 2.211 Prec@(1,3) (38.7%, 88.7%), ce_loss 1.884, lat_loss 6.658
09/18 04:38:46 PM | Train: [  3/180] Step 700/1249 Loss 2.206 Prec@(1,3) (38.8%, 89.0%), ce_loss 1.880, lat_loss 6.658
09/18 04:39:08 PM | Train: [  3/180] Step 750/1249 Loss 2.202 Prec@(1,3) (38.8%, 89.0%), ce_loss 1.876, lat_loss 6.658
09/18 04:39:28 PM | Train: [  3/180] Step 800/1249 Loss 2.198 Prec@(1,3) (39.0%, 89.1%), ce_loss 1.872, lat_loss 6.658
09/18 04:39:50 PM | Train: [  3/180] Step 850/1249 Loss 2.199 Prec@(1,3) (39.1%, 89.1%), ce_loss 1.869, lat_loss 6.658
09/18 04:40:12 PM | Train: [  3/180] Step 900/1249 Loss 2.196 Prec@(1,3) (39.1%, 89.1%), ce_loss 1.865, lat_loss 6.658
09/18 04:40:34 PM | Train: [  3/180] Step 950/1249 Loss 2.193 Prec@(1,3) (39.1%, 89.2%), ce_loss 1.861, lat_loss 6.658
09/18 04:40:56 PM | Train: [  3/180] Step 1000/1249 Loss 2.190 Prec@(1,3) (39.2%, 89.3%), ce_loss 1.858, lat_loss 6.658
09/18 04:41:16 PM | Train: [  3/180] Step 1050/1249 Loss 2.188 Prec@(1,3) (39.2%, 89.3%), ce_loss 1.854, lat_loss 6.658
09/18 04:41:39 PM | Train: [  3/180] Step 1100/1249 Loss 2.185 Prec@(1,3) (39.4%, 89.4%), ce_loss 1.851, lat_loss 6.658
09/18 04:42:02 PM | Train: [  3/180] Step 1150/1249 Loss 2.185 Prec@(1,3) (39.4%, 89.3%), ce_loss 1.848, lat_loss 6.658
09/18 04:42:26 PM | Train: [  3/180] Step 1200/1249 Loss 2.182 Prec@(1,3) (39.5%, 89.4%), ce_loss 1.844, lat_loss 6.658
09/18 04:42:50 PM | Train: [  3/180] Step 1249/1249 Loss 2.183 Prec@(1,3) (39.5%, 89.4%), ce_loss 1.842, lat_loss 6.658
09/18 04:42:50 PM | _w_step_train: [  3/180] Final Prec@1 39.5150% Time 561.56
09/18 04:42:50 PM | Firstly, start to train weights for epoch 3
09/18 04:43:16 PM | Train: [  4/180] Step 050/1249 Loss 2.071 Prec@(1,3) (43.1%, 90.8%), ce_loss 1.838, lat_loss 6.658
09/18 04:43:37 PM | Train: [  4/180] Step 100/1249 Loss 2.096 Prec@(1,3) (42.4%, 90.4%), ce_loss 1.835, lat_loss 6.658
09/18 04:43:51 PM | Train: [  4/180] Step 150/1249 Loss 2.090 Prec@(1,3) (42.8%, 90.6%), ce_loss 1.831, lat_loss 6.658
09/18 04:44:05 PM | Train: [  4/180] Step 200/1249 Loss 2.086 Prec@(1,3) (42.9%, 90.3%), ce_loss 1.828, lat_loss 6.658
09/18 04:44:20 PM | Train: [  4/180] Step 250/1249 Loss 2.080 Prec@(1,3) (43.2%, 90.4%), ce_loss 1.824, lat_loss 6.658
09/18 04:44:34 PM | Train: [  4/180] Step 300/1249 Loss 2.084 Prec@(1,3) (42.8%, 90.4%), ce_loss 1.821, lat_loss 6.658
09/18 04:44:49 PM | Train: [  4/180] Step 350/1249 Loss 2.083 Prec@(1,3) (42.9%, 90.6%), ce_loss 1.818, lat_loss 6.658
09/18 04:45:03 PM | Train: [  4/180] Step 400/1249 Loss 2.086 Prec@(1,3) (42.8%, 90.6%), ce_loss 1.815, lat_loss 6.658
09/18 04:45:18 PM | Train: [  4/180] Step 450/1249 Loss 2.089 Prec@(1,3) (42.8%, 90.5%), ce_loss 1.812, lat_loss 6.658
09/18 04:45:32 PM | Train: [  4/180] Step 500/1249 Loss 2.084 Prec@(1,3) (42.8%, 90.6%), ce_loss 1.809, lat_loss 6.658
09/18 04:45:47 PM | Train: [  4/180] Step 550/1249 Loss 2.083 Prec@(1,3) (42.7%, 90.7%), ce_loss 1.806, lat_loss 6.658
09/18 04:46:01 PM | Train: [  4/180] Step 600/1249 Loss 2.079 Prec@(1,3) (42.8%, 90.7%), ce_loss 1.803, lat_loss 6.658
09/18 04:46:16 PM | Train: [  4/180] Step 650/1249 Loss 2.078 Prec@(1,3) (42.8%, 90.7%), ce_loss 1.800, lat_loss 6.658
09/18 04:46:30 PM | Train: [  4/180] Step 700/1249 Loss 2.077 Prec@(1,3) (42.9%, 90.8%), ce_loss 1.797, lat_loss 6.658
09/18 04:46:49 PM | Train: [  4/180] Step 750/1249 Loss 2.076 Prec@(1,3) (42.9%, 90.8%), ce_loss 1.795, lat_loss 6.658
09/18 04:47:14 PM | Train: [  4/180] Step 800/1249 Loss 2.076 Prec@(1,3) (42.8%, 90.7%), ce_loss 1.792, lat_loss 6.658
09/18 04:47:39 PM | Train: [  4/180] Step 850/1249 Loss 2.075 Prec@(1,3) (42.8%, 90.8%), ce_loss 1.789, lat_loss 6.658
09/18 04:48:04 PM | Train: [  4/180] Step 900/1249 Loss 2.070 Prec@(1,3) (43.0%, 90.9%), ce_loss 1.786, lat_loss 6.658
09/18 04:48:29 PM | Train: [  4/180] Step 950/1249 Loss 2.069 Prec@(1,3) (43.0%, 90.9%), ce_loss 1.783, lat_loss 6.658
09/18 04:48:52 PM | Train: [  4/180] Step 1000/1249 Loss 2.067 Prec@(1,3) (42.9%, 90.9%), ce_loss 1.781, lat_loss 6.658
09/18 04:49:15 PM | Train: [  4/180] Step 1050/1249 Loss 2.066 Prec@(1,3) (43.0%, 90.9%), ce_loss 1.778, lat_loss 6.658
09/18 04:49:36 PM | Train: [  4/180] Step 1100/1249 Loss 2.062 Prec@(1,3) (43.2%, 90.9%), ce_loss 1.775, lat_loss 6.658
09/18 04:49:58 PM | Train: [  4/180] Step 1150/1249 Loss 2.059 Prec@(1,3) (43.3%, 90.9%), ce_loss 1.772, lat_loss 6.658
09/18 04:50:20 PM | Train: [  4/180] Step 1200/1249 Loss 2.055 Prec@(1,3) (43.4%, 91.0%), ce_loss 1.769, lat_loss 6.658
09/18 04:50:42 PM | Train: [  4/180] Step 1249/1249 Loss 2.051 Prec@(1,3) (43.5%, 91.0%), ce_loss 1.766, lat_loss 6.658
09/18 04:50:42 PM | _w_step_train: [  4/180] Final Prec@1 43.4700% Time 471.58
09/18 04:50:42 PM | Firstly, start to train weights for epoch 4
09/18 04:51:07 PM | Train: [  5/180] Step 050/1249 Loss 1.906 Prec@(1,3) (46.4%, 92.5%), ce_loss 1.763, lat_loss 6.658
09/18 04:51:32 PM | Train: [  5/180] Step 100/1249 Loss 1.950 Prec@(1,3) (46.2%, 91.8%), ce_loss 1.760, lat_loss 6.658
09/18 04:51:56 PM | Train: [  5/180] Step 150/1249 Loss 1.947 Prec@(1,3) (46.1%, 92.3%), ce_loss 1.758, lat_loss 6.658
09/18 04:52:20 PM | Train: [  5/180] Step 200/1249 Loss 1.949 Prec@(1,3) (46.6%, 91.8%), ce_loss 1.755, lat_loss 6.658
09/18 04:52:44 PM | Train: [  5/180] Step 250/1249 Loss 1.969 Prec@(1,3) (46.2%, 91.5%), ce_loss 1.753, lat_loss 6.658
09/18 04:53:06 PM | Train: [  5/180] Step 300/1249 Loss 1.979 Prec@(1,3) (46.0%, 91.4%), ce_loss 1.751, lat_loss 6.658
09/18 04:53:30 PM | Train: [  5/180] Step 350/1249 Loss 1.977 Prec@(1,3) (46.0%, 91.4%), ce_loss 1.748, lat_loss 6.658
09/18 04:53:54 PM | Train: [  5/180] Step 400/1249 Loss 1.982 Prec@(1,3) (45.9%, 91.2%), ce_loss 1.746, lat_loss 6.658
09/18 04:54:19 PM | Train: [  5/180] Step 450/1249 Loss 1.982 Prec@(1,3) (46.0%, 91.4%), ce_loss 1.743, lat_loss 6.658
09/18 04:54:43 PM | Train: [  5/180] Step 500/1249 Loss 1.976 Prec@(1,3) (46.1%, 91.7%), ce_loss 1.741, lat_loss 6.658
09/18 04:55:07 PM | Train: [  5/180] Step 550/1249 Loss 1.973 Prec@(1,3) (46.3%, 91.6%), ce_loss 1.738, lat_loss 6.658
09/18 04:55:31 PM | Train: [  5/180] Step 600/1249 Loss 1.970 Prec@(1,3) (46.5%, 91.6%), ce_loss 1.736, lat_loss 6.658
09/18 04:55:56 PM | Train: [  5/180] Step 650/1249 Loss 1.970 Prec@(1,3) (46.5%, 91.6%), ce_loss 1.733, lat_loss 6.658
09/18 04:56:20 PM | Train: [  5/180] Step 700/1249 Loss 1.967 Prec@(1,3) (46.5%, 91.7%), ce_loss 1.731, lat_loss 6.658
09/18 04:56:43 PM | Train: [  5/180] Step 750/1249 Loss 1.967 Prec@(1,3) (46.5%, 91.7%), ce_loss 1.729, lat_loss 6.658
09/18 04:57:07 PM | Train: [  5/180] Step 800/1249 Loss 1.967 Prec@(1,3) (46.5%, 91.8%), ce_loss 1.726, lat_loss 6.658
09/18 04:57:29 PM | Train: [  5/180] Step 850/1249 Loss 1.965 Prec@(1,3) (46.4%, 91.7%), ce_loss 1.724, lat_loss 6.658
09/18 04:57:53 PM | Train: [  5/180] Step 900/1249 Loss 1.964 Prec@(1,3) (46.4%, 91.8%), ce_loss 1.722, lat_loss 6.658
09/18 04:58:15 PM | Train: [  5/180] Step 950/1249 Loss 1.960 Prec@(1,3) (46.4%, 91.8%), ce_loss 1.719, lat_loss 6.658
09/18 04:58:34 PM | Train: [  5/180] Step 1000/1249 Loss 1.959 Prec@(1,3) (46.5%, 91.8%), ce_loss 1.717, lat_loss 6.658
09/18 04:58:53 PM | Train: [  5/180] Step 1050/1249 Loss 1.959 Prec@(1,3) (46.5%, 91.9%), ce_loss 1.715, lat_loss 6.658
09/18 04:59:15 PM | Train: [  5/180] Step 1100/1249 Loss 1.956 Prec@(1,3) (46.5%, 91.9%), ce_loss 1.713, lat_loss 6.658
09/18 04:59:37 PM | Train: [  5/180] Step 1150/1249 Loss 1.951 Prec@(1,3) (46.6%, 92.0%), ce_loss 1.710, lat_loss 6.658
09/18 04:59:59 PM | Train: [  5/180] Step 1200/1249 Loss 1.951 Prec@(1,3) (46.5%, 92.0%), ce_loss 1.708, lat_loss 6.658
09/18 05:00:23 PM | Train: [  5/180] Step 1249/1249 Loss 1.948 Prec@(1,3) (46.6%, 92.1%), ce_loss 1.706, lat_loss 6.658
09/18 05:00:23 PM | _w_step_train: [  5/180] Final Prec@1 46.6350% Time 581.75
09/18 05:00:23 PM | Firstly, start to train weights for epoch 5
09/18 05:00:46 PM | Train: [  6/180] Step 050/1249 Loss 1.928 Prec@(1,3) (45.3%, 92.3%), ce_loss 1.704, lat_loss 6.658
09/18 05:01:07 PM | Train: [  6/180] Step 100/1249 Loss 1.936 Prec@(1,3) (46.0%, 92.6%), ce_loss 1.702, lat_loss 6.658
09/18 05:01:26 PM | Train: [  6/180] Step 150/1249 Loss 1.907 Prec@(1,3) (47.6%, 92.7%), ce_loss 1.699, lat_loss 6.658
09/18 05:01:47 PM | Train: [  6/180] Step 200/1249 Loss 1.901 Prec@(1,3) (47.7%, 92.4%), ce_loss 1.697, lat_loss 6.658
09/18 05:02:07 PM | Train: [  6/180] Step 250/1249 Loss 1.905 Prec@(1,3) (47.6%, 92.5%), ce_loss 1.695, lat_loss 6.658
09/18 05:02:28 PM | Train: [  6/180] Step 300/1249 Loss 1.906 Prec@(1,3) (47.7%, 92.5%), ce_loss 1.693, lat_loss 6.658
09/18 05:02:49 PM | Train: [  6/180] Step 350/1249 Loss 1.900 Prec@(1,3) (48.2%, 92.6%), ce_loss 1.691, lat_loss 6.658
09/18 05:03:09 PM | Train: [  6/180] Step 400/1249 Loss 1.892 Prec@(1,3) (48.5%, 92.7%), ce_loss 1.689, lat_loss 6.658
09/18 05:03:29 PM | Train: [  6/180] Step 450/1249 Loss 1.886 Prec@(1,3) (48.6%, 92.8%), ce_loss 1.686, lat_loss 6.658
09/18 05:03:50 PM | Train: [  6/180] Step 500/1249 Loss 1.883 Prec@(1,3) (48.8%, 92.7%), ce_loss 1.684, lat_loss 6.658
09/18 05:04:12 PM | Train: [  6/180] Step 550/1249 Loss 1.880 Prec@(1,3) (48.7%, 92.8%), ce_loss 1.682, lat_loss 6.658
09/18 05:04:34 PM | Train: [  6/180] Step 600/1249 Loss 1.884 Prec@(1,3) (48.7%, 92.7%), ce_loss 1.680, lat_loss 6.658
09/18 05:04:56 PM | Train: [  6/180] Step 650/1249 Loss 1.880 Prec@(1,3) (48.8%, 92.8%), ce_loss 1.678, lat_loss 6.658
09/18 05:05:17 PM | Train: [  6/180] Step 700/1249 Loss 1.877 Prec@(1,3) (48.9%, 92.8%), ce_loss 1.676, lat_loss 6.658
09/18 05:05:37 PM | Train: [  6/180] Step 750/1249 Loss 1.875 Prec@(1,3) (48.8%, 92.8%), ce_loss 1.674, lat_loss 6.658
09/18 05:05:57 PM | Train: [  6/180] Step 800/1249 Loss 1.871 Prec@(1,3) (49.1%, 92.8%), ce_loss 1.672, lat_loss 6.658
09/18 05:06:17 PM | Train: [  6/180] Step 850/1249 Loss 1.872 Prec@(1,3) (49.1%, 92.8%), ce_loss 1.670, lat_loss 6.658
09/18 05:06:36 PM | Train: [  6/180] Step 900/1249 Loss 1.870 Prec@(1,3) (49.2%, 92.8%), ce_loss 1.668, lat_loss 6.658
09/18 05:06:57 PM | Train: [  6/180] Step 950/1249 Loss 1.867 Prec@(1,3) (49.3%, 92.8%), ce_loss 1.666, lat_loss 6.658
09/18 05:07:17 PM | Train: [  6/180] Step 1000/1249 Loss 1.866 Prec@(1,3) (49.3%, 92.8%), ce_loss 1.664, lat_loss 6.658
09/18 05:07:40 PM | Train: [  6/180] Step 1050/1249 Loss 1.864 Prec@(1,3) (49.4%, 92.9%), ce_loss 1.662, lat_loss 6.658
09/18 05:08:02 PM | Train: [  6/180] Step 1100/1249 Loss 1.865 Prec@(1,3) (49.3%, 92.9%), ce_loss 1.660, lat_loss 6.658
09/18 05:08:23 PM | Train: [  6/180] Step 1150/1249 Loss 1.862 Prec@(1,3) (49.4%, 92.9%), ce_loss 1.658, lat_loss 6.658
09/18 05:08:45 PM | Train: [  6/180] Step 1200/1249 Loss 1.861 Prec@(1,3) (49.5%, 92.9%), ce_loss 1.656, lat_loss 6.658
09/18 05:09:09 PM | Train: [  6/180] Step 1249/1249 Loss 1.858 Prec@(1,3) (49.5%, 92.9%), ce_loss 1.654, lat_loss 6.658
09/18 05:09:09 PM | _w_step_train: [  6/180] Final Prec@1 49.4950% Time 525.99
09/18 05:09:09 PM | Firstly, start to train weights for epoch 6
09/18 05:09:31 PM | Train: [  7/180] Step 050/1249 Loss 1.804 Prec@(1,3) (49.0%, 93.6%), ce_loss 1.652, lat_loss 6.658
09/18 05:09:53 PM | Train: [  7/180] Step 100/1249 Loss 1.814 Prec@(1,3) (49.6%, 93.7%), ce_loss 1.650, lat_loss 6.658
09/18 05:10:15 PM | Train: [  7/180] Step 150/1249 Loss 1.801 Prec@(1,3) (50.6%, 93.4%), ce_loss 1.648, lat_loss 6.658
09/18 05:10:36 PM | Train: [  7/180] Step 200/1249 Loss 1.815 Prec@(1,3) (50.5%, 93.2%), ce_loss 1.647, lat_loss 6.658
09/18 05:10:55 PM | Train: [  7/180] Step 250/1249 Loss 1.823 Prec@(1,3) (50.2%, 93.2%), ce_loss 1.645, lat_loss 6.658
09/18 05:11:15 PM | Train: [  7/180] Step 300/1249 Loss 1.829 Prec@(1,3) (49.9%, 93.2%), ce_loss 1.643, lat_loss 6.658
09/18 05:11:37 PM | Train: [  7/180] Step 350/1249 Loss 1.825 Prec@(1,3) (50.1%, 93.2%), ce_loss 1.641, lat_loss 6.658
09/18 05:12:00 PM | Train: [  7/180] Step 400/1249 Loss 1.818 Prec@(1,3) (50.2%, 93.3%), ce_loss 1.639, lat_loss 6.658
09/18 05:12:23 PM | Train: [  7/180] Step 450/1249 Loss 1.809 Prec@(1,3) (50.4%, 93.5%), ce_loss 1.637, lat_loss 6.658
09/18 05:12:47 PM | Train: [  7/180] Step 500/1249 Loss 1.808 Prec@(1,3) (50.5%, 93.5%), ce_loss 1.636, lat_loss 6.658
09/18 05:13:10 PM | Train: [  7/180] Step 550/1249 Loss 1.807 Prec@(1,3) (50.4%, 93.6%), ce_loss 1.634, lat_loss 6.658
09/18 05:13:34 PM | Train: [  7/180] Step 600/1249 Loss 1.800 Prec@(1,3) (50.7%, 93.7%), ce_loss 1.632, lat_loss 6.658
09/18 05:13:55 PM | Train: [  7/180] Step 650/1249 Loss 1.797 Prec@(1,3) (50.8%, 93.7%), ce_loss 1.630, lat_loss 6.658
09/18 05:14:20 PM | Train: [  7/180] Step 700/1249 Loss 1.795 Prec@(1,3) (50.9%, 93.7%), ce_loss 1.628, lat_loss 6.658
09/18 05:14:44 PM | Train: [  7/180] Step 750/1249 Loss 1.794 Prec@(1,3) (51.0%, 93.7%), ce_loss 1.626, lat_loss 6.658
09/18 05:15:08 PM | Train: [  7/180] Step 800/1249 Loss 1.791 Prec@(1,3) (51.1%, 93.7%), ce_loss 1.624, lat_loss 6.658
09/18 05:15:30 PM | Train: [  7/180] Step 850/1249 Loss 1.791 Prec@(1,3) (51.1%, 93.7%), ce_loss 1.623, lat_loss 6.658
09/18 05:15:54 PM | Train: [  7/180] Step 900/1249 Loss 1.790 Prec@(1,3) (51.1%, 93.7%), ce_loss 1.621, lat_loss 6.658
09/18 05:16:17 PM | Train: [  7/180] Step 950/1249 Loss 1.786 Prec@(1,3) (51.2%, 93.7%), ce_loss 1.619, lat_loss 6.658
09/18 05:16:40 PM | Train: [  7/180] Step 1000/1249 Loss 1.785 Prec@(1,3) (51.2%, 93.8%), ce_loss 1.617, lat_loss 6.658
09/18 05:17:03 PM | Train: [  7/180] Step 1050/1249 Loss 1.781 Prec@(1,3) (51.4%, 93.8%), ce_loss 1.615, lat_loss 6.658
09/18 05:17:27 PM | Train: [  7/180] Step 1100/1249 Loss 1.780 Prec@(1,3) (51.4%, 93.7%), ce_loss 1.613, lat_loss 6.658
09/18 05:17:50 PM | Train: [  7/180] Step 1150/1249 Loss 1.779 Prec@(1,3) (51.5%, 93.7%), ce_loss 1.612, lat_loss 6.658
09/18 05:18:11 PM | Train: [  7/180] Step 1200/1249 Loss 1.779 Prec@(1,3) (51.5%, 93.7%), ce_loss 1.610, lat_loss 6.658
09/18 05:18:32 PM | Train: [  7/180] Step 1249/1249 Loss 1.777 Prec@(1,3) (51.6%, 93.8%), ce_loss 1.608, lat_loss 6.658
09/18 05:18:32 PM | _w_step_train: [  7/180] Final Prec@1 51.6000% Time 562.76
09/18 05:18:32 PM | Firstly, start to train weights for epoch 7
09/18 05:18:48 PM | Train: [  8/180] Step 050/1249 Loss 1.726 Prec@(1,3) (53.6%, 94.7%), ce_loss 1.607, lat_loss 6.658
09/18 05:19:02 PM | Train: [  8/180] Step 100/1249 Loss 1.726 Prec@(1,3) (53.5%, 94.9%), ce_loss 1.605, lat_loss 6.658
09/18 05:19:17 PM | Train: [  8/180] Step 150/1249 Loss 1.714 Prec@(1,3) (53.8%, 94.7%), ce_loss 1.603, lat_loss 6.658
09/18 05:19:32 PM | Train: [  8/180] Step 200/1249 Loss 1.702 Prec@(1,3) (53.9%, 94.7%), ce_loss 1.601, lat_loss 6.658
09/18 05:19:54 PM | Train: [  8/180] Step 250/1249 Loss 1.714 Prec@(1,3) (53.1%, 94.8%), ce_loss 1.600, lat_loss 6.658
09/18 05:20:16 PM | Train: [  8/180] Step 300/1249 Loss 1.721 Prec@(1,3) (52.9%, 94.7%), ce_loss 1.598, lat_loss 6.658
09/18 05:20:39 PM | Train: [  8/180] Step 350/1249 Loss 1.716 Prec@(1,3) (53.1%, 94.7%), ce_loss 1.596, lat_loss 6.658
09/18 05:21:01 PM | Train: [  8/180] Step 400/1249 Loss 1.716 Prec@(1,3) (53.3%, 94.7%), ce_loss 1.594, lat_loss 6.658
09/18 05:21:23 PM | Train: [  8/180] Step 450/1249 Loss 1.713 Prec@(1,3) (53.4%, 94.6%), ce_loss 1.593, lat_loss 6.658
09/18 05:21:44 PM | Train: [  8/180] Step 500/1249 Loss 1.711 Prec@(1,3) (53.4%, 94.6%), ce_loss 1.591, lat_loss 6.658
09/18 05:22:05 PM | Train: [  8/180] Step 550/1249 Loss 1.715 Prec@(1,3) (53.4%, 94.6%), ce_loss 1.589, lat_loss 6.658
09/18 05:22:28 PM | Train: [  8/180] Step 600/1249 Loss 1.718 Prec@(1,3) (53.3%, 94.4%), ce_loss 1.588, lat_loss 6.658
09/18 05:22:52 PM | Train: [  8/180] Step 650/1249 Loss 1.717 Prec@(1,3) (53.4%, 94.4%), ce_loss 1.586, lat_loss 6.658
09/18 05:23:15 PM | Train: [  8/180] Step 700/1249 Loss 1.713 Prec@(1,3) (53.5%, 94.4%), ce_loss 1.585, lat_loss 6.658
09/18 05:23:39 PM | Train: [  8/180] Step 750/1249 Loss 1.710 Prec@(1,3) (53.6%, 94.4%), ce_loss 1.583, lat_loss 6.658
09/18 05:24:03 PM | Train: [  8/180] Step 800/1249 Loss 1.710 Prec@(1,3) (53.6%, 94.4%), ce_loss 1.581, lat_loss 6.658
09/18 05:24:27 PM | Train: [  8/180] Step 850/1249 Loss 1.706 Prec@(1,3) (53.8%, 94.4%), ce_loss 1.579, lat_loss 6.658
09/18 05:24:50 PM | Train: [  8/180] Step 900/1249 Loss 1.706 Prec@(1,3) (53.8%, 94.4%), ce_loss 1.578, lat_loss 6.658
09/18 05:25:14 PM | Train: [  8/180] Step 950/1249 Loss 1.708 Prec@(1,3) (53.7%, 94.4%), ce_loss 1.577, lat_loss 6.658
09/18 05:25:38 PM | Train: [  8/180] Step 1000/1249 Loss 1.704 Prec@(1,3) (53.8%, 94.4%), ce_loss 1.575, lat_loss 6.658
09/18 05:26:01 PM | Train: [  8/180] Step 1050/1249 Loss 1.705 Prec@(1,3) (53.8%, 94.4%), ce_loss 1.573, lat_loss 6.658
09/18 05:26:23 PM | Train: [  8/180] Step 1100/1249 Loss 1.705 Prec@(1,3) (53.8%, 94.4%), ce_loss 1.572, lat_loss 6.658
09/18 05:26:45 PM | Train: [  8/180] Step 1150/1249 Loss 1.701 Prec@(1,3) (53.9%, 94.4%), ce_loss 1.570, lat_loss 6.658
09/18 05:27:07 PM | Train: [  8/180] Step 1200/1249 Loss 1.698 Prec@(1,3) (54.0%, 94.3%), ce_loss 1.568, lat_loss 6.658
09/18 05:27:30 PM | Train: [  8/180] Step 1249/1249 Loss 1.697 Prec@(1,3) (54.1%, 94.3%), ce_loss 1.567, lat_loss 6.658
09/18 05:27:30 PM | _w_step_train: [  8/180] Final Prec@1 54.0975% Time 537.92
09/18 05:27:30 PM | Firstly, start to train weights for epoch 8
09/18 05:27:55 PM | Train: [  9/180] Step 050/1249 Loss 1.594 Prec@(1,3) (57.2%, 95.4%), ce_loss 1.565, lat_loss 6.658
09/18 05:28:19 PM | Train: [  9/180] Step 100/1249 Loss 1.630 Prec@(1,3) (56.5%, 94.8%), ce_loss 1.563, lat_loss 6.658
09/18 05:28:41 PM | Train: [  9/180] Step 150/1249 Loss 1.638 Prec@(1,3) (56.0%, 94.5%), ce_loss 1.562, lat_loss 6.658
09/18 05:29:05 PM | Train: [  9/180] Step 200/1249 Loss 1.655 Prec@(1,3) (55.7%, 94.2%), ce_loss 1.560, lat_loss 6.658
09/18 05:29:29 PM | Train: [  9/180] Step 250/1249 Loss 1.644 Prec@(1,3) (55.9%, 94.3%), ce_loss 1.559, lat_loss 6.658
09/18 05:29:52 PM | Train: [  9/180] Step 300/1249 Loss 1.638 Prec@(1,3) (55.9%, 94.4%), ce_loss 1.557, lat_loss 6.658
09/18 05:30:15 PM | Train: [  9/180] Step 350/1249 Loss 1.641 Prec@(1,3) (55.8%, 94.5%), ce_loss 1.555, lat_loss 6.658
09/18 05:30:40 PM | Train: [  9/180] Step 400/1249 Loss 1.639 Prec@(1,3) (55.9%, 94.5%), ce_loss 1.554, lat_loss 6.658
09/18 05:31:03 PM | Train: [  9/180] Step 450/1249 Loss 1.642 Prec@(1,3) (55.9%, 94.6%), ce_loss 1.552, lat_loss 6.658
09/18 05:31:25 PM | Train: [  9/180] Step 500/1249 Loss 1.634 Prec@(1,3) (56.0%, 94.7%), ce_loss 1.551, lat_loss 6.658
09/18 05:31:48 PM | Train: [  9/180] Step 550/1249 Loss 1.632 Prec@(1,3) (56.1%, 94.7%), ce_loss 1.549, lat_loss 6.658
09/18 05:32:11 PM | Train: [  9/180] Step 600/1249 Loss 1.629 Prec@(1,3) (56.1%, 94.7%), ce_loss 1.547, lat_loss 6.658
09/18 05:32:35 PM | Train: [  9/180] Step 650/1249 Loss 1.620 Prec@(1,3) (56.4%, 94.8%), ce_loss 1.545, lat_loss 6.658
09/18 05:33:00 PM | Train: [  9/180] Step 700/1249 Loss 1.623 Prec@(1,3) (56.4%, 94.8%), ce_loss 1.544, lat_loss 6.658
09/18 05:33:24 PM | Train: [  9/180] Step 750/1249 Loss 1.627 Prec@(1,3) (56.4%, 94.7%), ce_loss 1.543, lat_loss 6.658
09/18 05:33:48 PM | Train: [  9/180] Step 800/1249 Loss 1.627 Prec@(1,3) (56.3%, 94.7%), ce_loss 1.541, lat_loss 6.658
09/18 05:34:12 PM | Train: [  9/180] Step 850/1249 Loss 1.628 Prec@(1,3) (56.3%, 94.8%), ce_loss 1.540, lat_loss 6.658
09/18 05:34:36 PM | Train: [  9/180] Step 900/1249 Loss 1.628 Prec@(1,3) (56.2%, 94.8%), ce_loss 1.538, lat_loss 6.658
09/18 05:34:59 PM | Train: [  9/180] Step 950/1249 Loss 1.624 Prec@(1,3) (56.3%, 94.9%), ce_loss 1.537, lat_loss 6.658
09/18 05:35:20 PM | Train: [  9/180] Step 1000/1249 Loss 1.627 Prec@(1,3) (56.3%, 94.8%), ce_loss 1.535, lat_loss 6.658
09/18 05:35:44 PM | Train: [  9/180] Step 1050/1249 Loss 1.625 Prec@(1,3) (56.4%, 94.9%), ce_loss 1.534, lat_loss 6.658
09/18 05:36:08 PM | Train: [  9/180] Step 1100/1249 Loss 1.626 Prec@(1,3) (56.4%, 94.8%), ce_loss 1.532, lat_loss 6.658
09/18 05:36:32 PM | Train: [  9/180] Step 1150/1249 Loss 1.626 Prec@(1,3) (56.4%, 94.8%), ce_loss 1.531, lat_loss 6.658
09/18 05:36:57 PM | Train: [  9/180] Step 1200/1249 Loss 1.624 Prec@(1,3) (56.4%, 94.8%), ce_loss 1.530, lat_loss 6.658
09/18 05:37:21 PM | Train: [  9/180] Step 1249/1249 Loss 1.624 Prec@(1,3) (56.5%, 94.8%), ce_loss 1.528, lat_loss 6.658
09/18 05:37:21 PM | _w_step_train: [  9/180] Final Prec@1 56.4500% Time 590.63
09/18 05:37:21 PM | Firstly, start to train weights for epoch 9
09/18 05:37:47 PM | Train: [ 10/180] Step 050/1249 Loss 1.605 Prec@(1,3) (57.7%, 94.8%), ce_loss 1.527, lat_loss 6.658
09/18 05:38:09 PM | Train: [ 10/180] Step 100/1249 Loss 1.598 Prec@(1,3) (57.1%, 94.7%), ce_loss 1.525, lat_loss 6.658
09/18 05:38:23 PM | Train: [ 10/180] Step 150/1249 Loss 1.616 Prec@(1,3) (56.1%, 94.7%), ce_loss 1.524, lat_loss 6.658
09/18 05:38:38 PM | Train: [ 10/180] Step 200/1249 Loss 1.610 Prec@(1,3) (56.2%, 94.9%), ce_loss 1.523, lat_loss 6.658
09/18 05:38:52 PM | Train: [ 10/180] Step 250/1249 Loss 1.596 Prec@(1,3) (57.1%, 95.1%), ce_loss 1.521, lat_loss 6.658
09/18 05:39:07 PM | Train: [ 10/180] Step 300/1249 Loss 1.589 Prec@(1,3) (57.4%, 95.1%), ce_loss 1.519, lat_loss 6.658
09/18 05:39:23 PM | Train: [ 10/180] Step 350/1249 Loss 1.584 Prec@(1,3) (57.5%, 95.2%), ce_loss 1.518, lat_loss 6.658
09/18 05:39:37 PM | Train: [ 10/180] Step 400/1249 Loss 1.587 Prec@(1,3) (57.3%, 95.1%), ce_loss 1.517, lat_loss 6.658
09/18 05:39:52 PM | Train: [ 10/180] Step 450/1249 Loss 1.580 Prec@(1,3) (57.7%, 95.1%), ce_loss 1.515, lat_loss 6.658
09/18 05:40:06 PM | Train: [ 10/180] Step 500/1249 Loss 1.575 Prec@(1,3) (57.9%, 95.2%), ce_loss 1.513, lat_loss 6.658
09/18 05:40:21 PM | Train: [ 10/180] Step 550/1249 Loss 1.572 Prec@(1,3) (58.0%, 95.2%), ce_loss 1.512, lat_loss 6.658
09/18 05:40:37 PM | Train: [ 10/180] Step 600/1249 Loss 1.568 Prec@(1,3) (58.1%, 95.2%), ce_loss 1.510, lat_loss 6.658
09/18 05:40:52 PM | Train: [ 10/180] Step 650/1249 Loss 1.565 Prec@(1,3) (58.2%, 95.3%), ce_loss 1.509, lat_loss 6.658
09/18 05:41:07 PM | Train: [ 10/180] Step 700/1249 Loss 1.569 Prec@(1,3) (58.0%, 95.3%), ce_loss 1.508, lat_loss 6.658
09/18 05:41:22 PM | Train: [ 10/180] Step 750/1249 Loss 1.568 Prec@(1,3) (58.0%, 95.3%), ce_loss 1.506, lat_loss 6.658
09/18 05:41:36 PM | Train: [ 10/180] Step 800/1249 Loss 1.564 Prec@(1,3) (58.2%, 95.3%), ce_loss 1.505, lat_loss 6.658
09/18 05:41:51 PM | Train: [ 10/180] Step 850/1249 Loss 1.562 Prec@(1,3) (58.2%, 95.3%), ce_loss 1.503, lat_loss 6.658
09/18 05:42:05 PM | Train: [ 10/180] Step 900/1249 Loss 1.567 Prec@(1,3) (58.0%, 95.3%), ce_loss 1.502, lat_loss 6.658
09/18 05:42:20 PM | Train: [ 10/180] Step 950/1249 Loss 1.564 Prec@(1,3) (58.1%, 95.3%), ce_loss 1.501, lat_loss 6.658
09/18 05:42:34 PM | Train: [ 10/180] Step 1000/1249 Loss 1.562 Prec@(1,3) (58.2%, 95.3%), ce_loss 1.499, lat_loss 6.658
09/18 05:42:49 PM | Train: [ 10/180] Step 1050/1249 Loss 1.565 Prec@(1,3) (58.1%, 95.4%), ce_loss 1.498, lat_loss 6.658
09/18 05:43:04 PM | Train: [ 10/180] Step 1100/1249 Loss 1.565 Prec@(1,3) (58.1%, 95.4%), ce_loss 1.497, lat_loss 6.658
09/18 05:43:19 PM | Train: [ 10/180] Step 1150/1249 Loss 1.563 Prec@(1,3) (58.1%, 95.4%), ce_loss 1.495, lat_loss 6.658
09/18 05:43:34 PM | Train: [ 10/180] Step 1200/1249 Loss 1.557 Prec@(1,3) (58.3%, 95.4%), ce_loss 1.494, lat_loss 6.658
09/18 05:43:48 PM | Train: [ 10/180] Step 1249/1249 Loss 1.553 Prec@(1,3) (58.4%, 95.5%), ce_loss 1.492, lat_loss 6.658
09/18 05:43:48 PM | _w_step_train: [ 10/180] Final Prec@1 58.4125% Time 387.08
09/18 05:43:48 PM | Start to train weights for epoch 10
09/18 05:44:11 PM | Train: [ 11/180] Step 050/1249 Loss 1.481 Prec@(1,3) (60.0%, 95.6%), ce_loss 1.490, lat_loss 6.658
09/18 05:44:32 PM | Train: [ 11/180] Step 100/1249 Loss 1.491 Prec@(1,3) (59.3%, 95.9%), ce_loss 1.489, lat_loss 6.658
09/18 05:44:56 PM | Train: [ 11/180] Step 150/1249 Loss 1.499 Prec@(1,3) (59.9%, 95.5%), ce_loss 1.488, lat_loss 6.658
09/18 05:45:20 PM | Train: [ 11/180] Step 200/1249 Loss 1.505 Prec@(1,3) (59.9%, 95.5%), ce_loss 1.486, lat_loss 6.658
09/18 05:45:44 PM | Train: [ 11/180] Step 250/1249 Loss 1.502 Prec@(1,3) (60.0%, 95.7%), ce_loss 1.485, lat_loss 6.658
09/18 05:46:06 PM | Train: [ 11/180] Step 300/1249 Loss 1.496 Prec@(1,3) (60.3%, 95.7%), ce_loss 1.483, lat_loss 6.658
09/18 05:46:29 PM | Train: [ 11/180] Step 350/1249 Loss 1.497 Prec@(1,3) (60.1%, 95.6%), ce_loss 1.482, lat_loss 6.658
09/18 05:46:51 PM | Train: [ 11/180] Step 400/1249 Loss 1.493 Prec@(1,3) (60.3%, 95.8%), ce_loss 1.480, lat_loss 6.658
09/18 05:47:13 PM | Train: [ 11/180] Step 450/1249 Loss 1.495 Prec@(1,3) (60.2%, 95.7%), ce_loss 1.479, lat_loss 6.658
09/18 05:47:35 PM | Train: [ 11/180] Step 500/1249 Loss 1.495 Prec@(1,3) (60.2%, 95.6%), ce_loss 1.478, lat_loss 6.658
09/18 05:47:57 PM | Train: [ 11/180] Step 550/1249 Loss 1.493 Prec@(1,3) (60.2%, 95.7%), ce_loss 1.476, lat_loss 6.658
09/18 05:48:18 PM | Train: [ 11/180] Step 600/1249 Loss 1.492 Prec@(1,3) (60.2%, 95.8%), ce_loss 1.475, lat_loss 6.658
09/18 05:48:40 PM | Train: [ 11/180] Step 650/1249 Loss 1.496 Prec@(1,3) (60.0%, 95.7%), ce_loss 1.474, lat_loss 6.658
09/18 05:49:01 PM | Train: [ 11/180] Step 700/1249 Loss 1.495 Prec@(1,3) (60.0%, 95.8%), ce_loss 1.472, lat_loss 6.658
09/18 05:49:23 PM | Train: [ 11/180] Step 750/1249 Loss 1.493 Prec@(1,3) (60.2%, 95.8%), ce_loss 1.471, lat_loss 6.658
09/18 05:49:45 PM | Train: [ 11/180] Step 800/1249 Loss 1.489 Prec@(1,3) (60.3%, 95.8%), ce_loss 1.469, lat_loss 6.658
09/18 05:50:06 PM | Train: [ 11/180] Step 850/1249 Loss 1.489 Prec@(1,3) (60.3%, 95.8%), ce_loss 1.468, lat_loss 6.658
09/18 05:50:30 PM | Train: [ 11/180] Step 900/1249 Loss 1.487 Prec@(1,3) (60.4%, 95.8%), ce_loss 1.467, lat_loss 6.658
09/18 05:50:53 PM | Train: [ 11/180] Step 950/1249 Loss 1.486 Prec@(1,3) (60.4%, 95.8%), ce_loss 1.465, lat_loss 6.658
09/18 05:51:17 PM | Train: [ 11/180] Step 1000/1249 Loss 1.485 Prec@(1,3) (60.4%, 95.8%), ce_loss 1.464, lat_loss 6.658
09/18 05:51:40 PM | Train: [ 11/180] Step 1050/1249 Loss 1.484 Prec@(1,3) (60.4%, 95.8%), ce_loss 1.463, lat_loss 6.658
09/18 05:52:03 PM | Train: [ 11/180] Step 1100/1249 Loss 1.484 Prec@(1,3) (60.4%, 95.9%), ce_loss 1.461, lat_loss 6.658
09/18 05:52:25 PM | Train: [ 11/180] Step 1150/1249 Loss 1.482 Prec@(1,3) (60.5%, 95.9%), ce_loss 1.460, lat_loss 6.658
09/18 05:52:42 PM | Train: [ 11/180] Step 1200/1249 Loss 1.483 Prec@(1,3) (60.4%, 95.9%), ce_loss 1.459, lat_loss 6.658
09/18 05:52:57 PM | Train: [ 11/180] Step 1249/1249 Loss 1.482 Prec@(1,3) (60.5%, 95.9%), ce_loss 1.458, lat_loss 6.658
09/18 05:52:57 PM | _w_step_train: [ 11/180] Final Prec@1 60.4550% Time 549.31
09/18 05:52:57 PM | Start to train theta for epoch 10
09/18 05:53:19 PM | Train: [ 11/180] Step 050/312 Loss 1.498 Prec@(1,3) (59.9%, 95.8%), ce_loss 1.456, lat_loss 6.658
09/18 05:53:39 PM | Train: [ 11/180] Step 100/312 Loss 1.468 Prec@(1,3) (61.0%, 95.7%), ce_loss 1.455, lat_loss 6.658
09/18 05:54:00 PM | Train: [ 11/180] Step 150/312 Loss 1.498 Prec@(1,3) (60.5%, 95.4%), ce_loss 1.454, lat_loss 6.658
09/18 05:54:21 PM | Train: [ 11/180] Step 200/312 Loss 1.512 Prec@(1,3) (60.0%, 95.4%), ce_loss 1.453, lat_loss 6.658
09/18 05:54:41 PM | Train: [ 11/180] Step 250/312 Loss 1.512 Prec@(1,3) (60.1%, 95.7%), ce_loss 1.452, lat_loss 6.658
09/18 05:55:00 PM | Train: [ 11/180] Step 300/312 Loss 1.504 Prec@(1,3) (60.6%, 95.7%), ce_loss 1.451, lat_loss 6.658
09/18 05:55:06 PM | Train: [ 11/180] Step 312/312 Loss 1.502 Prec@(1,3) (60.7%, 95.6%), ce_loss 1.450, lat_loss 6.658
09/18 05:55:06 PM | _theta_step_train: [ 11/180] Final Prec@1 60.6800% Time 128.91
09/18 05:55:11 PM | Valid: [ 11/180] Step 050/312 Loss 1.375 Prec@(1,3) (62.9%, 96.6%), ce_loss 1.449, lat_loss 6.658
09/18 05:55:16 PM | Valid: [ 11/180] Step 100/312 Loss 1.393 Prec@(1,3) (63.5%, 96.4%), ce_loss 1.447, lat_loss 6.658
09/18 05:55:21 PM | Valid: [ 11/180] Step 150/312 Loss 1.398 Prec@(1,3) (63.5%, 95.9%), ce_loss 1.446, lat_loss 6.658
09/18 05:55:25 PM | Valid: [ 11/180] Step 200/312 Loss 1.399 Prec@(1,3) (63.2%, 96.2%), ce_loss 1.445, lat_loss 6.658
09/18 05:55:30 PM | Valid: [ 11/180] Step 250/312 Loss 1.399 Prec@(1,3) (63.3%, 96.2%), ce_loss 1.443, lat_loss 6.658
09/18 05:55:34 PM | Valid: [ 11/180] Step 300/312 Loss 1.395 Prec@(1,3) (63.4%, 96.2%), ce_loss 1.442, lat_loss 6.658
09/18 05:55:35 PM | Valid: [ 11/180] Step 312/312 Loss 1.396 Prec@(1,3) (63.4%, 96.2%), ce_loss 1.442, lat_loss 6.658
09/18 05:55:36 PM | val: [ 11/180] Final Prec@1 63.3700% Time 29.82
09/18 05:55:36 PM | Best top1 acc by now. Save model
09/18 05:55:36 PM | Start to train weights for epoch 11
09/18 05:55:53 PM | Train: [ 12/180] Step 050/1249 Loss 1.472 Prec@(1,3) (60.0%, 95.6%), ce_loss 1.440, lat_loss 6.658
09/18 05:56:09 PM | Train: [ 12/180] Step 100/1249 Loss 1.479 Prec@(1,3) (59.9%, 95.7%), ce_loss 1.439, lat_loss 6.658
09/18 05:56:26 PM | Train: [ 12/180] Step 150/1249 Loss 1.468 Prec@(1,3) (60.2%, 95.7%), ce_loss 1.438, lat_loss 6.658
09/18 05:56:41 PM | Train: [ 12/180] Step 200/1249 Loss 1.452 Prec@(1,3) (61.0%, 95.8%), ce_loss 1.437, lat_loss 6.658
09/18 05:56:57 PM | Train: [ 12/180] Step 250/1249 Loss 1.471 Prec@(1,3) (60.8%, 95.7%), ce_loss 1.436, lat_loss 6.658
09/18 05:57:13 PM | Train: [ 12/180] Step 300/1249 Loss 1.461 Prec@(1,3) (61.1%, 95.8%), ce_loss 1.434, lat_loss 6.658
09/18 05:57:29 PM | Train: [ 12/180] Step 350/1249 Loss 1.460 Prec@(1,3) (61.2%, 95.8%), ce_loss 1.433, lat_loss 6.658
09/18 05:57:45 PM | Train: [ 12/180] Step 400/1249 Loss 1.460 Prec@(1,3) (61.2%, 95.8%), ce_loss 1.432, lat_loss 6.658
09/18 05:58:01 PM | Train: [ 12/180] Step 450/1249 Loss 1.463 Prec@(1,3) (61.1%, 95.9%), ce_loss 1.431, lat_loss 6.658
09/18 05:58:17 PM | Train: [ 12/180] Step 500/1249 Loss 1.460 Prec@(1,3) (61.1%, 95.9%), ce_loss 1.430, lat_loss 6.658
09/18 05:58:33 PM | Train: [ 12/180] Step 550/1249 Loss 1.457 Prec@(1,3) (61.2%, 96.0%), ce_loss 1.429, lat_loss 6.658
09/18 05:58:49 PM | Train: [ 12/180] Step 600/1249 Loss 1.452 Prec@(1,3) (61.2%, 96.0%), ce_loss 1.427, lat_loss 6.658
09/18 05:59:05 PM | Train: [ 12/180] Step 650/1249 Loss 1.451 Prec@(1,3) (61.3%, 96.0%), ce_loss 1.426, lat_loss 6.658
09/18 05:59:21 PM | Train: [ 12/180] Step 700/1249 Loss 1.450 Prec@(1,3) (61.4%, 96.1%), ce_loss 1.425, lat_loss 6.658
09/18 05:59:37 PM | Train: [ 12/180] Step 750/1249 Loss 1.452 Prec@(1,3) (61.3%, 96.1%), ce_loss 1.424, lat_loss 6.658
09/18 05:59:53 PM | Train: [ 12/180] Step 800/1249 Loss 1.451 Prec@(1,3) (61.3%, 96.1%), ce_loss 1.423, lat_loss 6.658
09/18 06:00:09 PM | Train: [ 12/180] Step 850/1249 Loss 1.451 Prec@(1,3) (61.3%, 96.1%), ce_loss 1.422, lat_loss 6.658
09/18 06:00:25 PM | Train: [ 12/180] Step 900/1249 Loss 1.447 Prec@(1,3) (61.4%, 96.1%), ce_loss 1.421, lat_loss 6.658
09/18 06:00:41 PM | Train: [ 12/180] Step 950/1249 Loss 1.442 Prec@(1,3) (61.5%, 96.1%), ce_loss 1.419, lat_loss 6.658
09/18 06:00:57 PM | Train: [ 12/180] Step 1000/1249 Loss 1.440 Prec@(1,3) (61.7%, 96.1%), ce_loss 1.418, lat_loss 6.658
09/18 06:01:13 PM | Train: [ 12/180] Step 1050/1249 Loss 1.440 Prec@(1,3) (61.7%, 96.1%), ce_loss 1.417, lat_loss 6.658
09/18 06:01:29 PM | Train: [ 12/180] Step 1100/1249 Loss 1.440 Prec@(1,3) (61.7%, 96.1%), ce_loss 1.416, lat_loss 6.658
09/18 06:01:45 PM | Train: [ 12/180] Step 1150/1249 Loss 1.441 Prec@(1,3) (61.7%, 96.0%), ce_loss 1.415, lat_loss 6.658
09/18 06:02:01 PM | Train: [ 12/180] Step 1200/1249 Loss 1.441 Prec@(1,3) (61.6%, 96.0%), ce_loss 1.414, lat_loss 6.658
09/18 06:02:17 PM | Train: [ 12/180] Step 1249/1249 Loss 1.438 Prec@(1,3) (61.7%, 96.0%), ce_loss 1.413, lat_loss 6.658
09/18 06:02:17 PM | _w_step_train: [ 12/180] Final Prec@1 61.7200% Time 400.77
09/18 06:02:17 PM | Start to train theta for epoch 11
09/18 06:02:38 PM | Train: [ 12/180] Step 050/312 Loss 1.469 Prec@(1,3) (61.7%, 95.7%), ce_loss 1.412, lat_loss 6.658
09/18 06:02:59 PM | Train: [ 12/180] Step 100/312 Loss 1.398 Prec@(1,3) (63.1%, 96.1%), ce_loss 1.410, lat_loss 6.658
09/18 06:03:20 PM | Train: [ 12/180] Step 150/312 Loss 1.399 Prec@(1,3) (62.9%, 96.2%), ce_loss 1.409, lat_loss 6.658
09/18 06:03:40 PM | Train: [ 12/180] Step 200/312 Loss 1.412 Prec@(1,3) (62.4%, 96.1%), ce_loss 1.408, lat_loss 6.658
09/18 06:04:01 PM | Train: [ 12/180] Step 250/312 Loss 1.395 Prec@(1,3) (62.8%, 96.2%), ce_loss 1.407, lat_loss 6.658
09/18 06:04:22 PM | Train: [ 12/180] Step 300/312 Loss 1.408 Prec@(1,3) (62.5%, 96.2%), ce_loss 1.406, lat_loss 6.657
09/18 06:04:27 PM | Train: [ 12/180] Step 312/312 Loss 1.405 Prec@(1,3) (62.6%, 96.2%), ce_loss 1.406, lat_loss 6.657
09/18 06:04:27 PM | _theta_step_train: [ 12/180] Final Prec@1 62.5800% Time 129.75
09/18 06:04:32 PM | Valid: [ 12/180] Step 050/312 Loss 1.334 Prec@(1,3) (63.6%, 96.9%), ce_loss 1.404, lat_loss 6.657
09/18 06:04:36 PM | Valid: [ 12/180] Step 100/312 Loss 1.327 Prec@(1,3) (64.5%, 96.5%), ce_loss 1.403, lat_loss 6.657
09/18 06:04:40 PM | Valid: [ 12/180] Step 150/312 Loss 1.330 Prec@(1,3) (64.7%, 96.3%), ce_loss 1.402, lat_loss 6.657
09/18 06:04:44 PM | Valid: [ 12/180] Step 200/312 Loss 1.338 Prec@(1,3) (64.3%, 96.5%), ce_loss 1.401, lat_loss 6.657
09/18 06:04:48 PM | Valid: [ 12/180] Step 250/312 Loss 1.333 Prec@(1,3) (64.6%, 96.5%), ce_loss 1.399, lat_loss 6.657
09/18 06:04:53 PM | Valid: [ 12/180] Step 300/312 Loss 1.334 Prec@(1,3) (64.7%, 96.5%), ce_loss 1.398, lat_loss 6.657
09/18 06:04:54 PM | Valid: [ 12/180] Step 312/312 Loss 1.334 Prec@(1,3) (64.7%, 96.5%), ce_loss 1.398, lat_loss 6.657
09/18 06:04:54 PM | val: [ 12/180] Final Prec@1 64.6800% Time 26.98
09/18 06:04:54 PM | Best top1 acc by now. Save model
09/18 06:04:54 PM | Start to train weights for epoch 12
09/18 06:05:20 PM | Train: [ 13/180] Step 050/1249 Loss 1.424 Prec@(1,3) (61.7%, 96.7%), ce_loss 1.397, lat_loss 6.657
09/18 06:05:44 PM | Train: [ 13/180] Step 100/1249 Loss 1.436 Prec@(1,3) (61.4%, 96.3%), ce_loss 1.396, lat_loss 6.657
09/18 06:06:09 PM | Train: [ 13/180] Step 150/1249 Loss 1.446 Prec@(1,3) (60.9%, 96.1%), ce_loss 1.395, lat_loss 6.657
09/18 06:06:34 PM | Train: [ 13/180] Step 200/1249 Loss 1.430 Prec@(1,3) (61.6%, 96.2%), ce_loss 1.394, lat_loss 6.657
09/18 06:06:59 PM | Train: [ 13/180] Step 250/1249 Loss 1.415 Prec@(1,3) (62.0%, 96.3%), ce_loss 1.393, lat_loss 6.657
09/18 06:07:24 PM | Train: [ 13/180] Step 300/1249 Loss 1.414 Prec@(1,3) (62.3%, 96.3%), ce_loss 1.392, lat_loss 6.657
09/18 06:07:49 PM | Train: [ 13/180] Step 350/1249 Loss 1.409 Prec@(1,3) (62.5%, 96.3%), ce_loss 1.391, lat_loss 6.657
09/18 06:08:13 PM | Train: [ 13/180] Step 400/1249 Loss 1.408 Prec@(1,3) (62.5%, 96.4%), ce_loss 1.390, lat_loss 6.657
09/18 06:08:38 PM | Train: [ 13/180] Step 450/1249 Loss 1.406 Prec@(1,3) (62.7%, 96.3%), ce_loss 1.389, lat_loss 6.657
09/18 06:08:59 PM | Train: [ 13/180] Step 500/1249 Loss 1.408 Prec@(1,3) (62.7%, 96.2%), ce_loss 1.388, lat_loss 6.657
09/18 06:09:22 PM | Train: [ 13/180] Step 550/1249 Loss 1.407 Prec@(1,3) (62.7%, 96.2%), ce_loss 1.387, lat_loss 6.657
09/18 06:09:44 PM | Train: [ 13/180] Step 600/1249 Loss 1.403 Prec@(1,3) (62.7%, 96.2%), ce_loss 1.386, lat_loss 6.657
09/18 06:10:06 PM | Train: [ 13/180] Step 650/1249 Loss 1.401 Prec@(1,3) (62.6%, 96.3%), ce_loss 1.385, lat_loss 6.657
09/18 06:10:28 PM | Train: [ 13/180] Step 700/1249 Loss 1.399 Prec@(1,3) (62.6%, 96.3%), ce_loss 1.383, lat_loss 6.657
09/18 06:10:50 PM | Train: [ 13/180] Step 750/1249 Loss 1.397 Prec@(1,3) (62.7%, 96.3%), ce_loss 1.382, lat_loss 6.657
09/18 06:11:13 PM | Train: [ 13/180] Step 800/1249 Loss 1.398 Prec@(1,3) (62.7%, 96.3%), ce_loss 1.382, lat_loss 6.657
09/18 06:11:35 PM | Train: [ 13/180] Step 850/1249 Loss 1.399 Prec@(1,3) (62.8%, 96.2%), ce_loss 1.381, lat_loss 6.657
09/18 06:11:57 PM | Train: [ 13/180] Step 900/1249 Loss 1.397 Prec@(1,3) (62.8%, 96.3%), ce_loss 1.380, lat_loss 6.657
09/18 06:12:18 PM | Train: [ 13/180] Step 950/1249 Loss 1.397 Prec@(1,3) (62.7%, 96.3%), ce_loss 1.379, lat_loss 6.657
09/18 06:12:39 PM | Train: [ 13/180] Step 1000/1249 Loss 1.395 Prec@(1,3) (62.8%, 96.3%), ce_loss 1.378, lat_loss 6.657
09/18 06:13:01 PM | Train: [ 13/180] Step 1050/1249 Loss 1.392 Prec@(1,3) (62.8%, 96.3%), ce_loss 1.376, lat_loss 6.657
09/18 06:13:23 PM | Train: [ 13/180] Step 1100/1249 Loss 1.391 Prec@(1,3) (62.9%, 96.3%), ce_loss 1.375, lat_loss 6.657
09/18 06:13:43 PM | Train: [ 13/180] Step 1150/1249 Loss 1.394 Prec@(1,3) (62.8%, 96.3%), ce_loss 1.375, lat_loss 6.657
09/18 06:13:59 PM | Train: [ 13/180] Step 1200/1249 Loss 1.392 Prec@(1,3) (62.9%, 96.3%), ce_loss 1.374, lat_loss 6.657
09/18 06:14:16 PM | Train: [ 13/180] Step 1249/1249 Loss 1.389 Prec@(1,3) (63.0%, 96.3%), ce_loss 1.373, lat_loss 6.657
09/18 06:14:16 PM | _w_step_train: [ 13/180] Final Prec@1 63.0025% Time 561.94
09/18 06:14:16 PM | Start to train theta for epoch 12
09/18 06:14:37 PM | Train: [ 13/180] Step 050/312 Loss 1.372 Prec@(1,3) (64.0%, 96.6%), ce_loss 1.372, lat_loss 6.657
09/18 06:14:58 PM | Train: [ 13/180] Step 100/312 Loss 1.408 Prec@(1,3) (62.5%, 96.3%), ce_loss 1.371, lat_loss 6.657
09/18 06:15:19 PM | Train: [ 13/180] Step 150/312 Loss 1.406 Prec@(1,3) (62.7%, 96.2%), ce_loss 1.370, lat_loss 6.657
09/18 06:15:40 PM | Train: [ 13/180] Step 200/312 Loss 1.393 Prec@(1,3) (62.7%, 96.3%), ce_loss 1.369, lat_loss 6.657
09/18 06:16:00 PM | Train: [ 13/180] Step 250/312 Loss 1.383 Prec@(1,3) (63.2%, 96.3%), ce_loss 1.368, lat_loss 6.657
09/18 06:16:21 PM | Train: [ 13/180] Step 300/312 Loss 1.383 Prec@(1,3) (63.4%, 96.4%), ce_loss 1.367, lat_loss 6.657
09/18 06:16:26 PM | Train: [ 13/180] Step 312/312 Loss 1.386 Prec@(1,3) (63.3%, 96.3%), ce_loss 1.367, lat_loss 6.657
09/18 06:16:26 PM | _theta_step_train: [ 13/180] Final Prec@1 63.2600% Time 130.40
09/18 06:16:32 PM | Valid: [ 13/180] Step 050/312 Loss 1.264 Prec@(1,3) (65.6%, 97.6%), ce_loss 1.366, lat_loss 6.657
09/18 06:16:36 PM | Valid: [ 13/180] Step 100/312 Loss 1.279 Prec@(1,3) (66.1%, 97.0%), ce_loss 1.364, lat_loss 6.657
09/18 06:16:41 PM | Valid: [ 13/180] Step 150/312 Loss 1.281 Prec@(1,3) (65.9%, 96.7%), ce_loss 1.363, lat_loss 6.657
09/18 06:16:45 PM | Valid: [ 13/180] Step 200/312 Loss 1.285 Prec@(1,3) (65.7%, 96.9%), ce_loss 1.362, lat_loss 6.657
09/18 06:16:50 PM | Valid: [ 13/180] Step 250/312 Loss 1.289 Prec@(1,3) (65.8%, 96.8%), ce_loss 1.361, lat_loss 6.657
09/18 06:16:55 PM | Valid: [ 13/180] Step 300/312 Loss 1.292 Prec@(1,3) (65.8%, 96.8%), ce_loss 1.360, lat_loss 6.657
09/18 06:16:56 PM | Valid: [ 13/180] Step 312/312 Loss 1.294 Prec@(1,3) (65.8%, 96.8%), ce_loss 1.360, lat_loss 6.657
09/18 06:16:56 PM | val: [ 13/180] Final Prec@1 65.7700% Time 29.60
09/18 06:16:56 PM | Best top1 acc by now. Save model
09/18 06:16:56 PM | Start to train weights for epoch 13
09/18 06:17:20 PM | Train: [ 14/180] Step 050/1249 Loss 1.322 Prec@(1,3) (64.7%, 96.9%), ce_loss 1.359, lat_loss 6.657
09/18 06:17:42 PM | Train: [ 14/180] Step 100/1249 Loss 1.320 Prec@(1,3) (65.0%, 97.0%), ce_loss 1.358, lat_loss 6.657
09/18 06:18:05 PM | Train: [ 14/180] Step 150/1249 Loss 1.315 Prec@(1,3) (65.0%, 96.9%), ce_loss 1.357, lat_loss 6.657
09/18 06:18:28 PM | Train: [ 14/180] Step 200/1249 Loss 1.335 Prec@(1,3) (64.7%, 96.8%), ce_loss 1.356, lat_loss 6.657
09/18 06:18:51 PM | Train: [ 14/180] Step 250/1249 Loss 1.351 Prec@(1,3) (64.2%, 96.7%), ce_loss 1.355, lat_loss 6.657
09/18 06:19:12 PM | Train: [ 14/180] Step 300/1249 Loss 1.346 Prec@(1,3) (64.1%, 96.8%), ce_loss 1.354, lat_loss 6.657
09/18 06:19:34 PM | Train: [ 14/180] Step 350/1249 Loss 1.352 Prec@(1,3) (64.0%, 96.8%), ce_loss 1.353, lat_loss 6.657
09/18 06:19:55 PM | Train: [ 14/180] Step 400/1249 Loss 1.348 Prec@(1,3) (64.1%, 96.9%), ce_loss 1.352, lat_loss 6.657
09/18 06:20:17 PM | Train: [ 14/180] Step 450/1249 Loss 1.349 Prec@(1,3) (64.1%, 96.8%), ce_loss 1.351, lat_loss 6.657
09/18 06:20:39 PM | Train: [ 14/180] Step 500/1249 Loss 1.349 Prec@(1,3) (64.1%, 96.8%), ce_loss 1.351, lat_loss 6.657
09/18 06:21:01 PM | Train: [ 14/180] Step 550/1249 Loss 1.347 Prec@(1,3) (64.3%, 96.8%), ce_loss 1.350, lat_loss 6.657
09/18 06:21:22 PM | Train: [ 14/180] Step 600/1249 Loss 1.350 Prec@(1,3) (64.2%, 96.7%), ce_loss 1.349, lat_loss 6.657
09/18 06:21:45 PM | Train: [ 14/180] Step 650/1249 Loss 1.353 Prec@(1,3) (64.1%, 96.7%), ce_loss 1.348, lat_loss 6.657
09/18 06:22:06 PM | Train: [ 14/180] Step 700/1249 Loss 1.351 Prec@(1,3) (64.2%, 96.7%), ce_loss 1.347, lat_loss 6.657
09/18 06:22:29 PM | Train: [ 14/180] Step 750/1249 Loss 1.348 Prec@(1,3) (64.2%, 96.7%), ce_loss 1.346, lat_loss 6.657
09/18 06:22:52 PM | Train: [ 14/180] Step 800/1249 Loss 1.350 Prec@(1,3) (64.2%, 96.6%), ce_loss 1.345, lat_loss 6.657
09/18 06:23:14 PM | Train: [ 14/180] Step 850/1249 Loss 1.346 Prec@(1,3) (64.3%, 96.7%), ce_loss 1.344, lat_loss 6.657
09/18 06:23:37 PM | Train: [ 14/180] Step 900/1249 Loss 1.344 Prec@(1,3) (64.3%, 96.6%), ce_loss 1.343, lat_loss 6.657
09/18 06:24:00 PM | Train: [ 14/180] Step 950/1249 Loss 1.343 Prec@(1,3) (64.4%, 96.6%), ce_loss 1.342, lat_loss 6.657
09/18 06:24:22 PM | Train: [ 14/180] Step 1000/1249 Loss 1.342 Prec@(1,3) (64.5%, 96.6%), ce_loss 1.341, lat_loss 6.657
09/18 06:24:44 PM | Train: [ 14/180] Step 1050/1249 Loss 1.343 Prec@(1,3) (64.4%, 96.6%), ce_loss 1.341, lat_loss 6.657
09/18 06:25:06 PM | Train: [ 14/180] Step 1100/1249 Loss 1.346 Prec@(1,3) (64.4%, 96.5%), ce_loss 1.340, lat_loss 6.657
09/18 06:25:29 PM | Train: [ 14/180] Step 1150/1249 Loss 1.345 Prec@(1,3) (64.4%, 96.6%), ce_loss 1.339, lat_loss 6.657
09/18 06:25:51 PM | Train: [ 14/180] Step 1200/1249 Loss 1.344 Prec@(1,3) (64.5%, 96.6%), ce_loss 1.338, lat_loss 6.657
09/18 06:26:15 PM | Train: [ 14/180] Step 1249/1249 Loss 1.344 Prec@(1,3) (64.5%, 96.6%), ce_loss 1.337, lat_loss 6.657
09/18 06:26:15 PM | _w_step_train: [ 14/180] Final Prec@1 64.4575% Time 559.49
09/18 06:26:15 PM | Start to train theta for epoch 13
09/18 06:26:37 PM | Train: [ 14/180] Step 050/312 Loss 1.344 Prec@(1,3) (65.2%, 96.1%), ce_loss 1.336, lat_loss 6.657
09/18 06:26:57 PM | Train: [ 14/180] Step 100/312 Loss 1.337 Prec@(1,3) (65.1%, 96.6%), ce_loss 1.336, lat_loss 6.657
09/18 06:27:18 PM | Train: [ 14/180] Step 150/312 Loss 1.329 Prec@(1,3) (65.0%, 96.6%), ce_loss 1.335, lat_loss 6.657
09/18 06:27:38 PM | Train: [ 14/180] Step 200/312 Loss 1.335 Prec@(1,3) (65.1%, 96.5%), ce_loss 1.334, lat_loss 6.657
09/18 06:27:59 PM | Train: [ 14/180] Step 250/312 Loss 1.332 Prec@(1,3) (65.2%, 96.4%), ce_loss 1.333, lat_loss 6.657
09/18 06:28:19 PM | Train: [ 14/180] Step 300/312 Loss 1.323 Prec@(1,3) (65.3%, 96.5%), ce_loss 1.332, lat_loss 6.657
09/18 06:28:24 PM | Train: [ 14/180] Step 312/312 Loss 1.327 Prec@(1,3) (65.1%, 96.5%), ce_loss 1.332, lat_loss 6.657
09/18 06:28:25 PM | _theta_step_train: [ 14/180] Final Prec@1 65.1300% Time 129.07
09/18 06:28:30 PM | Valid: [ 14/180] Step 050/312 Loss 1.234 Prec@(1,3) (67.5%, 97.4%), ce_loss 1.331, lat_loss 6.657
09/18 06:28:34 PM | Valid: [ 14/180] Step 100/312 Loss 1.231 Prec@(1,3) (67.4%, 97.5%), ce_loss 1.330, lat_loss 6.657
09/18 06:28:39 PM | Valid: [ 14/180] Step 150/312 Loss 1.224 Prec@(1,3) (68.0%, 97.4%), ce_loss 1.329, lat_loss 6.657
09/18 06:28:44 PM | Valid: [ 14/180] Step 200/312 Loss 1.233 Prec@(1,3) (67.7%, 97.3%), ce_loss 1.328, lat_loss 6.657
09/18 06:28:48 PM | Valid: [ 14/180] Step 250/312 Loss 1.239 Prec@(1,3) (67.8%, 97.2%), ce_loss 1.327, lat_loss 6.657
09/18 06:28:53 PM | Valid: [ 14/180] Step 300/312 Loss 1.241 Prec@(1,3) (67.7%, 97.2%), ce_loss 1.326, lat_loss 6.657
09/18 06:28:54 PM | Valid: [ 14/180] Step 312/312 Loss 1.242 Prec@(1,3) (67.6%, 97.3%), ce_loss 1.326, lat_loss 6.657
09/18 06:28:54 PM | val: [ 14/180] Final Prec@1 67.6000% Time 29.60
09/18 06:28:54 PM | Best top1 acc by now. Save model
09/18 06:28:54 PM | Start to train weights for epoch 14
09/18 06:29:21 PM | Train: [ 15/180] Step 050/1249 Loss 1.292 Prec@(1,3) (65.5%, 96.8%), ce_loss 1.325, lat_loss 6.657
09/18 06:29:45 PM | Train: [ 15/180] Step 100/1249 Loss 1.302 Prec@(1,3) (65.0%, 96.7%), ce_loss 1.324, lat_loss 6.657
09/18 06:30:09 PM | Train: [ 15/180] Step 150/1249 Loss 1.318 Prec@(1,3) (65.0%, 96.8%), ce_loss 1.323, lat_loss 6.657
09/18 06:30:32 PM | Train: [ 15/180] Step 200/1249 Loss 1.320 Prec@(1,3) (64.8%, 96.9%), ce_loss 1.322, lat_loss 6.657
09/18 06:30:56 PM | Train: [ 15/180] Step 250/1249 Loss 1.324 Prec@(1,3) (64.6%, 96.8%), ce_loss 1.322, lat_loss 6.657
09/18 06:31:20 PM | Train: [ 15/180] Step 300/1249 Loss 1.327 Prec@(1,3) (64.7%, 96.9%), ce_loss 1.321, lat_loss 6.657
09/18 06:31:45 PM | Train: [ 15/180] Step 350/1249 Loss 1.324 Prec@(1,3) (64.8%, 96.8%), ce_loss 1.320, lat_loss 6.657
09/18 06:32:10 PM | Train: [ 15/180] Step 400/1249 Loss 1.311 Prec@(1,3) (65.2%, 97.0%), ce_loss 1.319, lat_loss 6.657
09/18 06:32:34 PM | Train: [ 15/180] Step 450/1249 Loss 1.306 Prec@(1,3) (65.2%, 97.0%), ce_loss 1.318, lat_loss 6.657
09/18 06:32:57 PM | Train: [ 15/180] Step 500/1249 Loss 1.304 Prec@(1,3) (65.2%, 97.0%), ce_loss 1.317, lat_loss 6.657
09/18 06:33:22 PM | Train: [ 15/180] Step 550/1249 Loss 1.304 Prec@(1,3) (65.3%, 97.0%), ce_loss 1.316, lat_loss 6.657
09/18 06:33:46 PM | Train: [ 15/180] Step 600/1249 Loss 1.310 Prec@(1,3) (65.0%, 97.0%), ce_loss 1.316, lat_loss 6.657
09/18 06:34:10 PM | Train: [ 15/180] Step 650/1249 Loss 1.313 Prec@(1,3) (64.9%, 96.9%), ce_loss 1.315, lat_loss 6.657
09/18 06:34:34 PM | Train: [ 15/180] Step 700/1249 Loss 1.313 Prec@(1,3) (65.0%, 96.9%), ce_loss 1.314, lat_loss 6.657
09/18 06:34:58 PM | Train: [ 15/180] Step 750/1249 Loss 1.312 Prec@(1,3) (65.0%, 96.8%), ce_loss 1.313, lat_loss 6.657
09/18 06:35:21 PM | Train: [ 15/180] Step 800/1249 Loss 1.310 Prec@(1,3) (65.1%, 96.8%), ce_loss 1.313, lat_loss 6.657
09/18 06:35:45 PM | Train: [ 15/180] Step 850/1249 Loss 1.312 Prec@(1,3) (65.0%, 96.8%), ce_loss 1.312, lat_loss 6.657
09/18 06:36:10 PM | Train: [ 15/180] Step 900/1249 Loss 1.310 Prec@(1,3) (65.0%, 96.8%), ce_loss 1.311, lat_loss 6.657
09/18 06:36:34 PM | Train: [ 15/180] Step 950/1249 Loss 1.311 Prec@(1,3) (65.0%, 96.8%), ce_loss 1.310, lat_loss 6.657
09/18 06:36:58 PM | Train: [ 15/180] Step 1000/1249 Loss 1.311 Prec@(1,3) (65.0%, 96.8%), ce_loss 1.309, lat_loss 6.657
09/18 06:37:21 PM | Train: [ 15/180] Step 1050/1249 Loss 1.310 Prec@(1,3) (65.0%, 96.8%), ce_loss 1.309, lat_loss 6.657
09/18 06:37:46 PM | Train: [ 15/180] Step 1100/1249 Loss 1.308 Prec@(1,3) (65.1%, 96.8%), ce_loss 1.308, lat_loss 6.657
09/18 06:38:09 PM | Train: [ 15/180] Step 1150/1249 Loss 1.306 Prec@(1,3) (65.1%, 96.9%), ce_loss 1.307, lat_loss 6.657
09/18 06:38:34 PM | Train: [ 15/180] Step 1200/1249 Loss 1.306 Prec@(1,3) (65.1%, 96.9%), ce_loss 1.306, lat_loss 6.657
09/18 06:38:58 PM | Train: [ 15/180] Step 1249/1249 Loss 1.307 Prec@(1,3) (65.1%, 96.9%), ce_loss 1.305, lat_loss 6.657
09/18 06:38:58 PM | _w_step_train: [ 15/180] Final Prec@1 65.1300% Time 603.58
09/18 06:38:58 PM | Start to train theta for epoch 14
09/18 06:39:19 PM | Train: [ 15/180] Step 050/312 Loss 1.302 Prec@(1,3) (66.1%, 96.8%), ce_loss 1.305, lat_loss 6.657
09/18 06:39:39 PM | Train: [ 15/180] Step 100/312 Loss 1.322 Prec@(1,3) (65.2%, 96.8%), ce_loss 1.304, lat_loss 6.657
09/18 06:40:00 PM | Train: [ 15/180] Step 150/312 Loss 1.345 Prec@(1,3) (64.7%, 96.7%), ce_loss 1.303, lat_loss 6.657
09/18 06:40:21 PM | Train: [ 15/180] Step 200/312 Loss 1.341 Prec@(1,3) (64.7%, 96.6%), ce_loss 1.303, lat_loss 6.657
09/18 06:40:41 PM | Train: [ 15/180] Step 250/312 Loss 1.340 Prec@(1,3) (64.9%, 96.6%), ce_loss 1.302, lat_loss 6.657
09/18 06:41:02 PM | Train: [ 15/180] Step 300/312 Loss 1.332 Prec@(1,3) (65.0%, 96.5%), ce_loss 1.301, lat_loss 6.657
09/18 06:41:07 PM | Train: [ 15/180] Step 312/312 Loss 1.331 Prec@(1,3) (65.0%, 96.6%), ce_loss 1.301, lat_loss 6.657
09/18 06:41:07 PM | _theta_step_train: [ 15/180] Final Prec@1 64.9700% Time 129.47
09/18 06:41:13 PM | Valid: [ 15/180] Step 050/312 Loss 1.239 Prec@(1,3) (67.3%, 97.5%), ce_loss 1.300, lat_loss 6.657
09/18 06:41:17 PM | Valid: [ 15/180] Step 100/312 Loss 1.237 Prec@(1,3) (67.2%, 97.2%), ce_loss 1.299, lat_loss 6.657
09/18 06:41:22 PM | Valid: [ 15/180] Step 150/312 Loss 1.235 Prec@(1,3) (67.4%, 97.0%), ce_loss 1.298, lat_loss 6.657
09/18 06:41:27 PM | Valid: [ 15/180] Step 200/312 Loss 1.236 Prec@(1,3) (67.3%, 97.1%), ce_loss 1.298, lat_loss 6.657
09/18 06:41:31 PM | Valid: [ 15/180] Step 250/312 Loss 1.238 Prec@(1,3) (67.3%, 97.0%), ce_loss 1.297, lat_loss 6.657
09/18 06:41:36 PM | Valid: [ 15/180] Step 300/312 Loss 1.243 Prec@(1,3) (67.3%, 97.0%), ce_loss 1.296, lat_loss 6.657
09/18 06:41:38 PM | Valid: [ 15/180] Step 312/312 Loss 1.251 Prec@(1,3) (67.2%, 96.9%), ce_loss 1.296, lat_loss 6.657
09/18 06:41:38 PM | val: [ 15/180] Final Prec@1 67.1900% Time 30.28
09/18 06:41:38 PM | Start to train weights for epoch 15
09/18 06:42:03 PM | Train: [ 16/180] Step 050/1249 Loss 1.229 Prec@(1,3) (66.8%, 97.2%), ce_loss 1.295, lat_loss 6.657
09/18 06:42:28 PM | Train: [ 16/180] Step 100/1249 Loss 1.224 Prec@(1,3) (67.2%, 97.2%), ce_loss 1.294, lat_loss 6.657
09/18 06:42:51 PM | Train: [ 16/180] Step 150/1249 Loss 1.219 Prec@(1,3) (67.4%, 97.4%), ce_loss 1.293, lat_loss 6.657
09/18 06:43:15 PM | Train: [ 16/180] Step 200/1249 Loss 1.230 Prec@(1,3) (67.0%, 97.1%), ce_loss 1.292, lat_loss 6.657
09/18 06:43:39 PM | Train: [ 16/180] Step 250/1249 Loss 1.250 Prec@(1,3) (66.4%, 97.1%), ce_loss 1.292, lat_loss 6.657
09/18 06:44:04 PM | Train: [ 16/180] Step 300/1249 Loss 1.254 Prec@(1,3) (66.4%, 97.1%), ce_loss 1.291, lat_loss 6.657
09/18 06:44:29 PM | Train: [ 16/180] Step 350/1249 Loss 1.248 Prec@(1,3) (66.6%, 97.2%), ce_loss 1.290, lat_loss 6.657
09/18 06:44:54 PM | Train: [ 16/180] Step 400/1249 Loss 1.253 Prec@(1,3) (66.4%, 97.2%), ce_loss 1.289, lat_loss 6.657
09/18 06:45:19 PM | Train: [ 16/180] Step 450/1249 Loss 1.260 Prec@(1,3) (66.4%, 97.2%), ce_loss 1.289, lat_loss 6.657
09/18 06:45:44 PM | Train: [ 16/180] Step 500/1249 Loss 1.265 Prec@(1,3) (66.3%, 97.1%), ce_loss 1.288, lat_loss 6.657
09/18 06:46:09 PM | Train: [ 16/180] Step 550/1249 Loss 1.264 Prec@(1,3) (66.4%, 97.1%), ce_loss 1.287, lat_loss 6.657
09/18 06:46:34 PM | Train: [ 16/180] Step 600/1249 Loss 1.264 Prec@(1,3) (66.4%, 97.2%), ce_loss 1.287, lat_loss 6.657
09/18 06:46:59 PM | Train: [ 16/180] Step 650/1249 Loss 1.266 Prec@(1,3) (66.4%, 97.2%), ce_loss 1.286, lat_loss 6.657
09/18 06:47:24 PM | Train: [ 16/180] Step 700/1249 Loss 1.268 Prec@(1,3) (66.3%, 97.2%), ce_loss 1.285, lat_loss 6.657
09/18 06:47:49 PM | Train: [ 16/180] Step 750/1249 Loss 1.268 Prec@(1,3) (66.2%, 97.2%), ce_loss 1.284, lat_loss 6.657
09/18 06:48:14 PM | Train: [ 16/180] Step 800/1249 Loss 1.266 Prec@(1,3) (66.3%, 97.2%), ce_loss 1.284, lat_loss 6.657
09/18 06:48:39 PM | Train: [ 16/180] Step 850/1249 Loss 1.268 Prec@(1,3) (66.3%, 97.2%), ce_loss 1.283, lat_loss 6.657
09/18 06:49:04 PM | Train: [ 16/180] Step 900/1249 Loss 1.264 Prec@(1,3) (66.4%, 97.2%), ce_loss 1.282, lat_loss 6.657
09/18 06:49:29 PM | Train: [ 16/180] Step 950/1249 Loss 1.263 Prec@(1,3) (66.5%, 97.2%), ce_loss 1.281, lat_loss 6.657
09/18 06:49:54 PM | Train: [ 16/180] Step 1000/1249 Loss 1.263 Prec@(1,3) (66.5%, 97.2%), ce_loss 1.281, lat_loss 6.657
09/18 06:50:19 PM | Train: [ 16/180] Step 1050/1249 Loss 1.263 Prec@(1,3) (66.5%, 97.2%), ce_loss 1.280, lat_loss 6.657
09/18 06:50:44 PM | Train: [ 16/180] Step 1100/1249 Loss 1.261 Prec@(1,3) (66.6%, 97.2%), ce_loss 1.279, lat_loss 6.657
09/18 06:51:09 PM | Train: [ 16/180] Step 1150/1249 Loss 1.261 Prec@(1,3) (66.6%, 97.2%), ce_loss 1.278, lat_loss 6.657
09/18 06:51:34 PM | Train: [ 16/180] Step 1200/1249 Loss 1.262 Prec@(1,3) (66.6%, 97.2%), ce_loss 1.278, lat_loss 6.657
09/18 06:51:58 PM | Train: [ 16/180] Step 1249/1249 Loss 1.262 Prec@(1,3) (66.6%, 97.2%), ce_loss 1.277, lat_loss 6.657
09/18 06:51:58 PM | _w_step_train: [ 16/180] Final Prec@1 66.5700% Time 620.22
09/18 06:51:58 PM | Start to train theta for epoch 15
09/18 06:52:17 PM | Train: [ 16/180] Step 050/312 Loss 1.241 Prec@(1,3) (67.1%, 97.4%), ce_loss 1.276, lat_loss 6.657
09/18 06:52:35 PM | Train: [ 16/180] Step 100/312 Loss 1.234 Prec@(1,3) (67.4%, 97.0%), ce_loss 1.276, lat_loss 6.657
09/18 06:52:55 PM | Train: [ 16/180] Step 150/312 Loss 1.258 Prec@(1,3) (66.5%, 96.8%), ce_loss 1.275, lat_loss 6.657
09/18 06:53:16 PM | Train: [ 16/180] Step 200/312 Loss 1.269 Prec@(1,3) (66.3%, 96.7%), ce_loss 1.274, lat_loss 6.657
09/18 06:53:37 PM | Train: [ 16/180] Step 250/312 Loss 1.272 Prec@(1,3) (66.6%, 96.8%), ce_loss 1.274, lat_loss 6.657
09/18 06:53:58 PM | Train: [ 16/180] Step 300/312 Loss 1.281 Prec@(1,3) (66.4%, 97.0%), ce_loss 1.273, lat_loss 6.657
09/18 06:54:03 PM | Train: [ 16/180] Step 312/312 Loss 1.282 Prec@(1,3) (66.4%, 96.9%), ce_loss 1.273, lat_loss 6.657
09/18 06:54:03 PM | _theta_step_train: [ 16/180] Final Prec@1 66.4200% Time 124.66
09/18 06:54:08 PM | Valid: [ 16/180] Step 050/312 Loss 1.256 Prec@(1,3) (67.5%, 97.2%), ce_loss 1.272, lat_loss 6.657
09/18 06:54:13 PM | Valid: [ 16/180] Step 100/312 Loss 1.247 Prec@(1,3) (67.8%, 97.1%), ce_loss 1.271, lat_loss 6.657
09/18 06:54:17 PM | Valid: [ 16/180] Step 150/312 Loss 1.229 Prec@(1,3) (68.3%, 97.2%), ce_loss 1.271, lat_loss 6.657
09/18 06:54:22 PM | Valid: [ 16/180] Step 200/312 Loss 1.226 Prec@(1,3) (68.2%, 97.3%), ce_loss 1.270, lat_loss 6.657
09/18 06:54:27 PM | Valid: [ 16/180] Step 250/312 Loss 1.227 Prec@(1,3) (68.0%, 97.3%), ce_loss 1.269, lat_loss 6.657
09/18 06:54:31 PM | Valid: [ 16/180] Step 300/312 Loss 1.224 Prec@(1,3) (68.1%, 97.2%), ce_loss 1.268, lat_loss 6.657
09/18 06:54:33 PM | Valid: [ 16/180] Step 312/312 Loss 1.222 Prec@(1,3) (68.2%, 97.2%), ce_loss 1.268, lat_loss 6.657
09/18 06:54:33 PM | val: [ 16/180] Final Prec@1 68.1700% Time 29.90
09/18 06:54:33 PM | Best top1 acc by now. Save model
09/18 06:54:33 PM | Start to train weights for epoch 16
09/18 06:54:57 PM | Train: [ 17/180] Step 050/1249 Loss 1.248 Prec@(1,3) (66.3%, 96.9%), ce_loss 1.267, lat_loss 6.657
09/18 06:55:24 PM | Train: [ 17/180] Step 100/1249 Loss 1.231 Prec@(1,3) (67.4%, 96.9%), ce_loss 1.267, lat_loss 6.657
09/18 06:55:49 PM | Train: [ 17/180] Step 150/1249 Loss 1.245 Prec@(1,3) (67.2%, 97.0%), ce_loss 1.266, lat_loss 6.657
09/18 06:56:15 PM | Train: [ 17/180] Step 200/1249 Loss 1.239 Prec@(1,3) (67.4%, 97.1%), ce_loss 1.265, lat_loss 6.657
09/18 06:56:39 PM | Train: [ 17/180] Step 250/1249 Loss 1.241 Prec@(1,3) (67.4%, 97.1%), ce_loss 1.265, lat_loss 6.657
09/18 06:57:04 PM | Train: [ 17/180] Step 300/1249 Loss 1.229 Prec@(1,3) (67.7%, 97.1%), ce_loss 1.264, lat_loss 6.657
09/18 06:57:29 PM | Train: [ 17/180] Step 350/1249 Loss 1.232 Prec@(1,3) (67.5%, 97.1%), ce_loss 1.263, lat_loss 6.657
09/18 06:57:54 PM | Train: [ 17/180] Step 400/1249 Loss 1.241 Prec@(1,3) (67.3%, 97.0%), ce_loss 1.263, lat_loss 6.657
09/18 06:58:17 PM | Train: [ 17/180] Step 450/1249 Loss 1.244 Prec@(1,3) (67.0%, 97.0%), ce_loss 1.262, lat_loss 6.657
09/18 06:58:32 PM | Train: [ 17/180] Step 500/1249 Loss 1.238 Prec@(1,3) (67.1%, 97.1%), ce_loss 1.261, lat_loss 6.657
09/18 06:58:48 PM | Train: [ 17/180] Step 550/1249 Loss 1.235 Prec@(1,3) (67.2%, 97.2%), ce_loss 1.260, lat_loss 6.657
09/18 06:59:04 PM | Train: [ 17/180] Step 600/1249 Loss 1.235 Prec@(1,3) (67.1%, 97.2%), ce_loss 1.260, lat_loss 6.657
09/18 06:59:20 PM | Train: [ 17/180] Step 650/1249 Loss 1.237 Prec@(1,3) (67.1%, 97.2%), ce_loss 1.259, lat_loss 6.657
09/18 06:59:41 PM | Train: [ 17/180] Step 700/1249 Loss 1.234 Prec@(1,3) (67.2%, 97.2%), ce_loss 1.258, lat_loss 6.657
09/18 07:00:04 PM | Train: [ 17/180] Step 750/1249 Loss 1.230 Prec@(1,3) (67.4%, 97.2%), ce_loss 1.258, lat_loss 6.657
09/18 07:00:25 PM | Train: [ 17/180] Step 800/1249 Loss 1.231 Prec@(1,3) (67.4%, 97.2%), ce_loss 1.257, lat_loss 6.657
09/18 07:00:48 PM | Train: [ 17/180] Step 850/1249 Loss 1.232 Prec@(1,3) (67.5%, 97.2%), ce_loss 1.256, lat_loss 6.657
09/18 07:01:11 PM | Train: [ 17/180] Step 900/1249 Loss 1.232 Prec@(1,3) (67.5%, 97.2%), ce_loss 1.256, lat_loss 6.657
09/18 07:01:32 PM | Train: [ 17/180] Step 950/1249 Loss 1.230 Prec@(1,3) (67.6%, 97.2%), ce_loss 1.255, lat_loss 6.657
09/18 07:01:54 PM | Train: [ 17/180] Step 1000/1249 Loss 1.232 Prec@(1,3) (67.6%, 97.1%), ce_loss 1.254, lat_loss 6.657
09/18 07:02:17 PM | Train: [ 17/180] Step 1050/1249 Loss 1.233 Prec@(1,3) (67.6%, 97.1%), ce_loss 1.254, lat_loss 6.657
09/18 07:02:38 PM | Train: [ 17/180] Step 1100/1249 Loss 1.231 Prec@(1,3) (67.6%, 97.2%), ce_loss 1.253, lat_loss 6.657
09/18 07:03:00 PM | Train: [ 17/180] Step 1150/1249 Loss 1.230 Prec@(1,3) (67.7%, 97.2%), ce_loss 1.252, lat_loss 6.657
09/18 07:03:23 PM | Train: [ 17/180] Step 1200/1249 Loss 1.231 Prec@(1,3) (67.7%, 97.2%), ce_loss 1.252, lat_loss 6.657
09/18 07:03:47 PM | Train: [ 17/180] Step 1249/1249 Loss 1.230 Prec@(1,3) (67.7%, 97.2%), ce_loss 1.251, lat_loss 6.657
09/18 07:03:47 PM | _w_step_train: [ 17/180] Final Prec@1 67.6875% Time 553.87
09/18 07:03:47 PM | Start to train theta for epoch 16
09/18 07:04:08 PM | Train: [ 17/180] Step 050/312 Loss 1.256 Prec@(1,3) (67.2%, 97.1%), ce_loss 1.250, lat_loss 6.657
09/18 07:04:29 PM | Train: [ 17/180] Step 100/312 Loss 1.245 Prec@(1,3) (67.6%, 97.2%), ce_loss 1.250, lat_loss 6.657
09/18 07:04:49 PM | Train: [ 17/180] Step 150/312 Loss 1.244 Prec@(1,3) (67.1%, 97.1%), ce_loss 1.249, lat_loss 6.657
09/18 07:05:09 PM | Train: [ 17/180] Step 200/312 Loss 1.223 Prec@(1,3) (67.8%, 97.2%), ce_loss 1.248, lat_loss 6.657
09/18 07:05:29 PM | Train: [ 17/180] Step 250/312 Loss 1.218 Prec@(1,3) (68.1%, 97.3%), ce_loss 1.248, lat_loss 6.657
09/18 07:05:47 PM | Train: [ 17/180] Step 300/312 Loss 1.231 Prec@(1,3) (67.8%, 97.1%), ce_loss 1.247, lat_loss 6.657
09/18 07:05:51 PM | Train: [ 17/180] Step 312/312 Loss 1.228 Prec@(1,3) (67.8%, 97.2%), ce_loss 1.247, lat_loss 6.657
09/18 07:05:51 PM | _theta_step_train: [ 17/180] Final Prec@1 67.8200% Time 124.81
09/18 07:05:57 PM | Valid: [ 17/180] Step 050/312 Loss 1.175 Prec@(1,3) (67.6%, 97.5%), ce_loss 1.246, lat_loss 6.657
09/18 07:06:01 PM | Valid: [ 17/180] Step 100/312 Loss 1.201 Prec@(1,3) (67.6%, 97.2%), ce_loss 1.246, lat_loss 6.657
09/18 07:06:06 PM | Valid: [ 17/180] Step 150/312 Loss 1.195 Prec@(1,3) (68.1%, 97.1%), ce_loss 1.245, lat_loss 6.657
09/18 07:06:11 PM | Valid: [ 17/180] Step 200/312 Loss 1.199 Prec@(1,3) (68.2%, 97.2%), ce_loss 1.244, lat_loss 6.657
09/18 07:06:15 PM | Valid: [ 17/180] Step 250/312 Loss 1.194 Prec@(1,3) (68.4%, 97.3%), ce_loss 1.244, lat_loss 6.657
09/18 07:06:20 PM | Valid: [ 17/180] Step 300/312 Loss 1.182 Prec@(1,3) (68.8%, 97.5%), ce_loss 1.243, lat_loss 6.657
09/18 07:06:21 PM | Valid: [ 17/180] Step 312/312 Loss 1.181 Prec@(1,3) (68.8%, 97.5%), ce_loss 1.243, lat_loss 6.657
09/18 07:06:21 PM | val: [ 17/180] Final Prec@1 68.8400% Time 29.53
09/18 07:06:21 PM | Best top1 acc by now. Save model
09/18 07:06:21 PM | Start to train weights for epoch 17
09/18 07:06:47 PM | Train: [ 18/180] Step 050/1249 Loss 1.216 Prec@(1,3) (66.9%, 97.6%), ce_loss 1.242, lat_loss 6.657
09/18 07:07:10 PM | Train: [ 18/180] Step 100/1249 Loss 1.217 Prec@(1,3) (67.5%, 97.5%), ce_loss 1.241, lat_loss 6.657
09/18 07:07:35 PM | Train: [ 18/180] Step 150/1249 Loss 1.245 Prec@(1,3) (66.7%, 97.2%), ce_loss 1.241, lat_loss 6.657
09/18 07:07:59 PM | Train: [ 18/180] Step 200/1249 Loss 1.251 Prec@(1,3) (66.8%, 97.2%), ce_loss 1.240, lat_loss 6.657
09/18 07:08:24 PM | Train: [ 18/180] Step 250/1249 Loss 1.226 Prec@(1,3) (67.4%, 97.3%), ce_loss 1.239, lat_loss 6.657
09/18 07:08:49 PM | Train: [ 18/180] Step 300/1249 Loss 1.227 Prec@(1,3) (67.4%, 97.3%), ce_loss 1.239, lat_loss 6.657
09/18 07:09:14 PM | Train: [ 18/180] Step 350/1249 Loss 1.226 Prec@(1,3) (67.3%, 97.2%), ce_loss 1.238, lat_loss 6.657
09/18 07:09:39 PM | Train: [ 18/180] Step 400/1249 Loss 1.221 Prec@(1,3) (67.6%, 97.2%), ce_loss 1.238, lat_loss 6.657
09/18 07:10:04 PM | Train: [ 18/180] Step 450/1249 Loss 1.217 Prec@(1,3) (67.7%, 97.2%), ce_loss 1.237, lat_loss 6.657
09/18 07:10:28 PM | Train: [ 18/180] Step 500/1249 Loss 1.215 Prec@(1,3) (67.8%, 97.2%), ce_loss 1.236, lat_loss 6.657
09/18 07:10:51 PM | Train: [ 18/180] Step 550/1249 Loss 1.216 Prec@(1,3) (67.6%, 97.2%), ce_loss 1.236, lat_loss 6.657
09/18 07:11:16 PM | Train: [ 18/180] Step 600/1249 Loss 1.220 Prec@(1,3) (67.6%, 97.2%), ce_loss 1.235, lat_loss 6.657
09/18 07:11:41 PM | Train: [ 18/180] Step 650/1249 Loss 1.217 Prec@(1,3) (67.6%, 97.3%), ce_loss 1.234, lat_loss 6.657
09/18 07:12:05 PM | Train: [ 18/180] Step 700/1249 Loss 1.222 Prec@(1,3) (67.6%, 97.2%), ce_loss 1.234, lat_loss 6.657
09/18 07:12:30 PM | Train: [ 18/180] Step 750/1249 Loss 1.221 Prec@(1,3) (67.6%, 97.2%), ce_loss 1.233, lat_loss 6.657
09/18 07:12:55 PM | Train: [ 18/180] Step 800/1249 Loss 1.215 Prec@(1,3) (67.8%, 97.3%), ce_loss 1.233, lat_loss 6.657
09/18 07:13:20 PM | Train: [ 18/180] Step 850/1249 Loss 1.212 Prec@(1,3) (67.8%, 97.3%), ce_loss 1.232, lat_loss 6.657
09/18 07:13:44 PM | Train: [ 18/180] Step 900/1249 Loss 1.210 Prec@(1,3) (67.9%, 97.3%), ce_loss 1.231, lat_loss 6.657
09/18 07:14:09 PM | Train: [ 18/180] Step 950/1249 Loss 1.209 Prec@(1,3) (67.9%, 97.3%), ce_loss 1.231, lat_loss 6.657
09/18 07:14:33 PM | Train: [ 18/180] Step 1000/1249 Loss 1.206 Prec@(1,3) (68.0%, 97.4%), ce_loss 1.230, lat_loss 6.657
09/18 07:14:58 PM | Train: [ 18/180] Step 1050/1249 Loss 1.209 Prec@(1,3) (67.9%, 97.4%), ce_loss 1.229, lat_loss 6.657
09/18 07:15:19 PM | Train: [ 18/180] Step 1100/1249 Loss 1.208 Prec@(1,3) (67.9%, 97.4%), ce_loss 1.229, lat_loss 6.657
09/18 07:15:39 PM | Train: [ 18/180] Step 1150/1249 Loss 1.209 Prec@(1,3) (67.9%, 97.4%), ce_loss 1.228, lat_loss 6.657
09/18 07:16:01 PM | Train: [ 18/180] Step 1200/1249 Loss 1.206 Prec@(1,3) (68.0%, 97.4%), ce_loss 1.227, lat_loss 6.657
09/18 07:16:25 PM | Train: [ 18/180] Step 1249/1249 Loss 1.205 Prec@(1,3) (68.1%, 97.4%), ce_loss 1.227, lat_loss 6.657
09/18 07:16:26 PM | _w_step_train: [ 18/180] Final Prec@1 68.0850% Time 604.38
09/18 07:16:26 PM | Start to train theta for epoch 17
09/18 07:16:46 PM | Train: [ 18/180] Step 050/312 Loss 1.186 Prec@(1,3) (69.4%, 98.2%), ce_loss 1.226, lat_loss 6.657
09/18 07:17:03 PM | Train: [ 18/180] Step 100/312 Loss 1.179 Prec@(1,3) (69.8%, 97.7%), ce_loss 1.226, lat_loss 6.657
09/18 07:17:22 PM | Train: [ 18/180] Step 150/312 Loss 1.224 Prec@(1,3) (68.0%, 97.6%), ce_loss 1.225, lat_loss 6.657
09/18 07:17:42 PM | Train: [ 18/180] Step 200/312 Loss 1.228 Prec@(1,3) (68.0%, 97.4%), ce_loss 1.225, lat_loss 6.657
09/18 07:18:02 PM | Train: [ 18/180] Step 250/312 Loss 1.226 Prec@(1,3) (67.9%, 97.3%), ce_loss 1.224, lat_loss 6.657
09/18 07:18:22 PM | Train: [ 18/180] Step 300/312 Loss 1.229 Prec@(1,3) (67.9%, 97.2%), ce_loss 1.224, lat_loss 6.657
09/18 07:18:27 PM | Train: [ 18/180] Step 312/312 Loss 1.228 Prec@(1,3) (67.9%, 97.2%), ce_loss 1.223, lat_loss 6.657
09/18 07:18:27 PM | _theta_step_train: [ 18/180] Final Prec@1 67.9100% Time 121.52
09/18 07:18:32 PM | Valid: [ 18/180] Step 050/312 Loss 1.112 Prec@(1,3) (70.6%, 98.1%), ce_loss 1.223, lat_loss 6.657
09/18 07:18:37 PM | Valid: [ 18/180] Step 100/312 Loss 1.145 Prec@(1,3) (70.5%, 97.9%), ce_loss 1.222, lat_loss 6.657
09/18 07:18:42 PM | Valid: [ 18/180] Step 150/312 Loss 1.159 Prec@(1,3) (69.9%, 97.7%), ce_loss 1.221, lat_loss 6.657
09/18 07:18:46 PM | Valid: [ 18/180] Step 200/312 Loss 1.165 Prec@(1,3) (69.3%, 97.7%), ce_loss 1.221, lat_loss 6.657
09/18 07:18:51 PM | Valid: [ 18/180] Step 250/312 Loss 1.173 Prec@(1,3) (69.3%, 97.5%), ce_loss 1.220, lat_loss 6.657
09/18 07:18:56 PM | Valid: [ 18/180] Step 300/312 Loss 1.172 Prec@(1,3) (69.2%, 97.5%), ce_loss 1.220, lat_loss 6.657
09/18 07:18:57 PM | Valid: [ 18/180] Step 312/312 Loss 1.173 Prec@(1,3) (69.2%, 97.5%), ce_loss 1.219, lat_loss 6.657
09/18 07:18:57 PM | val: [ 18/180] Final Prec@1 69.1800% Time 29.87
09/18 07:18:57 PM | Best top1 acc by now. Save model
09/18 07:18:57 PM | Start to train weights for epoch 18
09/18 07:19:23 PM | Train: [ 19/180] Step 050/1249 Loss 1.111 Prec@(1,3) (70.5%, 98.0%), ce_loss 1.219, lat_loss 6.657
09/18 07:19:47 PM | Train: [ 19/180] Step 100/1249 Loss 1.148 Prec@(1,3) (69.8%, 98.0%), ce_loss 1.218, lat_loss 6.657
09/18 07:20:11 PM | Train: [ 19/180] Step 150/1249 Loss 1.152 Prec@(1,3) (69.7%, 97.9%), ce_loss 1.218, lat_loss 6.657
09/18 07:20:36 PM | Train: [ 19/180] Step 200/1249 Loss 1.158 Prec@(1,3) (69.9%, 97.7%), ce_loss 1.217, lat_loss 6.657
09/18 07:21:00 PM | Train: [ 19/180] Step 250/1249 Loss 1.161 Prec@(1,3) (69.7%, 97.7%), ce_loss 1.216, lat_loss 6.657
09/18 07:21:25 PM | Train: [ 19/180] Step 300/1249 Loss 1.169 Prec@(1,3) (69.4%, 97.6%), ce_loss 1.216, lat_loss 6.657
09/18 07:21:49 PM | Train: [ 19/180] Step 350/1249 Loss 1.171 Prec@(1,3) (69.3%, 97.6%), ce_loss 1.215, lat_loss 6.657
09/18 07:22:10 PM | Train: [ 19/180] Step 400/1249 Loss 1.171 Prec@(1,3) (69.1%, 97.6%), ce_loss 1.215, lat_loss 6.657
09/18 07:22:34 PM | Train: [ 19/180] Step 450/1249 Loss 1.169 Prec@(1,3) (69.1%, 97.6%), ce_loss 1.214, lat_loss 6.657
09/18 07:22:58 PM | Train: [ 19/180] Step 500/1249 Loss 1.172 Prec@(1,3) (69.1%, 97.6%), ce_loss 1.213, lat_loss 6.657
09/18 07:23:23 PM | Train: [ 19/180] Step 550/1249 Loss 1.170 Prec@(1,3) (69.2%, 97.6%), ce_loss 1.213, lat_loss 6.657
09/18 07:23:47 PM | Train: [ 19/180] Step 600/1249 Loss 1.173 Prec@(1,3) (69.2%, 97.5%), ce_loss 1.212, lat_loss 6.657
09/18 07:24:11 PM | Train: [ 19/180] Step 650/1249 Loss 1.170 Prec@(1,3) (69.3%, 97.5%), ce_loss 1.212, lat_loss 6.657
09/18 07:24:36 PM | Train: [ 19/180] Step 700/1249 Loss 1.169 Prec@(1,3) (69.3%, 97.5%), ce_loss 1.211, lat_loss 6.657
09/18 07:25:01 PM | Train: [ 19/180] Step 750/1249 Loss 1.168 Prec@(1,3) (69.2%, 97.5%), ce_loss 1.210, lat_loss 6.657
09/18 07:25:25 PM | Train: [ 19/180] Step 800/1249 Loss 1.168 Prec@(1,3) (69.2%, 97.5%), ce_loss 1.210, lat_loss 6.657
09/18 07:25:46 PM | Train: [ 19/180] Step 850/1249 Loss 1.166 Prec@(1,3) (69.3%, 97.5%), ce_loss 1.209, lat_loss 6.657
09/18 07:26:08 PM | Train: [ 19/180] Step 900/1249 Loss 1.168 Prec@(1,3) (69.3%, 97.5%), ce_loss 1.209, lat_loss 6.657
09/18 07:26:30 PM | Train: [ 19/180] Step 950/1249 Loss 1.164 Prec@(1,3) (69.3%, 97.5%), ce_loss 1.208, lat_loss 6.657
09/18 07:26:51 PM | Train: [ 19/180] Step 1000/1249 Loss 1.163 Prec@(1,3) (69.4%, 97.5%), ce_loss 1.207, lat_loss 6.657
09/18 07:27:15 PM | Train: [ 19/180] Step 1050/1249 Loss 1.163 Prec@(1,3) (69.3%, 97.5%), ce_loss 1.207, lat_loss 6.657
09/18 07:27:40 PM | Train: [ 19/180] Step 1100/1249 Loss 1.162 Prec@(1,3) (69.3%, 97.5%), ce_loss 1.206, lat_loss 6.657
09/18 07:28:04 PM | Train: [ 19/180] Step 1150/1249 Loss 1.162 Prec@(1,3) (69.3%, 97.5%), ce_loss 1.206, lat_loss 6.657
09/18 07:28:26 PM | Train: [ 19/180] Step 1200/1249 Loss 1.162 Prec@(1,3) (69.3%, 97.5%), ce_loss 1.205, lat_loss 6.657
09/18 07:28:50 PM | Train: [ 19/180] Step 1249/1249 Loss 1.164 Prec@(1,3) (69.3%, 97.5%), ce_loss 1.204, lat_loss 6.657
09/18 07:28:51 PM | _w_step_train: [ 19/180] Final Prec@1 69.2775% Time 593.32
09/18 07:28:51 PM | Start to train theta for epoch 18
09/18 07:29:10 PM | Train: [ 19/180] Step 050/312 Loss 1.205 Prec@(1,3) (67.9%, 97.4%), ce_loss 1.204, lat_loss 6.657
09/18 07:29:28 PM | Train: [ 19/180] Step 100/312 Loss 1.186 Prec@(1,3) (69.1%, 97.5%), ce_loss 1.203, lat_loss 6.657
09/18 07:29:45 PM | Train: [ 19/180] Step 150/312 Loss 1.187 Prec@(1,3) (68.8%, 97.5%), ce_loss 1.203, lat_loss 6.657
09/18 07:30:03 PM | Train: [ 19/180] Step 200/312 Loss 1.197 Prec@(1,3) (68.6%, 97.4%), ce_loss 1.202, lat_loss 6.657
09/18 07:30:23 PM | Train: [ 19/180] Step 250/312 Loss 1.200 Prec@(1,3) (68.6%, 97.4%), ce_loss 1.202, lat_loss 6.657
09/18 07:30:44 PM | Train: [ 19/180] Step 300/312 Loss 1.192 Prec@(1,3) (68.8%, 97.4%), ce_loss 1.201, lat_loss 6.657
09/18 07:30:49 PM | Train: [ 19/180] Step 312/312 Loss 1.191 Prec@(1,3) (68.8%, 97.4%), ce_loss 1.201, lat_loss 6.657
09/18 07:30:49 PM | _theta_step_train: [ 19/180] Final Prec@1 68.8300% Time 118.86
09/18 07:30:55 PM | Valid: [ 19/180] Step 050/312 Loss 1.143 Prec@(1,3) (70.2%, 98.2%), ce_loss 1.201, lat_loss 6.657
09/18 07:30:59 PM | Valid: [ 19/180] Step 100/312 Loss 1.182 Prec@(1,3) (68.7%, 98.1%), ce_loss 1.200, lat_loss 6.657
09/18 07:31:04 PM | Valid: [ 19/180] Step 150/312 Loss 1.175 Prec@(1,3) (69.3%, 97.7%), ce_loss 1.199, lat_loss 6.657
09/18 07:31:08 PM | Valid: [ 19/180] Step 200/312 Loss 1.182 Prec@(1,3) (68.9%, 97.6%), ce_loss 1.199, lat_loss 6.657
09/18 07:31:13 PM | Valid: [ 19/180] Step 250/312 Loss 1.189 Prec@(1,3) (68.8%, 97.5%), ce_loss 1.199, lat_loss 6.657
09/18 07:31:18 PM | Valid: [ 19/180] Step 300/312 Loss 1.183 Prec@(1,3) (68.9%, 97.5%), ce_loss 1.198, lat_loss 6.657
09/18 07:31:19 PM | Valid: [ 19/180] Step 312/312 Loss 1.183 Prec@(1,3) (69.0%, 97.5%), ce_loss 1.198, lat_loss 6.657
09/18 07:31:19 PM | val: [ 19/180] Final Prec@1 69.0100% Time 29.40
09/18 07:31:19 PM | Start to train weights for epoch 19
09/18 07:31:43 PM | Train: [ 20/180] Step 050/1249 Loss 1.111 Prec@(1,3) (70.5%, 98.2%), ce_loss 1.197, lat_loss 6.657
09/18 07:32:08 PM | Train: [ 20/180] Step 100/1249 Loss 1.122 Prec@(1,3) (70.7%, 98.1%), ce_loss 1.197, lat_loss 6.657
09/18 07:32:33 PM | Train: [ 20/180] Step 150/1249 Loss 1.126 Prec@(1,3) (70.9%, 98.0%), ce_loss 1.196, lat_loss 6.657
09/18 07:32:57 PM | Train: [ 20/180] Step 200/1249 Loss 1.130 Prec@(1,3) (70.7%, 97.9%), ce_loss 1.195, lat_loss 6.657
09/18 07:33:22 PM | Train: [ 20/180] Step 250/1249 Loss 1.126 Prec@(1,3) (70.6%, 97.9%), ce_loss 1.195, lat_loss 6.657
09/18 07:33:47 PM | Train: [ 20/180] Step 300/1249 Loss 1.139 Prec@(1,3) (70.2%, 97.9%), ce_loss 1.194, lat_loss 6.657
09/18 07:34:12 PM | Train: [ 20/180] Step 350/1249 Loss 1.141 Prec@(1,3) (70.1%, 97.9%), ce_loss 1.194, lat_loss 6.657
09/18 07:34:37 PM | Train: [ 20/180] Step 400/1249 Loss 1.143 Prec@(1,3) (69.9%, 97.8%), ce_loss 1.193, lat_loss 6.657
09/18 07:35:02 PM | Train: [ 20/180] Step 450/1249 Loss 1.146 Prec@(1,3) (69.8%, 97.8%), ce_loss 1.193, lat_loss 6.657
09/18 07:35:26 PM | Train: [ 20/180] Step 500/1249 Loss 1.149 Prec@(1,3) (69.7%, 97.8%), ce_loss 1.192, lat_loss 6.657
09/18 07:35:49 PM | Train: [ 20/180] Step 550/1249 Loss 1.151 Prec@(1,3) (69.6%, 97.7%), ce_loss 1.192, lat_loss 6.657
09/18 07:36:12 PM | Train: [ 20/180] Step 600/1249 Loss 1.148 Prec@(1,3) (69.7%, 97.7%), ce_loss 1.191, lat_loss 6.657
09/18 07:36:35 PM | Train: [ 20/180] Step 650/1249 Loss 1.150 Prec@(1,3) (69.7%, 97.7%), ce_loss 1.191, lat_loss 6.657
09/18 07:37:00 PM | Train: [ 20/180] Step 700/1249 Loss 1.152 Prec@(1,3) (69.7%, 97.6%), ce_loss 1.190, lat_loss 6.657
09/18 07:37:24 PM | Train: [ 20/180] Step 750/1249 Loss 1.155 Prec@(1,3) (69.6%, 97.6%), ce_loss 1.190, lat_loss 6.657
09/18 07:37:49 PM | Train: [ 20/180] Step 800/1249 Loss 1.153 Prec@(1,3) (69.7%, 97.6%), ce_loss 1.189, lat_loss 6.657
09/18 07:38:13 PM | Train: [ 20/180] Step 850/1249 Loss 1.149 Prec@(1,3) (69.7%, 97.6%), ce_loss 1.188, lat_loss 6.657
09/18 07:38:38 PM | Train: [ 20/180] Step 900/1249 Loss 1.149 Prec@(1,3) (69.7%, 97.7%), ce_loss 1.188, lat_loss 6.657
09/18 07:39:03 PM | Train: [ 20/180] Step 950/1249 Loss 1.152 Prec@(1,3) (69.6%, 97.7%), ce_loss 1.187, lat_loss 6.657
09/18 07:39:28 PM | Train: [ 20/180] Step 1000/1249 Loss 1.152 Prec@(1,3) (69.6%, 97.7%), ce_loss 1.187, lat_loss 6.657
09/18 07:39:53 PM | Train: [ 20/180] Step 1050/1249 Loss 1.149 Prec@(1,3) (69.7%, 97.7%), ce_loss 1.186, lat_loss 6.657
09/18 07:40:17 PM | Train: [ 20/180] Step 1100/1249 Loss 1.147 Prec@(1,3) (69.8%, 97.7%), ce_loss 1.186, lat_loss 6.657
09/18 07:40:41 PM | Train: [ 20/180] Step 1150/1249 Loss 1.147 Prec@(1,3) (69.7%, 97.7%), ce_loss 1.185, lat_loss 6.657
09/18 07:41:04 PM | Train: [ 20/180] Step 1200/1249 Loss 1.148 Prec@(1,3) (69.7%, 97.7%), ce_loss 1.185, lat_loss 6.657
09/18 07:41:28 PM | Train: [ 20/180] Step 1249/1249 Loss 1.150 Prec@(1,3) (69.7%, 97.7%), ce_loss 1.184, lat_loss 6.657
09/18 07:41:28 PM | _w_step_train: [ 20/180] Final Prec@1 69.6700% Time 609.60
09/18 07:41:28 PM | Start to train theta for epoch 19
09/18 07:41:48 PM | Train: [ 20/180] Step 050/312 Loss 1.177 Prec@(1,3) (69.9%, 97.4%), ce_loss 1.184, lat_loss 6.657
09/18 07:42:07 PM | Train: [ 20/180] Step 100/312 Loss 1.188 Prec@(1,3) (69.0%, 97.2%), ce_loss 1.183, lat_loss 6.657
09/18 07:42:27 PM | Train: [ 20/180] Step 150/312 Loss 1.194 Prec@(1,3) (68.8%, 97.4%), ce_loss 1.183, lat_loss 6.657
09/18 07:42:47 PM | Train: [ 20/180] Step 200/312 Loss 1.179 Prec@(1,3) (69.2%, 97.5%), ce_loss 1.182, lat_loss 6.657
09/18 07:43:08 PM | Train: [ 20/180] Step 250/312 Loss 1.187 Prec@(1,3) (68.9%, 97.4%), ce_loss 1.182, lat_loss 6.657
09/18 07:43:29 PM | Train: [ 20/180] Step 300/312 Loss 1.182 Prec@(1,3) (68.7%, 97.3%), ce_loss 1.181, lat_loss 6.657
09/18 07:43:34 PM | Train: [ 20/180] Step 312/312 Loss 1.176 Prec@(1,3) (68.8%, 97.4%), ce_loss 1.181, lat_loss 6.657
09/18 07:43:34 PM | _theta_step_train: [ 20/180] Final Prec@1 68.8300% Time 125.62
09/18 07:43:39 PM | Valid: [ 20/180] Step 050/312 Loss 1.157 Prec@(1,3) (68.7%, 98.1%), ce_loss 1.181, lat_loss 6.657
09/18 07:43:44 PM | Valid: [ 20/180] Step 100/312 Loss 1.191 Prec@(1,3) (68.8%, 97.6%), ce_loss 1.180, lat_loss 6.657
09/18 07:43:49 PM | Valid: [ 20/180] Step 150/312 Loss 1.173 Prec@(1,3) (69.4%, 97.6%), ce_loss 1.180, lat_loss 6.657
09/18 07:43:53 PM | Valid: [ 20/180] Step 200/312 Loss 1.175 Prec@(1,3) (69.2%, 97.6%), ce_loss 1.179, lat_loss 6.657
09/18 07:43:58 PM | Valid: [ 20/180] Step 250/312 Loss 1.172 Prec@(1,3) (69.2%, 97.6%), ce_loss 1.179, lat_loss 6.657
09/18 07:44:03 PM | Valid: [ 20/180] Step 300/312 Loss 1.176 Prec@(1,3) (69.2%, 97.6%), ce_loss 1.178, lat_loss 6.657
09/18 07:44:04 PM | Valid: [ 20/180] Step 312/312 Loss 1.173 Prec@(1,3) (69.3%, 97.6%), ce_loss 1.178, lat_loss 6.657
09/18 07:44:04 PM | val: [ 20/180] Final Prec@1 69.2600% Time 29.61
09/18 07:44:04 PM | Best top1 acc by now. Save model
09/18 07:44:04 PM | Start to train weights for epoch 20
09/18 07:44:29 PM | Train: [ 21/180] Step 050/1249 Loss 1.116 Prec@(1,3) (70.7%, 97.9%), ce_loss 1.178, lat_loss 6.657
09/18 07:44:52 PM | Train: [ 21/180] Step 100/1249 Loss 1.147 Prec@(1,3) (70.1%, 97.5%), ce_loss 1.177, lat_loss 6.657
09/18 07:45:16 PM | Train: [ 21/180] Step 150/1249 Loss 1.123 Prec@(1,3) (70.6%, 97.7%), ce_loss 1.177, lat_loss 6.657
09/18 07:45:40 PM | Train: [ 21/180] Step 200/1249 Loss 1.136 Prec@(1,3) (70.3%, 97.7%), ce_loss 1.176, lat_loss 6.657
09/18 07:46:03 PM | Train: [ 21/180] Step 250/1249 Loss 1.133 Prec@(1,3) (70.4%, 97.8%), ce_loss 1.176, lat_loss 6.657
09/18 07:46:24 PM | Train: [ 21/180] Step 300/1249 Loss 1.127 Prec@(1,3) (70.3%, 97.8%), ce_loss 1.175, lat_loss 6.657
09/18 07:46:48 PM | Train: [ 21/180] Step 350/1249 Loss 1.121 Prec@(1,3) (70.5%, 97.8%), ce_loss 1.174, lat_loss 6.657
09/18 07:47:10 PM | Train: [ 21/180] Step 400/1249 Loss 1.120 Prec@(1,3) (70.7%, 97.8%), ce_loss 1.174, lat_loss 6.657
09/18 07:47:32 PM | Train: [ 21/180] Step 450/1249 Loss 1.122 Prec@(1,3) (70.6%, 97.7%), ce_loss 1.173, lat_loss 6.657
09/18 07:47:54 PM | Train: [ 21/180] Step 500/1249 Loss 1.122 Prec@(1,3) (70.5%, 97.7%), ce_loss 1.173, lat_loss 6.657
09/18 07:48:16 PM | Train: [ 21/180] Step 550/1249 Loss 1.123 Prec@(1,3) (70.5%, 97.7%), ce_loss 1.172, lat_loss 6.657
09/18 07:48:39 PM | Train: [ 21/180] Step 600/1249 Loss 1.129 Prec@(1,3) (70.2%, 97.8%), ce_loss 1.172, lat_loss 6.657
09/18 07:49:03 PM | Train: [ 21/180] Step 650/1249 Loss 1.129 Prec@(1,3) (70.4%, 97.7%), ce_loss 1.171, lat_loss 6.657
09/18 07:49:26 PM | Train: [ 21/180] Step 700/1249 Loss 1.129 Prec@(1,3) (70.3%, 97.7%), ce_loss 1.171, lat_loss 6.657
09/18 07:49:50 PM | Train: [ 21/180] Step 750/1249 Loss 1.134 Prec@(1,3) (70.2%, 97.7%), ce_loss 1.170, lat_loss 6.657
09/18 07:50:13 PM | Train: [ 21/180] Step 800/1249 Loss 1.132 Prec@(1,3) (70.2%, 97.7%), ce_loss 1.170, lat_loss 6.657
09/18 07:50:37 PM | Train: [ 21/180] Step 850/1249 Loss 1.134 Prec@(1,3) (70.2%, 97.7%), ce_loss 1.169, lat_loss 6.657
09/18 07:51:00 PM | Train: [ 21/180] Step 900/1249 Loss 1.132 Prec@(1,3) (70.2%, 97.8%), ce_loss 1.169, lat_loss 6.657
09/18 07:51:23 PM | Train: [ 21/180] Step 950/1249 Loss 1.130 Prec@(1,3) (70.2%, 97.8%), ce_loss 1.168, lat_loss 6.657
09/18 07:51:47 PM | Train: [ 21/180] Step 1000/1249 Loss 1.131 Prec@(1,3) (70.2%, 97.8%), ce_loss 1.168, lat_loss 6.657
09/18 07:52:10 PM | Train: [ 21/180] Step 1050/1249 Loss 1.128 Prec@(1,3) (70.3%, 97.8%), ce_loss 1.167, lat_loss 6.657
09/18 07:52:34 PM | Train: [ 21/180] Step 1100/1249 Loss 1.128 Prec@(1,3) (70.3%, 97.8%), ce_loss 1.167, lat_loss 6.657
09/18 07:52:57 PM | Train: [ 21/180] Step 1150/1249 Loss 1.130 Prec@(1,3) (70.2%, 97.7%), ce_loss 1.166, lat_loss 6.657
09/18 07:53:21 PM | Train: [ 21/180] Step 1200/1249 Loss 1.131 Prec@(1,3) (70.2%, 97.7%), ce_loss 1.166, lat_loss 6.657
09/18 07:53:45 PM | Train: [ 21/180] Step 1249/1249 Loss 1.129 Prec@(1,3) (70.2%, 97.7%), ce_loss 1.165, lat_loss 6.657
09/18 07:53:45 PM | _w_step_train: [ 21/180] Final Prec@1 70.1950% Time 581.06
09/18 07:53:45 PM | Start to train theta for epoch 20
09/18 07:53:58 PM | Train: [ 21/180] Step 050/312 Loss 1.118 Prec@(1,3) (72.0%, 97.4%), ce_loss 1.165, lat_loss 6.657
09/18 07:54:10 PM | Train: [ 21/180] Step 100/312 Loss 1.141 Prec@(1,3) (70.3%, 97.6%), ce_loss 1.165, lat_loss 6.657
09/18 07:54:22 PM | Train: [ 21/180] Step 150/312 Loss 1.110 Prec@(1,3) (71.3%, 97.8%), ce_loss 1.164, lat_loss 6.657
09/18 07:54:35 PM | Train: [ 21/180] Step 200/312 Loss 1.124 Prec@(1,3) (71.2%, 97.5%), ce_loss 1.163, lat_loss 6.657
09/18 07:54:47 PM | Train: [ 21/180] Step 250/312 Loss 1.130 Prec@(1,3) (71.0%, 97.5%), ce_loss 1.163, lat_loss 6.657
09/18 07:54:59 PM | Train: [ 21/180] Step 300/312 Loss 1.139 Prec@(1,3) (70.8%, 97.4%), ce_loss 1.163, lat_loss 6.657
09/18 07:55:02 PM | Train: [ 21/180] Step 312/312 Loss 1.143 Prec@(1,3) (70.6%, 97.4%), ce_loss 1.163, lat_loss 6.657
09/18 07:55:02 PM | _theta_step_train: [ 21/180] Final Prec@1 70.6000% Time 77.21
09/18 07:55:07 PM | Valid: [ 21/180] Step 050/312 Loss 1.083 Prec@(1,3) (71.1%, 98.4%), ce_loss 1.162, lat_loss 6.657
09/18 07:55:12 PM | Valid: [ 21/180] Step 100/312 Loss 1.106 Prec@(1,3) (71.0%, 97.9%), ce_loss 1.162, lat_loss 6.657
09/18 07:55:17 PM | Valid: [ 21/180] Step 150/312 Loss 1.112 Prec@(1,3) (71.4%, 97.6%), ce_loss 1.161, lat_loss 6.657
09/18 07:55:21 PM | Valid: [ 21/180] Step 200/312 Loss 1.114 Prec@(1,3) (71.0%, 97.7%), ce_loss 1.161, lat_loss 6.657
09/18 07:55:26 PM | Valid: [ 21/180] Step 250/312 Loss 1.108 Prec@(1,3) (71.3%, 97.8%), ce_loss 1.160, lat_loss 6.657
09/18 07:55:31 PM | Valid: [ 21/180] Step 300/312 Loss 1.106 Prec@(1,3) (71.5%, 97.9%), ce_loss 1.160, lat_loss 6.657
09/18 07:55:32 PM | Valid: [ 21/180] Step 312/312 Loss 1.112 Prec@(1,3) (71.4%, 97.9%), ce_loss 1.159, lat_loss 6.657
09/18 07:55:32 PM | val: [ 21/180] Final Prec@1 71.3700% Time 29.48
09/18 07:55:32 PM | Best top1 acc by now. Save model
09/18 07:55:32 PM | Start to train weights for epoch 21
09/18 07:55:59 PM | Train: [ 22/180] Step 050/1249 Loss 1.132 Prec@(1,3) (70.4%, 97.5%), ce_loss 1.159, lat_loss 6.657
09/18 07:56:24 PM | Train: [ 22/180] Step 100/1249 Loss 1.116 Prec@(1,3) (70.6%, 97.8%), ce_loss 1.158, lat_loss 6.657
09/18 07:56:49 PM | Train: [ 22/180] Step 150/1249 Loss 1.088 Prec@(1,3) (71.4%, 98.0%), ce_loss 1.158, lat_loss 6.657
09/18 07:57:13 PM | Train: [ 22/180] Step 200/1249 Loss 1.081 Prec@(1,3) (71.6%, 98.2%), ce_loss 1.157, lat_loss 6.657
09/18 07:57:38 PM | Train: [ 22/180] Step 250/1249 Loss 1.083 Prec@(1,3) (71.5%, 98.1%), ce_loss 1.157, lat_loss 6.657
09/18 07:58:03 PM | Train: [ 22/180] Step 300/1249 Loss 1.095 Prec@(1,3) (71.2%, 98.0%), ce_loss 1.156, lat_loss 6.657
09/18 07:58:28 PM | Train: [ 22/180] Step 350/1249 Loss 1.100 Prec@(1,3) (71.1%, 98.0%), ce_loss 1.156, lat_loss 6.657
09/18 07:58:52 PM | Train: [ 22/180] Step 400/1249 Loss 1.101 Prec@(1,3) (71.1%, 98.0%), ce_loss 1.155, lat_loss 6.657
09/18 07:59:08 PM | Train: [ 22/180] Step 450/1249 Loss 1.106 Prec@(1,3) (71.0%, 98.0%), ce_loss 1.155, lat_loss 6.657
09/18 07:59:24 PM | Train: [ 22/180] Step 500/1249 Loss 1.105 Prec@(1,3) (71.0%, 98.0%), ce_loss 1.155, lat_loss 6.657
09/18 07:59:40 PM | Train: [ 22/180] Step 550/1249 Loss 1.107 Prec@(1,3) (70.9%, 98.0%), ce_loss 1.154, lat_loss 6.657
09/18 08:00:00 PM | Train: [ 22/180] Step 600/1249 Loss 1.105 Prec@(1,3) (71.0%, 98.0%), ce_loss 1.154, lat_loss 6.657
09/18 08:00:17 PM | Train: [ 22/180] Step 650/1249 Loss 1.110 Prec@(1,3) (70.9%, 98.0%), ce_loss 1.153, lat_loss 6.657
09/18 08:00:32 PM | Train: [ 22/180] Step 700/1249 Loss 1.110 Prec@(1,3) (70.9%, 98.0%), ce_loss 1.153, lat_loss 6.657
09/18 08:00:49 PM | Train: [ 22/180] Step 750/1249 Loss 1.112 Prec@(1,3) (70.9%, 98.0%), ce_loss 1.152, lat_loss 6.657
09/18 08:01:09 PM | Train: [ 22/180] Step 800/1249 Loss 1.111 Prec@(1,3) (70.9%, 98.0%), ce_loss 1.152, lat_loss 6.657
09/18 08:01:34 PM | Train: [ 22/180] Step 850/1249 Loss 1.112 Prec@(1,3) (70.9%, 98.0%), ce_loss 1.151, lat_loss 6.657
09/18 08:01:58 PM | Train: [ 22/180] Step 900/1249 Loss 1.109 Prec@(1,3) (71.0%, 98.0%), ce_loss 1.151, lat_loss 6.657
09/18 08:02:23 PM | Train: [ 22/180] Step 950/1249 Loss 1.109 Prec@(1,3) (71.0%, 98.0%), ce_loss 1.150, lat_loss 6.657
09/18 08:02:47 PM | Train: [ 22/180] Step 1000/1249 Loss 1.111 Prec@(1,3) (71.0%, 98.0%), ce_loss 1.150, lat_loss 6.657
09/18 08:03:12 PM | Train: [ 22/180] Step 1050/1249 Loss 1.112 Prec@(1,3) (70.9%, 98.0%), ce_loss 1.149, lat_loss 6.657
09/18 08:03:37 PM | Train: [ 22/180] Step 1100/1249 Loss 1.112 Prec@(1,3) (70.8%, 98.0%), ce_loss 1.149, lat_loss 6.657
09/18 08:04:02 PM | Train: [ 22/180] Step 1150/1249 Loss 1.112 Prec@(1,3) (70.8%, 98.0%), ce_loss 1.149, lat_loss 6.657
09/18 08:04:27 PM | Train: [ 22/180] Step 1200/1249 Loss 1.111 Prec@(1,3) (70.8%, 98.0%), ce_loss 1.148, lat_loss 6.657
09/18 08:04:51 PM | Train: [ 22/180] Step 1249/1249 Loss 1.110 Prec@(1,3) (70.9%, 97.9%), ce_loss 1.148, lat_loss 6.657
09/18 08:04:51 PM | _w_step_train: [ 22/180] Final Prec@1 70.9200% Time 558.48
09/18 08:04:51 PM | Start to train theta for epoch 21
09/18 08:05:12 PM | Train: [ 22/180] Step 050/312 Loss 1.149 Prec@(1,3) (70.2%, 97.8%), ce_loss 1.147, lat_loss 6.657
09/18 08:05:32 PM | Train: [ 22/180] Step 100/312 Loss 1.163 Prec@(1,3) (70.0%, 97.8%), ce_loss 1.147, lat_loss 6.657
09/18 08:05:52 PM | Train: [ 22/180] Step 150/312 Loss 1.152 Prec@(1,3) (70.3%, 97.6%), ce_loss 1.146, lat_loss 6.657
09/18 08:06:12 PM | Train: [ 22/180] Step 200/312 Loss 1.149 Prec@(1,3) (70.5%, 97.4%), ce_loss 1.146, lat_loss 6.657
09/18 08:06:32 PM | Train: [ 22/180] Step 250/312 Loss 1.147 Prec@(1,3) (70.5%, 97.4%), ce_loss 1.146, lat_loss 6.657
09/18 08:06:50 PM | Train: [ 22/180] Step 300/312 Loss 1.143 Prec@(1,3) (70.6%, 97.5%), ce_loss 1.145, lat_loss 6.657
09/18 08:06:55 PM | Train: [ 22/180] Step 312/312 Loss 1.141 Prec@(1,3) (70.7%, 97.5%), ce_loss 1.145, lat_loss 6.657
09/18 08:06:55 PM | _theta_step_train: [ 22/180] Final Prec@1 70.6800% Time 124.58
09/18 08:07:01 PM | Valid: [ 22/180] Step 050/312 Loss 1.105 Prec@(1,3) (71.9%, 98.1%), ce_loss 1.144, lat_loss 6.657
09/18 08:07:05 PM | Valid: [ 22/180] Step 100/312 Loss 1.138 Prec@(1,3) (71.1%, 97.9%), ce_loss 1.144, lat_loss 6.657
09/18 08:07:10 PM | Valid: [ 22/180] Step 150/312 Loss 1.142 Prec@(1,3) (71.0%, 97.6%), ce_loss 1.144, lat_loss 6.657
09/18 08:07:15 PM | Valid: [ 22/180] Step 200/312 Loss 1.158 Prec@(1,3) (70.0%, 97.7%), ce_loss 1.143, lat_loss 6.657
09/18 08:07:19 PM | Valid: [ 22/180] Step 250/312 Loss 1.167 Prec@(1,3) (69.7%, 97.6%), ce_loss 1.143, lat_loss 6.657
09/18 08:07:24 PM | Valid: [ 22/180] Step 300/312 Loss 1.165 Prec@(1,3) (69.5%, 97.5%), ce_loss 1.143, lat_loss 6.657
09/18 08:07:25 PM | Valid: [ 22/180] Step 312/312 Loss 1.165 Prec@(1,3) (69.5%, 97.6%), ce_loss 1.143, lat_loss 6.657
09/18 08:07:25 PM | val: [ 22/180] Final Prec@1 69.5400% Time 29.60
09/18 08:07:25 PM | Start to train weights for epoch 22
09/18 08:07:50 PM | Train: [ 23/180] Step 050/1249 Loss 1.149 Prec@(1,3) (69.5%, 97.8%), ce_loss 1.142, lat_loss 6.657
09/18 08:08:14 PM | Train: [ 23/180] Step 100/1249 Loss 1.151 Prec@(1,3) (69.7%, 97.4%), ce_loss 1.142, lat_loss 6.657
09/18 08:08:39 PM | Train: [ 23/180] Step 150/1249 Loss 1.148 Prec@(1,3) (70.1%, 97.5%), ce_loss 1.141, lat_loss 6.657
09/18 08:09:03 PM | Train: [ 23/180] Step 200/1249 Loss 1.124 Prec@(1,3) (70.7%, 97.7%), ce_loss 1.141, lat_loss 6.657
09/18 08:09:27 PM | Train: [ 23/180] Step 250/1249 Loss 1.125 Prec@(1,3) (70.7%, 97.7%), ce_loss 1.140, lat_loss 6.657
09/18 08:09:52 PM | Train: [ 23/180] Step 300/1249 Loss 1.119 Prec@(1,3) (70.6%, 97.7%), ce_loss 1.140, lat_loss 6.657
09/18 08:10:17 PM | Train: [ 23/180] Step 350/1249 Loss 1.119 Prec@(1,3) (70.7%, 97.7%), ce_loss 1.140, lat_loss 6.657
09/18 08:10:42 PM | Train: [ 23/180] Step 400/1249 Loss 1.113 Prec@(1,3) (70.9%, 97.6%), ce_loss 1.139, lat_loss 6.657
09/18 08:11:07 PM | Train: [ 23/180] Step 450/1249 Loss 1.111 Prec@(1,3) (71.0%, 97.7%), ce_loss 1.139, lat_loss 6.657
09/18 08:11:31 PM | Train: [ 23/180] Step 500/1249 Loss 1.105 Prec@(1,3) (71.1%, 97.7%), ce_loss 1.138, lat_loss 6.657
09/18 08:11:55 PM | Train: [ 23/180] Step 550/1249 Loss 1.101 Prec@(1,3) (71.1%, 97.7%), ce_loss 1.138, lat_loss 6.657
09/18 08:12:20 PM | Train: [ 23/180] Step 600/1249 Loss 1.102 Prec@(1,3) (71.1%, 97.7%), ce_loss 1.137, lat_loss 6.657
09/18 08:12:45 PM | Train: [ 23/180] Step 650/1249 Loss 1.100 Prec@(1,3) (71.2%, 97.7%), ce_loss 1.137, lat_loss 6.657
09/18 08:13:10 PM | Train: [ 23/180] Step 700/1249 Loss 1.106 Prec@(1,3) (71.0%, 97.7%), ce_loss 1.136, lat_loss 6.657
09/18 08:13:34 PM | Train: [ 23/180] Step 750/1249 Loss 1.102 Prec@(1,3) (71.1%, 97.7%), ce_loss 1.136, lat_loss 6.657
09/18 08:13:59 PM | Train: [ 23/180] Step 800/1249 Loss 1.099 Prec@(1,3) (71.2%, 97.8%), ce_loss 1.135, lat_loss 6.657
09/18 08:14:24 PM | Train: [ 23/180] Step 850/1249 Loss 1.101 Prec@(1,3) (71.1%, 97.8%), ce_loss 1.135, lat_loss 6.657
09/18 08:14:48 PM | Train: [ 23/180] Step 900/1249 Loss 1.100 Prec@(1,3) (71.1%, 97.8%), ce_loss 1.135, lat_loss 6.657
09/18 08:15:13 PM | Train: [ 23/180] Step 950/1249 Loss 1.103 Prec@(1,3) (71.0%, 97.8%), ce_loss 1.134, lat_loss 6.657
09/18 08:15:38 PM | Train: [ 23/180] Step 1000/1249 Loss 1.101 Prec@(1,3) (71.1%, 97.8%), ce_loss 1.134, lat_loss 6.657
09/18 08:16:03 PM | Train: [ 23/180] Step 1050/1249 Loss 1.101 Prec@(1,3) (71.1%, 97.8%), ce_loss 1.133, lat_loss 6.657
09/18 08:16:26 PM | Train: [ 23/180] Step 1100/1249 Loss 1.099 Prec@(1,3) (71.2%, 97.8%), ce_loss 1.133, lat_loss 6.657
09/18 08:16:51 PM | Train: [ 23/180] Step 1150/1249 Loss 1.102 Prec@(1,3) (71.1%, 97.8%), ce_loss 1.133, lat_loss 6.657
09/18 08:17:16 PM | Train: [ 23/180] Step 1200/1249 Loss 1.101 Prec@(1,3) (71.2%, 97.8%), ce_loss 1.132, lat_loss 6.657
09/18 08:17:41 PM | Train: [ 23/180] Step 1249/1249 Loss 1.097 Prec@(1,3) (71.3%, 97.8%), ce_loss 1.132, lat_loss 6.657
09/18 08:17:41 PM | _w_step_train: [ 23/180] Final Prec@1 71.2650% Time 615.69
09/18 08:17:41 PM | Start to train theta for epoch 22
09/18 08:18:02 PM | Train: [ 23/180] Step 050/312 Loss 1.076 Prec@(1,3) (71.6%, 98.0%), ce_loss 1.131, lat_loss 6.657
09/18 08:18:21 PM | Train: [ 23/180] Step 100/312 Loss 1.098 Prec@(1,3) (70.6%, 98.0%), ce_loss 1.131, lat_loss 6.657
09/18 08:18:39 PM | Train: [ 23/180] Step 150/312 Loss 1.120 Prec@(1,3) (70.1%, 97.9%), ce_loss 1.130, lat_loss 6.657
09/18 08:18:56 PM | Train: [ 23/180] Step 200/312 Loss 1.120 Prec@(1,3) (70.5%, 97.7%), ce_loss 1.130, lat_loss 6.657
09/18 08:19:12 PM | Train: [ 23/180] Step 250/312 Loss 1.110 Prec@(1,3) (70.8%, 97.7%), ce_loss 1.130, lat_loss 6.657
09/18 08:19:29 PM | Train: [ 23/180] Step 300/312 Loss 1.101 Prec@(1,3) (71.0%, 97.8%), ce_loss 1.129, lat_loss 6.657
09/18 08:19:33 PM | Train: [ 23/180] Step 312/312 Loss 1.098 Prec@(1,3) (71.1%, 97.8%), ce_loss 1.129, lat_loss 6.657
09/18 08:19:34 PM | _theta_step_train: [ 23/180] Final Prec@1 71.1300% Time 112.75
09/18 08:19:39 PM | Valid: [ 23/180] Step 050/312 Loss 1.135 Prec@(1,3) (71.7%, 97.8%), ce_loss 1.129, lat_loss 6.657
09/18 08:19:44 PM | Valid: [ 23/180] Step 100/312 Loss 1.198 Prec@(1,3) (70.0%, 97.1%), ce_loss 1.128, lat_loss 6.657
09/18 08:19:49 PM | Valid: [ 23/180] Step 150/312 Loss 1.180 Prec@(1,3) (70.2%, 97.1%), ce_loss 1.128, lat_loss 6.657
09/18 08:19:53 PM | Valid: [ 23/180] Step 200/312 Loss 1.187 Prec@(1,3) (69.7%, 97.2%), ce_loss 1.128, lat_loss 6.657
09/18 08:19:58 PM | Valid: [ 23/180] Step 250/312 Loss 1.198 Prec@(1,3) (69.1%, 97.3%), ce_loss 1.127, lat_loss 6.657
09/18 08:20:03 PM | Valid: [ 23/180] Step 300/312 Loss 1.194 Prec@(1,3) (69.2%, 97.2%), ce_loss 1.127, lat_loss 6.657
09/18 08:20:04 PM | Valid: [ 23/180] Step 312/312 Loss 1.199 Prec@(1,3) (69.1%, 97.3%), ce_loss 1.127, lat_loss 6.657
09/18 08:20:04 PM | val: [ 23/180] Final Prec@1 69.1200% Time 30.21
09/18 08:20:04 PM | Start to train weights for epoch 23
09/18 08:20:29 PM | Train: [ 24/180] Step 050/1249 Loss 1.100 Prec@(1,3) (71.4%, 97.5%), ce_loss 1.127, lat_loss 6.657
09/18 08:20:54 PM | Train: [ 24/180] Step 100/1249 Loss 1.125 Prec@(1,3) (70.5%, 97.6%), ce_loss 1.126, lat_loss 6.657
09/18 08:21:18 PM | Train: [ 24/180] Step 150/1249 Loss 1.109 Prec@(1,3) (70.9%, 97.7%), ce_loss 1.126, lat_loss 6.657
09/18 08:21:41 PM | Train: [ 24/180] Step 200/1249 Loss 1.105 Prec@(1,3) (70.9%, 97.7%), ce_loss 1.125, lat_loss 6.657
09/18 08:22:04 PM | Train: [ 24/180] Step 250/1249 Loss 1.091 Prec@(1,3) (71.5%, 97.8%), ce_loss 1.125, lat_loss 6.657
09/18 08:22:27 PM | Train: [ 24/180] Step 300/1249 Loss 1.091 Prec@(1,3) (71.5%, 97.8%), ce_loss 1.125, lat_loss 6.657
09/18 08:22:50 PM | Train: [ 24/180] Step 350/1249 Loss 1.087 Prec@(1,3) (71.5%, 97.8%), ce_loss 1.124, lat_loss 6.657
09/18 08:23:14 PM | Train: [ 24/180] Step 400/1249 Loss 1.085 Prec@(1,3) (71.5%, 97.8%), ce_loss 1.124, lat_loss 6.657
09/18 08:23:38 PM | Train: [ 24/180] Step 450/1249 Loss 1.088 Prec@(1,3) (71.5%, 97.8%), ce_loss 1.123, lat_loss 6.657
09/18 08:24:00 PM | Train: [ 24/180] Step 500/1249 Loss 1.080 Prec@(1,3) (71.6%, 97.8%), ce_loss 1.123, lat_loss 6.657
09/18 08:24:22 PM | Train: [ 24/180] Step 550/1249 Loss 1.080 Prec@(1,3) (71.8%, 97.8%), ce_loss 1.122, lat_loss 6.657
09/18 08:24:46 PM | Train: [ 24/180] Step 600/1249 Loss 1.080 Prec@(1,3) (71.7%, 97.9%), ce_loss 1.122, lat_loss 6.657
09/18 08:25:10 PM | Train: [ 24/180] Step 650/1249 Loss 1.086 Prec@(1,3) (71.6%, 97.8%), ce_loss 1.122, lat_loss 6.657
09/18 08:25:35 PM | Train: [ 24/180] Step 700/1249 Loss 1.086 Prec@(1,3) (71.6%, 97.8%), ce_loss 1.121, lat_loss 6.657
09/18 08:25:59 PM | Train: [ 24/180] Step 750/1249 Loss 1.086 Prec@(1,3) (71.6%, 97.9%), ce_loss 1.121, lat_loss 6.657
09/18 08:26:19 PM | Train: [ 24/180] Step 800/1249 Loss 1.081 Prec@(1,3) (71.7%, 97.9%), ce_loss 1.120, lat_loss 6.657
09/18 08:26:40 PM | Train: [ 24/180] Step 850/1249 Loss 1.080 Prec@(1,3) (71.8%, 97.9%), ce_loss 1.120, lat_loss 6.657
09/18 08:27:04 PM | Train: [ 24/180] Step 900/1249 Loss 1.079 Prec@(1,3) (71.9%, 97.9%), ce_loss 1.119, lat_loss 6.657
09/18 08:27:28 PM | Train: [ 24/180] Step 950/1249 Loss 1.080 Prec@(1,3) (71.9%, 97.9%), ce_loss 1.119, lat_loss 6.657
09/18 08:27:51 PM | Train: [ 24/180] Step 1000/1249 Loss 1.082 Prec@(1,3) (71.8%, 97.9%), ce_loss 1.119, lat_loss 6.657
09/18 08:28:17 PM | Train: [ 24/180] Step 1050/1249 Loss 1.080 Prec@(1,3) (71.8%, 97.9%), ce_loss 1.118, lat_loss 6.657
09/18 08:28:42 PM | Train: [ 24/180] Step 1100/1249 Loss 1.081 Prec@(1,3) (71.8%, 97.9%), ce_loss 1.118, lat_loss 6.657
09/18 08:29:07 PM | Train: [ 24/180] Step 1150/1249 Loss 1.077 Prec@(1,3) (71.9%, 97.9%), ce_loss 1.117, lat_loss 6.657
09/18 08:29:31 PM | Train: [ 24/180] Step 1200/1249 Loss 1.075 Prec@(1,3) (72.0%, 97.9%), ce_loss 1.117, lat_loss 6.657
09/18 08:29:56 PM | Train: [ 24/180] Step 1249/1249 Loss 1.074 Prec@(1,3) (72.0%, 97.9%), ce_loss 1.116, lat_loss 6.657
09/18 08:29:56 PM | _w_step_train: [ 24/180] Final Prec@1 71.9600% Time 591.99
09/18 08:29:56 PM | Start to train theta for epoch 23
09/18 08:30:18 PM | Train: [ 24/180] Step 050/312 Loss 1.130 Prec@(1,3) (70.8%, 97.9%), ce_loss 1.116, lat_loss 6.657
09/18 08:30:37 PM | Train: [ 24/180] Step 100/312 Loss 1.120 Prec@(1,3) (70.8%, 98.0%), ce_loss 1.116, lat_loss 6.657
09/18 08:30:58 PM | Train: [ 24/180] Step 150/312 Loss 1.113 Prec@(1,3) (70.9%, 97.8%), ce_loss 1.115, lat_loss 6.657
09/18 08:31:19 PM | Train: [ 24/180] Step 200/312 Loss 1.101 Prec@(1,3) (71.3%, 97.9%), ce_loss 1.115, lat_loss 6.657
09/18 08:31:40 PM | Train: [ 24/180] Step 250/312 Loss 1.102 Prec@(1,3) (71.2%, 98.0%), ce_loss 1.115, lat_loss 6.657
09/18 08:32:01 PM | Train: [ 24/180] Step 300/312 Loss 1.101 Prec@(1,3) (71.4%, 97.8%), ce_loss 1.114, lat_loss 6.657
09/18 08:32:06 PM | Train: [ 24/180] Step 312/312 Loss 1.103 Prec@(1,3) (71.3%, 97.8%), ce_loss 1.114, lat_loss 6.657
09/18 08:32:06 PM | _theta_step_train: [ 24/180] Final Prec@1 71.2900% Time 130.62
09/18 08:32:12 PM | Valid: [ 24/180] Step 050/312 Loss 1.171 Prec@(1,3) (69.0%, 97.3%), ce_loss 1.114, lat_loss 6.657
09/18 08:32:16 PM | Valid: [ 24/180] Step 100/312 Loss 1.204 Prec@(1,3) (68.7%, 97.1%), ce_loss 1.114, lat_loss 6.657
09/18 08:32:21 PM | Valid: [ 24/180] Step 150/312 Loss 1.169 Prec@(1,3) (69.8%, 97.0%), ce_loss 1.113, lat_loss 6.657
09/18 08:32:26 PM | Valid: [ 24/180] Step 200/312 Loss 1.180 Prec@(1,3) (69.8%, 97.2%), ce_loss 1.113, lat_loss 6.657
09/18 08:32:30 PM | Valid: [ 24/180] Step 250/312 Loss 1.185 Prec@(1,3) (69.7%, 97.1%), ce_loss 1.113, lat_loss 6.657
09/18 08:32:35 PM | Valid: [ 24/180] Step 300/312 Loss 1.188 Prec@(1,3) (69.6%, 97.1%), ce_loss 1.112, lat_loss 6.657
09/18 08:32:36 PM | Valid: [ 24/180] Step 312/312 Loss 1.189 Prec@(1,3) (69.6%, 97.2%), ce_loss 1.112, lat_loss 6.657
09/18 08:32:36 PM | val: [ 24/180] Final Prec@1 69.5700% Time 29.67
09/18 08:32:36 PM | Start to train weights for epoch 24
09/18 08:33:01 PM | Train: [ 25/180] Step 050/1249 Loss 1.099 Prec@(1,3) (71.8%, 97.9%), ce_loss 1.112, lat_loss 6.657
09/18 08:33:26 PM | Train: [ 25/180] Step 100/1249 Loss 1.082 Prec@(1,3) (71.9%, 98.0%), ce_loss 1.112, lat_loss 6.657
09/18 08:33:51 PM | Train: [ 25/180] Step 150/1249 Loss 1.051 Prec@(1,3) (72.6%, 98.1%), ce_loss 1.111, lat_loss 6.657
09/18 08:34:17 PM | Train: [ 25/180] Step 200/1249 Loss 1.063 Prec@(1,3) (72.3%, 98.0%), ce_loss 1.111, lat_loss 6.657
09/18 08:34:42 PM | Train: [ 25/180] Step 250/1249 Loss 1.066 Prec@(1,3) (72.5%, 98.0%), ce_loss 1.110, lat_loss 6.657
09/18 08:35:07 PM | Train: [ 25/180] Step 300/1249 Loss 1.064 Prec@(1,3) (72.3%, 98.0%), ce_loss 1.110, lat_loss 6.657
09/18 08:35:32 PM | Train: [ 25/180] Step 350/1249 Loss 1.065 Prec@(1,3) (72.2%, 98.0%), ce_loss 1.110, lat_loss 6.657
09/18 08:35:58 PM | Train: [ 25/180] Step 400/1249 Loss 1.061 Prec@(1,3) (72.3%, 98.0%), ce_loss 1.109, lat_loss 6.657
09/18 08:36:23 PM | Train: [ 25/180] Step 450/1249 Loss 1.062 Prec@(1,3) (72.2%, 98.0%), ce_loss 1.109, lat_loss 6.657
09/18 08:36:48 PM | Train: [ 25/180] Step 500/1249 Loss 1.065 Prec@(1,3) (72.0%, 98.0%), ce_loss 1.108, lat_loss 6.657
09/18 08:37:13 PM | Train: [ 25/180] Step 550/1249 Loss 1.060 Prec@(1,3) (72.1%, 98.0%), ce_loss 1.108, lat_loss 6.657
09/18 08:37:39 PM | Train: [ 25/180] Step 600/1249 Loss 1.069 Prec@(1,3) (72.0%, 98.0%), ce_loss 1.108, lat_loss 6.657
09/18 08:38:04 PM | Train: [ 25/180] Step 650/1249 Loss 1.065 Prec@(1,3) (72.0%, 98.0%), ce_loss 1.107, lat_loss 6.657
09/18 08:38:29 PM | Train: [ 25/180] Step 700/1249 Loss 1.062 Prec@(1,3) (72.2%, 98.0%), ce_loss 1.107, lat_loss 6.657
09/18 08:38:54 PM | Train: [ 25/180] Step 750/1249 Loss 1.067 Prec@(1,3) (72.0%, 98.0%), ce_loss 1.106, lat_loss 6.657
09/18 08:39:18 PM | Train: [ 25/180] Step 800/1249 Loss 1.067 Prec@(1,3) (72.0%, 98.0%), ce_loss 1.106, lat_loss 6.657
09/18 08:39:43 PM | Train: [ 25/180] Step 850/1249 Loss 1.062 Prec@(1,3) (72.1%, 98.0%), ce_loss 1.106, lat_loss 6.657
09/18 08:40:08 PM | Train: [ 25/180] Step 900/1249 Loss 1.064 Prec@(1,3) (72.0%, 98.0%), ce_loss 1.105, lat_loss 6.657
09/18 08:40:33 PM | Train: [ 25/180] Step 950/1249 Loss 1.063 Prec@(1,3) (72.0%, 98.0%), ce_loss 1.105, lat_loss 6.657
09/18 08:40:58 PM | Train: [ 25/180] Step 1000/1249 Loss 1.064 Prec@(1,3) (72.0%, 98.0%), ce_loss 1.104, lat_loss 6.657
09/18 08:41:23 PM | Train: [ 25/180] Step 1050/1249 Loss 1.066 Prec@(1,3) (71.9%, 98.0%), ce_loss 1.104, lat_loss 6.657
09/18 08:41:48 PM | Train: [ 25/180] Step 1100/1249 Loss 1.063 Prec@(1,3) (72.0%, 98.0%), ce_loss 1.104, lat_loss 6.657
09/18 08:42:13 PM | Train: [ 25/180] Step 1150/1249 Loss 1.060 Prec@(1,3) (72.1%, 98.0%), ce_loss 1.103, lat_loss 6.657
09/18 08:42:37 PM | Train: [ 25/180] Step 1200/1249 Loss 1.058 Prec@(1,3) (72.1%, 98.0%), ce_loss 1.103, lat_loss 6.657
09/18 08:43:02 PM | Train: [ 25/180] Step 1249/1249 Loss 1.059 Prec@(1,3) (72.1%, 98.0%), ce_loss 1.102, lat_loss 6.657
09/18 08:43:02 PM | _w_step_train: [ 25/180] Final Prec@1 72.1250% Time 625.91
09/18 08:43:02 PM | Start to train theta for epoch 24
09/18 08:43:20 PM | Train: [ 25/180] Step 050/312 Loss 1.111 Prec@(1,3) (70.6%, 97.6%), ce_loss 1.102, lat_loss 6.657
09/18 08:43:36 PM | Train: [ 25/180] Step 100/312 Loss 1.080 Prec@(1,3) (71.5%, 98.0%), ce_loss 1.102, lat_loss 6.657
09/18 08:43:53 PM | Train: [ 25/180] Step 150/312 Loss 1.106 Prec@(1,3) (71.1%, 98.0%), ce_loss 1.101, lat_loss 6.657
09/18 08:44:09 PM | Train: [ 25/180] Step 200/312 Loss 1.099 Prec@(1,3) (71.7%, 97.9%), ce_loss 1.101, lat_loss 6.657
09/18 08:44:25 PM | Train: [ 25/180] Step 250/312 Loss 1.096 Prec@(1,3) (71.8%, 97.8%), ce_loss 1.101, lat_loss 6.657
09/18 08:44:42 PM | Train: [ 25/180] Step 300/312 Loss 1.100 Prec@(1,3) (71.6%, 97.7%), ce_loss 1.100, lat_loss 6.657
09/18 08:44:47 PM | Train: [ 25/180] Step 312/312 Loss 1.097 Prec@(1,3) (71.8%, 97.7%), ce_loss 1.100, lat_loss 6.657
09/18 08:44:47 PM | _theta_step_train: [ 25/180] Final Prec@1 71.7700% Time 104.83
09/18 08:44:52 PM | Valid: [ 25/180] Step 050/312 Loss 1.083 Prec@(1,3) (70.8%, 98.3%), ce_loss 1.100, lat_loss 6.657
09/18 08:44:57 PM | Valid: [ 25/180] Step 100/312 Loss 1.131 Prec@(1,3) (70.3%, 97.9%), ce_loss 1.100, lat_loss 6.657
09/18 08:45:01 PM | Valid: [ 25/180] Step 150/312 Loss 1.126 Prec@(1,3) (70.6%, 97.7%), ce_loss 1.099, lat_loss 6.657
09/18 08:45:06 PM | Valid: [ 25/180] Step 200/312 Loss 1.144 Prec@(1,3) (69.8%, 97.8%), ce_loss 1.099, lat_loss 6.657
09/18 08:45:11 PM | Valid: [ 25/180] Step 250/312 Loss 1.148 Prec@(1,3) (70.1%, 97.8%), ce_loss 1.099, lat_loss 6.657
09/18 08:45:15 PM | Valid: [ 25/180] Step 300/312 Loss 1.150 Prec@(1,3) (70.1%, 97.7%), ce_loss 1.098, lat_loss 6.657
09/18 08:45:16 PM | Valid: [ 25/180] Step 312/312 Loss 1.151 Prec@(1,3) (70.2%, 97.7%), ce_loss 1.098, lat_loss 6.657
09/18 08:45:17 PM | val: [ 25/180] Final Prec@1 70.1800% Time 29.68
09/18 08:45:17 PM | Start to train weights for epoch 25
09/18 08:45:34 PM | Train: [ 26/180] Step 050/1249 Loss 1.070 Prec@(1,3) (72.3%, 97.8%), ce_loss 1.098, lat_loss 6.657
09/18 08:45:50 PM | Train: [ 26/180] Step 100/1249 Loss 1.055 Prec@(1,3) (73.1%, 98.0%), ce_loss 1.098, lat_loss 6.657
09/18 08:46:05 PM | Train: [ 26/180] Step 150/1249 Loss 1.076 Prec@(1,3) (72.6%, 97.9%), ce_loss 1.097, lat_loss 6.657
09/18 08:46:21 PM | Train: [ 26/180] Step 200/1249 Loss 1.074 Prec@(1,3) (72.5%, 98.0%), ce_loss 1.097, lat_loss 6.657
09/18 08:46:37 PM | Train: [ 26/180] Step 250/1249 Loss 1.076 Prec@(1,3) (72.5%, 97.8%), ce_loss 1.097, lat_loss 6.658
09/18 08:46:53 PM | Train: [ 26/180] Step 300/1249 Loss 1.073 Prec@(1,3) (72.3%, 97.8%), ce_loss 1.096, lat_loss 6.658
09/18 08:47:09 PM | Train: [ 26/180] Step 350/1249 Loss 1.073 Prec@(1,3) (72.2%, 97.9%), ce_loss 1.096, lat_loss 6.658
09/18 08:47:25 PM | Train: [ 26/180] Step 400/1249 Loss 1.071 Prec@(1,3) (72.3%, 97.8%), ce_loss 1.096, lat_loss 6.658
09/18 08:47:41 PM | Train: [ 26/180] Step 450/1249 Loss 1.068 Prec@(1,3) (72.3%, 97.9%), ce_loss 1.095, lat_loss 6.658
09/18 08:47:57 PM | Train: [ 26/180] Step 500/1249 Loss 1.065 Prec@(1,3) (72.5%, 97.9%), ce_loss 1.095, lat_loss 6.658
09/18 08:48:13 PM | Train: [ 26/180] Step 550/1249 Loss 1.063 Prec@(1,3) (72.4%, 98.0%), ce_loss 1.094, lat_loss 6.658
09/18 08:48:29 PM | Train: [ 26/180] Step 600/1249 Loss 1.057 Prec@(1,3) (72.5%, 98.0%), ce_loss 1.094, lat_loss 6.658
09/18 08:48:44 PM | Train: [ 26/180] Step 650/1249 Loss 1.057 Prec@(1,3) (72.5%, 98.0%), ce_loss 1.094, lat_loss 6.658
09/18 08:49:00 PM | Train: [ 26/180] Step 700/1249 Loss 1.057 Prec@(1,3) (72.5%, 98.0%), ce_loss 1.093, lat_loss 6.658
09/18 08:49:16 PM | Train: [ 26/180] Step 750/1249 Loss 1.057 Prec@(1,3) (72.5%, 98.0%), ce_loss 1.093, lat_loss 6.658
09/18 08:49:32 PM | Train: [ 26/180] Step 800/1249 Loss 1.060 Prec@(1,3) (72.5%, 98.0%), ce_loss 1.093, lat_loss 6.658
09/18 08:49:48 PM | Train: [ 26/180] Step 850/1249 Loss 1.058 Prec@(1,3) (72.5%, 98.0%), ce_loss 1.092, lat_loss 6.658
09/18 08:50:04 PM | Train: [ 26/180] Step 900/1249 Loss 1.056 Prec@(1,3) (72.5%, 98.0%), ce_loss 1.092, lat_loss 6.658
09/18 08:50:20 PM | Train: [ 26/180] Step 950/1249 Loss 1.055 Prec@(1,3) (72.5%, 98.0%), ce_loss 1.091, lat_loss 6.658
09/18 08:50:36 PM | Train: [ 26/180] Step 1000/1249 Loss 1.057 Prec@(1,3) (72.4%, 98.0%), ce_loss 1.091, lat_loss 6.658
09/18 08:50:51 PM | Train: [ 26/180] Step 1050/1249 Loss 1.057 Prec@(1,3) (72.4%, 98.0%), ce_loss 1.091, lat_loss 6.658
09/18 08:51:08 PM | Train: [ 26/180] Step 1100/1249 Loss 1.056 Prec@(1,3) (72.4%, 98.0%), ce_loss 1.090, lat_loss 6.658
09/18 08:51:24 PM | Train: [ 26/180] Step 1150/1249 Loss 1.053 Prec@(1,3) (72.4%, 98.0%), ce_loss 1.090, lat_loss 6.658
09/18 08:51:40 PM | Train: [ 26/180] Step 1200/1249 Loss 1.052 Prec@(1,3) (72.5%, 98.0%), ce_loss 1.090, lat_loss 6.658
09/18 08:51:55 PM | Train: [ 26/180] Step 1249/1249 Loss 1.053 Prec@(1,3) (72.4%, 98.0%), ce_loss 1.089, lat_loss 6.658
09/18 08:51:55 PM | _w_step_train: [ 26/180] Final Prec@1 72.4450% Time 398.79
09/18 08:51:55 PM | Start to train theta for epoch 25
09/18 08:52:15 PM | Train: [ 26/180] Step 050/312 Loss 1.064 Prec@(1,3) (71.6%, 97.7%), ce_loss 1.089, lat_loss 6.658
09/18 08:52:35 PM | Train: [ 26/180] Step 100/312 Loss 1.068 Prec@(1,3) (72.1%, 97.6%), ce_loss 1.089, lat_loss 6.658
09/18 08:52:55 PM | Train: [ 26/180] Step 150/312 Loss 1.086 Prec@(1,3) (71.6%, 97.6%), ce_loss 1.088, lat_loss 6.658
09/18 08:53:16 PM | Train: [ 26/180] Step 200/312 Loss 1.087 Prec@(1,3) (72.0%, 97.6%), ce_loss 1.088, lat_loss 6.658
09/18 08:53:37 PM | Train: [ 26/180] Step 250/312 Loss 1.073 Prec@(1,3) (72.4%, 97.7%), ce_loss 1.088, lat_loss 6.658
09/18 08:53:58 PM | Train: [ 26/180] Step 300/312 Loss 1.073 Prec@(1,3) (72.3%, 97.7%), ce_loss 1.087, lat_loss 6.658
09/18 08:54:03 PM | Train: [ 26/180] Step 312/312 Loss 1.069 Prec@(1,3) (72.4%, 97.8%), ce_loss 1.087, lat_loss 6.658
09/18 08:54:03 PM | _theta_step_train: [ 26/180] Final Prec@1 72.3900% Time 127.86
09/18 08:54:09 PM | Valid: [ 26/180] Step 050/312 Loss 1.160 Prec@(1,3) (68.9%, 98.2%), ce_loss 1.087, lat_loss 6.658
09/18 08:54:13 PM | Valid: [ 26/180] Step 100/312 Loss 1.174 Prec@(1,3) (69.3%, 97.3%), ce_loss 1.087, lat_loss 6.658
09/18 08:54:18 PM | Valid: [ 26/180] Step 150/312 Loss 1.152 Prec@(1,3) (70.0%, 97.4%), ce_loss 1.086, lat_loss 6.658
09/18 08:54:22 PM | Valid: [ 26/180] Step 200/312 Loss 1.163 Prec@(1,3) (69.7%, 97.4%), ce_loss 1.086, lat_loss 6.658
09/18 08:54:27 PM | Valid: [ 26/180] Step 250/312 Loss 1.163 Prec@(1,3) (69.8%, 97.4%), ce_loss 1.086, lat_loss 6.658
09/18 08:54:32 PM | Valid: [ 26/180] Step 300/312 Loss 1.161 Prec@(1,3) (69.9%, 97.5%), ce_loss 1.086, lat_loss 6.658
09/18 08:54:33 PM | Valid: [ 26/180] Step 312/312 Loss 1.164 Prec@(1,3) (69.8%, 97.5%), ce_loss 1.086, lat_loss 6.658
09/18 08:54:33 PM | val: [ 26/180] Final Prec@1 69.7800% Time 29.99
09/18 08:54:33 PM | Start to train weights for epoch 26
09/18 08:54:58 PM | Train: [ 27/180] Step 050/1249 Loss 1.060 Prec@(1,3) (72.2%, 98.2%), ce_loss 1.085, lat_loss 6.658
09/18 08:55:22 PM | Train: [ 27/180] Step 100/1249 Loss 1.034 Prec@(1,3) (73.0%, 97.9%), ce_loss 1.085, lat_loss 6.658
09/18 08:55:47 PM | Train: [ 27/180] Step 150/1249 Loss 1.022 Prec@(1,3) (73.3%, 98.0%), ce_loss 1.084, lat_loss 6.658
09/18 08:56:11 PM | Train: [ 27/180] Step 200/1249 Loss 1.034 Prec@(1,3) (72.9%, 98.0%), ce_loss 1.084, lat_loss 6.658
09/18 08:56:33 PM | Train: [ 27/180] Step 250/1249 Loss 1.033 Prec@(1,3) (73.1%, 98.1%), ce_loss 1.084, lat_loss 6.658
09/18 08:56:59 PM | Train: [ 27/180] Step 300/1249 Loss 1.042 Prec@(1,3) (72.9%, 98.0%), ce_loss 1.083, lat_loss 6.658
09/18 08:57:24 PM | Train: [ 27/180] Step 350/1249 Loss 1.042 Prec@(1,3) (73.0%, 98.1%), ce_loss 1.083, lat_loss 6.658
09/18 08:57:49 PM | Train: [ 27/180] Step 400/1249 Loss 1.045 Prec@(1,3) (72.9%, 98.0%), ce_loss 1.083, lat_loss 6.658
09/18 08:58:14 PM | Train: [ 27/180] Step 450/1249 Loss 1.047 Prec@(1,3) (72.8%, 98.0%), ce_loss 1.082, lat_loss 6.658
09/18 08:58:39 PM | Train: [ 27/180] Step 500/1249 Loss 1.045 Prec@(1,3) (73.1%, 98.0%), ce_loss 1.082, lat_loss 6.658
09/18 08:59:04 PM | Train: [ 27/180] Step 550/1249 Loss 1.043 Prec@(1,3) (73.1%, 98.0%), ce_loss 1.082, lat_loss 6.658
09/18 08:59:29 PM | Train: [ 27/180] Step 600/1249 Loss 1.045 Prec@(1,3) (73.0%, 97.9%), ce_loss 1.081, lat_loss 6.658
09/18 08:59:45 PM | Train: [ 27/180] Step 650/1249 Loss 1.043 Prec@(1,3) (73.0%, 98.0%), ce_loss 1.081, lat_loss 6.658
09/18 09:00:04 PM | Train: [ 27/180] Step 700/1249 Loss 1.044 Prec@(1,3) (73.0%, 98.0%), ce_loss 1.081, lat_loss 6.658
09/18 09:00:29 PM | Train: [ 27/180] Step 750/1249 Loss 1.036 Prec@(1,3) (73.2%, 98.0%), ce_loss 1.080, lat_loss 6.658
09/18 09:00:46 PM | Train: [ 27/180] Step 800/1249 Loss 1.034 Prec@(1,3) (73.2%, 98.0%), ce_loss 1.080, lat_loss 6.658
09/18 09:01:02 PM | Train: [ 27/180] Step 850/1249 Loss 1.035 Prec@(1,3) (73.2%, 98.0%), ce_loss 1.079, lat_loss 6.658
09/18 09:01:18 PM | Train: [ 27/180] Step 900/1249 Loss 1.036 Prec@(1,3) (73.2%, 98.0%), ce_loss 1.079, lat_loss 6.658
09/18 09:01:34 PM | Train: [ 27/180] Step 950/1249 Loss 1.038 Prec@(1,3) (73.1%, 98.0%), ce_loss 1.079, lat_loss 6.658
09/18 09:01:50 PM | Train: [ 27/180] Step 1000/1249 Loss 1.037 Prec@(1,3) (73.2%, 98.0%), ce_loss 1.078, lat_loss 6.658
09/18 09:02:06 PM | Train: [ 27/180] Step 1050/1249 Loss 1.039 Prec@(1,3) (73.1%, 98.0%), ce_loss 1.078, lat_loss 6.658
09/18 09:02:22 PM | Train: [ 27/180] Step 1100/1249 Loss 1.035 Prec@(1,3) (73.2%, 98.0%), ce_loss 1.078, lat_loss 6.658
09/18 09:02:38 PM | Train: [ 27/180] Step 1150/1249 Loss 1.038 Prec@(1,3) (73.1%, 98.0%), ce_loss 1.077, lat_loss 6.658
09/18 09:02:54 PM | Train: [ 27/180] Step 1200/1249 Loss 1.039 Prec@(1,3) (73.0%, 98.0%), ce_loss 1.077, lat_loss 6.658
09/18 09:03:09 PM | Train: [ 27/180] Step 1249/1249 Loss 1.039 Prec@(1,3) (73.0%, 98.0%), ce_loss 1.077, lat_loss 6.658
09/18 09:03:09 PM | _w_step_train: [ 27/180] Final Prec@1 73.0275% Time 516.09
09/18 09:03:09 PM | Start to train theta for epoch 26
09/18 09:03:31 PM | Train: [ 27/180] Step 050/312 Loss 1.114 Prec@(1,3) (71.0%, 97.5%), ce_loss 1.076, lat_loss 6.658
09/18 09:03:51 PM | Train: [ 27/180] Step 100/312 Loss 1.064 Prec@(1,3) (72.6%, 98.1%), ce_loss 1.076, lat_loss 6.658
09/18 09:04:11 PM | Train: [ 27/180] Step 150/312 Loss 1.075 Prec@(1,3) (72.4%, 97.9%), ce_loss 1.076, lat_loss 6.658
09/18 09:04:29 PM | Train: [ 27/180] Step 200/312 Loss 1.069 Prec@(1,3) (72.3%, 98.0%), ce_loss 1.076, lat_loss 6.658
09/18 09:04:49 PM | Train: [ 27/180] Step 250/312 Loss 1.058 Prec@(1,3) (72.7%, 97.9%), ce_loss 1.075, lat_loss 6.658
09/18 09:05:09 PM | Train: [ 27/180] Step 300/312 Loss 1.062 Prec@(1,3) (72.5%, 97.9%), ce_loss 1.075, lat_loss 6.658
09/18 09:05:13 PM | Train: [ 27/180] Step 312/312 Loss 1.064 Prec@(1,3) (72.5%, 97.9%), ce_loss 1.075, lat_loss 6.658
09/18 09:05:13 PM | _theta_step_train: [ 27/180] Final Prec@1 72.4700% Time 124.17
09/18 09:05:19 PM | Valid: [ 27/180] Step 050/312 Loss 1.099 Prec@(1,3) (72.2%, 98.2%), ce_loss 1.075, lat_loss 6.658
09/18 09:05:24 PM | Valid: [ 27/180] Step 100/312 Loss 1.180 Prec@(1,3) (70.2%, 97.5%), ce_loss 1.074, lat_loss 6.658
09/18 09:05:28 PM | Valid: [ 27/180] Step 150/312 Loss 1.185 Prec@(1,3) (69.7%, 97.1%), ce_loss 1.074, lat_loss 6.658
09/18 09:05:33 PM | Valid: [ 27/180] Step 200/312 Loss 1.185 Prec@(1,3) (69.3%, 97.2%), ce_loss 1.074, lat_loss 6.658
09/18 09:05:38 PM | Valid: [ 27/180] Step 250/312 Loss 1.213 Prec@(1,3) (68.5%, 97.1%), ce_loss 1.074, lat_loss 6.658
09/18 09:05:42 PM | Valid: [ 27/180] Step 300/312 Loss 1.242 Prec@(1,3) (67.9%, 97.0%), ce_loss 1.074, lat_loss 6.658
09/18 09:05:43 PM | Valid: [ 27/180] Step 312/312 Loss 1.244 Prec@(1,3) (67.8%, 97.0%), ce_loss 1.074, lat_loss 6.658
09/18 09:05:43 PM | val: [ 27/180] Final Prec@1 67.8100% Time 29.87
09/18 09:05:43 PM | Start to train weights for epoch 27
09/18 09:06:09 PM | Train: [ 28/180] Step 050/1249 Loss 1.040 Prec@(1,3) (73.3%, 98.3%), ce_loss 1.073, lat_loss 6.658
09/18 09:06:34 PM | Train: [ 28/180] Step 100/1249 Loss 1.066 Prec@(1,3) (72.8%, 98.2%), ce_loss 1.073, lat_loss 6.658
09/18 09:06:59 PM | Train: [ 28/180] Step 150/1249 Loss 1.060 Prec@(1,3) (72.6%, 98.2%), ce_loss 1.073, lat_loss 6.658
09/18 09:07:24 PM | Train: [ 28/180] Step 200/1249 Loss 1.053 Prec@(1,3) (72.8%, 98.1%), ce_loss 1.073, lat_loss 6.658
09/18 09:07:48 PM | Train: [ 28/180] Step 250/1249 Loss 1.051 Prec@(1,3) (72.9%, 97.9%), ce_loss 1.072, lat_loss 6.658
09/18 09:08:13 PM | Train: [ 28/180] Step 300/1249 Loss 1.050 Prec@(1,3) (72.7%, 98.0%), ce_loss 1.072, lat_loss 6.658
09/18 09:08:38 PM | Train: [ 28/180] Step 350/1249 Loss 1.044 Prec@(1,3) (72.8%, 98.0%), ce_loss 1.072, lat_loss 6.658
09/18 09:09:03 PM | Train: [ 28/180] Step 400/1249 Loss 1.042 Prec@(1,3) (72.9%, 98.0%), ce_loss 1.071, lat_loss 6.658
09/18 09:09:27 PM | Train: [ 28/180] Step 450/1249 Loss 1.043 Prec@(1,3) (72.8%, 98.0%), ce_loss 1.071, lat_loss 6.658
09/18 09:09:52 PM | Train: [ 28/180] Step 500/1249 Loss 1.043 Prec@(1,3) (72.9%, 97.9%), ce_loss 1.071, lat_loss 6.658
09/18 09:10:16 PM | Train: [ 28/180] Step 550/1249 Loss 1.041 Prec@(1,3) (73.1%, 97.9%), ce_loss 1.070, lat_loss 6.658
09/18 09:10:38 PM | Train: [ 28/180] Step 600/1249 Loss 1.045 Prec@(1,3) (73.0%, 97.9%), ce_loss 1.070, lat_loss 6.658
09/18 09:11:02 PM | Train: [ 28/180] Step 650/1249 Loss 1.041 Prec@(1,3) (73.1%, 97.9%), ce_loss 1.070, lat_loss 6.658
09/18 09:11:25 PM | Train: [ 28/180] Step 700/1249 Loss 1.038 Prec@(1,3) (73.2%, 98.0%), ce_loss 1.069, lat_loss 6.658
09/18 09:11:49 PM | Train: [ 28/180] Step 750/1249 Loss 1.041 Prec@(1,3) (73.0%, 98.0%), ce_loss 1.069, lat_loss 6.658
09/18 09:12:11 PM | Train: [ 28/180] Step 800/1249 Loss 1.038 Prec@(1,3) (73.0%, 98.0%), ce_loss 1.069, lat_loss 6.658
09/18 09:12:35 PM | Train: [ 28/180] Step 850/1249 Loss 1.035 Prec@(1,3) (73.1%, 98.1%), ce_loss 1.068, lat_loss 6.658
09/18 09:12:59 PM | Train: [ 28/180] Step 900/1249 Loss 1.037 Prec@(1,3) (73.1%, 98.0%), ce_loss 1.068, lat_loss 6.658
09/18 09:13:22 PM | Train: [ 28/180] Step 950/1249 Loss 1.037 Prec@(1,3) (73.1%, 98.0%), ce_loss 1.068, lat_loss 6.658
09/18 09:13:44 PM | Train: [ 28/180] Step 1000/1249 Loss 1.035 Prec@(1,3) (73.2%, 98.0%), ce_loss 1.067, lat_loss 6.658
09/18 09:14:07 PM | Train: [ 28/180] Step 1050/1249 Loss 1.036 Prec@(1,3) (73.2%, 98.0%), ce_loss 1.067, lat_loss 6.658
09/18 09:14:28 PM | Train: [ 28/180] Step 1100/1249 Loss 1.038 Prec@(1,3) (73.1%, 98.0%), ce_loss 1.067, lat_loss 6.658
09/18 09:14:44 PM | Train: [ 28/180] Step 1150/1249 Loss 1.037 Prec@(1,3) (73.1%, 98.1%), ce_loss 1.066, lat_loss 6.658
09/18 09:15:00 PM | Train: [ 28/180] Step 1200/1249 Loss 1.038 Prec@(1,3) (73.0%, 98.1%), ce_loss 1.066, lat_loss 6.658
09/18 09:15:15 PM | Train: [ 28/180] Step 1249/1249 Loss 1.038 Prec@(1,3) (73.1%, 98.0%), ce_loss 1.066, lat_loss 6.658
09/18 09:15:16 PM | _w_step_train: [ 28/180] Final Prec@1 73.0700% Time 572.20
09/18 09:15:16 PM | Start to train theta for epoch 27
09/18 09:15:37 PM | Train: [ 28/180] Step 050/312 Loss 1.086 Prec@(1,3) (72.0%, 97.7%), ce_loss 1.065, lat_loss 6.658
09/18 09:15:57 PM | Train: [ 28/180] Step 100/312 Loss 1.082 Prec@(1,3) (72.3%, 97.6%), ce_loss 1.065, lat_loss 6.658
09/18 09:16:18 PM | Train: [ 28/180] Step 150/312 Loss 1.042 Prec@(1,3) (72.9%, 98.0%), ce_loss 1.065, lat_loss 6.658
09/18 09:16:39 PM | Train: [ 28/180] Step 200/312 Loss 1.031 Prec@(1,3) (73.3%, 98.1%), ce_loss 1.064, lat_loss 6.658
09/18 09:16:59 PM | Train: [ 28/180] Step 250/312 Loss 1.054 Prec@(1,3) (72.8%, 98.0%), ce_loss 1.064, lat_loss 6.658
09/18 09:17:20 PM | Train: [ 28/180] Step 300/312 Loss 1.057 Prec@(1,3) (72.8%, 98.0%), ce_loss 1.064, lat_loss 6.658
09/18 09:17:25 PM | Train: [ 28/180] Step 312/312 Loss 1.062 Prec@(1,3) (72.7%, 98.0%), ce_loss 1.064, lat_loss 6.658
09/18 09:17:25 PM | _theta_step_train: [ 28/180] Final Prec@1 72.6800% Time 129.63
09/18 09:17:31 PM | Valid: [ 28/180] Step 050/312 Loss 1.172 Prec@(1,3) (69.1%, 97.9%), ce_loss 1.064, lat_loss 6.658
09/18 09:17:35 PM | Valid: [ 28/180] Step 100/312 Loss 1.196 Prec@(1,3) (69.0%, 97.6%), ce_loss 1.064, lat_loss 6.658
09/18 09:17:40 PM | Valid: [ 28/180] Step 150/312 Loss 1.192 Prec@(1,3) (69.5%, 97.2%), ce_loss 1.063, lat_loss 6.658
09/18 09:17:44 PM | Valid: [ 28/180] Step 200/312 Loss 1.199 Prec@(1,3) (69.2%, 97.3%), ce_loss 1.063, lat_loss 6.658
09/18 09:17:49 PM | Valid: [ 28/180] Step 250/312 Loss 1.204 Prec@(1,3) (69.1%, 97.3%), ce_loss 1.063, lat_loss 6.658
09/18 09:17:54 PM | Valid: [ 28/180] Step 300/312 Loss 1.192 Prec@(1,3) (69.5%, 97.3%), ce_loss 1.063, lat_loss 6.658
09/18 09:17:55 PM | Valid: [ 28/180] Step 312/312 Loss 1.198 Prec@(1,3) (69.4%, 97.2%), ce_loss 1.063, lat_loss 6.658
09/18 09:17:55 PM | val: [ 28/180] Final Prec@1 69.3900% Time 29.58
09/18 09:17:55 PM | Start to train weights for epoch 28
09/18 09:18:12 PM | Train: [ 29/180] Step 050/1249 Loss 1.069 Prec@(1,3) (72.8%, 98.2%), ce_loss 1.062, lat_loss 6.658
09/18 09:18:28 PM | Train: [ 29/180] Step 100/1249 Loss 1.019 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.062, lat_loss 6.658
09/18 09:18:44 PM | Train: [ 29/180] Step 150/1249 Loss 1.022 Prec@(1,3) (73.5%, 98.1%), ce_loss 1.062, lat_loss 6.658
09/18 09:19:00 PM | Train: [ 29/180] Step 200/1249 Loss 1.035 Prec@(1,3) (73.2%, 98.1%), ce_loss 1.062, lat_loss 6.658
09/18 09:19:16 PM | Train: [ 29/180] Step 250/1249 Loss 1.022 Prec@(1,3) (73.4%, 98.2%), ce_loss 1.061, lat_loss 6.658
09/18 09:19:33 PM | Train: [ 29/180] Step 300/1249 Loss 1.009 Prec@(1,3) (73.8%, 98.2%), ce_loss 1.061, lat_loss 6.658
09/18 09:19:49 PM | Train: [ 29/180] Step 350/1249 Loss 1.010 Prec@(1,3) (73.8%, 98.3%), ce_loss 1.060, lat_loss 6.658
09/18 09:20:05 PM | Train: [ 29/180] Step 400/1249 Loss 1.017 Prec@(1,3) (73.6%, 98.2%), ce_loss 1.060, lat_loss 6.658
09/18 09:20:21 PM | Train: [ 29/180] Step 450/1249 Loss 1.020 Prec@(1,3) (73.6%, 98.3%), ce_loss 1.060, lat_loss 6.658
09/18 09:20:37 PM | Train: [ 29/180] Step 500/1249 Loss 1.023 Prec@(1,3) (73.5%, 98.2%), ce_loss 1.060, lat_loss 6.658
09/18 09:20:53 PM | Train: [ 29/180] Step 550/1249 Loss 1.025 Prec@(1,3) (73.4%, 98.2%), ce_loss 1.059, lat_loss 6.658
09/18 09:21:09 PM | Train: [ 29/180] Step 600/1249 Loss 1.025 Prec@(1,3) (73.4%, 98.2%), ce_loss 1.059, lat_loss 6.658
09/18 09:21:25 PM | Train: [ 29/180] Step 650/1249 Loss 1.026 Prec@(1,3) (73.4%, 98.2%), ce_loss 1.059, lat_loss 6.658
09/18 09:21:47 PM | Train: [ 29/180] Step 700/1249 Loss 1.022 Prec@(1,3) (73.6%, 98.1%), ce_loss 1.058, lat_loss 6.658
09/18 09:22:12 PM | Train: [ 29/180] Step 750/1249 Loss 1.026 Prec@(1,3) (73.6%, 98.1%), ce_loss 1.058, lat_loss 6.658
09/18 09:22:36 PM | Train: [ 29/180] Step 800/1249 Loss 1.030 Prec@(1,3) (73.5%, 98.1%), ce_loss 1.058, lat_loss 6.658
09/18 09:23:01 PM | Train: [ 29/180] Step 850/1249 Loss 1.034 Prec@(1,3) (73.4%, 98.1%), ce_loss 1.058, lat_loss 6.658
09/18 09:23:26 PM | Train: [ 29/180] Step 900/1249 Loss 1.034 Prec@(1,3) (73.4%, 98.1%), ce_loss 1.057, lat_loss 6.658
09/18 09:23:51 PM | Train: [ 29/180] Step 950/1249 Loss 1.030 Prec@(1,3) (73.5%, 98.1%), ce_loss 1.057, lat_loss 6.658
09/18 09:24:15 PM | Train: [ 29/180] Step 1000/1249 Loss 1.032 Prec@(1,3) (73.5%, 98.1%), ce_loss 1.057, lat_loss 6.658
09/18 09:24:40 PM | Train: [ 29/180] Step 1050/1249 Loss 1.031 Prec@(1,3) (73.4%, 98.1%), ce_loss 1.056, lat_loss 6.658
09/18 09:25:05 PM | Train: [ 29/180] Step 1100/1249 Loss 1.027 Prec@(1,3) (73.5%, 98.1%), ce_loss 1.056, lat_loss 6.658
09/18 09:25:30 PM | Train: [ 29/180] Step 1150/1249 Loss 1.027 Prec@(1,3) (73.5%, 98.1%), ce_loss 1.056, lat_loss 6.658
09/18 09:25:55 PM | Train: [ 29/180] Step 1200/1249 Loss 1.027 Prec@(1,3) (73.5%, 98.1%), ce_loss 1.055, lat_loss 6.658
09/18 09:26:19 PM | Train: [ 29/180] Step 1249/1249 Loss 1.024 Prec@(1,3) (73.5%, 98.1%), ce_loss 1.055, lat_loss 6.658
09/18 09:26:19 PM | _w_step_train: [ 29/180] Final Prec@1 73.5300% Time 504.24
09/18 09:26:19 PM | Start to train theta for epoch 28
09/18 09:26:39 PM | Train: [ 29/180] Step 050/312 Loss 1.109 Prec@(1,3) (72.4%, 97.3%), ce_loss 1.055, lat_loss 6.658
09/18 09:26:55 PM | Train: [ 29/180] Step 100/312 Loss 1.084 Prec@(1,3) (72.8%, 97.6%), ce_loss 1.055, lat_loss 6.658
09/18 09:27:11 PM | Train: [ 29/180] Step 150/312 Loss 1.080 Prec@(1,3) (72.9%, 97.6%), ce_loss 1.054, lat_loss 6.658
09/18 09:27:27 PM | Train: [ 29/180] Step 200/312 Loss 1.075 Prec@(1,3) (72.6%, 97.7%), ce_loss 1.054, lat_loss 6.658
09/18 09:27:43 PM | Train: [ 29/180] Step 250/312 Loss 1.080 Prec@(1,3) (72.5%, 97.8%), ce_loss 1.054, lat_loss 6.658
09/18 09:28:04 PM | Train: [ 29/180] Step 300/312 Loss 1.066 Prec@(1,3) (72.8%, 97.9%), ce_loss 1.053, lat_loss 6.658
09/18 09:28:09 PM | Train: [ 29/180] Step 312/312 Loss 1.064 Prec@(1,3) (72.9%, 97.9%), ce_loss 1.053, lat_loss 6.658
09/18 09:28:09 PM | _theta_step_train: [ 29/180] Final Prec@1 72.8600% Time 109.51
09/18 09:28:14 PM | Valid: [ 29/180] Step 050/312 Loss 1.184 Prec@(1,3) (68.3%, 97.9%), ce_loss 1.053, lat_loss 6.658
09/18 09:28:18 PM | Valid: [ 29/180] Step 100/312 Loss 1.239 Prec@(1,3) (68.0%, 97.3%), ce_loss 1.053, lat_loss 6.658
09/18 09:28:23 PM | Valid: [ 29/180] Step 150/312 Loss 1.210 Prec@(1,3) (68.6%, 97.2%), ce_loss 1.053, lat_loss 6.658
09/18 09:28:28 PM | Valid: [ 29/180] Step 200/312 Loss 1.238 Prec@(1,3) (67.8%, 97.3%), ce_loss 1.053, lat_loss 6.658
09/18 09:28:32 PM | Valid: [ 29/180] Step 250/312 Loss 1.238 Prec@(1,3) (67.9%, 97.4%), ce_loss 1.053, lat_loss 6.658
09/18 09:28:37 PM | Valid: [ 29/180] Step 300/312 Loss 1.232 Prec@(1,3) (68.2%, 97.3%), ce_loss 1.053, lat_loss 6.658
09/18 09:28:38 PM | Valid: [ 29/180] Step 312/312 Loss 1.234 Prec@(1,3) (68.2%, 97.3%), ce_loss 1.053, lat_loss 6.658
09/18 09:28:38 PM | val: [ 29/180] Final Prec@1 68.1900% Time 29.47
09/18 09:28:38 PM | Start to train weights for epoch 29
09/18 09:29:04 PM | Train: [ 30/180] Step 050/1249 Loss 1.035 Prec@(1,3) (74.3%, 98.2%), ce_loss 1.052, lat_loss 6.658
09/18 09:29:28 PM | Train: [ 30/180] Step 100/1249 Loss 1.020 Prec@(1,3) (74.5%, 98.0%), ce_loss 1.052, lat_loss 6.658
09/18 09:29:51 PM | Train: [ 30/180] Step 150/1249 Loss 1.029 Prec@(1,3) (74.0%, 97.9%), ce_loss 1.052, lat_loss 6.658
09/18 09:30:16 PM | Train: [ 30/180] Step 200/1249 Loss 1.040 Prec@(1,3) (73.3%, 97.8%), ce_loss 1.051, lat_loss 6.658
09/18 09:30:40 PM | Train: [ 30/180] Step 250/1249 Loss 1.042 Prec@(1,3) (73.2%, 97.9%), ce_loss 1.051, lat_loss 6.658
09/18 09:31:05 PM | Train: [ 30/180] Step 300/1249 Loss 1.042 Prec@(1,3) (73.1%, 98.0%), ce_loss 1.051, lat_loss 6.658
09/18 09:31:29 PM | Train: [ 30/180] Step 350/1249 Loss 1.046 Prec@(1,3) (73.2%, 97.9%), ce_loss 1.051, lat_loss 6.658
09/18 09:31:54 PM | Train: [ 30/180] Step 400/1249 Loss 1.037 Prec@(1,3) (73.3%, 97.9%), ce_loss 1.050, lat_loss 6.658
09/18 09:32:19 PM | Train: [ 30/180] Step 450/1249 Loss 1.030 Prec@(1,3) (73.5%, 98.0%), ce_loss 1.050, lat_loss 6.658
09/18 09:32:43 PM | Train: [ 30/180] Step 500/1249 Loss 1.027 Prec@(1,3) (73.6%, 97.9%), ce_loss 1.050, lat_loss 6.658
09/18 09:33:08 PM | Train: [ 30/180] Step 550/1249 Loss 1.024 Prec@(1,3) (73.7%, 97.9%), ce_loss 1.049, lat_loss 6.658
09/18 09:33:33 PM | Train: [ 30/180] Step 600/1249 Loss 1.029 Prec@(1,3) (73.6%, 97.9%), ce_loss 1.049, lat_loss 6.658
09/18 09:33:58 PM | Train: [ 30/180] Step 650/1249 Loss 1.030 Prec@(1,3) (73.6%, 97.9%), ce_loss 1.049, lat_loss 6.658
09/18 09:34:23 PM | Train: [ 30/180] Step 700/1249 Loss 1.031 Prec@(1,3) (73.7%, 97.9%), ce_loss 1.049, lat_loss 6.658
09/18 09:34:47 PM | Train: [ 30/180] Step 750/1249 Loss 1.031 Prec@(1,3) (73.6%, 97.9%), ce_loss 1.048, lat_loss 6.658
09/18 09:35:12 PM | Train: [ 30/180] Step 800/1249 Loss 1.027 Prec@(1,3) (73.7%, 98.0%), ce_loss 1.048, lat_loss 6.658
09/18 09:35:37 PM | Train: [ 30/180] Step 850/1249 Loss 1.031 Prec@(1,3) (73.6%, 97.9%), ce_loss 1.048, lat_loss 6.658
09/18 09:36:02 PM | Train: [ 30/180] Step 900/1249 Loss 1.030 Prec@(1,3) (73.6%, 97.9%), ce_loss 1.047, lat_loss 6.658
09/18 09:36:27 PM | Train: [ 30/180] Step 950/1249 Loss 1.029 Prec@(1,3) (73.6%, 97.9%), ce_loss 1.047, lat_loss 6.658
09/18 09:36:52 PM | Train: [ 30/180] Step 1000/1249 Loss 1.031 Prec@(1,3) (73.5%, 97.9%), ce_loss 1.047, lat_loss 6.658
09/18 09:37:16 PM | Train: [ 30/180] Step 1050/1249 Loss 1.028 Prec@(1,3) (73.5%, 97.9%), ce_loss 1.047, lat_loss 6.659
09/18 09:37:41 PM | Train: [ 30/180] Step 1100/1249 Loss 1.030 Prec@(1,3) (73.5%, 97.9%), ce_loss 1.046, lat_loss 6.659
09/18 09:38:06 PM | Train: [ 30/180] Step 1150/1249 Loss 1.031 Prec@(1,3) (73.5%, 97.9%), ce_loss 1.046, lat_loss 6.659
09/18 09:38:31 PM | Train: [ 30/180] Step 1200/1249 Loss 1.027 Prec@(1,3) (73.6%, 98.0%), ce_loss 1.046, lat_loss 6.659
09/18 09:38:55 PM | Train: [ 30/180] Step 1249/1249 Loss 1.025 Prec@(1,3) (73.6%, 98.0%), ce_loss 1.045, lat_loss 6.659
09/18 09:38:55 PM | _w_step_train: [ 30/180] Final Prec@1 73.6225% Time 617.34
09/18 09:38:55 PM | Start to train theta for epoch 29
09/18 09:39:16 PM | Train: [ 30/180] Step 050/312 Loss 1.052 Prec@(1,3) (71.8%, 98.7%), ce_loss 1.045, lat_loss 6.659
09/18 09:39:36 PM | Train: [ 30/180] Step 100/312 Loss 1.018 Prec@(1,3) (73.5%, 98.3%), ce_loss 1.045, lat_loss 6.659
09/18 09:39:57 PM | Train: [ 30/180] Step 150/312 Loss 1.034 Prec@(1,3) (73.1%, 98.0%), ce_loss 1.045, lat_loss 6.659
09/18 09:40:16 PM | Train: [ 30/180] Step 200/312 Loss 1.043 Prec@(1,3) (73.1%, 98.0%), ce_loss 1.044, lat_loss 6.659
09/18 09:40:34 PM | Train: [ 30/180] Step 250/312 Loss 1.047 Prec@(1,3) (72.9%, 98.0%), ce_loss 1.044, lat_loss 6.659
09/18 09:40:50 PM | Train: [ 30/180] Step 300/312 Loss 1.054 Prec@(1,3) (72.7%, 98.0%), ce_loss 1.044, lat_loss 6.659
09/18 09:40:54 PM | Train: [ 30/180] Step 312/312 Loss 1.051 Prec@(1,3) (72.8%, 98.0%), ce_loss 1.044, lat_loss 6.659
09/18 09:40:55 PM | _theta_step_train: [ 30/180] Final Prec@1 72.8300% Time 119.07
09/18 09:41:01 PM | Valid: [ 30/180] Step 050/312 Loss 1.196 Prec@(1,3) (70.5%, 98.0%), ce_loss 1.044, lat_loss 6.659
09/18 09:41:05 PM | Valid: [ 30/180] Step 100/312 Loss 1.191 Prec@(1,3) (70.3%, 97.6%), ce_loss 1.043, lat_loss 6.659
09/18 09:41:10 PM | Valid: [ 30/180] Step 150/312 Loss 1.169 Prec@(1,3) (70.5%, 97.5%), ce_loss 1.043, lat_loss 6.659
09/18 09:41:14 PM | Valid: [ 30/180] Step 200/312 Loss 1.191 Prec@(1,3) (69.9%, 97.5%), ce_loss 1.043, lat_loss 6.659
09/18 09:41:19 PM | Valid: [ 30/180] Step 250/312 Loss 1.198 Prec@(1,3) (69.8%, 97.4%), ce_loss 1.043, lat_loss 6.659
09/18 09:41:24 PM | Valid: [ 30/180] Step 300/312 Loss 1.176 Prec@(1,3) (70.4%, 97.5%), ce_loss 1.043, lat_loss 6.659
09/18 09:41:25 PM | Valid: [ 30/180] Step 312/312 Loss 1.172 Prec@(1,3) (70.5%, 97.5%), ce_loss 1.043, lat_loss 6.659
09/18 09:41:25 PM | val: [ 30/180] Final Prec@1 70.4900% Time 30.68
09/18 09:41:25 PM | Start to train weights for epoch 30
09/18 09:41:51 PM | Train: [ 31/180] Step 050/1249 Loss 0.964 Prec@(1,3) (74.3%, 99.1%), ce_loss 1.042, lat_loss 6.659
09/18 09:42:14 PM | Train: [ 31/180] Step 100/1249 Loss 1.044 Prec@(1,3) (72.9%, 98.4%), ce_loss 1.042, lat_loss 6.659
09/18 09:42:36 PM | Train: [ 31/180] Step 150/1249 Loss 1.024 Prec@(1,3) (73.7%, 98.2%), ce_loss 1.042, lat_loss 6.659
09/18 09:42:58 PM | Train: [ 31/180] Step 200/1249 Loss 1.033 Prec@(1,3) (73.7%, 98.1%), ce_loss 1.042, lat_loss 6.659
09/18 09:43:20 PM | Train: [ 31/180] Step 250/1249 Loss 1.024 Prec@(1,3) (73.9%, 98.2%), ce_loss 1.041, lat_loss 6.659
09/18 09:43:42 PM | Train: [ 31/180] Step 300/1249 Loss 1.016 Prec@(1,3) (74.1%, 98.2%), ce_loss 1.041, lat_loss 6.659
09/18 09:44:03 PM | Train: [ 31/180] Step 350/1249 Loss 1.014 Prec@(1,3) (74.0%, 98.3%), ce_loss 1.041, lat_loss 6.659
09/18 09:44:25 PM | Train: [ 31/180] Step 400/1249 Loss 1.015 Prec@(1,3) (74.0%, 98.2%), ce_loss 1.040, lat_loss 6.659
09/18 09:44:49 PM | Train: [ 31/180] Step 450/1249 Loss 1.017 Prec@(1,3) (74.0%, 98.2%), ce_loss 1.040, lat_loss 6.659
09/18 09:45:12 PM | Train: [ 31/180] Step 500/1249 Loss 1.014 Prec@(1,3) (74.1%, 98.1%), ce_loss 1.040, lat_loss 6.659
09/18 09:45:36 PM | Train: [ 31/180] Step 550/1249 Loss 1.017 Prec@(1,3) (74.1%, 98.1%), ce_loss 1.040, lat_loss 6.659
09/18 09:46:01 PM | Train: [ 31/180] Step 600/1249 Loss 1.019 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.039, lat_loss 6.659
09/18 09:46:26 PM | Train: [ 31/180] Step 650/1249 Loss 1.019 Prec@(1,3) (73.9%, 98.2%), ce_loss 1.039, lat_loss 6.659
09/18 09:46:50 PM | Train: [ 31/180] Step 700/1249 Loss 1.023 Prec@(1,3) (73.8%, 98.2%), ce_loss 1.039, lat_loss 6.659
09/18 09:47:15 PM | Train: [ 31/180] Step 750/1249 Loss 1.023 Prec@(1,3) (73.7%, 98.2%), ce_loss 1.039, lat_loss 6.659
09/18 09:47:40 PM | Train: [ 31/180] Step 800/1249 Loss 1.022 Prec@(1,3) (73.8%, 98.1%), ce_loss 1.038, lat_loss 6.659
09/18 09:48:04 PM | Train: [ 31/180] Step 850/1249 Loss 1.023 Prec@(1,3) (73.8%, 98.1%), ce_loss 1.038, lat_loss 6.659
09/18 09:48:29 PM | Train: [ 31/180] Step 900/1249 Loss 1.019 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.038, lat_loss 6.659
09/18 09:48:53 PM | Train: [ 31/180] Step 950/1249 Loss 1.018 Prec@(1,3) (74.0%, 98.1%), ce_loss 1.037, lat_loss 6.659
09/18 09:49:17 PM | Train: [ 31/180] Step 1000/1249 Loss 1.018 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.037, lat_loss 6.659
09/18 09:49:40 PM | Train: [ 31/180] Step 1050/1249 Loss 1.020 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.037, lat_loss 6.659
09/18 09:50:05 PM | Train: [ 31/180] Step 1100/1249 Loss 1.017 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.037, lat_loss 6.659
09/18 09:50:30 PM | Train: [ 31/180] Step 1150/1249 Loss 1.016 Prec@(1,3) (74.0%, 98.1%), ce_loss 1.036, lat_loss 6.659
09/18 09:50:55 PM | Train: [ 31/180] Step 1200/1249 Loss 1.019 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.036, lat_loss 6.659
09/18 09:51:20 PM | Train: [ 31/180] Step 1249/1249 Loss 1.018 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.036, lat_loss 6.659
09/18 09:51:20 PM | _w_step_train: [ 31/180] Final Prec@1 73.8875% Time 594.44
09/18 09:51:20 PM | Start to train theta for epoch 30
09/18 09:51:33 PM | Train: [ 31/180] Step 050/312 Loss 1.106 Prec@(1,3) (71.6%, 97.2%), ce_loss 1.036, lat_loss 6.659
09/18 09:51:45 PM | Train: [ 31/180] Step 100/312 Loss 1.062 Prec@(1,3) (72.8%, 97.5%), ce_loss 1.035, lat_loss 6.659
09/18 09:51:58 PM | Train: [ 31/180] Step 150/312 Loss 1.055 Prec@(1,3) (73.0%, 97.6%), ce_loss 1.035, lat_loss 6.659
09/18 09:52:10 PM | Train: [ 31/180] Step 200/312 Loss 1.063 Prec@(1,3) (73.0%, 97.6%), ce_loss 1.035, lat_loss 6.659
09/18 09:52:22 PM | Train: [ 31/180] Step 250/312 Loss 1.067 Prec@(1,3) (72.8%, 97.6%), ce_loss 1.035, lat_loss 6.659
09/18 09:52:34 PM | Train: [ 31/180] Step 300/312 Loss 1.065 Prec@(1,3) (72.7%, 97.8%), ce_loss 1.034, lat_loss 6.659
09/18 09:52:38 PM | Train: [ 31/180] Step 312/312 Loss 1.062 Prec@(1,3) (72.8%, 97.8%), ce_loss 1.034, lat_loss 6.659
09/18 09:52:38 PM | _theta_step_train: [ 31/180] Final Prec@1 72.8300% Time 78.11
09/18 09:52:43 PM | Valid: [ 31/180] Step 050/312 Loss 1.174 Prec@(1,3) (70.6%, 97.6%), ce_loss 1.034, lat_loss 6.659
09/18 09:52:47 PM | Valid: [ 31/180] Step 100/312 Loss 1.224 Prec@(1,3) (69.5%, 97.2%), ce_loss 1.034, lat_loss 6.659
09/18 09:52:52 PM | Valid: [ 31/180] Step 150/312 Loss 1.208 Prec@(1,3) (69.7%, 97.1%), ce_loss 1.034, lat_loss 6.659
09/18 09:52:57 PM | Valid: [ 31/180] Step 200/312 Loss 1.210 Prec@(1,3) (69.6%, 97.4%), ce_loss 1.034, lat_loss 6.659
09/18 09:53:01 PM | Valid: [ 31/180] Step 250/312 Loss 1.213 Prec@(1,3) (69.4%, 97.3%), ce_loss 1.034, lat_loss 6.659
09/18 09:53:06 PM | Valid: [ 31/180] Step 300/312 Loss 1.188 Prec@(1,3) (70.1%, 97.5%), ce_loss 1.034, lat_loss 6.659
09/18 09:53:07 PM | Valid: [ 31/180] Step 312/312 Loss 1.190 Prec@(1,3) (70.1%, 97.5%), ce_loss 1.034, lat_loss 6.659
09/18 09:53:07 PM | val: [ 31/180] Final Prec@1 70.0600% Time 29.32
09/18 09:53:07 PM | Start to train weights for epoch 31
09/18 09:53:32 PM | Train: [ 32/180] Step 050/1249 Loss 1.074 Prec@(1,3) (72.7%, 97.4%), ce_loss 1.033, lat_loss 6.659
09/18 09:53:55 PM | Train: [ 32/180] Step 100/1249 Loss 1.007 Prec@(1,3) (74.0%, 97.9%), ce_loss 1.033, lat_loss 6.659
09/18 09:54:17 PM | Train: [ 32/180] Step 150/1249 Loss 1.009 Prec@(1,3) (73.8%, 98.0%), ce_loss 1.033, lat_loss 6.659
09/18 09:54:41 PM | Train: [ 32/180] Step 200/1249 Loss 1.014 Prec@(1,3) (73.7%, 98.2%), ce_loss 1.033, lat_loss 6.659
09/18 09:55:04 PM | Train: [ 32/180] Step 250/1249 Loss 1.000 Prec@(1,3) (74.4%, 98.2%), ce_loss 1.032, lat_loss 6.659
09/18 09:55:26 PM | Train: [ 32/180] Step 300/1249 Loss 1.009 Prec@(1,3) (74.2%, 98.2%), ce_loss 1.032, lat_loss 6.659
09/18 09:55:49 PM | Train: [ 32/180] Step 350/1249 Loss 1.008 Prec@(1,3) (74.2%, 98.2%), ce_loss 1.032, lat_loss 6.659
09/18 09:56:13 PM | Train: [ 32/180] Step 400/1249 Loss 1.020 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.032, lat_loss 6.659
09/18 09:56:36 PM | Train: [ 32/180] Step 450/1249 Loss 1.020 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.031, lat_loss 6.659
09/18 09:56:58 PM | Train: [ 32/180] Step 500/1249 Loss 1.017 Prec@(1,3) (74.0%, 98.1%), ce_loss 1.031, lat_loss 6.659
09/18 09:57:22 PM | Train: [ 32/180] Step 550/1249 Loss 1.020 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.031, lat_loss 6.659
09/18 09:57:46 PM | Train: [ 32/180] Step 600/1249 Loss 1.024 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.031, lat_loss 6.659
09/18 09:58:10 PM | Train: [ 32/180] Step 650/1249 Loss 1.023 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.030, lat_loss 6.659
09/18 09:58:33 PM | Train: [ 32/180] Step 700/1249 Loss 1.027 Prec@(1,3) (73.8%, 98.1%), ce_loss 1.030, lat_loss 6.659
09/18 09:58:56 PM | Train: [ 32/180] Step 750/1249 Loss 1.027 Prec@(1,3) (73.7%, 98.1%), ce_loss 1.030, lat_loss 6.659
09/18 09:59:20 PM | Train: [ 32/180] Step 800/1249 Loss 1.023 Prec@(1,3) (73.8%, 98.1%), ce_loss 1.030, lat_loss 6.659
09/18 09:59:43 PM | Train: [ 32/180] Step 850/1249 Loss 1.023 Prec@(1,3) (73.8%, 98.2%), ce_loss 1.029, lat_loss 6.659
09/18 10:00:07 PM | Train: [ 32/180] Step 900/1249 Loss 1.021 Prec@(1,3) (73.8%, 98.2%), ce_loss 1.029, lat_loss 6.659
09/18 10:00:30 PM | Train: [ 32/180] Step 950/1249 Loss 1.018 Prec@(1,3) (73.8%, 98.2%), ce_loss 1.029, lat_loss 6.659
09/18 10:00:52 PM | Train: [ 32/180] Step 1000/1249 Loss 1.021 Prec@(1,3) (73.7%, 98.1%), ce_loss 1.028, lat_loss 6.659
09/18 10:01:13 PM | Train: [ 32/180] Step 1050/1249 Loss 1.020 Prec@(1,3) (73.8%, 98.1%), ce_loss 1.028, lat_loss 6.659
09/18 10:01:35 PM | Train: [ 32/180] Step 1100/1249 Loss 1.019 Prec@(1,3) (73.8%, 98.2%), ce_loss 1.028, lat_loss 6.659
09/18 10:02:00 PM | Train: [ 32/180] Step 1150/1249 Loss 1.019 Prec@(1,3) (73.8%, 98.1%), ce_loss 1.028, lat_loss 6.659
09/18 10:02:25 PM | Train: [ 32/180] Step 1200/1249 Loss 1.017 Prec@(1,3) (73.8%, 98.1%), ce_loss 1.027, lat_loss 6.659
09/18 10:02:49 PM | Train: [ 32/180] Step 1249/1249 Loss 1.016 Prec@(1,3) (73.8%, 98.2%), ce_loss 1.027, lat_loss 6.659
09/18 10:02:49 PM | _w_step_train: [ 32/180] Final Prec@1 73.8100% Time 582.36
09/18 10:02:49 PM | Start to train theta for epoch 31
09/18 10:03:11 PM | Train: [ 32/180] Step 050/312 Loss 1.125 Prec@(1,3) (70.4%, 97.9%), ce_loss 1.027, lat_loss 6.659
09/18 10:03:32 PM | Train: [ 32/180] Step 100/312 Loss 1.091 Prec@(1,3) (71.3%, 98.1%), ce_loss 1.027, lat_loss 6.659
09/18 10:03:52 PM | Train: [ 32/180] Step 150/312 Loss 1.072 Prec@(1,3) (72.1%, 98.0%), ce_loss 1.027, lat_loss 6.659
09/18 10:04:13 PM | Train: [ 32/180] Step 200/312 Loss 1.059 Prec@(1,3) (72.6%, 98.0%), ce_loss 1.026, lat_loss 6.659
09/18 10:04:34 PM | Train: [ 32/180] Step 250/312 Loss 1.071 Prec@(1,3) (72.6%, 98.0%), ce_loss 1.026, lat_loss 6.659
09/18 10:04:54 PM | Train: [ 32/180] Step 300/312 Loss 1.074 Prec@(1,3) (72.5%, 97.8%), ce_loss 1.026, lat_loss 6.659
09/18 10:04:59 PM | Train: [ 32/180] Step 312/312 Loss 1.074 Prec@(1,3) (72.5%, 97.8%), ce_loss 1.026, lat_loss 6.659
09/18 10:05:00 PM | _theta_step_train: [ 32/180] Final Prec@1 72.4800% Time 130.11
09/18 10:05:05 PM | Valid: [ 32/180] Step 050/312 Loss 1.146 Prec@(1,3) (70.7%, 97.5%), ce_loss 1.026, lat_loss 6.659
09/18 10:05:09 PM | Valid: [ 32/180] Step 100/312 Loss 1.205 Prec@(1,3) (70.2%, 97.0%), ce_loss 1.026, lat_loss 6.659
09/18 10:05:14 PM | Valid: [ 32/180] Step 150/312 Loss 1.232 Prec@(1,3) (69.9%, 96.9%), ce_loss 1.026, lat_loss 6.659
09/18 10:05:19 PM | Valid: [ 32/180] Step 200/312 Loss 1.236 Prec@(1,3) (69.8%, 97.0%), ce_loss 1.026, lat_loss 6.659
09/18 10:05:24 PM | Valid: [ 32/180] Step 250/312 Loss 1.226 Prec@(1,3) (70.2%, 97.1%), ce_loss 1.025, lat_loss 6.659
09/18 10:05:28 PM | Valid: [ 32/180] Step 300/312 Loss 1.234 Prec@(1,3) (70.2%, 97.0%), ce_loss 1.025, lat_loss 6.659
09/18 10:05:29 PM | Valid: [ 32/180] Step 312/312 Loss 1.226 Prec@(1,3) (70.3%, 97.1%), ce_loss 1.025, lat_loss 6.659
09/18 10:05:29 PM | val: [ 32/180] Final Prec@1 70.2800% Time 29.82
09/18 10:05:29 PM | Start to train weights for epoch 32
09/18 10:05:56 PM | Train: [ 33/180] Step 050/1249 Loss 1.044 Prec@(1,3) (73.4%, 98.2%), ce_loss 1.025, lat_loss 6.659
09/18 10:06:21 PM | Train: [ 33/180] Step 100/1249 Loss 1.012 Prec@(1,3) (73.9%, 98.3%), ce_loss 1.025, lat_loss 6.660
09/18 10:06:45 PM | Train: [ 33/180] Step 150/1249 Loss 1.024 Prec@(1,3) (73.8%, 98.4%), ce_loss 1.025, lat_loss 6.660
09/18 10:07:07 PM | Train: [ 33/180] Step 200/1249 Loss 1.025 Prec@(1,3) (73.8%, 98.3%), ce_loss 1.024, lat_loss 6.660
09/18 10:07:30 PM | Train: [ 33/180] Step 250/1249 Loss 1.032 Prec@(1,3) (73.7%, 98.3%), ce_loss 1.024, lat_loss 6.660
09/18 10:07:53 PM | Train: [ 33/180] Step 300/1249 Loss 1.021 Prec@(1,3) (73.9%, 98.2%), ce_loss 1.024, lat_loss 6.660
09/18 10:08:15 PM | Train: [ 33/180] Step 350/1249 Loss 1.017 Prec@(1,3) (73.9%, 98.2%), ce_loss 1.024, lat_loss 6.660
09/18 10:08:37 PM | Train: [ 33/180] Step 400/1249 Loss 1.010 Prec@(1,3) (74.0%, 98.3%), ce_loss 1.023, lat_loss 6.660
09/18 10:09:01 PM | Train: [ 33/180] Step 450/1249 Loss 1.007 Prec@(1,3) (74.1%, 98.3%), ce_loss 1.023, lat_loss 6.660
09/18 10:09:25 PM | Train: [ 33/180] Step 500/1249 Loss 1.018 Prec@(1,3) (74.0%, 98.2%), ce_loss 1.023, lat_loss 6.660
09/18 10:09:50 PM | Train: [ 33/180] Step 550/1249 Loss 1.019 Prec@(1,3) (73.9%, 98.2%), ce_loss 1.023, lat_loss 6.660
09/18 10:10:14 PM | Train: [ 33/180] Step 600/1249 Loss 1.017 Prec@(1,3) (73.9%, 98.2%), ce_loss 1.022, lat_loss 6.660
09/18 10:10:36 PM | Train: [ 33/180] Step 650/1249 Loss 1.018 Prec@(1,3) (73.9%, 98.2%), ce_loss 1.022, lat_loss 6.660
09/18 10:10:59 PM | Train: [ 33/180] Step 700/1249 Loss 1.018 Prec@(1,3) (74.0%, 98.2%), ce_loss 1.022, lat_loss 6.660
09/18 10:11:21 PM | Train: [ 33/180] Step 750/1249 Loss 1.016 Prec@(1,3) (74.1%, 98.2%), ce_loss 1.022, lat_loss 6.660
09/18 10:11:42 PM | Train: [ 33/180] Step 800/1249 Loss 1.013 Prec@(1,3) (74.2%, 98.2%), ce_loss 1.021, lat_loss 6.660
09/18 10:12:05 PM | Train: [ 33/180] Step 850/1249 Loss 1.012 Prec@(1,3) (74.2%, 98.2%), ce_loss 1.021, lat_loss 6.660
09/18 10:12:27 PM | Train: [ 33/180] Step 900/1249 Loss 1.011 Prec@(1,3) (74.3%, 98.2%), ce_loss 1.021, lat_loss 6.660
09/18 10:12:48 PM | Train: [ 33/180] Step 950/1249 Loss 1.010 Prec@(1,3) (74.3%, 98.2%), ce_loss 1.021, lat_loss 6.660
09/18 10:13:10 PM | Train: [ 33/180] Step 1000/1249 Loss 1.006 Prec@(1,3) (74.4%, 98.2%), ce_loss 1.020, lat_loss 6.660
09/18 10:13:33 PM | Train: [ 33/180] Step 1050/1249 Loss 1.008 Prec@(1,3) (74.3%, 98.2%), ce_loss 1.020, lat_loss 6.660
09/18 10:13:57 PM | Train: [ 33/180] Step 1100/1249 Loss 1.009 Prec@(1,3) (74.3%, 98.1%), ce_loss 1.020, lat_loss 6.660
09/18 10:14:21 PM | Train: [ 33/180] Step 1150/1249 Loss 1.011 Prec@(1,3) (74.3%, 98.1%), ce_loss 1.020, lat_loss 6.660
09/18 10:14:45 PM | Train: [ 33/180] Step 1200/1249 Loss 1.010 Prec@(1,3) (74.3%, 98.1%), ce_loss 1.019, lat_loss 6.660
09/18 10:15:09 PM | Train: [ 33/180] Step 1249/1249 Loss 1.008 Prec@(1,3) (74.3%, 98.1%), ce_loss 1.019, lat_loss 6.660
09/18 10:15:09 PM | _w_step_train: [ 33/180] Final Prec@1 74.2950% Time 579.85
09/18 10:15:09 PM | Start to train theta for epoch 32
09/18 10:15:29 PM | Train: [ 33/180] Step 050/312 Loss 0.995 Prec@(1,3) (74.4%, 98.3%), ce_loss 1.019, lat_loss 6.660
09/18 10:15:49 PM | Train: [ 33/180] Step 100/312 Loss 1.009 Prec@(1,3) (74.3%, 98.0%), ce_loss 1.019, lat_loss 6.660
09/18 10:16:08 PM | Train: [ 33/180] Step 150/312 Loss 1.018 Prec@(1,3) (74.0%, 98.2%), ce_loss 1.018, lat_loss 6.660
09/18 10:16:28 PM | Train: [ 33/180] Step 200/312 Loss 1.035 Prec@(1,3) (73.6%, 98.0%), ce_loss 1.018, lat_loss 6.660
09/18 10:16:47 PM | Train: [ 33/180] Step 250/312 Loss 1.041 Prec@(1,3) (73.5%, 98.0%), ce_loss 1.018, lat_loss 6.660
09/18 10:17:06 PM | Train: [ 33/180] Step 300/312 Loss 1.036 Prec@(1,3) (73.6%, 98.0%), ce_loss 1.018, lat_loss 6.660
09/18 10:17:10 PM | Train: [ 33/180] Step 312/312 Loss 1.032 Prec@(1,3) (73.6%, 98.0%), ce_loss 1.018, lat_loss 6.660
09/18 10:17:10 PM | _theta_step_train: [ 33/180] Final Prec@1 73.6400% Time 120.84
09/18 10:17:15 PM | Valid: [ 33/180] Step 050/312 Loss 1.258 Prec@(1,3) (67.2%, 97.9%), ce_loss 1.018, lat_loss 6.660
09/18 10:17:20 PM | Valid: [ 33/180] Step 100/312 Loss 1.251 Prec@(1,3) (67.8%, 97.3%), ce_loss 1.018, lat_loss 6.660
09/18 10:17:25 PM | Valid: [ 33/180] Step 150/312 Loss 1.248 Prec@(1,3) (68.4%, 96.9%), ce_loss 1.018, lat_loss 6.660
09/18 10:17:29 PM | Valid: [ 33/180] Step 200/312 Loss 1.256 Prec@(1,3) (68.3%, 97.1%), ce_loss 1.017, lat_loss 6.660
09/18 10:17:34 PM | Valid: [ 33/180] Step 250/312 Loss 1.251 Prec@(1,3) (68.3%, 97.0%), ce_loss 1.017, lat_loss 6.660
09/18 10:17:39 PM | Valid: [ 33/180] Step 300/312 Loss 1.252 Prec@(1,3) (68.3%, 96.9%), ce_loss 1.017, lat_loss 6.660
09/18 10:17:40 PM | Valid: [ 33/180] Step 312/312 Loss 1.250 Prec@(1,3) (68.3%, 96.9%), ce_loss 1.017, lat_loss 6.660
09/18 10:17:40 PM | val: [ 33/180] Final Prec@1 68.3000% Time 29.99
09/18 10:17:40 PM | Start to train weights for epoch 33
09/18 10:18:06 PM | Train: [ 34/180] Step 050/1249 Loss 0.928 Prec@(1,3) (76.1%, 98.2%), ce_loss 1.017, lat_loss 6.660
09/18 10:18:29 PM | Train: [ 34/180] Step 100/1249 Loss 0.933 Prec@(1,3) (76.0%, 98.2%), ce_loss 1.017, lat_loss 6.660
09/18 10:18:52 PM | Train: [ 34/180] Step 150/1249 Loss 0.965 Prec@(1,3) (75.0%, 98.1%), ce_loss 1.016, lat_loss 6.660
09/18 10:19:15 PM | Train: [ 34/180] Step 200/1249 Loss 0.970 Prec@(1,3) (74.8%, 98.2%), ce_loss 1.016, lat_loss 6.660
09/18 10:19:38 PM | Train: [ 34/180] Step 250/1249 Loss 0.982 Prec@(1,3) (74.5%, 98.1%), ce_loss 1.016, lat_loss 6.660
09/18 10:20:01 PM | Train: [ 34/180] Step 300/1249 Loss 0.989 Prec@(1,3) (74.1%, 98.2%), ce_loss 1.016, lat_loss 6.660
09/18 10:20:25 PM | Train: [ 34/180] Step 350/1249 Loss 0.994 Prec@(1,3) (74.0%, 98.1%), ce_loss 1.016, lat_loss 6.660
09/18 10:20:48 PM | Train: [ 34/180] Step 400/1249 Loss 0.991 Prec@(1,3) (74.1%, 98.1%), ce_loss 1.015, lat_loss 6.660
09/18 10:21:14 PM | Train: [ 34/180] Step 450/1249 Loss 0.996 Prec@(1,3) (74.0%, 98.2%), ce_loss 1.015, lat_loss 6.660
09/18 10:21:38 PM | Train: [ 34/180] Step 500/1249 Loss 0.989 Prec@(1,3) (74.2%, 98.2%), ce_loss 1.015, lat_loss 6.660
09/18 10:22:03 PM | Train: [ 34/180] Step 550/1249 Loss 0.994 Prec@(1,3) (74.1%, 98.1%), ce_loss 1.015, lat_loss 6.660
09/18 10:22:28 PM | Train: [ 34/180] Step 600/1249 Loss 1.002 Prec@(1,3) (73.9%, 98.2%), ce_loss 1.014, lat_loss 6.660
09/18 10:22:53 PM | Train: [ 34/180] Step 650/1249 Loss 1.005 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.014, lat_loss 6.660
09/18 10:23:18 PM | Train: [ 34/180] Step 700/1249 Loss 1.005 Prec@(1,3) (74.0%, 98.1%), ce_loss 1.014, lat_loss 6.660
09/18 10:23:43 PM | Train: [ 34/180] Step 750/1249 Loss 1.005 Prec@(1,3) (74.0%, 98.1%), ce_loss 1.014, lat_loss 6.660
09/18 10:24:08 PM | Train: [ 34/180] Step 800/1249 Loss 1.007 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.014, lat_loss 6.660
09/18 10:24:33 PM | Train: [ 34/180] Step 850/1249 Loss 1.009 Prec@(1,3) (73.8%, 98.1%), ce_loss 1.013, lat_loss 6.660
09/18 10:24:56 PM | Train: [ 34/180] Step 900/1249 Loss 1.012 Prec@(1,3) (73.8%, 98.1%), ce_loss 1.013, lat_loss 6.660
09/18 10:25:20 PM | Train: [ 34/180] Step 950/1249 Loss 1.011 Prec@(1,3) (73.8%, 98.1%), ce_loss 1.013, lat_loss 6.660
09/18 10:25:45 PM | Train: [ 34/180] Step 1000/1249 Loss 1.011 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.013, lat_loss 6.660
09/18 10:26:04 PM | Train: [ 34/180] Step 1050/1249 Loss 1.013 Prec@(1,3) (73.8%, 98.1%), ce_loss 1.012, lat_loss 6.660
09/18 10:26:20 PM | Train: [ 34/180] Step 1100/1249 Loss 1.012 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.012, lat_loss 6.660
09/18 10:26:36 PM | Train: [ 34/180] Step 1150/1249 Loss 1.012 Prec@(1,3) (73.8%, 98.1%), ce_loss 1.012, lat_loss 6.660
09/18 10:26:52 PM | Train: [ 34/180] Step 1200/1249 Loss 1.011 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.012, lat_loss 6.660
09/18 10:27:08 PM | Train: [ 34/180] Step 1249/1249 Loss 1.009 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.012, lat_loss 6.660
09/18 10:27:08 PM | _w_step_train: [ 34/180] Final Prec@1 73.8925% Time 567.46
09/18 10:27:08 PM | Start to train theta for epoch 33
09/18 10:27:29 PM | Train: [ 34/180] Step 050/312 Loss 1.052 Prec@(1,3) (72.8%, 98.0%), ce_loss 1.011, lat_loss 6.660
09/18 10:27:49 PM | Train: [ 34/180] Step 100/312 Loss 1.053 Prec@(1,3) (73.2%, 98.1%), ce_loss 1.011, lat_loss 6.660
09/18 10:28:09 PM | Train: [ 34/180] Step 150/312 Loss 1.068 Prec@(1,3) (72.9%, 98.0%), ce_loss 1.011, lat_loss 6.660
09/18 10:28:27 PM | Train: [ 34/180] Step 200/312 Loss 1.056 Prec@(1,3) (73.2%, 97.8%), ce_loss 1.011, lat_loss 6.660
09/18 10:28:46 PM | Train: [ 34/180] Step 250/312 Loss 1.052 Prec@(1,3) (73.2%, 97.9%), ce_loss 1.011, lat_loss 6.660
09/18 10:29:05 PM | Train: [ 34/180] Step 300/312 Loss 1.051 Prec@(1,3) (73.5%, 97.8%), ce_loss 1.010, lat_loss 6.660
09/18 10:29:10 PM | Train: [ 34/180] Step 312/312 Loss 1.052 Prec@(1,3) (73.5%, 97.8%), ce_loss 1.010, lat_loss 6.660
09/18 10:29:10 PM | _theta_step_train: [ 34/180] Final Prec@1 73.5300% Time 122.33
09/18 10:29:15 PM | Valid: [ 34/180] Step 050/312 Loss 1.239 Prec@(1,3) (68.7%, 97.2%), ce_loss 1.010, lat_loss 6.660
09/18 10:29:20 PM | Valid: [ 34/180] Step 100/312 Loss 1.253 Prec@(1,3) (68.6%, 97.3%), ce_loss 1.010, lat_loss 6.660
09/18 10:29:25 PM | Valid: [ 34/180] Step 150/312 Loss 1.240 Prec@(1,3) (69.1%, 97.5%), ce_loss 1.010, lat_loss 6.660
09/18 10:29:29 PM | Valid: [ 34/180] Step 200/312 Loss 1.255 Prec@(1,3) (68.5%, 97.5%), ce_loss 1.010, lat_loss 6.660
09/18 10:29:34 PM | Valid: [ 34/180] Step 250/312 Loss 1.252 Prec@(1,3) (68.8%, 97.3%), ce_loss 1.010, lat_loss 6.660
09/18 10:29:38 PM | Valid: [ 34/180] Step 300/312 Loss 1.265 Prec@(1,3) (68.5%, 97.2%), ce_loss 1.010, lat_loss 6.660
09/18 10:29:40 PM | Valid: [ 34/180] Step 312/312 Loss 1.270 Prec@(1,3) (68.3%, 97.2%), ce_loss 1.010, lat_loss 6.660
09/18 10:29:40 PM | val: [ 34/180] Final Prec@1 68.3400% Time 29.66
09/18 10:29:40 PM | Start to train weights for epoch 34
09/18 10:30:05 PM | Train: [ 35/180] Step 050/1249 Loss 1.033 Prec@(1,3) (71.9%, 98.0%), ce_loss 1.010, lat_loss 6.660
09/18 10:30:25 PM | Train: [ 35/180] Step 100/1249 Loss 1.031 Prec@(1,3) (72.3%, 98.3%), ce_loss 1.010, lat_loss 6.660
09/18 10:30:46 PM | Train: [ 35/180] Step 150/1249 Loss 1.016 Prec@(1,3) (72.7%, 98.2%), ce_loss 1.009, lat_loss 6.660
09/18 10:31:07 PM | Train: [ 35/180] Step 200/1249 Loss 1.007 Prec@(1,3) (73.1%, 98.3%), ce_loss 1.009, lat_loss 6.660
09/18 10:31:29 PM | Train: [ 35/180] Step 250/1249 Loss 1.009 Prec@(1,3) (73.3%, 98.2%), ce_loss 1.009, lat_loss 6.660
09/18 10:31:50 PM | Train: [ 35/180] Step 300/1249 Loss 0.996 Prec@(1,3) (73.7%, 98.2%), ce_loss 1.009, lat_loss 6.660
09/18 10:32:11 PM | Train: [ 35/180] Step 350/1249 Loss 1.003 Prec@(1,3) (73.7%, 98.2%), ce_loss 1.008, lat_loss 6.660
09/18 10:32:32 PM | Train: [ 35/180] Step 400/1249 Loss 0.998 Prec@(1,3) (73.8%, 98.2%), ce_loss 1.008, lat_loss 6.660
09/18 10:32:55 PM | Train: [ 35/180] Step 450/1249 Loss 1.006 Prec@(1,3) (73.6%, 98.1%), ce_loss 1.008, lat_loss 6.660
09/18 10:33:16 PM | Train: [ 35/180] Step 500/1249 Loss 1.009 Prec@(1,3) (73.6%, 98.1%), ce_loss 1.008, lat_loss 6.660
09/18 10:33:37 PM | Train: [ 35/180] Step 550/1249 Loss 1.012 Prec@(1,3) (73.5%, 98.1%), ce_loss 1.008, lat_loss 6.660
09/18 10:33:58 PM | Train: [ 35/180] Step 600/1249 Loss 1.011 Prec@(1,3) (73.7%, 98.1%), ce_loss 1.007, lat_loss 6.660
09/18 10:34:20 PM | Train: [ 35/180] Step 650/1249 Loss 1.011 Prec@(1,3) (73.7%, 98.1%), ce_loss 1.007, lat_loss 6.660
09/18 10:34:41 PM | Train: [ 35/180] Step 700/1249 Loss 1.006 Prec@(1,3) (73.8%, 98.1%), ce_loss 1.007, lat_loss 6.661
09/18 10:35:03 PM | Train: [ 35/180] Step 750/1249 Loss 1.007 Prec@(1,3) (73.8%, 98.1%), ce_loss 1.007, lat_loss 6.661
09/18 10:35:25 PM | Train: [ 35/180] Step 800/1249 Loss 1.005 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.006, lat_loss 6.661
09/18 10:35:44 PM | Train: [ 35/180] Step 850/1249 Loss 1.004 Prec@(1,3) (73.9%, 98.1%), ce_loss 1.006, lat_loss 6.661
09/18 10:36:03 PM | Train: [ 35/180] Step 900/1249 Loss 1.001 Prec@(1,3) (74.0%, 98.1%), ce_loss 1.006, lat_loss 6.661
09/18 10:36:23 PM | Train: [ 35/180] Step 950/1249 Loss 0.997 Prec@(1,3) (74.1%, 98.1%), ce_loss 1.006, lat_loss 6.661
09/18 10:36:45 PM | Train: [ 35/180] Step 1000/1249 Loss 0.998 Prec@(1,3) (74.1%, 98.2%), ce_loss 1.006, lat_loss 6.661
09/18 10:37:05 PM | Train: [ 35/180] Step 1050/1249 Loss 1.001 Prec@(1,3) (74.0%, 98.2%), ce_loss 1.005, lat_loss 6.661
09/18 10:37:25 PM | Train: [ 35/180] Step 1100/1249 Loss 1.001 Prec@(1,3) (74.1%, 98.2%), ce_loss 1.005, lat_loss 6.661
09/18 10:37:47 PM | Train: [ 35/180] Step 1150/1249 Loss 1.000 Prec@(1,3) (74.1%, 98.2%), ce_loss 1.005, lat_loss 6.661
09/18 10:38:09 PM | Train: [ 35/180] Step 1200/1249 Loss 0.998 Prec@(1,3) (74.1%, 98.2%), ce_loss 1.005, lat_loss 6.661
09/18 10:38:34 PM | Train: [ 35/180] Step 1249/1249 Loss 0.998 Prec@(1,3) (74.2%, 98.2%), ce_loss 1.004, lat_loss 6.661
09/18 10:38:34 PM | _w_step_train: [ 35/180] Final Prec@1 74.1550% Time 534.29
09/18 10:38:34 PM | Start to train theta for epoch 34
09/18 10:38:54 PM | Train: [ 35/180] Step 050/312 Loss 1.076 Prec@(1,3) (71.6%, 97.5%), ce_loss 1.004, lat_loss 6.661
09/18 10:39:11 PM | Train: [ 35/180] Step 100/312 Loss 1.090 Prec@(1,3) (71.4%, 97.4%), ce_loss 1.004, lat_loss 6.661
09/18 10:39:28 PM | Train: [ 35/180] Step 150/312 Loss 1.067 Prec@(1,3) (72.1%, 97.5%), ce_loss 1.004, lat_loss 6.661
09/18 10:39:45 PM | Train: [ 35/180] Step 200/312 Loss 1.053 Prec@(1,3) (72.4%, 97.7%), ce_loss 1.004, lat_loss 6.661
09/18 10:40:05 PM | Train: [ 35/180] Step 250/312 Loss 1.044 Prec@(1,3) (72.7%, 97.7%), ce_loss 1.003, lat_loss 6.661
09/18 10:40:24 PM | Train: [ 35/180] Step 300/312 Loss 1.042 Prec@(1,3) (72.6%, 97.8%), ce_loss 1.003, lat_loss 6.661
09/18 10:40:29 PM | Train: [ 35/180] Step 312/312 Loss 1.040 Prec@(1,3) (72.7%, 97.8%), ce_loss 1.003, lat_loss 6.661
09/18 10:40:30 PM | _theta_step_train: [ 35/180] Final Prec@1 72.7000% Time 115.57
09/18 10:40:34 PM | Valid: [ 35/180] Step 050/312 Loss 1.257 Prec@(1,3) (67.0%, 96.9%), ce_loss 1.003, lat_loss 6.661
09/18 10:40:39 PM | Valid: [ 35/180] Step 100/312 Loss 1.301 Prec@(1,3) (66.2%, 96.7%), ce_loss 1.003, lat_loss 6.661
09/18 10:40:43 PM | Valid: [ 35/180] Step 150/312 Loss 1.326 Prec@(1,3) (65.8%, 96.7%), ce_loss 1.003, lat_loss 6.661
09/18 10:40:47 PM | Valid: [ 35/180] Step 200/312 Loss 1.359 Prec@(1,3) (65.1%, 96.4%), ce_loss 1.003, lat_loss 6.661
09/18 10:40:51 PM | Valid: [ 35/180] Step 250/312 Loss 1.363 Prec@(1,3) (64.9%, 96.4%), ce_loss 1.003, lat_loss 6.661
09/18 10:40:56 PM | Valid: [ 35/180] Step 300/312 Loss 1.355 Prec@(1,3) (65.2%, 96.4%), ce_loss 1.003, lat_loss 6.661
09/18 10:40:57 PM | Valid: [ 35/180] Step 312/312 Loss 1.361 Prec@(1,3) (65.1%, 96.4%), ce_loss 1.003, lat_loss 6.661
09/18 10:40:57 PM | val: [ 35/180] Final Prec@1 65.0800% Time 27.12
09/18 10:40:57 PM | Start to train weights for epoch 35
09/18 10:41:21 PM | Train: [ 36/180] Step 050/1249 Loss 1.001 Prec@(1,3) (74.9%, 97.8%), ce_loss 1.003, lat_loss 6.661
09/18 10:41:42 PM | Train: [ 36/180] Step 100/1249 Loss 1.008 Prec@(1,3) (74.4%, 97.9%), ce_loss 1.003, lat_loss 6.661
09/18 10:42:06 PM | Train: [ 36/180] Step 150/1249 Loss 0.998 Prec@(1,3) (74.7%, 98.0%), ce_loss 1.003, lat_loss 6.661
09/18 10:42:29 PM | Train: [ 36/180] Step 200/1249 Loss 1.004 Prec@(1,3) (74.6%, 97.9%), ce_loss 1.002, lat_loss 6.661
09/18 10:42:51 PM | Train: [ 36/180] Step 250/1249 Loss 0.993 Prec@(1,3) (74.7%, 98.1%), ce_loss 1.002, lat_loss 6.661
09/18 10:43:14 PM | Train: [ 36/180] Step 300/1249 Loss 0.998 Prec@(1,3) (74.6%, 98.0%), ce_loss 1.002, lat_loss 6.661
09/18 10:43:35 PM | Train: [ 36/180] Step 350/1249 Loss 0.993 Prec@(1,3) (74.6%, 98.0%), ce_loss 1.002, lat_loss 6.661
09/18 10:43:57 PM | Train: [ 36/180] Step 400/1249 Loss 0.986 Prec@(1,3) (74.7%, 98.1%), ce_loss 1.002, lat_loss 6.661
09/18 10:44:19 PM | Train: [ 36/180] Step 450/1249 Loss 0.992 Prec@(1,3) (74.6%, 98.1%), ce_loss 1.001, lat_loss 6.661
09/18 10:44:41 PM | Train: [ 36/180] Step 500/1249 Loss 0.996 Prec@(1,3) (74.5%, 98.1%), ce_loss 1.001, lat_loss 6.661
09/18 10:45:04 PM | Train: [ 36/180] Step 550/1249 Loss 0.994 Prec@(1,3) (74.6%, 98.1%), ce_loss 1.001, lat_loss 6.661
09/18 10:45:29 PM | Train: [ 36/180] Step 600/1249 Loss 0.988 Prec@(1,3) (74.8%, 98.1%), ce_loss 1.001, lat_loss 6.661
09/18 10:45:54 PM | Train: [ 36/180] Step 650/1249 Loss 0.995 Prec@(1,3) (74.6%, 98.1%), ce_loss 1.001, lat_loss 6.661
09/18 10:46:19 PM | Train: [ 36/180] Step 700/1249 Loss 0.997 Prec@(1,3) (74.5%, 98.0%), ce_loss 1.000, lat_loss 6.661
09/18 10:46:43 PM | Train: [ 36/180] Step 750/1249 Loss 1.004 Prec@(1,3) (74.3%, 98.0%), ce_loss 1.000, lat_loss 6.661
09/18 10:47:08 PM | Train: [ 36/180] Step 800/1249 Loss 1.003 Prec@(1,3) (74.3%, 98.0%), ce_loss 1.000, lat_loss 6.661
09/18 10:47:32 PM | Train: [ 36/180] Step 850/1249 Loss 1.002 Prec@(1,3) (74.4%, 98.0%), ce_loss 1.000, lat_loss 6.661
09/18 10:47:57 PM | Train: [ 36/180] Step 900/1249 Loss 1.004 Prec@(1,3) (74.3%, 98.0%), ce_loss 1.000, lat_loss 6.661
09/18 10:48:20 PM | Train: [ 36/180] Step 950/1249 Loss 1.004 Prec@(1,3) (74.2%, 98.0%), ce_loss 0.999, lat_loss 6.661
09/18 10:48:44 PM | Train: [ 36/180] Step 1000/1249 Loss 1.002 Prec@(1,3) (74.3%, 98.1%), ce_loss 0.999, lat_loss 6.661
09/18 10:49:07 PM | Train: [ 36/180] Step 1050/1249 Loss 1.003 Prec@(1,3) (74.3%, 98.0%), ce_loss 0.999, lat_loss 6.661
09/18 10:49:31 PM | Train: [ 36/180] Step 1100/1249 Loss 1.001 Prec@(1,3) (74.4%, 98.1%), ce_loss 0.999, lat_loss 6.661
09/18 10:49:56 PM | Train: [ 36/180] Step 1150/1249 Loss 1.002 Prec@(1,3) (74.3%, 98.1%), ce_loss 0.999, lat_loss 6.661
09/18 10:50:21 PM | Train: [ 36/180] Step 1200/1249 Loss 1.004 Prec@(1,3) (74.2%, 98.1%), ce_loss 0.998, lat_loss 6.661
09/18 10:50:45 PM | Train: [ 36/180] Step 1249/1249 Loss 1.004 Prec@(1,3) (74.3%, 98.1%), ce_loss 0.998, lat_loss 6.661
09/18 10:50:45 PM | _w_step_train: [ 36/180] Final Prec@1 74.2600% Time 588.08
09/18 10:50:45 PM | Start to train theta for epoch 35
09/18 10:51:06 PM | Train: [ 36/180] Step 050/312 Loss 1.044 Prec@(1,3) (73.3%, 97.8%), ce_loss 0.998, lat_loss 6.661
09/18 10:51:26 PM | Train: [ 36/180] Step 100/312 Loss 1.070 Prec@(1,3) (72.8%, 97.6%), ce_loss 0.998, lat_loss 6.661
09/18 10:51:46 PM | Train: [ 36/180] Step 150/312 Loss 1.060 Prec@(1,3) (73.1%, 97.8%), ce_loss 0.998, lat_loss 6.661
09/18 10:52:07 PM | Train: [ 36/180] Step 200/312 Loss 1.048 Prec@(1,3) (73.4%, 97.9%), ce_loss 0.997, lat_loss 6.661
09/18 10:52:27 PM | Train: [ 36/180] Step 250/312 Loss 1.048 Prec@(1,3) (73.2%, 98.0%), ce_loss 0.997, lat_loss 6.661
09/18 10:52:47 PM | Train: [ 36/180] Step 300/312 Loss 1.041 Prec@(1,3) (73.3%, 98.0%), ce_loss 0.997, lat_loss 6.661
09/18 10:52:52 PM | Train: [ 36/180] Step 312/312 Loss 1.037 Prec@(1,3) (73.4%, 98.0%), ce_loss 0.997, lat_loss 6.661
09/18 10:52:53 PM | _theta_step_train: [ 36/180] Final Prec@1 73.3800% Time 128.23
09/18 10:52:58 PM | Valid: [ 36/180] Step 050/312 Loss 1.245 Prec@(1,3) (69.7%, 97.9%), ce_loss 0.997, lat_loss 6.661
09/18 10:53:03 PM | Valid: [ 36/180] Step 100/312 Loss 1.290 Prec@(1,3) (68.9%, 97.0%), ce_loss 0.997, lat_loss 6.661
09/18 10:53:08 PM | Valid: [ 36/180] Step 150/312 Loss 1.272 Prec@(1,3) (69.0%, 97.0%), ce_loss 0.997, lat_loss 6.661
09/18 10:53:12 PM | Valid: [ 36/180] Step 200/312 Loss 1.290 Prec@(1,3) (68.5%, 96.8%), ce_loss 0.997, lat_loss 6.661
09/18 10:53:17 PM | Valid: [ 36/180] Step 250/312 Loss 1.311 Prec@(1,3) (67.8%, 96.6%), ce_loss 0.997, lat_loss 6.661
09/18 10:53:21 PM | Valid: [ 36/180] Step 300/312 Loss 1.308 Prec@(1,3) (67.9%, 96.6%), ce_loss 0.997, lat_loss 6.661
09/18 10:53:22 PM | Valid: [ 36/180] Step 312/312 Loss 1.311 Prec@(1,3) (67.9%, 96.6%), ce_loss 0.997, lat_loss 6.661
09/18 10:53:22 PM | val: [ 36/180] Final Prec@1 67.9200% Time 29.39
09/18 10:53:22 PM | Start to train weights for epoch 36
09/18 10:53:46 PM | Train: [ 37/180] Step 050/1249 Loss 0.977 Prec@(1,3) (75.2%, 98.0%), ce_loss 0.997, lat_loss 6.661
09/18 10:54:09 PM | Train: [ 37/180] Step 100/1249 Loss 0.971 Prec@(1,3) (75.2%, 98.1%), ce_loss 0.996, lat_loss 6.661
09/18 10:54:32 PM | Train: [ 37/180] Step 150/1249 Loss 0.996 Prec@(1,3) (74.7%, 98.1%), ce_loss 0.996, lat_loss 6.661
09/18 10:54:54 PM | Train: [ 37/180] Step 200/1249 Loss 1.011 Prec@(1,3) (74.4%, 98.1%), ce_loss 0.996, lat_loss 6.661
09/18 10:55:15 PM | Train: [ 37/180] Step 250/1249 Loss 1.013 Prec@(1,3) (74.3%, 98.0%), ce_loss 0.996, lat_loss 6.661
09/18 10:55:39 PM | Train: [ 37/180] Step 300/1249 Loss 1.011 Prec@(1,3) (74.5%, 98.0%), ce_loss 0.996, lat_loss 6.661
09/18 10:56:01 PM | Train: [ 37/180] Step 350/1249 Loss 0.999 Prec@(1,3) (74.8%, 98.0%), ce_loss 0.995, lat_loss 6.661
09/18 10:56:24 PM | Train: [ 37/180] Step 400/1249 Loss 0.995 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.995, lat_loss 6.661
09/18 10:56:47 PM | Train: [ 37/180] Step 450/1249 Loss 0.993 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.995, lat_loss 6.661
09/18 10:57:09 PM | Train: [ 37/180] Step 500/1249 Loss 0.995 Prec@(1,3) (74.9%, 98.0%), ce_loss 0.995, lat_loss 6.661
09/18 10:57:30 PM | Train: [ 37/180] Step 550/1249 Loss 0.996 Prec@(1,3) (74.7%, 98.1%), ce_loss 0.995, lat_loss 6.661
09/18 10:57:53 PM | Train: [ 37/180] Step 600/1249 Loss 0.998 Prec@(1,3) (74.7%, 98.0%), ce_loss 0.994, lat_loss 6.661
09/18 10:58:15 PM | Train: [ 37/180] Step 650/1249 Loss 1.002 Prec@(1,3) (74.6%, 98.1%), ce_loss 0.994, lat_loss 6.661
09/18 10:58:37 PM | Train: [ 37/180] Step 700/1249 Loss 1.007 Prec@(1,3) (74.4%, 98.0%), ce_loss 0.994, lat_loss 6.661
09/18 10:59:01 PM | Train: [ 37/180] Step 750/1249 Loss 1.007 Prec@(1,3) (74.4%, 98.0%), ce_loss 0.994, lat_loss 6.661
09/18 10:59:24 PM | Train: [ 37/180] Step 800/1249 Loss 1.008 Prec@(1,3) (74.4%, 98.0%), ce_loss 0.994, lat_loss 6.661
09/18 10:59:47 PM | Train: [ 37/180] Step 850/1249 Loss 1.005 Prec@(1,3) (74.4%, 98.0%), ce_loss 0.994, lat_loss 6.661
09/18 11:00:10 PM | Train: [ 37/180] Step 900/1249 Loss 1.006 Prec@(1,3) (74.4%, 98.0%), ce_loss 0.993, lat_loss 6.661
09/18 11:00:34 PM | Train: [ 37/180] Step 950/1249 Loss 1.007 Prec@(1,3) (74.3%, 98.0%), ce_loss 0.993, lat_loss 6.662
09/18 11:00:56 PM | Train: [ 37/180] Step 1000/1249 Loss 1.007 Prec@(1,3) (74.3%, 98.0%), ce_loss 0.993, lat_loss 6.662
09/18 11:01:17 PM | Train: [ 37/180] Step 1050/1249 Loss 1.008 Prec@(1,3) (74.3%, 98.0%), ce_loss 0.993, lat_loss 6.662
09/18 11:01:40 PM | Train: [ 37/180] Step 1100/1249 Loss 1.006 Prec@(1,3) (74.3%, 98.0%), ce_loss 0.993, lat_loss 6.662
09/18 11:02:04 PM | Train: [ 37/180] Step 1150/1249 Loss 1.004 Prec@(1,3) (74.3%, 98.0%), ce_loss 0.992, lat_loss 6.662
09/18 11:02:27 PM | Train: [ 37/180] Step 1200/1249 Loss 1.004 Prec@(1,3) (74.3%, 98.0%), ce_loss 0.992, lat_loss 6.662
09/18 11:02:52 PM | Train: [ 37/180] Step 1249/1249 Loss 1.003 Prec@(1,3) (74.4%, 98.0%), ce_loss 0.992, lat_loss 6.662
09/18 11:02:52 PM | _w_step_train: [ 37/180] Final Prec@1 74.3775% Time 569.24
09/18 11:02:52 PM | Start to train theta for epoch 36
09/18 11:03:13 PM | Train: [ 37/180] Step 050/312 Loss 1.004 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.992, lat_loss 6.662
09/18 11:03:34 PM | Train: [ 37/180] Step 100/312 Loss 1.025 Prec@(1,3) (73.9%, 98.1%), ce_loss 0.992, lat_loss 6.662
09/18 11:03:54 PM | Train: [ 37/180] Step 150/312 Loss 1.045 Prec@(1,3) (73.5%, 98.1%), ce_loss 0.991, lat_loss 6.662
09/18 11:04:14 PM | Train: [ 37/180] Step 200/312 Loss 1.038 Prec@(1,3) (73.4%, 98.0%), ce_loss 0.991, lat_loss 6.662
09/18 11:04:35 PM | Train: [ 37/180] Step 250/312 Loss 1.042 Prec@(1,3) (73.2%, 97.9%), ce_loss 0.991, lat_loss 6.662
09/18 11:04:55 PM | Train: [ 37/180] Step 300/312 Loss 1.041 Prec@(1,3) (73.2%, 97.9%), ce_loss 0.991, lat_loss 6.662
09/18 11:05:00 PM | Train: [ 37/180] Step 312/312 Loss 1.044 Prec@(1,3) (73.0%, 98.0%), ce_loss 0.991, lat_loss 6.662
09/18 11:05:00 PM | _theta_step_train: [ 37/180] Final Prec@1 73.0500% Time 128.77
09/18 11:05:06 PM | Valid: [ 37/180] Step 050/312 Loss 1.451 Prec@(1,3) (67.7%, 96.7%), ce_loss 0.991, lat_loss 6.662
09/18 11:05:10 PM | Valid: [ 37/180] Step 100/312 Loss 1.422 Prec@(1,3) (67.1%, 96.5%), ce_loss 0.991, lat_loss 6.662
09/18 11:05:15 PM | Valid: [ 37/180] Step 150/312 Loss 1.376 Prec@(1,3) (67.9%, 96.8%), ce_loss 0.991, lat_loss 6.662
09/18 11:05:19 PM | Valid: [ 37/180] Step 200/312 Loss 1.397 Prec@(1,3) (67.2%, 96.7%), ce_loss 0.991, lat_loss 6.662
09/18 11:05:24 PM | Valid: [ 37/180] Step 250/312 Loss 1.387 Prec@(1,3) (67.3%, 96.7%), ce_loss 0.991, lat_loss 6.662
09/18 11:05:29 PM | Valid: [ 37/180] Step 300/312 Loss 1.358 Prec@(1,3) (67.8%, 96.8%), ce_loss 0.991, lat_loss 6.662
09/18 11:05:30 PM | Valid: [ 37/180] Step 312/312 Loss 1.360 Prec@(1,3) (67.7%, 96.8%), ce_loss 0.991, lat_loss 6.662
09/18 11:05:30 PM | val: [ 37/180] Final Prec@1 67.7100% Time 29.39
09/18 11:05:30 PM | Start to train weights for epoch 37
09/18 11:05:56 PM | Train: [ 38/180] Step 050/1249 Loss 1.065 Prec@(1,3) (72.6%, 98.1%), ce_loss 0.991, lat_loss 6.662
09/18 11:06:20 PM | Train: [ 38/180] Step 100/1249 Loss 1.010 Prec@(1,3) (74.1%, 98.1%), ce_loss 0.991, lat_loss 6.662
09/18 11:06:43 PM | Train: [ 38/180] Step 150/1249 Loss 1.004 Prec@(1,3) (74.3%, 98.2%), ce_loss 0.991, lat_loss 6.662
09/18 11:07:07 PM | Train: [ 38/180] Step 200/1249 Loss 1.020 Prec@(1,3) (73.8%, 98.2%), ce_loss 0.990, lat_loss 6.662
09/18 11:07:29 PM | Train: [ 38/180] Step 250/1249 Loss 1.019 Prec@(1,3) (73.8%, 98.1%), ce_loss 0.990, lat_loss 6.662
09/18 11:07:53 PM | Train: [ 38/180] Step 300/1249 Loss 1.026 Prec@(1,3) (73.7%, 98.1%), ce_loss 0.990, lat_loss 6.662
09/18 11:08:17 PM | Train: [ 38/180] Step 350/1249 Loss 1.016 Prec@(1,3) (74.1%, 98.1%), ce_loss 0.990, lat_loss 6.662
09/18 11:08:39 PM | Train: [ 38/180] Step 400/1249 Loss 1.020 Prec@(1,3) (74.0%, 98.1%), ce_loss 0.990, lat_loss 6.662
09/18 11:09:04 PM | Train: [ 38/180] Step 450/1249 Loss 1.016 Prec@(1,3) (74.1%, 98.1%), ce_loss 0.989, lat_loss 6.662
09/18 11:09:27 PM | Train: [ 38/180] Step 500/1249 Loss 1.016 Prec@(1,3) (74.2%, 98.0%), ce_loss 0.989, lat_loss 6.662
09/18 11:09:49 PM | Train: [ 38/180] Step 550/1249 Loss 1.014 Prec@(1,3) (74.3%, 98.0%), ce_loss 0.989, lat_loss 6.662
09/18 11:10:11 PM | Train: [ 38/180] Step 600/1249 Loss 1.009 Prec@(1,3) (74.3%, 98.0%), ce_loss 0.989, lat_loss 6.662
09/18 11:10:35 PM | Train: [ 38/180] Step 650/1249 Loss 1.010 Prec@(1,3) (74.2%, 98.0%), ce_loss 0.989, lat_loss 6.662
09/18 11:10:59 PM | Train: [ 38/180] Step 700/1249 Loss 1.007 Prec@(1,3) (74.3%, 98.1%), ce_loss 0.988, lat_loss 6.662
09/18 11:11:23 PM | Train: [ 38/180] Step 750/1249 Loss 1.007 Prec@(1,3) (74.4%, 98.0%), ce_loss 0.988, lat_loss 6.662
09/18 11:11:46 PM | Train: [ 38/180] Step 800/1249 Loss 1.008 Prec@(1,3) (74.3%, 98.0%), ce_loss 0.988, lat_loss 6.662
09/18 11:12:08 PM | Train: [ 38/180] Step 850/1249 Loss 1.007 Prec@(1,3) (74.4%, 98.0%), ce_loss 0.988, lat_loss 6.662
09/18 11:12:31 PM | Train: [ 38/180] Step 900/1249 Loss 1.005 Prec@(1,3) (74.3%, 98.1%), ce_loss 0.988, lat_loss 6.662
09/18 11:12:55 PM | Train: [ 38/180] Step 950/1249 Loss 1.006 Prec@(1,3) (74.3%, 98.0%), ce_loss 0.988, lat_loss 6.662
09/18 11:13:17 PM | Train: [ 38/180] Step 1000/1249 Loss 1.007 Prec@(1,3) (74.3%, 98.0%), ce_loss 0.987, lat_loss 6.662
09/18 11:13:41 PM | Train: [ 38/180] Step 1050/1249 Loss 1.006 Prec@(1,3) (74.3%, 98.0%), ce_loss 0.987, lat_loss 6.662
09/18 11:14:05 PM | Train: [ 38/180] Step 1100/1249 Loss 1.005 Prec@(1,3) (74.3%, 98.1%), ce_loss 0.987, lat_loss 6.662
09/18 11:14:29 PM | Train: [ 38/180] Step 1150/1249 Loss 1.004 Prec@(1,3) (74.4%, 98.1%), ce_loss 0.987, lat_loss 6.662
09/18 11:14:51 PM | Train: [ 38/180] Step 1200/1249 Loss 1.006 Prec@(1,3) (74.4%, 98.0%), ce_loss 0.987, lat_loss 6.662
09/18 11:15:15 PM | Train: [ 38/180] Step 1249/1249 Loss 1.007 Prec@(1,3) (74.4%, 98.1%), ce_loss 0.986, lat_loss 6.662
09/18 11:15:16 PM | _w_step_train: [ 38/180] Final Prec@1 74.3575% Time 585.63
09/18 11:15:16 PM | Start to train theta for epoch 37
09/18 11:15:34 PM | Train: [ 38/180] Step 050/312 Loss 1.038 Prec@(1,3) (72.7%, 98.0%), ce_loss 0.986, lat_loss 6.662
09/18 11:15:52 PM | Train: [ 38/180] Step 100/312 Loss 1.041 Prec@(1,3) (73.1%, 97.8%), ce_loss 0.986, lat_loss 6.662
09/18 11:16:13 PM | Train: [ 38/180] Step 150/312 Loss 1.036 Prec@(1,3) (73.0%, 97.9%), ce_loss 0.986, lat_loss 6.662
09/18 11:16:34 PM | Train: [ 38/180] Step 200/312 Loss 1.031 Prec@(1,3) (73.3%, 98.0%), ce_loss 0.986, lat_loss 6.662
09/18 11:16:55 PM | Train: [ 38/180] Step 250/312 Loss 1.027 Prec@(1,3) (73.5%, 97.9%), ce_loss 0.986, lat_loss 6.662
09/18 11:17:15 PM | Train: [ 38/180] Step 300/312 Loss 1.014 Prec@(1,3) (73.9%, 98.0%), ce_loss 0.985, lat_loss 6.662
09/18 11:17:20 PM | Train: [ 38/180] Step 312/312 Loss 1.021 Prec@(1,3) (73.7%, 97.9%), ce_loss 0.985, lat_loss 6.662
09/18 11:17:20 PM | _theta_step_train: [ 38/180] Final Prec@1 73.7300% Time 124.87
09/18 11:17:26 PM | Valid: [ 38/180] Step 050/312 Loss 1.220 Prec@(1,3) (68.5%, 97.7%), ce_loss 0.985, lat_loss 6.662
09/18 11:17:30 PM | Valid: [ 38/180] Step 100/312 Loss 1.277 Prec@(1,3) (68.3%, 96.8%), ce_loss 0.985, lat_loss 6.662
09/18 11:17:35 PM | Valid: [ 38/180] Step 150/312 Loss 1.309 Prec@(1,3) (68.1%, 96.6%), ce_loss 0.985, lat_loss 6.662
09/18 11:17:39 PM | Valid: [ 38/180] Step 200/312 Loss 1.304 Prec@(1,3) (68.3%, 96.8%), ce_loss 0.985, lat_loss 6.662
09/18 11:17:44 PM | Valid: [ 38/180] Step 250/312 Loss 1.311 Prec@(1,3) (68.3%, 96.7%), ce_loss 0.985, lat_loss 6.662
09/18 11:17:49 PM | Valid: [ 38/180] Step 300/312 Loss 1.309 Prec@(1,3) (68.2%, 96.7%), ce_loss 0.985, lat_loss 6.662
09/18 11:17:50 PM | Valid: [ 38/180] Step 312/312 Loss 1.306 Prec@(1,3) (68.2%, 96.7%), ce_loss 0.985, lat_loss 6.662
09/18 11:17:50 PM | val: [ 38/180] Final Prec@1 68.1900% Time 29.42
09/18 11:17:50 PM | Start to train weights for epoch 38
09/18 11:18:16 PM | Train: [ 39/180] Step 050/1249 Loss 0.975 Prec@(1,3) (75.0%, 98.2%), ce_loss 0.985, lat_loss 6.662
09/18 11:18:40 PM | Train: [ 39/180] Step 100/1249 Loss 0.997 Prec@(1,3) (74.0%, 98.2%), ce_loss 0.985, lat_loss 6.662
09/18 11:19:05 PM | Train: [ 39/180] Step 150/1249 Loss 0.999 Prec@(1,3) (74.2%, 98.3%), ce_loss 0.985, lat_loss 6.662
09/18 11:19:30 PM | Train: [ 39/180] Step 200/1249 Loss 0.992 Prec@(1,3) (74.5%, 98.2%), ce_loss 0.985, lat_loss 6.662
09/18 11:19:55 PM | Train: [ 39/180] Step 250/1249 Loss 0.995 Prec@(1,3) (74.7%, 98.3%), ce_loss 0.984, lat_loss 6.662
09/18 11:20:20 PM | Train: [ 39/180] Step 300/1249 Loss 1.003 Prec@(1,3) (74.6%, 98.2%), ce_loss 0.984, lat_loss 6.662
09/18 11:20:45 PM | Train: [ 39/180] Step 350/1249 Loss 0.996 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.984, lat_loss 6.662
09/18 11:21:10 PM | Train: [ 39/180] Step 400/1249 Loss 0.995 Prec@(1,3) (74.6%, 98.2%), ce_loss 0.984, lat_loss 6.662
09/18 11:21:34 PM | Train: [ 39/180] Step 450/1249 Loss 0.995 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.984, lat_loss 6.662
09/18 11:21:59 PM | Train: [ 39/180] Step 500/1249 Loss 0.999 Prec@(1,3) (74.6%, 98.2%), ce_loss 0.984, lat_loss 6.662
09/18 11:22:24 PM | Train: [ 39/180] Step 550/1249 Loss 0.998 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.983, lat_loss 6.662
09/18 11:22:49 PM | Train: [ 39/180] Step 600/1249 Loss 1.003 Prec@(1,3) (74.5%, 98.2%), ce_loss 0.983, lat_loss 6.662
09/18 11:23:14 PM | Train: [ 39/180] Step 650/1249 Loss 0.999 Prec@(1,3) (74.8%, 98.2%), ce_loss 0.983, lat_loss 6.663
09/18 11:23:39 PM | Train: [ 39/180] Step 700/1249 Loss 0.996 Prec@(1,3) (74.8%, 98.2%), ce_loss 0.983, lat_loss 6.663
09/18 11:24:04 PM | Train: [ 39/180] Step 750/1249 Loss 0.998 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.983, lat_loss 6.663
09/18 11:24:29 PM | Train: [ 39/180] Step 800/1249 Loss 0.998 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.982, lat_loss 6.663
09/18 11:24:54 PM | Train: [ 39/180] Step 850/1249 Loss 0.998 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.982, lat_loss 6.663
09/18 11:25:18 PM | Train: [ 39/180] Step 900/1249 Loss 1.000 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.982, lat_loss 6.663
09/18 11:25:42 PM | Train: [ 39/180] Step 950/1249 Loss 0.998 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.982, lat_loss 6.663
09/18 11:26:02 PM | Train: [ 39/180] Step 1000/1249 Loss 1.000 Prec@(1,3) (74.6%, 98.2%), ce_loss 0.982, lat_loss 6.663
09/18 11:26:24 PM | Train: [ 39/180] Step 1050/1249 Loss 1.001 Prec@(1,3) (74.6%, 98.2%), ce_loss 0.982, lat_loss 6.663
09/18 11:26:44 PM | Train: [ 39/180] Step 1100/1249 Loss 1.003 Prec@(1,3) (74.5%, 98.2%), ce_loss 0.981, lat_loss 6.663
09/18 11:27:06 PM | Train: [ 39/180] Step 1150/1249 Loss 1.000 Prec@(1,3) (74.6%, 98.2%), ce_loss 0.981, lat_loss 6.663
09/18 11:27:30 PM | Train: [ 39/180] Step 1200/1249 Loss 1.000 Prec@(1,3) (74.6%, 98.1%), ce_loss 0.981, lat_loss 6.663
09/18 11:27:55 PM | Train: [ 39/180] Step 1249/1249 Loss 1.001 Prec@(1,3) (74.6%, 98.1%), ce_loss 0.981, lat_loss 6.663
09/18 11:27:55 PM | _w_step_train: [ 39/180] Final Prec@1 74.6325% Time 604.86
09/18 11:27:55 PM | Start to train theta for epoch 38
09/18 11:28:08 PM | Train: [ 39/180] Step 050/312 Loss 1.003 Prec@(1,3) (74.3%, 97.9%), ce_loss 0.981, lat_loss 6.663
09/18 11:28:20 PM | Train: [ 39/180] Step 100/312 Loss 0.998 Prec@(1,3) (74.6%, 98.1%), ce_loss 0.981, lat_loss 6.663
09/18 11:28:32 PM | Train: [ 39/180] Step 150/312 Loss 1.007 Prec@(1,3) (74.3%, 97.9%), ce_loss 0.980, lat_loss 6.663
09/18 11:28:45 PM | Train: [ 39/180] Step 200/312 Loss 1.007 Prec@(1,3) (74.4%, 97.8%), ce_loss 0.980, lat_loss 6.663
09/18 11:28:57 PM | Train: [ 39/180] Step 250/312 Loss 1.005 Prec@(1,3) (74.5%, 97.8%), ce_loss 0.980, lat_loss 6.663
09/18 11:29:09 PM | Train: [ 39/180] Step 300/312 Loss 0.996 Prec@(1,3) (74.6%, 97.9%), ce_loss 0.980, lat_loss 6.663
09/18 11:29:12 PM | Train: [ 39/180] Step 312/312 Loss 1.000 Prec@(1,3) (74.4%, 97.9%), ce_loss 0.980, lat_loss 6.663
09/18 11:29:12 PM | _theta_step_train: [ 39/180] Final Prec@1 74.4100% Time 77.31
09/18 11:29:17 PM | Valid: [ 39/180] Step 050/312 Loss 1.234 Prec@(1,3) (68.9%, 97.2%), ce_loss 0.980, lat_loss 6.663
09/18 11:29:21 PM | Valid: [ 39/180] Step 100/312 Loss 1.345 Prec@(1,3) (66.2%, 96.3%), ce_loss 0.980, lat_loss 6.663
09/18 11:29:25 PM | Valid: [ 39/180] Step 150/312 Loss 1.354 Prec@(1,3) (66.3%, 96.0%), ce_loss 0.980, lat_loss 6.663
09/18 11:29:29 PM | Valid: [ 39/180] Step 200/312 Loss 1.358 Prec@(1,3) (66.0%, 96.2%), ce_loss 0.980, lat_loss 6.663
09/18 11:29:34 PM | Valid: [ 39/180] Step 250/312 Loss 1.388 Prec@(1,3) (65.7%, 96.0%), ce_loss 0.980, lat_loss 6.663
09/18 11:29:38 PM | Valid: [ 39/180] Step 300/312 Loss 1.379 Prec@(1,3) (66.0%, 96.1%), ce_loss 0.980, lat_loss 6.663
09/18 11:29:39 PM | Valid: [ 39/180] Step 312/312 Loss 1.382 Prec@(1,3) (65.9%, 96.1%), ce_loss 0.980, lat_loss 6.663
09/18 11:29:39 PM | val: [ 39/180] Final Prec@1 65.9300% Time 26.88
09/18 11:29:39 PM | Start to train weights for epoch 39
09/18 11:30:05 PM | Train: [ 40/180] Step 050/1249 Loss 0.939 Prec@(1,3) (75.9%, 98.7%), ce_loss 0.980, lat_loss 6.663
09/18 11:30:28 PM | Train: [ 40/180] Step 100/1249 Loss 0.980 Prec@(1,3) (75.2%, 98.3%), ce_loss 0.980, lat_loss 6.663
09/18 11:30:52 PM | Train: [ 40/180] Step 150/1249 Loss 0.980 Prec@(1,3) (75.4%, 98.5%), ce_loss 0.979, lat_loss 6.663
09/18 11:31:16 PM | Train: [ 40/180] Step 200/1249 Loss 0.979 Prec@(1,3) (75.1%, 98.4%), ce_loss 0.979, lat_loss 6.663
09/18 11:31:39 PM | Train: [ 40/180] Step 250/1249 Loss 0.978 Prec@(1,3) (75.1%, 98.3%), ce_loss 0.979, lat_loss 6.663
09/18 11:32:02 PM | Train: [ 40/180] Step 300/1249 Loss 0.992 Prec@(1,3) (75.0%, 98.3%), ce_loss 0.979, lat_loss 6.663
09/18 11:32:25 PM | Train: [ 40/180] Step 350/1249 Loss 0.983 Prec@(1,3) (75.0%, 98.3%), ce_loss 0.979, lat_loss 6.663
09/18 11:32:49 PM | Train: [ 40/180] Step 400/1249 Loss 0.986 Prec@(1,3) (74.9%, 98.3%), ce_loss 0.979, lat_loss 6.663
09/18 11:33:13 PM | Train: [ 40/180] Step 450/1249 Loss 0.994 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.978, lat_loss 6.663
09/18 11:33:37 PM | Train: [ 40/180] Step 500/1249 Loss 0.998 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.978, lat_loss 6.663
09/18 11:34:01 PM | Train: [ 40/180] Step 550/1249 Loss 0.993 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.978, lat_loss 6.663
09/18 11:34:26 PM | Train: [ 40/180] Step 600/1249 Loss 0.990 Prec@(1,3) (74.8%, 98.2%), ce_loss 0.978, lat_loss 6.663
09/18 11:34:50 PM | Train: [ 40/180] Step 650/1249 Loss 0.993 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.978, lat_loss 6.663
09/18 11:35:15 PM | Train: [ 40/180] Step 700/1249 Loss 0.994 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.978, lat_loss 6.663
09/18 11:35:39 PM | Train: [ 40/180] Step 750/1249 Loss 0.993 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.977, lat_loss 6.663
09/18 11:36:04 PM | Train: [ 40/180] Step 800/1249 Loss 0.991 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.977, lat_loss 6.663
09/18 11:36:28 PM | Train: [ 40/180] Step 850/1249 Loss 0.989 Prec@(1,3) (74.9%, 98.3%), ce_loss 0.977, lat_loss 6.663
09/18 11:36:53 PM | Train: [ 40/180] Step 900/1249 Loss 0.985 Prec@(1,3) (75.0%, 98.2%), ce_loss 0.977, lat_loss 6.663
09/18 11:37:16 PM | Train: [ 40/180] Step 950/1249 Loss 0.985 Prec@(1,3) (75.1%, 98.2%), ce_loss 0.977, lat_loss 6.663
09/18 11:37:39 PM | Train: [ 40/180] Step 1000/1249 Loss 0.989 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.977, lat_loss 6.663
09/18 11:38:03 PM | Train: [ 40/180] Step 1050/1249 Loss 0.989 Prec@(1,3) (75.0%, 98.2%), ce_loss 0.976, lat_loss 6.663
09/18 11:38:27 PM | Train: [ 40/180] Step 1100/1249 Loss 0.991 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.976, lat_loss 6.663
09/18 11:38:51 PM | Train: [ 40/180] Step 1150/1249 Loss 0.992 Prec@(1,3) (74.8%, 98.2%), ce_loss 0.976, lat_loss 6.663
09/18 11:39:16 PM | Train: [ 40/180] Step 1200/1249 Loss 0.992 Prec@(1,3) (74.8%, 98.2%), ce_loss 0.976, lat_loss 6.663
09/18 11:39:40 PM | Train: [ 40/180] Step 1249/1249 Loss 0.991 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.976, lat_loss 6.663
09/18 11:39:40 PM | _w_step_train: [ 40/180] Final Prec@1 74.8550% Time 601.20
09/18 11:39:40 PM | Start to train theta for epoch 39
09/18 11:40:01 PM | Train: [ 40/180] Step 050/312 Loss 1.068 Prec@(1,3) (72.3%, 97.4%), ce_loss 0.976, lat_loss 6.663
09/18 11:40:21 PM | Train: [ 40/180] Step 100/312 Loss 1.059 Prec@(1,3) (72.6%, 97.6%), ce_loss 0.975, lat_loss 6.663
09/18 11:40:42 PM | Train: [ 40/180] Step 150/312 Loss 1.028 Prec@(1,3) (73.6%, 97.8%), ce_loss 0.975, lat_loss 6.663
09/18 11:41:03 PM | Train: [ 40/180] Step 200/312 Loss 1.018 Prec@(1,3) (73.9%, 97.8%), ce_loss 0.975, lat_loss 6.663
09/18 11:41:24 PM | Train: [ 40/180] Step 250/312 Loss 1.022 Prec@(1,3) (73.8%, 97.8%), ce_loss 0.975, lat_loss 6.663
09/18 11:41:45 PM | Train: [ 40/180] Step 300/312 Loss 1.021 Prec@(1,3) (73.8%, 97.9%), ce_loss 0.975, lat_loss 6.663
09/18 11:41:50 PM | Train: [ 40/180] Step 312/312 Loss 1.019 Prec@(1,3) (73.9%, 97.9%), ce_loss 0.975, lat_loss 6.663
09/18 11:41:50 PM | _theta_step_train: [ 40/180] Final Prec@1 73.9200% Time 129.64
09/18 11:41:55 PM | Valid: [ 40/180] Step 050/312 Loss 1.360 Prec@(1,3) (67.3%, 96.8%), ce_loss 0.975, lat_loss 6.663
09/18 11:42:00 PM | Valid: [ 40/180] Step 100/312 Loss 1.322 Prec@(1,3) (67.7%, 96.7%), ce_loss 0.975, lat_loss 6.663
09/18 11:42:04 PM | Valid: [ 40/180] Step 150/312 Loss 1.310 Prec@(1,3) (68.3%, 96.7%), ce_loss 0.975, lat_loss 6.663
09/18 11:42:09 PM | Valid: [ 40/180] Step 200/312 Loss 1.286 Prec@(1,3) (68.5%, 97.1%), ce_loss 0.975, lat_loss 6.663
09/18 11:42:13 PM | Valid: [ 40/180] Step 250/312 Loss 1.293 Prec@(1,3) (68.5%, 97.1%), ce_loss 0.975, lat_loss 6.663
09/18 11:42:18 PM | Valid: [ 40/180] Step 300/312 Loss 1.270 Prec@(1,3) (68.9%, 97.2%), ce_loss 0.975, lat_loss 6.663
09/18 11:42:19 PM | Valid: [ 40/180] Step 312/312 Loss 1.275 Prec@(1,3) (68.8%, 97.2%), ce_loss 0.975, lat_loss 6.663
09/18 11:42:19 PM | val: [ 40/180] Final Prec@1 68.8000% Time 29.40
09/18 11:42:19 PM | Start to train weights for epoch 40
09/18 11:42:42 PM | Train: [ 41/180] Step 050/1249 Loss 0.980 Prec@(1,3) (74.8%, 98.9%), ce_loss 0.974, lat_loss 6.663
09/18 11:43:05 PM | Train: [ 41/180] Step 100/1249 Loss 0.976 Prec@(1,3) (75.2%, 98.5%), ce_loss 0.974, lat_loss 6.663
09/18 11:43:28 PM | Train: [ 41/180] Step 150/1249 Loss 0.971 Prec@(1,3) (75.3%, 98.3%), ce_loss 0.974, lat_loss 6.663
09/18 11:43:51 PM | Train: [ 41/180] Step 200/1249 Loss 0.979 Prec@(1,3) (74.7%, 98.4%), ce_loss 0.974, lat_loss 6.663
09/18 11:44:16 PM | Train: [ 41/180] Step 250/1249 Loss 0.984 Prec@(1,3) (74.8%, 98.3%), ce_loss 0.974, lat_loss 6.664
09/18 11:44:37 PM | Train: [ 41/180] Step 300/1249 Loss 0.995 Prec@(1,3) (74.5%, 98.3%), ce_loss 0.974, lat_loss 6.664
09/18 11:44:58 PM | Train: [ 41/180] Step 350/1249 Loss 0.996 Prec@(1,3) (74.5%, 98.2%), ce_loss 0.973, lat_loss 6.664
09/18 11:45:18 PM | Train: [ 41/180] Step 400/1249 Loss 0.996 Prec@(1,3) (74.4%, 98.3%), ce_loss 0.973, lat_loss 6.664
09/18 11:45:40 PM | Train: [ 41/180] Step 450/1249 Loss 0.989 Prec@(1,3) (74.7%, 98.3%), ce_loss 0.973, lat_loss 6.664
09/18 11:46:05 PM | Train: [ 41/180] Step 500/1249 Loss 0.987 Prec@(1,3) (74.8%, 98.3%), ce_loss 0.973, lat_loss 6.664
09/18 11:46:29 PM | Train: [ 41/180] Step 550/1249 Loss 0.987 Prec@(1,3) (74.8%, 98.3%), ce_loss 0.973, lat_loss 6.664
09/18 11:46:54 PM | Train: [ 41/180] Step 600/1249 Loss 0.992 Prec@(1,3) (74.6%, 98.3%), ce_loss 0.973, lat_loss 6.664
09/18 11:47:19 PM | Train: [ 41/180] Step 650/1249 Loss 0.993 Prec@(1,3) (74.6%, 98.3%), ce_loss 0.972, lat_loss 6.664
09/18 11:47:43 PM | Train: [ 41/180] Step 700/1249 Loss 0.993 Prec@(1,3) (74.6%, 98.3%), ce_loss 0.972, lat_loss 6.664
09/18 11:48:08 PM | Train: [ 41/180] Step 750/1249 Loss 0.997 Prec@(1,3) (74.6%, 98.2%), ce_loss 0.972, lat_loss 6.664
09/18 11:48:33 PM | Train: [ 41/180] Step 800/1249 Loss 0.996 Prec@(1,3) (74.5%, 98.2%), ce_loss 0.972, lat_loss 6.664
09/18 11:48:58 PM | Train: [ 41/180] Step 850/1249 Loss 0.995 Prec@(1,3) (74.5%, 98.2%), ce_loss 0.972, lat_loss 6.664
09/18 11:49:19 PM | Train: [ 41/180] Step 900/1249 Loss 0.994 Prec@(1,3) (74.6%, 98.2%), ce_loss 0.972, lat_loss 6.664
09/18 11:49:43 PM | Train: [ 41/180] Step 950/1249 Loss 0.997 Prec@(1,3) (74.6%, 98.2%), ce_loss 0.971, lat_loss 6.664
09/18 11:50:07 PM | Train: [ 41/180] Step 1000/1249 Loss 0.994 Prec@(1,3) (74.7%, 98.2%), ce_loss 0.971, lat_loss 6.664
09/18 11:50:32 PM | Train: [ 41/180] Step 1050/1249 Loss 0.997 Prec@(1,3) (74.6%, 98.2%), ce_loss 0.971, lat_loss 6.664
09/18 11:50:57 PM | Train: [ 41/180] Step 1100/1249 Loss 0.996 Prec@(1,3) (74.6%, 98.1%), ce_loss 0.971, lat_loss 6.664
09/18 11:51:22 PM | Train: [ 41/180] Step 1150/1249 Loss 0.994 Prec@(1,3) (74.6%, 98.1%), ce_loss 0.971, lat_loss 6.664
09/18 11:51:47 PM | Train: [ 41/180] Step 1200/1249 Loss 0.993 Prec@(1,3) (74.7%, 98.1%), ce_loss 0.971, lat_loss 6.664
09/18 11:52:11 PM | Train: [ 41/180] Step 1249/1249 Loss 0.992 Prec@(1,3) (74.7%, 98.1%), ce_loss 0.970, lat_loss 6.664
09/18 11:52:11 PM | _w_step_train: [ 41/180] Final Prec@1 74.7150% Time 591.99
09/18 11:52:11 PM | Start to train theta for epoch 40
09/18 11:52:31 PM | Train: [ 41/180] Step 050/312 Loss 1.001 Prec@(1,3) (74.8%, 98.2%), ce_loss 0.970, lat_loss 6.664
09/18 11:52:52 PM | Train: [ 41/180] Step 100/312 Loss 1.032 Prec@(1,3) (74.5%, 97.9%), ce_loss 0.970, lat_loss 6.664
09/18 11:53:12 PM | Train: [ 41/180] Step 150/312 Loss 1.028 Prec@(1,3) (74.5%, 97.8%), ce_loss 0.970, lat_loss 6.664
09/18 11:53:32 PM | Train: [ 41/180] Step 200/312 Loss 1.040 Prec@(1,3) (74.0%, 97.9%), ce_loss 0.970, lat_loss 6.664
09/18 11:53:52 PM | Train: [ 41/180] Step 250/312 Loss 1.042 Prec@(1,3) (73.9%, 97.9%), ce_loss 0.970, lat_loss 6.664
09/18 11:54:12 PM | Train: [ 41/180] Step 300/312 Loss 1.048 Prec@(1,3) (73.6%, 97.8%), ce_loss 0.970, lat_loss 6.664
09/18 11:54:17 PM | Train: [ 41/180] Step 312/312 Loss 1.048 Prec@(1,3) (73.6%, 97.8%), ce_loss 0.970, lat_loss 6.664
09/18 11:54:17 PM | _theta_step_train: [ 41/180] Final Prec@1 73.5700% Time 126.22
09/18 11:54:23 PM | Valid: [ 41/180] Step 050/312 Loss 1.265 Prec@(1,3) (68.6%, 97.1%), ce_loss 0.970, lat_loss 6.664
09/18 11:54:27 PM | Valid: [ 41/180] Step 100/312 Loss 1.330 Prec@(1,3) (67.4%, 96.8%), ce_loss 0.970, lat_loss 6.664
09/18 11:54:32 PM | Valid: [ 41/180] Step 150/312 Loss 1.375 Prec@(1,3) (66.7%, 96.4%), ce_loss 0.970, lat_loss 6.664
09/18 11:54:37 PM | Valid: [ 41/180] Step 200/312 Loss 1.382 Prec@(1,3) (66.2%, 96.4%), ce_loss 0.970, lat_loss 6.664
09/18 11:54:42 PM | Valid: [ 41/180] Step 250/312 Loss 1.357 Prec@(1,3) (66.6%, 96.6%), ce_loss 0.970, lat_loss 6.664
09/18 11:54:46 PM | Valid: [ 41/180] Step 300/312 Loss 1.345 Prec@(1,3) (66.8%, 96.6%), ce_loss 0.970, lat_loss 6.664
09/18 11:54:48 PM | Valid: [ 41/180] Step 312/312 Loss 1.343 Prec@(1,3) (66.8%, 96.6%), ce_loss 0.970, lat_loss 6.664
09/18 11:54:48 PM | val: [ 41/180] Final Prec@1 66.8300% Time 30.31
09/18 11:54:48 PM | Start to train weights for epoch 41
09/18 11:55:05 PM | Train: [ 42/180] Step 050/1249 Loss 0.925 Prec@(1,3) (75.7%, 98.8%), ce_loss 0.970, lat_loss 6.664
09/18 11:55:22 PM | Train: [ 42/180] Step 100/1249 Loss 0.948 Prec@(1,3) (75.8%, 98.4%), ce_loss 0.969, lat_loss 6.664
09/18 11:55:38 PM | Train: [ 42/180] Step 150/1249 Loss 0.966 Prec@(1,3) (75.3%, 98.4%), ce_loss 0.969, lat_loss 6.664
09/18 11:55:54 PM | Train: [ 42/180] Step 200/1249 Loss 0.972 Prec@(1,3) (75.2%, 98.4%), ce_loss 0.969, lat_loss 6.664
09/18 11:56:10 PM | Train: [ 42/180] Step 250/1249 Loss 0.961 Prec@(1,3) (75.5%, 98.4%), ce_loss 0.969, lat_loss 6.664
09/18 11:56:26 PM | Train: [ 42/180] Step 300/1249 Loss 0.978 Prec@(1,3) (75.0%, 98.3%), ce_loss 0.969, lat_loss 6.664
09/18 11:56:42 PM | Train: [ 42/180] Step 350/1249 Loss 0.987 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.969, lat_loss 6.664
09/18 11:56:58 PM | Train: [ 42/180] Step 400/1249 Loss 0.986 Prec@(1,3) (74.8%, 98.3%), ce_loss 0.968, lat_loss 6.664
09/18 11:57:14 PM | Train: [ 42/180] Step 450/1249 Loss 0.981 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.968, lat_loss 6.664
09/18 11:57:30 PM | Train: [ 42/180] Step 500/1249 Loss 0.983 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.968, lat_loss 6.664
09/18 11:57:46 PM | Train: [ 42/180] Step 550/1249 Loss 0.977 Prec@(1,3) (75.0%, 98.2%), ce_loss 0.968, lat_loss 6.664
09/18 11:58:02 PM | Train: [ 42/180] Step 600/1249 Loss 0.976 Prec@(1,3) (75.1%, 98.2%), ce_loss 0.968, lat_loss 6.664
09/18 11:58:26 PM | Train: [ 42/180] Step 650/1249 Loss 0.978 Prec@(1,3) (75.1%, 98.2%), ce_loss 0.968, lat_loss 6.664
09/18 11:58:51 PM | Train: [ 42/180] Step 700/1249 Loss 0.976 Prec@(1,3) (75.1%, 98.2%), ce_loss 0.967, lat_loss 6.664
09/18 11:59:15 PM | Train: [ 42/180] Step 750/1249 Loss 0.976 Prec@(1,3) (75.1%, 98.2%), ce_loss 0.967, lat_loss 6.664
09/18 11:59:40 PM | Train: [ 42/180] Step 800/1249 Loss 0.976 Prec@(1,3) (75.1%, 98.2%), ce_loss 0.967, lat_loss 6.664
09/19 12:00:05 AM | Train: [ 42/180] Step 850/1249 Loss 0.979 Prec@(1,3) (75.0%, 98.2%), ce_loss 0.967, lat_loss 6.664
09/19 12:00:30 AM | Train: [ 42/180] Step 900/1249 Loss 0.979 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.967, lat_loss 6.664
09/19 12:00:54 AM | Train: [ 42/180] Step 950/1249 Loss 0.985 Prec@(1,3) (74.8%, 98.2%), ce_loss 0.967, lat_loss 6.664
09/19 12:01:19 AM | Train: [ 42/180] Step 1000/1249 Loss 0.984 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.967, lat_loss 6.664
09/19 12:01:43 AM | Train: [ 42/180] Step 1050/1249 Loss 0.987 Prec@(1,3) (74.8%, 98.2%), ce_loss 0.966, lat_loss 6.664
09/19 12:02:08 AM | Train: [ 42/180] Step 1100/1249 Loss 0.988 Prec@(1,3) (74.8%, 98.2%), ce_loss 0.966, lat_loss 6.664
09/19 12:02:33 AM | Train: [ 42/180] Step 1150/1249 Loss 0.986 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.966, lat_loss 6.664
09/19 12:02:57 AM | Train: [ 42/180] Step 1200/1249 Loss 0.987 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.966, lat_loss 6.664
09/19 12:03:21 AM | Train: [ 42/180] Step 1249/1249 Loss 0.988 Prec@(1,3) (74.8%, 98.1%), ce_loss 0.966, lat_loss 6.664
09/19 12:03:21 AM | _w_step_train: [ 42/180] Final Prec@1 74.8450% Time 513.61
09/19 12:03:21 AM | Start to train theta for epoch 41
09/19 12:03:43 AM | Train: [ 42/180] Step 050/312 Loss 1.000 Prec@(1,3) (74.4%, 98.0%), ce_loss 0.966, lat_loss 6.665
09/19 12:04:03 AM | Train: [ 42/180] Step 100/312 Loss 0.996 Prec@(1,3) (75.2%, 98.1%), ce_loss 0.965, lat_loss 6.665
09/19 12:04:24 AM | Train: [ 42/180] Step 150/312 Loss 1.010 Prec@(1,3) (74.6%, 97.9%), ce_loss 0.965, lat_loss 6.665
09/19 12:04:45 AM | Train: [ 42/180] Step 200/312 Loss 1.008 Prec@(1,3) (74.7%, 98.0%), ce_loss 0.965, lat_loss 6.665
09/19 12:05:05 AM | Train: [ 42/180] Step 250/312 Loss 1.002 Prec@(1,3) (74.7%, 98.1%), ce_loss 0.965, lat_loss 6.665
09/19 12:05:26 AM | Train: [ 42/180] Step 300/312 Loss 0.999 Prec@(1,3) (74.6%, 98.0%), ce_loss 0.965, lat_loss 6.665
09/19 12:05:31 AM | Train: [ 42/180] Step 312/312 Loss 1.001 Prec@(1,3) (74.5%, 98.0%), ce_loss 0.965, lat_loss 6.665
09/19 12:05:31 AM | _theta_step_train: [ 42/180] Final Prec@1 74.4700% Time 130.07
09/19 12:05:37 AM | Valid: [ 42/180] Step 050/312 Loss 1.492 Prec@(1,3) (63.1%, 95.2%), ce_loss 0.965, lat_loss 6.665
09/19 12:05:41 AM | Valid: [ 42/180] Step 100/312 Loss 1.430 Prec@(1,3) (64.7%, 95.7%), ce_loss 0.965, lat_loss 6.665
09/19 12:05:46 AM | Valid: [ 42/180] Step 150/312 Loss 1.432 Prec@(1,3) (65.1%, 95.3%), ce_loss 0.965, lat_loss 6.665
09/19 12:05:50 AM | Valid: [ 42/180] Step 200/312 Loss 1.400 Prec@(1,3) (66.2%, 95.7%), ce_loss 0.965, lat_loss 6.665
09/19 12:05:54 AM | Valid: [ 42/180] Step 250/312 Loss 1.402 Prec@(1,3) (66.1%, 95.8%), ce_loss 0.965, lat_loss 6.665
09/19 12:05:58 AM | Valid: [ 42/180] Step 300/312 Loss 1.418 Prec@(1,3) (66.1%, 95.5%), ce_loss 0.965, lat_loss 6.665
09/19 12:05:59 AM | Valid: [ 42/180] Step 312/312 Loss 1.414 Prec@(1,3) (66.0%, 95.5%), ce_loss 0.965, lat_loss 6.665
09/19 12:05:59 AM | val: [ 42/180] Final Prec@1 66.0500% Time 27.81
09/19 12:05:59 AM | Start to train weights for epoch 42
09/19 12:06:17 AM | Train: [ 43/180] Step 050/1249 Loss 0.962 Prec@(1,3) (76.8%, 98.5%), ce_loss 0.965, lat_loss 6.665
09/19 12:06:33 AM | Train: [ 43/180] Step 100/1249 Loss 0.982 Prec@(1,3) (76.0%, 98.4%), ce_loss 0.965, lat_loss 6.665
09/19 12:06:49 AM | Train: [ 43/180] Step 150/1249 Loss 0.978 Prec@(1,3) (75.4%, 98.5%), ce_loss 0.965, lat_loss 6.665
09/19 12:07:05 AM | Train: [ 43/180] Step 200/1249 Loss 0.975 Prec@(1,3) (75.5%, 98.4%), ce_loss 0.965, lat_loss 6.665
09/19 12:07:21 AM | Train: [ 43/180] Step 250/1249 Loss 0.967 Prec@(1,3) (75.4%, 98.4%), ce_loss 0.964, lat_loss 6.665
09/19 12:07:37 AM | Train: [ 43/180] Step 300/1249 Loss 0.976 Prec@(1,3) (75.3%, 98.3%), ce_loss 0.964, lat_loss 6.665
09/19 12:07:53 AM | Train: [ 43/180] Step 350/1249 Loss 0.982 Prec@(1,3) (75.1%, 98.2%), ce_loss 0.964, lat_loss 6.665
09/19 12:08:09 AM | Train: [ 43/180] Step 400/1249 Loss 0.979 Prec@(1,3) (75.2%, 98.2%), ce_loss 0.964, lat_loss 6.665
09/19 12:08:25 AM | Train: [ 43/180] Step 450/1249 Loss 0.976 Prec@(1,3) (75.3%, 98.2%), ce_loss 0.964, lat_loss 6.665
09/19 12:08:41 AM | Train: [ 43/180] Step 500/1249 Loss 0.981 Prec@(1,3) (75.3%, 98.1%), ce_loss 0.964, lat_loss 6.665
09/19 12:08:57 AM | Train: [ 43/180] Step 550/1249 Loss 0.976 Prec@(1,3) (75.4%, 98.1%), ce_loss 0.963, lat_loss 6.665
09/19 12:09:13 AM | Train: [ 43/180] Step 600/1249 Loss 0.976 Prec@(1,3) (75.3%, 98.1%), ce_loss 0.963, lat_loss 6.665
09/19 12:09:29 AM | Train: [ 43/180] Step 650/1249 Loss 0.973 Prec@(1,3) (75.4%, 98.2%), ce_loss 0.963, lat_loss 6.665
09/19 12:09:45 AM | Train: [ 43/180] Step 700/1249 Loss 0.970 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.963, lat_loss 6.665
09/19 12:10:01 AM | Train: [ 43/180] Step 750/1249 Loss 0.967 Prec@(1,3) (75.6%, 98.2%), ce_loss 0.963, lat_loss 6.665
09/19 12:10:17 AM | Train: [ 43/180] Step 800/1249 Loss 0.965 Prec@(1,3) (75.6%, 98.2%), ce_loss 0.963, lat_loss 6.665
09/19 12:10:33 AM | Train: [ 43/180] Step 850/1249 Loss 0.966 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.962, lat_loss 6.665
09/19 12:10:49 AM | Train: [ 43/180] Step 900/1249 Loss 0.970 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.962, lat_loss 6.665
09/19 12:11:05 AM | Train: [ 43/180] Step 950/1249 Loss 0.971 Prec@(1,3) (75.4%, 98.3%), ce_loss 0.962, lat_loss 6.665
09/19 12:11:21 AM | Train: [ 43/180] Step 1000/1249 Loss 0.974 Prec@(1,3) (75.4%, 98.2%), ce_loss 0.962, lat_loss 6.665
09/19 12:11:38 AM | Train: [ 43/180] Step 1050/1249 Loss 0.974 Prec@(1,3) (75.4%, 98.2%), ce_loss 0.962, lat_loss 6.665
09/19 12:11:54 AM | Train: [ 43/180] Step 1100/1249 Loss 0.977 Prec@(1,3) (75.3%, 98.2%), ce_loss 0.962, lat_loss 6.665
09/19 12:12:10 AM | Train: [ 43/180] Step 1150/1249 Loss 0.976 Prec@(1,3) (75.3%, 98.2%), ce_loss 0.962, lat_loss 6.665
09/19 12:12:26 AM | Train: [ 43/180] Step 1200/1249 Loss 0.974 Prec@(1,3) (75.3%, 98.2%), ce_loss 0.961, lat_loss 6.665
09/19 12:12:41 AM | Train: [ 43/180] Step 1249/1249 Loss 0.973 Prec@(1,3) (75.4%, 98.2%), ce_loss 0.961, lat_loss 6.665
09/19 12:12:41 AM | _w_step_train: [ 43/180] Final Prec@1 75.4125% Time 401.98
09/19 12:12:41 AM | Start to train theta for epoch 42
09/19 12:13:01 AM | Train: [ 43/180] Step 050/312 Loss 1.102 Prec@(1,3) (72.1%, 97.7%), ce_loss 0.961, lat_loss 6.665
09/19 12:13:22 AM | Train: [ 43/180] Step 100/312 Loss 1.075 Prec@(1,3) (72.6%, 98.0%), ce_loss 0.961, lat_loss 6.665
09/19 12:13:41 AM | Train: [ 43/180] Step 150/312 Loss 1.072 Prec@(1,3) (73.1%, 97.8%), ce_loss 0.961, lat_loss 6.665
09/19 12:14:00 AM | Train: [ 43/180] Step 200/312 Loss 1.059 Prec@(1,3) (73.1%, 98.0%), ce_loss 0.961, lat_loss 6.665
09/19 12:14:20 AM | Train: [ 43/180] Step 250/312 Loss 1.046 Prec@(1,3) (73.6%, 98.0%), ce_loss 0.961, lat_loss 6.665
09/19 12:14:40 AM | Train: [ 43/180] Step 300/312 Loss 1.043 Prec@(1,3) (73.8%, 98.0%), ce_loss 0.960, lat_loss 6.665
09/19 12:14:45 AM | Train: [ 43/180] Step 312/312 Loss 1.041 Prec@(1,3) (73.9%, 97.9%), ce_loss 0.960, lat_loss 6.665
09/19 12:14:45 AM | _theta_step_train: [ 43/180] Final Prec@1 73.8600% Time 123.48
09/19 12:14:50 AM | Valid: [ 43/180] Step 050/312 Loss 1.299 Prec@(1,3) (67.5%, 96.8%), ce_loss 0.960, lat_loss 6.665
09/19 12:14:55 AM | Valid: [ 43/180] Step 100/312 Loss 1.324 Prec@(1,3) (67.5%, 96.5%), ce_loss 0.960, lat_loss 6.665
09/19 12:14:59 AM | Valid: [ 43/180] Step 150/312 Loss 1.329 Prec@(1,3) (67.6%, 96.5%), ce_loss 0.960, lat_loss 6.665
09/19 12:15:04 AM | Valid: [ 43/180] Step 200/312 Loss 1.335 Prec@(1,3) (67.4%, 96.7%), ce_loss 0.960, lat_loss 6.665
09/19 12:15:09 AM | Valid: [ 43/180] Step 250/312 Loss 1.323 Prec@(1,3) (67.7%, 96.8%), ce_loss 0.960, lat_loss 6.665
09/19 12:15:13 AM | Valid: [ 43/180] Step 300/312 Loss 1.331 Prec@(1,3) (67.6%, 96.5%), ce_loss 0.961, lat_loss 6.665
09/19 12:15:14 AM | Valid: [ 43/180] Step 312/312 Loss 1.332 Prec@(1,3) (67.5%, 96.5%), ce_loss 0.961, lat_loss 6.665
09/19 12:15:14 AM | val: [ 43/180] Final Prec@1 67.4900% Time 29.69
09/19 12:15:14 AM | Start to train weights for epoch 43
09/19 12:15:41 AM | Train: [ 44/180] Step 050/1249 Loss 1.026 Prec@(1,3) (74.8%, 97.5%), ce_loss 0.960, lat_loss 6.665
09/19 12:16:05 AM | Train: [ 44/180] Step 100/1249 Loss 1.003 Prec@(1,3) (74.8%, 97.9%), ce_loss 0.960, lat_loss 6.665
09/19 12:16:28 AM | Train: [ 44/180] Step 150/1249 Loss 1.001 Prec@(1,3) (75.1%, 97.7%), ce_loss 0.960, lat_loss 6.666
09/19 12:16:52 AM | Train: [ 44/180] Step 200/1249 Loss 0.993 Prec@(1,3) (75.2%, 97.7%), ce_loss 0.960, lat_loss 6.666
09/19 12:17:16 AM | Train: [ 44/180] Step 250/1249 Loss 0.993 Prec@(1,3) (75.1%, 97.8%), ce_loss 0.960, lat_loss 6.666
09/19 12:17:38 AM | Train: [ 44/180] Step 300/1249 Loss 1.004 Prec@(1,3) (74.6%, 97.8%), ce_loss 0.960, lat_loss 6.666
09/19 12:18:01 AM | Train: [ 44/180] Step 350/1249 Loss 1.002 Prec@(1,3) (74.5%, 97.9%), ce_loss 0.960, lat_loss 6.666
09/19 12:18:26 AM | Train: [ 44/180] Step 400/1249 Loss 0.995 Prec@(1,3) (74.8%, 97.9%), ce_loss 0.959, lat_loss 6.666
09/19 12:18:47 AM | Train: [ 44/180] Step 450/1249 Loss 0.994 Prec@(1,3) (74.8%, 97.9%), ce_loss 0.959, lat_loss 6.666
09/19 12:19:09 AM | Train: [ 44/180] Step 500/1249 Loss 0.995 Prec@(1,3) (74.8%, 98.0%), ce_loss 0.959, lat_loss 6.666
09/19 12:19:30 AM | Train: [ 44/180] Step 550/1249 Loss 0.988 Prec@(1,3) (74.9%, 98.0%), ce_loss 0.959, lat_loss 6.666
09/19 12:19:52 AM | Train: [ 44/180] Step 600/1249 Loss 0.987 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.959, lat_loss 6.666
09/19 12:20:13 AM | Train: [ 44/180] Step 650/1249 Loss 0.988 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.959, lat_loss 6.666
09/19 12:20:35 AM | Train: [ 44/180] Step 700/1249 Loss 0.984 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.958, lat_loss 6.666
09/19 12:20:56 AM | Train: [ 44/180] Step 750/1249 Loss 0.985 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.958, lat_loss 6.666
09/19 12:21:17 AM | Train: [ 44/180] Step 800/1249 Loss 0.984 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.958, lat_loss 6.666
09/19 12:21:38 AM | Train: [ 44/180] Step 850/1249 Loss 0.984 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.958, lat_loss 6.666
09/19 12:22:00 AM | Train: [ 44/180] Step 900/1249 Loss 0.979 Prec@(1,3) (75.2%, 98.1%), ce_loss 0.958, lat_loss 6.666
09/19 12:22:23 AM | Train: [ 44/180] Step 950/1249 Loss 0.984 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.958, lat_loss 6.666
09/19 12:22:44 AM | Train: [ 44/180] Step 1000/1249 Loss 0.985 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.958, lat_loss 6.666
09/19 12:23:07 AM | Train: [ 44/180] Step 1050/1249 Loss 0.987 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.957, lat_loss 6.666
09/19 12:23:28 AM | Train: [ 44/180] Step 1100/1249 Loss 0.989 Prec@(1,3) (74.8%, 98.1%), ce_loss 0.957, lat_loss 6.666
09/19 12:23:50 AM | Train: [ 44/180] Step 1150/1249 Loss 0.991 Prec@(1,3) (74.8%, 98.1%), ce_loss 0.957, lat_loss 6.666
09/19 12:24:13 AM | Train: [ 44/180] Step 1200/1249 Loss 0.989 Prec@(1,3) (74.8%, 98.1%), ce_loss 0.957, lat_loss 6.666
09/19 12:24:37 AM | Train: [ 44/180] Step 1249/1249 Loss 0.989 Prec@(1,3) (74.8%, 98.1%), ce_loss 0.957, lat_loss 6.666
09/19 12:24:38 AM | _w_step_train: [ 44/180] Final Prec@1 74.7750% Time 563.05
09/19 12:24:38 AM | Start to train theta for epoch 43
09/19 12:24:59 AM | Train: [ 44/180] Step 050/312 Loss 1.004 Prec@(1,3) (74.4%, 97.8%), ce_loss 0.957, lat_loss 6.666
09/19 12:25:19 AM | Train: [ 44/180] Step 100/312 Loss 0.997 Prec@(1,3) (74.8%, 98.0%), ce_loss 0.957, lat_loss 6.666
09/19 12:25:39 AM | Train: [ 44/180] Step 150/312 Loss 0.990 Prec@(1,3) (75.0%, 98.2%), ce_loss 0.956, lat_loss 6.666
09/19 12:26:00 AM | Train: [ 44/180] Step 200/312 Loss 0.982 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.956, lat_loss 6.666
09/19 12:26:20 AM | Train: [ 44/180] Step 250/312 Loss 0.988 Prec@(1,3) (74.7%, 98.3%), ce_loss 0.956, lat_loss 6.666
09/19 12:26:41 AM | Train: [ 44/180] Step 300/312 Loss 0.986 Prec@(1,3) (74.7%, 98.3%), ce_loss 0.956, lat_loss 6.666
09/19 12:26:45 AM | Train: [ 44/180] Step 312/312 Loss 0.991 Prec@(1,3) (74.5%, 98.2%), ce_loss 0.956, lat_loss 6.666
09/19 12:26:45 AM | _theta_step_train: [ 44/180] Final Prec@1 74.5300% Time 127.90
09/19 12:26:50 AM | Valid: [ 44/180] Step 050/312 Loss 1.342 Prec@(1,3) (65.1%, 96.3%), ce_loss 0.956, lat_loss 6.666
09/19 12:26:55 AM | Valid: [ 44/180] Step 100/312 Loss 1.355 Prec@(1,3) (65.3%, 95.7%), ce_loss 0.956, lat_loss 6.666
09/19 12:26:59 AM | Valid: [ 44/180] Step 150/312 Loss 1.370 Prec@(1,3) (65.1%, 95.5%), ce_loss 0.956, lat_loss 6.666
09/19 12:27:03 AM | Valid: [ 44/180] Step 200/312 Loss 1.362 Prec@(1,3) (65.7%, 95.6%), ce_loss 0.956, lat_loss 6.666
09/19 12:27:07 AM | Valid: [ 44/180] Step 250/312 Loss 1.364 Prec@(1,3) (65.8%, 95.6%), ce_loss 0.956, lat_loss 6.666
09/19 12:27:11 AM | Valid: [ 44/180] Step 300/312 Loss 1.373 Prec@(1,3) (65.8%, 95.5%), ce_loss 0.956, lat_loss 6.666
09/19 12:27:12 AM | Valid: [ 44/180] Step 312/312 Loss 1.373 Prec@(1,3) (65.7%, 95.6%), ce_loss 0.956, lat_loss 6.666
09/19 12:27:13 AM | val: [ 44/180] Final Prec@1 65.6900% Time 27.09
09/19 12:27:13 AM | Start to train weights for epoch 44
09/19 12:27:30 AM | Train: [ 45/180] Step 050/1249 Loss 0.990 Prec@(1,3) (74.5%, 98.2%), ce_loss 0.956, lat_loss 6.666
09/19 12:27:46 AM | Train: [ 45/180] Step 100/1249 Loss 0.975 Prec@(1,3) (75.1%, 98.2%), ce_loss 0.956, lat_loss 6.666
09/19 12:28:02 AM | Train: [ 45/180] Step 150/1249 Loss 0.995 Prec@(1,3) (74.7%, 98.0%), ce_loss 0.956, lat_loss 6.666
09/19 12:28:18 AM | Train: [ 45/180] Step 200/1249 Loss 0.993 Prec@(1,3) (74.8%, 98.0%), ce_loss 0.956, lat_loss 6.666
09/19 12:28:35 AM | Train: [ 45/180] Step 250/1249 Loss 0.990 Prec@(1,3) (74.8%, 98.1%), ce_loss 0.956, lat_loss 6.666
09/19 12:28:51 AM | Train: [ 45/180] Step 300/1249 Loss 0.989 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.955, lat_loss 6.666
09/19 12:29:07 AM | Train: [ 45/180] Step 350/1249 Loss 0.988 Prec@(1,3) (74.8%, 98.1%), ce_loss 0.955, lat_loss 6.666
09/19 12:29:23 AM | Train: [ 45/180] Step 400/1249 Loss 0.985 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.955, lat_loss 6.666
09/19 12:29:39 AM | Train: [ 45/180] Step 450/1249 Loss 0.988 Prec@(1,3) (74.8%, 98.1%), ce_loss 0.955, lat_loss 6.666
09/19 12:29:59 AM | Train: [ 45/180] Step 500/1249 Loss 0.990 Prec@(1,3) (74.8%, 98.1%), ce_loss 0.955, lat_loss 6.666
09/19 12:30:24 AM | Train: [ 45/180] Step 550/1249 Loss 0.987 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.955, lat_loss 6.666
09/19 12:30:48 AM | Train: [ 45/180] Step 600/1249 Loss 0.985 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.955, lat_loss 6.667
09/19 12:31:13 AM | Train: [ 45/180] Step 650/1249 Loss 0.982 Prec@(1,3) (75.0%, 98.2%), ce_loss 0.954, lat_loss 6.667
09/19 12:31:38 AM | Train: [ 45/180] Step 700/1249 Loss 0.980 Prec@(1,3) (75.0%, 98.2%), ce_loss 0.954, lat_loss 6.667
09/19 12:32:03 AM | Train: [ 45/180] Step 750/1249 Loss 0.979 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.954, lat_loss 6.667
09/19 12:32:28 AM | Train: [ 45/180] Step 800/1249 Loss 0.981 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.954, lat_loss 6.667
09/19 12:32:52 AM | Train: [ 45/180] Step 850/1249 Loss 0.983 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.954, lat_loss 6.667
09/19 12:33:16 AM | Train: [ 45/180] Step 900/1249 Loss 0.982 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.954, lat_loss 6.667
09/19 12:33:41 AM | Train: [ 45/180] Step 950/1249 Loss 0.982 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.954, lat_loss 6.667
09/19 12:34:06 AM | Train: [ 45/180] Step 1000/1249 Loss 0.985 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.953, lat_loss 6.667
09/19 12:34:30 AM | Train: [ 45/180] Step 1050/1249 Loss 0.981 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.953, lat_loss 6.667
09/19 12:34:53 AM | Train: [ 45/180] Step 1100/1249 Loss 0.982 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.953, lat_loss 6.667
09/19 12:35:18 AM | Train: [ 45/180] Step 1150/1249 Loss 0.985 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.953, lat_loss 6.667
09/19 12:35:42 AM | Train: [ 45/180] Step 1200/1249 Loss 0.985 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.953, lat_loss 6.667
09/19 12:36:07 AM | Train: [ 45/180] Step 1249/1249 Loss 0.984 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.953, lat_loss 6.667
09/19 12:36:07 AM | _w_step_train: [ 45/180] Final Prec@1 74.9150% Time 534.23
09/19 12:36:07 AM | Start to train theta for epoch 44
09/19 12:36:28 AM | Train: [ 45/180] Step 050/312 Loss 0.986 Prec@(1,3) (76.1%, 97.9%), ce_loss 0.953, lat_loss 6.667
09/19 12:36:49 AM | Train: [ 45/180] Step 100/312 Loss 0.990 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.952, lat_loss 6.667
09/19 12:37:09 AM | Train: [ 45/180] Step 150/312 Loss 1.033 Prec@(1,3) (74.6%, 97.6%), ce_loss 0.952, lat_loss 6.667
09/19 12:37:29 AM | Train: [ 45/180] Step 200/312 Loss 1.022 Prec@(1,3) (74.6%, 97.8%), ce_loss 0.952, lat_loss 6.667
09/19 12:37:50 AM | Train: [ 45/180] Step 250/312 Loss 1.024 Prec@(1,3) (74.5%, 97.8%), ce_loss 0.952, lat_loss 6.667
09/19 12:38:11 AM | Train: [ 45/180] Step 300/312 Loss 1.032 Prec@(1,3) (74.3%, 97.8%), ce_loss 0.952, lat_loss 6.667
09/19 12:38:16 AM | Train: [ 45/180] Step 312/312 Loss 1.026 Prec@(1,3) (74.4%, 97.8%), ce_loss 0.952, lat_loss 6.667
09/19 12:38:17 AM | _theta_step_train: [ 45/180] Final Prec@1 74.4400% Time 129.96
09/19 12:38:22 AM | Valid: [ 45/180] Step 050/312 Loss 1.215 Prec@(1,3) (70.7%, 98.0%), ce_loss 0.952, lat_loss 6.667
09/19 12:38:27 AM | Valid: [ 45/180] Step 100/312 Loss 1.299 Prec@(1,3) (68.5%, 96.7%), ce_loss 0.952, lat_loss 6.667
09/19 12:38:31 AM | Valid: [ 45/180] Step 150/312 Loss 1.281 Prec@(1,3) (68.9%, 96.6%), ce_loss 0.952, lat_loss 6.667
09/19 12:38:36 AM | Valid: [ 45/180] Step 200/312 Loss 1.295 Prec@(1,3) (68.8%, 96.7%), ce_loss 0.952, lat_loss 6.667
09/19 12:38:41 AM | Valid: [ 45/180] Step 250/312 Loss 1.312 Prec@(1,3) (68.3%, 96.5%), ce_loss 0.952, lat_loss 6.667
09/19 12:38:45 AM | Valid: [ 45/180] Step 300/312 Loss 1.295 Prec@(1,3) (68.5%, 96.7%), ce_loss 0.952, lat_loss 6.667
09/19 12:38:46 AM | Valid: [ 45/180] Step 312/312 Loss 1.291 Prec@(1,3) (68.6%, 96.7%), ce_loss 0.952, lat_loss 6.667
09/19 12:38:46 AM | val: [ 45/180] Final Prec@1 68.6100% Time 29.66
09/19 12:38:46 AM | Start to train weights for epoch 45
09/19 12:39:12 AM | Train: [ 46/180] Step 050/1249 Loss 0.968 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.952, lat_loss 6.667
09/19 12:39:37 AM | Train: [ 46/180] Step 100/1249 Loss 0.963 Prec@(1,3) (76.1%, 98.5%), ce_loss 0.952, lat_loss 6.667
09/19 12:40:02 AM | Train: [ 46/180] Step 150/1249 Loss 0.974 Prec@(1,3) (75.5%, 98.4%), ce_loss 0.952, lat_loss 6.667
09/19 12:40:27 AM | Train: [ 46/180] Step 200/1249 Loss 0.980 Prec@(1,3) (75.3%, 98.3%), ce_loss 0.951, lat_loss 6.667
09/19 12:40:52 AM | Train: [ 46/180] Step 250/1249 Loss 0.981 Prec@(1,3) (75.3%, 98.2%), ce_loss 0.951, lat_loss 6.667
09/19 12:41:17 AM | Train: [ 46/180] Step 300/1249 Loss 0.974 Prec@(1,3) (75.3%, 98.3%), ce_loss 0.951, lat_loss 6.667
09/19 12:41:41 AM | Train: [ 46/180] Step 350/1249 Loss 0.975 Prec@(1,3) (75.2%, 98.4%), ce_loss 0.951, lat_loss 6.667
09/19 12:42:06 AM | Train: [ 46/180] Step 400/1249 Loss 0.964 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.951, lat_loss 6.667
09/19 12:42:31 AM | Train: [ 46/180] Step 450/1249 Loss 0.967 Prec@(1,3) (75.4%, 98.3%), ce_loss 0.951, lat_loss 6.667
09/19 12:42:55 AM | Train: [ 46/180] Step 500/1249 Loss 0.971 Prec@(1,3) (75.4%, 98.3%), ce_loss 0.951, lat_loss 6.667
09/19 12:43:16 AM | Train: [ 46/180] Step 550/1249 Loss 0.972 Prec@(1,3) (75.3%, 98.2%), ce_loss 0.950, lat_loss 6.667
09/19 12:43:39 AM | Train: [ 46/180] Step 600/1249 Loss 0.969 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.950, lat_loss 6.667
09/19 12:44:02 AM | Train: [ 46/180] Step 650/1249 Loss 0.972 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.950, lat_loss 6.667
09/19 12:44:26 AM | Train: [ 46/180] Step 700/1249 Loss 0.973 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.950, lat_loss 6.667
09/19 12:44:50 AM | Train: [ 46/180] Step 750/1249 Loss 0.974 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.950, lat_loss 6.667
09/19 12:45:14 AM | Train: [ 46/180] Step 800/1249 Loss 0.974 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.950, lat_loss 6.667
09/19 12:45:38 AM | Train: [ 46/180] Step 850/1249 Loss 0.972 Prec@(1,3) (75.6%, 98.2%), ce_loss 0.950, lat_loss 6.667
09/19 12:46:01 AM | Train: [ 46/180] Step 900/1249 Loss 0.967 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.949, lat_loss 6.667
09/19 12:46:25 AM | Train: [ 46/180] Step 950/1249 Loss 0.966 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.949, lat_loss 6.667
09/19 12:46:49 AM | Train: [ 46/180] Step 1000/1249 Loss 0.967 Prec@(1,3) (75.8%, 98.2%), ce_loss 0.949, lat_loss 6.667
09/19 12:47:12 AM | Train: [ 46/180] Step 1050/1249 Loss 0.966 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.949, lat_loss 6.667
09/19 12:47:35 AM | Train: [ 46/180] Step 1100/1249 Loss 0.966 Prec@(1,3) (75.8%, 98.1%), ce_loss 0.949, lat_loss 6.667
09/19 12:47:59 AM | Train: [ 46/180] Step 1150/1249 Loss 0.970 Prec@(1,3) (75.7%, 98.1%), ce_loss 0.949, lat_loss 6.668
09/19 12:48:23 AM | Train: [ 46/180] Step 1200/1249 Loss 0.968 Prec@(1,3) (75.7%, 98.1%), ce_loss 0.949, lat_loss 6.668
09/19 12:48:47 AM | Train: [ 46/180] Step 1249/1249 Loss 0.968 Prec@(1,3) (75.7%, 98.1%), ce_loss 0.948, lat_loss 6.668
09/19 12:48:48 AM | _w_step_train: [ 46/180] Final Prec@1 75.7200% Time 601.03
09/19 12:48:48 AM | Start to train theta for epoch 45
09/19 12:49:09 AM | Train: [ 46/180] Step 050/312 Loss 1.006 Prec@(1,3) (74.1%, 98.3%), ce_loss 0.948, lat_loss 6.668
09/19 12:49:29 AM | Train: [ 46/180] Step 100/312 Loss 1.011 Prec@(1,3) (74.1%, 98.0%), ce_loss 0.948, lat_loss 6.668
09/19 12:49:49 AM | Train: [ 46/180] Step 150/312 Loss 1.000 Prec@(1,3) (74.5%, 97.9%), ce_loss 0.948, lat_loss 6.668
09/19 12:50:09 AM | Train: [ 46/180] Step 200/312 Loss 1.004 Prec@(1,3) (74.6%, 97.7%), ce_loss 0.948, lat_loss 6.668
09/19 12:50:30 AM | Train: [ 46/180] Step 250/312 Loss 1.004 Prec@(1,3) (74.4%, 97.8%), ce_loss 0.948, lat_loss 6.668
09/19 12:50:50 AM | Train: [ 46/180] Step 300/312 Loss 1.020 Prec@(1,3) (74.0%, 97.7%), ce_loss 0.948, lat_loss 6.668
09/19 12:50:55 AM | Train: [ 46/180] Step 312/312 Loss 1.016 Prec@(1,3) (74.1%, 97.7%), ce_loss 0.948, lat_loss 6.668
09/19 12:50:55 AM | _theta_step_train: [ 46/180] Final Prec@1 74.0600% Time 127.60
09/19 12:51:00 AM | Valid: [ 46/180] Step 050/312 Loss 1.447 Prec@(1,3) (64.3%, 93.8%), ce_loss 0.948, lat_loss 6.668
09/19 12:51:05 AM | Valid: [ 46/180] Step 100/312 Loss 1.375 Prec@(1,3) (66.2%, 95.0%), ce_loss 0.948, lat_loss 6.668
09/19 12:51:10 AM | Valid: [ 46/180] Step 150/312 Loss 1.333 Prec@(1,3) (67.4%, 95.5%), ce_loss 0.948, lat_loss 6.668
09/19 12:51:14 AM | Valid: [ 46/180] Step 200/312 Loss 1.328 Prec@(1,3) (67.6%, 95.7%), ce_loss 0.948, lat_loss 6.668
09/19 12:51:19 AM | Valid: [ 46/180] Step 250/312 Loss 1.322 Prec@(1,3) (67.9%, 95.9%), ce_loss 0.948, lat_loss 6.668
09/19 12:51:24 AM | Valid: [ 46/180] Step 300/312 Loss 1.337 Prec@(1,3) (67.3%, 95.7%), ce_loss 0.948, lat_loss 6.668
09/19 12:51:25 AM | Valid: [ 46/180] Step 312/312 Loss 1.336 Prec@(1,3) (67.3%, 95.7%), ce_loss 0.948, lat_loss 6.668
09/19 12:51:25 AM | val: [ 46/180] Final Prec@1 67.2800% Time 30.06
09/19 12:51:25 AM | Start to train weights for epoch 46
09/19 12:51:51 AM | Train: [ 47/180] Step 050/1249 Loss 0.918 Prec@(1,3) (75.7%, 98.5%), ce_loss 0.948, lat_loss 6.668
09/19 12:52:16 AM | Train: [ 47/180] Step 100/1249 Loss 0.898 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.947, lat_loss 6.668
09/19 12:52:41 AM | Train: [ 47/180] Step 150/1249 Loss 0.906 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.947, lat_loss 6.668
09/19 12:53:05 AM | Train: [ 47/180] Step 200/1249 Loss 0.935 Prec@(1,3) (76.7%, 98.3%), ce_loss 0.947, lat_loss 6.668
09/19 12:53:29 AM | Train: [ 47/180] Step 250/1249 Loss 0.938 Prec@(1,3) (76.5%, 98.4%), ce_loss 0.947, lat_loss 6.668
09/19 12:53:53 AM | Train: [ 47/180] Step 300/1249 Loss 0.949 Prec@(1,3) (76.3%, 98.3%), ce_loss 0.947, lat_loss 6.668
09/19 12:54:18 AM | Train: [ 47/180] Step 350/1249 Loss 0.948 Prec@(1,3) (76.3%, 98.3%), ce_loss 0.947, lat_loss 6.668
09/19 12:54:43 AM | Train: [ 47/180] Step 400/1249 Loss 0.950 Prec@(1,3) (76.3%, 98.3%), ce_loss 0.947, lat_loss 6.668
09/19 12:55:07 AM | Train: [ 47/180] Step 450/1249 Loss 0.944 Prec@(1,3) (76.3%, 98.3%), ce_loss 0.946, lat_loss 6.668
09/19 12:55:32 AM | Train: [ 47/180] Step 500/1249 Loss 0.945 Prec@(1,3) (76.2%, 98.3%), ce_loss 0.946, lat_loss 6.668
09/19 12:55:56 AM | Train: [ 47/180] Step 550/1249 Loss 0.951 Prec@(1,3) (76.1%, 98.3%), ce_loss 0.946, lat_loss 6.668
09/19 12:56:20 AM | Train: [ 47/180] Step 600/1249 Loss 0.952 Prec@(1,3) (76.1%, 98.3%), ce_loss 0.946, lat_loss 6.668
09/19 12:56:45 AM | Train: [ 47/180] Step 650/1249 Loss 0.953 Prec@(1,3) (76.1%, 98.3%), ce_loss 0.946, lat_loss 6.668
09/19 12:57:09 AM | Train: [ 47/180] Step 700/1249 Loss 0.955 Prec@(1,3) (76.0%, 98.3%), ce_loss 0.946, lat_loss 6.668
09/19 12:57:34 AM | Train: [ 47/180] Step 750/1249 Loss 0.955 Prec@(1,3) (76.0%, 98.3%), ce_loss 0.946, lat_loss 6.668
09/19 12:57:59 AM | Train: [ 47/180] Step 800/1249 Loss 0.957 Prec@(1,3) (75.9%, 98.3%), ce_loss 0.945, lat_loss 6.668
09/19 12:58:24 AM | Train: [ 47/180] Step 850/1249 Loss 0.957 Prec@(1,3) (75.9%, 98.3%), ce_loss 0.945, lat_loss 6.668
09/19 12:58:49 AM | Train: [ 47/180] Step 900/1249 Loss 0.956 Prec@(1,3) (75.9%, 98.3%), ce_loss 0.945, lat_loss 6.668
09/19 12:59:14 AM | Train: [ 47/180] Step 950/1249 Loss 0.959 Prec@(1,3) (75.8%, 98.3%), ce_loss 0.945, lat_loss 6.668
09/19 12:59:39 AM | Train: [ 47/180] Step 1000/1249 Loss 0.963 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.945, lat_loss 6.668
09/19 01:00:03 AM | Train: [ 47/180] Step 1050/1249 Loss 0.961 Prec@(1,3) (75.8%, 98.2%), ce_loss 0.945, lat_loss 6.668
09/19 01:00:28 AM | Train: [ 47/180] Step 1100/1249 Loss 0.961 Prec@(1,3) (75.8%, 98.2%), ce_loss 0.945, lat_loss 6.668
09/19 01:00:53 AM | Train: [ 47/180] Step 1150/1249 Loss 0.965 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.945, lat_loss 6.668
09/19 01:01:18 AM | Train: [ 47/180] Step 1200/1249 Loss 0.965 Prec@(1,3) (75.8%, 98.2%), ce_loss 0.944, lat_loss 6.668
09/19 01:01:43 AM | Train: [ 47/180] Step 1249/1249 Loss 0.964 Prec@(1,3) (75.8%, 98.2%), ce_loss 0.944, lat_loss 6.668
09/19 01:01:43 AM | _w_step_train: [ 47/180] Final Prec@1 75.7925% Time 617.51
09/19 01:01:43 AM | Start to train theta for epoch 46
09/19 01:02:04 AM | Train: [ 47/180] Step 050/312 Loss 0.971 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.944, lat_loss 6.668
09/19 01:02:25 AM | Train: [ 47/180] Step 100/312 Loss 0.993 Prec@(1,3) (75.0%, 98.0%), ce_loss 0.944, lat_loss 6.668
09/19 01:02:45 AM | Train: [ 47/180] Step 150/312 Loss 0.988 Prec@(1,3) (75.2%, 98.0%), ce_loss 0.944, lat_loss 6.668
09/19 01:03:06 AM | Train: [ 47/180] Step 200/312 Loss 0.988 Prec@(1,3) (75.1%, 97.8%), ce_loss 0.944, lat_loss 6.668
09/19 01:03:26 AM | Train: [ 47/180] Step 250/312 Loss 0.989 Prec@(1,3) (75.1%, 97.8%), ce_loss 0.944, lat_loss 6.668
09/19 01:03:47 AM | Train: [ 47/180] Step 300/312 Loss 0.996 Prec@(1,3) (75.1%, 97.8%), ce_loss 0.944, lat_loss 6.668
09/19 01:03:51 AM | Train: [ 47/180] Step 312/312 Loss 0.994 Prec@(1,3) (75.1%, 97.8%), ce_loss 0.944, lat_loss 6.668
09/19 01:03:52 AM | _theta_step_train: [ 47/180] Final Prec@1 75.0800% Time 128.78
09/19 01:03:57 AM | Valid: [ 47/180] Step 050/312 Loss 1.200 Prec@(1,3) (70.6%, 96.9%), ce_loss 0.943, lat_loss 6.668
09/19 01:04:01 AM | Valid: [ 47/180] Step 100/312 Loss 1.214 Prec@(1,3) (70.9%, 96.6%), ce_loss 0.943, lat_loss 6.668
09/19 01:04:06 AM | Valid: [ 47/180] Step 150/312 Loss 1.191 Prec@(1,3) (71.2%, 96.8%), ce_loss 0.943, lat_loss 6.669
09/19 01:04:11 AM | Valid: [ 47/180] Step 200/312 Loss 1.191 Prec@(1,3) (71.0%, 96.9%), ce_loss 0.943, lat_loss 6.669
09/19 01:04:15 AM | Valid: [ 47/180] Step 250/312 Loss 1.228 Prec@(1,3) (70.2%, 96.8%), ce_loss 0.943, lat_loss 6.669
09/19 01:04:20 AM | Valid: [ 47/180] Step 300/312 Loss 1.222 Prec@(1,3) (70.0%, 96.9%), ce_loss 0.943, lat_loss 6.669
09/19 01:04:21 AM | Valid: [ 47/180] Step 312/312 Loss 1.230 Prec@(1,3) (69.7%, 96.8%), ce_loss 0.943, lat_loss 6.669
09/19 01:04:21 AM | val: [ 47/180] Final Prec@1 69.7400% Time 29.36
09/19 01:04:21 AM | Start to train weights for epoch 47
09/19 01:04:47 AM | Train: [ 48/180] Step 050/1249 Loss 0.955 Prec@(1,3) (75.9%, 98.0%), ce_loss 0.943, lat_loss 6.669
09/19 01:05:11 AM | Train: [ 48/180] Step 100/1249 Loss 0.925 Prec@(1,3) (77.1%, 98.1%), ce_loss 0.943, lat_loss 6.669
09/19 01:05:35 AM | Train: [ 48/180] Step 150/1249 Loss 0.945 Prec@(1,3) (76.1%, 98.1%), ce_loss 0.943, lat_loss 6.669
09/19 01:06:00 AM | Train: [ 48/180] Step 200/1249 Loss 0.942 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.943, lat_loss 6.669
09/19 01:06:25 AM | Train: [ 48/180] Step 250/1249 Loss 0.949 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.943, lat_loss 6.669
09/19 01:06:50 AM | Train: [ 48/180] Step 300/1249 Loss 0.948 Prec@(1,3) (75.7%, 98.2%), ce_loss 0.943, lat_loss 6.669
09/19 01:07:15 AM | Train: [ 48/180] Step 350/1249 Loss 0.944 Prec@(1,3) (75.8%, 98.3%), ce_loss 0.942, lat_loss 6.669
09/19 01:07:40 AM | Train: [ 48/180] Step 400/1249 Loss 0.947 Prec@(1,3) (75.7%, 98.3%), ce_loss 0.942, lat_loss 6.669
09/19 01:08:05 AM | Train: [ 48/180] Step 450/1249 Loss 0.950 Prec@(1,3) (75.7%, 98.3%), ce_loss 0.942, lat_loss 6.669
09/19 01:08:30 AM | Train: [ 48/180] Step 500/1249 Loss 0.950 Prec@(1,3) (75.7%, 98.3%), ce_loss 0.942, lat_loss 6.669
09/19 01:08:55 AM | Train: [ 48/180] Step 550/1249 Loss 0.948 Prec@(1,3) (75.8%, 98.3%), ce_loss 0.942, lat_loss 6.669
09/19 01:09:21 AM | Train: [ 48/180] Step 600/1249 Loss 0.948 Prec@(1,3) (75.9%, 98.3%), ce_loss 0.942, lat_loss 6.669
09/19 01:09:46 AM | Train: [ 48/180] Step 650/1249 Loss 0.952 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.942, lat_loss 6.669
09/19 01:10:10 AM | Train: [ 48/180] Step 700/1249 Loss 0.952 Prec@(1,3) (75.8%, 98.3%), ce_loss 0.941, lat_loss 6.669
09/19 01:10:34 AM | Train: [ 48/180] Step 750/1249 Loss 0.957 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.941, lat_loss 6.669
09/19 01:10:57 AM | Train: [ 48/180] Step 800/1249 Loss 0.958 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.941, lat_loss 6.669
09/19 01:11:21 AM | Train: [ 48/180] Step 850/1249 Loss 0.957 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.941, lat_loss 6.669
09/19 01:11:44 AM | Train: [ 48/180] Step 900/1249 Loss 0.955 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.941, lat_loss 6.669
09/19 01:12:08 AM | Train: [ 48/180] Step 950/1249 Loss 0.956 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.941, lat_loss 6.669
09/19 01:12:31 AM | Train: [ 48/180] Step 1000/1249 Loss 0.956 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.941, lat_loss 6.669
09/19 01:12:54 AM | Train: [ 48/180] Step 1050/1249 Loss 0.957 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.941, lat_loss 6.669
09/19 01:13:17 AM | Train: [ 48/180] Step 1100/1249 Loss 0.957 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.940, lat_loss 6.669
09/19 01:13:41 AM | Train: [ 48/180] Step 1150/1249 Loss 0.955 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.940, lat_loss 6.669
09/19 01:14:05 AM | Train: [ 48/180] Step 1200/1249 Loss 0.957 Prec@(1,3) (75.5%, 98.3%), ce_loss 0.940, lat_loss 6.669
09/19 01:14:27 AM | Train: [ 48/180] Step 1249/1249 Loss 0.956 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.940, lat_loss 6.669
09/19 01:14:27 AM | _w_step_train: [ 48/180] Final Prec@1 75.5800% Time 606.42
09/19 01:14:27 AM | Start to train theta for epoch 47
09/19 01:14:44 AM | Train: [ 48/180] Step 050/312 Loss 0.886 Prec@(1,3) (76.9%, 98.5%), ce_loss 0.940, lat_loss 6.669
09/19 01:15:04 AM | Train: [ 48/180] Step 100/312 Loss 0.969 Prec@(1,3) (75.2%, 97.8%), ce_loss 0.940, lat_loss 6.669
09/19 01:15:24 AM | Train: [ 48/180] Step 150/312 Loss 0.972 Prec@(1,3) (75.1%, 98.0%), ce_loss 0.940, lat_loss 6.669
09/19 01:15:44 AM | Train: [ 48/180] Step 200/312 Loss 0.984 Prec@(1,3) (74.9%, 98.0%), ce_loss 0.939, lat_loss 6.669
09/19 01:16:04 AM | Train: [ 48/180] Step 250/312 Loss 0.988 Prec@(1,3) (74.8%, 98.0%), ce_loss 0.939, lat_loss 6.669
09/19 01:16:22 AM | Train: [ 48/180] Step 300/312 Loss 0.988 Prec@(1,3) (74.8%, 97.9%), ce_loss 0.939, lat_loss 6.669
09/19 01:16:27 AM | Train: [ 48/180] Step 312/312 Loss 0.989 Prec@(1,3) (74.9%, 97.9%), ce_loss 0.939, lat_loss 6.669
09/19 01:16:27 AM | _theta_step_train: [ 48/180] Final Prec@1 74.8600% Time 119.62
09/19 01:16:32 AM | Valid: [ 48/180] Step 050/312 Loss 1.264 Prec@(1,3) (69.7%, 96.3%), ce_loss 0.939, lat_loss 6.669
09/19 01:16:37 AM | Valid: [ 48/180] Step 100/312 Loss 1.323 Prec@(1,3) (67.9%, 96.0%), ce_loss 0.939, lat_loss 6.669
09/19 01:16:41 AM | Valid: [ 48/180] Step 150/312 Loss 1.335 Prec@(1,3) (68.2%, 96.2%), ce_loss 0.939, lat_loss 6.669
09/19 01:16:46 AM | Valid: [ 48/180] Step 200/312 Loss 1.284 Prec@(1,3) (69.5%, 96.6%), ce_loss 0.939, lat_loss 6.669
09/19 01:16:51 AM | Valid: [ 48/180] Step 250/312 Loss 1.265 Prec@(1,3) (69.7%, 96.8%), ce_loss 0.939, lat_loss 6.669
09/19 01:16:55 AM | Valid: [ 48/180] Step 300/312 Loss 1.251 Prec@(1,3) (69.8%, 96.9%), ce_loss 0.939, lat_loss 6.669
09/19 01:16:56 AM | Valid: [ 48/180] Step 312/312 Loss 1.257 Prec@(1,3) (69.7%, 96.9%), ce_loss 0.939, lat_loss 6.669
09/19 01:16:56 AM | val: [ 48/180] Final Prec@1 69.6600% Time 29.44
09/19 01:16:56 AM | Start to train weights for epoch 48
09/19 01:17:20 AM | Train: [ 49/180] Step 050/1249 Loss 1.027 Prec@(1,3) (73.4%, 98.2%), ce_loss 0.939, lat_loss 6.669
09/19 01:17:45 AM | Train: [ 49/180] Step 100/1249 Loss 0.989 Prec@(1,3) (74.2%, 98.2%), ce_loss 0.939, lat_loss 6.669
09/19 01:18:09 AM | Train: [ 49/180] Step 150/1249 Loss 0.959 Prec@(1,3) (75.1%, 98.3%), ce_loss 0.939, lat_loss 6.669
09/19 01:18:33 AM | Train: [ 49/180] Step 200/1249 Loss 0.963 Prec@(1,3) (75.2%, 98.3%), ce_loss 0.939, lat_loss 6.669
09/19 01:18:58 AM | Train: [ 49/180] Step 250/1249 Loss 0.976 Prec@(1,3) (75.1%, 98.2%), ce_loss 0.939, lat_loss 6.669
09/19 01:19:22 AM | Train: [ 49/180] Step 300/1249 Loss 0.974 Prec@(1,3) (75.2%, 98.1%), ce_loss 0.938, lat_loss 6.669
09/19 01:19:45 AM | Train: [ 49/180] Step 350/1249 Loss 0.975 Prec@(1,3) (75.3%, 98.2%), ce_loss 0.938, lat_loss 6.669
09/19 01:20:07 AM | Train: [ 49/180] Step 400/1249 Loss 0.969 Prec@(1,3) (75.5%, 98.2%), ce_loss 0.938, lat_loss 6.669
09/19 01:20:29 AM | Train: [ 49/180] Step 450/1249 Loss 0.966 Prec@(1,3) (75.6%, 98.1%), ce_loss 0.938, lat_loss 6.669
09/19 01:20:52 AM | Train: [ 49/180] Step 500/1249 Loss 0.965 Prec@(1,3) (75.6%, 98.1%), ce_loss 0.938, lat_loss 6.669
09/19 01:21:15 AM | Train: [ 49/180] Step 550/1249 Loss 0.973 Prec@(1,3) (75.4%, 98.0%), ce_loss 0.938, lat_loss 6.669
09/19 01:21:36 AM | Train: [ 49/180] Step 600/1249 Loss 0.965 Prec@(1,3) (75.6%, 98.1%), ce_loss 0.938, lat_loss 6.669
09/19 01:22:00 AM | Train: [ 49/180] Step 650/1249 Loss 0.964 Prec@(1,3) (75.7%, 98.1%), ce_loss 0.938, lat_loss 6.670
09/19 01:22:20 AM | Train: [ 49/180] Step 700/1249 Loss 0.958 Prec@(1,3) (75.8%, 98.1%), ce_loss 0.937, lat_loss 6.670
09/19 01:22:43 AM | Train: [ 49/180] Step 750/1249 Loss 0.958 Prec@(1,3) (75.8%, 98.2%), ce_loss 0.937, lat_loss 6.670
09/19 01:23:06 AM | Train: [ 49/180] Step 800/1249 Loss 0.957 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.937, lat_loss 6.670
09/19 01:23:27 AM | Train: [ 49/180] Step 850/1249 Loss 0.956 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.937, lat_loss 6.670
09/19 01:23:48 AM | Train: [ 49/180] Step 900/1249 Loss 0.953 Prec@(1,3) (76.0%, 98.2%), ce_loss 0.937, lat_loss 6.670
09/19 01:24:10 AM | Train: [ 49/180] Step 950/1249 Loss 0.953 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.937, lat_loss 6.670
09/19 01:24:31 AM | Train: [ 49/180] Step 1000/1249 Loss 0.955 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.937, lat_loss 6.670
09/19 01:24:53 AM | Train: [ 49/180] Step 1050/1249 Loss 0.957 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.936, lat_loss 6.670
09/19 01:25:13 AM | Train: [ 49/180] Step 1100/1249 Loss 0.958 Prec@(1,3) (75.8%, 98.2%), ce_loss 0.936, lat_loss 6.670
09/19 01:25:34 AM | Train: [ 49/180] Step 1150/1249 Loss 0.957 Prec@(1,3) (75.8%, 98.2%), ce_loss 0.936, lat_loss 6.670
09/19 01:25:56 AM | Train: [ 49/180] Step 1200/1249 Loss 0.954 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.936, lat_loss 6.670
09/19 01:26:20 AM | Train: [ 49/180] Step 1249/1249 Loss 0.952 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.936, lat_loss 6.670
09/19 01:26:20 AM | _w_step_train: [ 49/180] Final Prec@1 75.9425% Time 563.73
09/19 01:26:20 AM | Start to train theta for epoch 48
09/19 01:26:39 AM | Train: [ 49/180] Step 050/312 Loss 1.069 Prec@(1,3) (72.5%, 97.7%), ce_loss 0.936, lat_loss 6.670
09/19 01:26:58 AM | Train: [ 49/180] Step 100/312 Loss 1.052 Prec@(1,3) (73.4%, 97.7%), ce_loss 0.936, lat_loss 6.670
09/19 01:27:17 AM | Train: [ 49/180] Step 150/312 Loss 1.050 Prec@(1,3) (73.8%, 97.7%), ce_loss 0.936, lat_loss 6.670
09/19 01:27:36 AM | Train: [ 49/180] Step 200/312 Loss 1.031 Prec@(1,3) (74.1%, 97.8%), ce_loss 0.935, lat_loss 6.670
09/19 01:27:53 AM | Train: [ 49/180] Step 250/312 Loss 1.018 Prec@(1,3) (74.7%, 98.0%), ce_loss 0.935, lat_loss 6.670
09/19 01:28:12 AM | Train: [ 49/180] Step 300/312 Loss 1.015 Prec@(1,3) (74.7%, 98.1%), ce_loss 0.935, lat_loss 6.670
09/19 01:28:16 AM | Train: [ 49/180] Step 312/312 Loss 1.018 Prec@(1,3) (74.7%, 98.0%), ce_loss 0.935, lat_loss 6.670
09/19 01:28:16 AM | _theta_step_train: [ 49/180] Final Prec@1 74.6700% Time 116.08
09/19 01:28:21 AM | Valid: [ 49/180] Step 050/312 Loss 1.215 Prec@(1,3) (69.2%, 97.4%), ce_loss 0.935, lat_loss 6.670
09/19 01:28:26 AM | Valid: [ 49/180] Step 100/312 Loss 1.232 Prec@(1,3) (69.8%, 97.2%), ce_loss 0.935, lat_loss 6.670
09/19 01:28:31 AM | Valid: [ 49/180] Step 150/312 Loss 1.271 Prec@(1,3) (69.4%, 96.8%), ce_loss 0.935, lat_loss 6.670
09/19 01:28:35 AM | Valid: [ 49/180] Step 200/312 Loss 1.288 Prec@(1,3) (68.6%, 96.8%), ce_loss 0.935, lat_loss 6.670
09/19 01:28:40 AM | Valid: [ 49/180] Step 250/312 Loss 1.278 Prec@(1,3) (68.8%, 96.8%), ce_loss 0.935, lat_loss 6.670
09/19 01:28:45 AM | Valid: [ 49/180] Step 300/312 Loss 1.276 Prec@(1,3) (68.9%, 96.9%), ce_loss 0.935, lat_loss 6.670
09/19 01:28:46 AM | Valid: [ 49/180] Step 312/312 Loss 1.294 Prec@(1,3) (68.5%, 96.8%), ce_loss 0.935, lat_loss 6.670
09/19 01:28:46 AM | val: [ 49/180] Final Prec@1 68.5300% Time 29.47
09/19 01:28:46 AM | Start to train weights for epoch 49
09/19 01:29:11 AM | Train: [ 50/180] Step 050/1249 Loss 0.969 Prec@(1,3) (75.4%, 98.0%), ce_loss 0.935, lat_loss 6.670
09/19 01:29:34 AM | Train: [ 50/180] Step 100/1249 Loss 0.976 Prec@(1,3) (76.0%, 97.9%), ce_loss 0.935, lat_loss 6.670
09/19 01:29:58 AM | Train: [ 50/180] Step 150/1249 Loss 0.963 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.935, lat_loss 6.670
09/19 01:30:22 AM | Train: [ 50/180] Step 200/1249 Loss 0.974 Prec@(1,3) (75.9%, 98.0%), ce_loss 0.935, lat_loss 6.670
09/19 01:30:45 AM | Train: [ 50/180] Step 250/1249 Loss 0.969 Prec@(1,3) (76.0%, 98.1%), ce_loss 0.935, lat_loss 6.670
09/19 01:31:05 AM | Train: [ 50/180] Step 300/1249 Loss 0.969 Prec@(1,3) (75.9%, 98.1%), ce_loss 0.935, lat_loss 6.670
09/19 01:31:28 AM | Train: [ 50/180] Step 350/1249 Loss 0.960 Prec@(1,3) (76.0%, 98.1%), ce_loss 0.934, lat_loss 6.670
09/19 01:31:51 AM | Train: [ 50/180] Step 400/1249 Loss 0.961 Prec@(1,3) (76.1%, 98.1%), ce_loss 0.934, lat_loss 6.670
09/19 01:32:14 AM | Train: [ 50/180] Step 450/1249 Loss 0.956 Prec@(1,3) (76.1%, 98.1%), ce_loss 0.934, lat_loss 6.670
09/19 01:32:37 AM | Train: [ 50/180] Step 500/1249 Loss 0.960 Prec@(1,3) (75.9%, 98.1%), ce_loss 0.934, lat_loss 6.670
09/19 01:33:00 AM | Train: [ 50/180] Step 550/1249 Loss 0.962 Prec@(1,3) (75.9%, 98.1%), ce_loss 0.934, lat_loss 6.670
09/19 01:33:22 AM | Train: [ 50/180] Step 600/1249 Loss 0.959 Prec@(1,3) (76.1%, 98.1%), ce_loss 0.934, lat_loss 6.670
09/19 01:33:45 AM | Train: [ 50/180] Step 650/1249 Loss 0.959 Prec@(1,3) (76.2%, 98.1%), ce_loss 0.934, lat_loss 6.670
09/19 01:34:10 AM | Train: [ 50/180] Step 700/1249 Loss 0.958 Prec@(1,3) (76.2%, 98.1%), ce_loss 0.934, lat_loss 6.670
09/19 01:34:34 AM | Train: [ 50/180] Step 750/1249 Loss 0.954 Prec@(1,3) (76.2%, 98.2%), ce_loss 0.933, lat_loss 6.670
09/19 01:35:00 AM | Train: [ 50/180] Step 800/1249 Loss 0.951 Prec@(1,3) (76.3%, 98.2%), ce_loss 0.933, lat_loss 6.670
09/19 01:35:24 AM | Train: [ 50/180] Step 850/1249 Loss 0.953 Prec@(1,3) (76.2%, 98.1%), ce_loss 0.933, lat_loss 6.670
09/19 01:35:47 AM | Train: [ 50/180] Step 900/1249 Loss 0.957 Prec@(1,3) (76.0%, 98.1%), ce_loss 0.933, lat_loss 6.670
09/19 01:36:12 AM | Train: [ 50/180] Step 950/1249 Loss 0.955 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.933, lat_loss 6.670
09/19 01:36:35 AM | Train: [ 50/180] Step 1000/1249 Loss 0.953 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.933, lat_loss 6.670
09/19 01:36:58 AM | Train: [ 50/180] Step 1050/1249 Loss 0.954 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.933, lat_loss 6.670
09/19 01:37:21 AM | Train: [ 50/180] Step 1100/1249 Loss 0.956 Prec@(1,3) (76.0%, 98.2%), ce_loss 0.932, lat_loss 6.670
09/19 01:37:45 AM | Train: [ 50/180] Step 1150/1249 Loss 0.956 Prec@(1,3) (76.0%, 98.2%), ce_loss 0.932, lat_loss 6.670
09/19 01:38:09 AM | Train: [ 50/180] Step 1200/1249 Loss 0.958 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.932, lat_loss 6.670
09/19 01:38:34 AM | Train: [ 50/180] Step 1249/1249 Loss 0.958 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.932, lat_loss 6.670
09/19 01:38:34 AM | _w_step_train: [ 50/180] Final Prec@1 75.8950% Time 588.21
09/19 01:38:34 AM | Start to train theta for epoch 49
09/19 01:38:54 AM | Train: [ 50/180] Step 050/312 Loss 0.999 Prec@(1,3) (73.9%, 98.5%), ce_loss 0.932, lat_loss 6.670
09/19 01:39:14 AM | Train: [ 50/180] Step 100/312 Loss 0.970 Prec@(1,3) (75.1%, 98.4%), ce_loss 0.932, lat_loss 6.670
09/19 01:39:34 AM | Train: [ 50/180] Step 150/312 Loss 0.965 Prec@(1,3) (75.2%, 98.5%), ce_loss 0.932, lat_loss 6.671
09/19 01:39:53 AM | Train: [ 50/180] Step 200/312 Loss 0.980 Prec@(1,3) (75.0%, 98.3%), ce_loss 0.932, lat_loss 6.671
09/19 01:40:14 AM | Train: [ 50/180] Step 250/312 Loss 0.991 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.932, lat_loss 6.671
09/19 01:40:34 AM | Train: [ 50/180] Step 300/312 Loss 0.995 Prec@(1,3) (74.7%, 98.1%), ce_loss 0.931, lat_loss 6.671
09/19 01:40:39 AM | Train: [ 50/180] Step 312/312 Loss 0.989 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.931, lat_loss 6.671
09/19 01:40:39 AM | _theta_step_train: [ 50/180] Final Prec@1 74.8900% Time 125.36
09/19 01:40:45 AM | Valid: [ 50/180] Step 050/312 Loss 1.278 Prec@(1,3) (68.6%, 96.0%), ce_loss 0.931, lat_loss 6.671
09/19 01:40:49 AM | Valid: [ 50/180] Step 100/312 Loss 1.199 Prec@(1,3) (70.3%, 96.7%), ce_loss 0.931, lat_loss 6.671
09/19 01:40:54 AM | Valid: [ 50/180] Step 150/312 Loss 1.186 Prec@(1,3) (70.7%, 97.0%), ce_loss 0.931, lat_loss 6.671
09/19 01:40:59 AM | Valid: [ 50/180] Step 200/312 Loss 1.195 Prec@(1,3) (71.1%, 97.2%), ce_loss 0.931, lat_loss 6.671
09/19 01:41:03 AM | Valid: [ 50/180] Step 250/312 Loss 1.192 Prec@(1,3) (71.4%, 97.2%), ce_loss 0.931, lat_loss 6.671
09/19 01:41:08 AM | Valid: [ 50/180] Step 300/312 Loss 1.165 Prec@(1,3) (71.8%, 97.4%), ce_loss 0.931, lat_loss 6.671
09/19 01:41:09 AM | Valid: [ 50/180] Step 312/312 Loss 1.160 Prec@(1,3) (71.9%, 97.4%), ce_loss 0.931, lat_loss 6.671
09/19 01:41:09 AM | val: [ 50/180] Final Prec@1 71.9200% Time 29.85
09/19 01:41:09 AM | Best top1 acc by now. Save model
09/19 01:41:09 AM | Start to train weights for epoch 50
09/19 01:41:36 AM | Train: [ 51/180] Step 050/1249 Loss 0.945 Prec@(1,3) (75.2%, 98.0%), ce_loss 0.931, lat_loss 6.671
09/19 01:41:59 AM | Train: [ 51/180] Step 100/1249 Loss 0.971 Prec@(1,3) (74.8%, 98.3%), ce_loss 0.931, lat_loss 6.671
09/19 01:42:15 AM | Train: [ 51/180] Step 150/1249 Loss 0.959 Prec@(1,3) (75.6%, 98.3%), ce_loss 0.931, lat_loss 6.671
09/19 01:42:31 AM | Train: [ 51/180] Step 200/1249 Loss 0.936 Prec@(1,3) (76.3%, 98.4%), ce_loss 0.931, lat_loss 6.671
09/19 01:42:46 AM | Train: [ 51/180] Step 250/1249 Loss 0.926 Prec@(1,3) (76.7%, 98.4%), ce_loss 0.931, lat_loss 6.671
09/19 01:43:03 AM | Train: [ 51/180] Step 300/1249 Loss 0.927 Prec@(1,3) (76.7%, 98.3%), ce_loss 0.930, lat_loss 6.671
09/19 01:43:19 AM | Train: [ 51/180] Step 350/1249 Loss 0.910 Prec@(1,3) (77.1%, 98.3%), ce_loss 0.930, lat_loss 6.671
09/19 01:43:34 AM | Train: [ 51/180] Step 400/1249 Loss 0.916 Prec@(1,3) (77.0%, 98.3%), ce_loss 0.930, lat_loss 6.671
09/19 01:43:50 AM | Train: [ 51/180] Step 450/1249 Loss 0.922 Prec@(1,3) (76.9%, 98.4%), ce_loss 0.930, lat_loss 6.671
09/19 01:44:06 AM | Train: [ 51/180] Step 500/1249 Loss 0.920 Prec@(1,3) (77.0%, 98.3%), ce_loss 0.930, lat_loss 6.671
09/19 01:44:23 AM | Train: [ 51/180] Step 550/1249 Loss 0.930 Prec@(1,3) (76.6%, 98.3%), ce_loss 0.930, lat_loss 6.671
09/19 01:44:45 AM | Train: [ 51/180] Step 600/1249 Loss 0.926 Prec@(1,3) (76.7%, 98.3%), ce_loss 0.930, lat_loss 6.671
09/19 01:45:09 AM | Train: [ 51/180] Step 650/1249 Loss 0.927 Prec@(1,3) (76.7%, 98.3%), ce_loss 0.929, lat_loss 6.671
09/19 01:45:34 AM | Train: [ 51/180] Step 700/1249 Loss 0.931 Prec@(1,3) (76.6%, 98.3%), ce_loss 0.929, lat_loss 6.671
09/19 01:45:58 AM | Train: [ 51/180] Step 750/1249 Loss 0.933 Prec@(1,3) (76.5%, 98.3%), ce_loss 0.929, lat_loss 6.671
09/19 01:46:20 AM | Train: [ 51/180] Step 800/1249 Loss 0.934 Prec@(1,3) (76.5%, 98.3%), ce_loss 0.929, lat_loss 6.671
09/19 01:46:44 AM | Train: [ 51/180] Step 850/1249 Loss 0.933 Prec@(1,3) (76.5%, 98.3%), ce_loss 0.929, lat_loss 6.671
09/19 01:47:06 AM | Train: [ 51/180] Step 900/1249 Loss 0.932 Prec@(1,3) (76.6%, 98.3%), ce_loss 0.929, lat_loss 6.671
09/19 01:47:30 AM | Train: [ 51/180] Step 950/1249 Loss 0.932 Prec@(1,3) (76.5%, 98.3%), ce_loss 0.929, lat_loss 6.671
09/19 01:47:53 AM | Train: [ 51/180] Step 1000/1249 Loss 0.935 Prec@(1,3) (76.4%, 98.3%), ce_loss 0.929, lat_loss 6.671
09/19 01:48:16 AM | Train: [ 51/180] Step 1050/1249 Loss 0.937 Prec@(1,3) (76.4%, 98.3%), ce_loss 0.928, lat_loss 6.671
09/19 01:48:37 AM | Train: [ 51/180] Step 1100/1249 Loss 0.937 Prec@(1,3) (76.3%, 98.3%), ce_loss 0.928, lat_loss 6.671
09/19 01:48:57 AM | Train: [ 51/180] Step 1150/1249 Loss 0.936 Prec@(1,3) (76.3%, 98.4%), ce_loss 0.928, lat_loss 6.671
09/19 01:49:19 AM | Train: [ 51/180] Step 1200/1249 Loss 0.935 Prec@(1,3) (76.3%, 98.4%), ce_loss 0.928, lat_loss 6.671
09/19 01:49:41 AM | Train: [ 51/180] Step 1249/1249 Loss 0.936 Prec@(1,3) (76.3%, 98.4%), ce_loss 0.928, lat_loss 6.671
09/19 01:49:41 AM | _w_step_train: [ 51/180] Final Prec@1 76.3175% Time 511.93
09/19 01:49:41 AM | Start to train theta for epoch 50
09/19 01:50:00 AM | Train: [ 51/180] Step 050/312 Loss 0.989 Prec@(1,3) (74.6%, 98.2%), ce_loss 0.928, lat_loss 6.671
09/19 01:50:17 AM | Train: [ 51/180] Step 100/312 Loss 0.990 Prec@(1,3) (74.9%, 98.2%), ce_loss 0.928, lat_loss 6.671
09/19 01:50:36 AM | Train: [ 51/180] Step 150/312 Loss 0.979 Prec@(1,3) (75.3%, 98.1%), ce_loss 0.928, lat_loss 6.671
09/19 01:50:54 AM | Train: [ 51/180] Step 200/312 Loss 0.978 Prec@(1,3) (75.0%, 98.1%), ce_loss 0.927, lat_loss 6.671
09/19 01:51:12 AM | Train: [ 51/180] Step 250/312 Loss 0.981 Prec@(1,3) (75.0%, 98.0%), ce_loss 0.927, lat_loss 6.671
09/19 01:51:31 AM | Train: [ 51/180] Step 300/312 Loss 0.978 Prec@(1,3) (75.2%, 98.0%), ce_loss 0.927, lat_loss 6.671
09/19 01:51:36 AM | Train: [ 51/180] Step 312/312 Loss 0.977 Prec@(1,3) (75.3%, 98.1%), ce_loss 0.927, lat_loss 6.671
09/19 01:51:36 AM | _theta_step_train: [ 51/180] Final Prec@1 75.2800% Time 114.22
09/19 01:51:41 AM | Valid: [ 51/180] Step 050/312 Loss 1.039 Prec@(1,3) (73.9%, 98.2%), ce_loss 0.927, lat_loss 6.671
09/19 01:51:46 AM | Valid: [ 51/180] Step 100/312 Loss 1.064 Prec@(1,3) (73.6%, 98.1%), ce_loss 0.927, lat_loss 6.671
09/19 01:51:50 AM | Valid: [ 51/180] Step 150/312 Loss 1.069 Prec@(1,3) (73.8%, 97.9%), ce_loss 0.927, lat_loss 6.671
09/19 01:51:55 AM | Valid: [ 51/180] Step 200/312 Loss 1.142 Prec@(1,3) (72.4%, 97.4%), ce_loss 0.927, lat_loss 6.672
09/19 01:51:59 AM | Valid: [ 51/180] Step 250/312 Loss 1.168 Prec@(1,3) (72.0%, 97.2%), ce_loss 0.927, lat_loss 6.672
09/19 01:52:04 AM | Valid: [ 51/180] Step 300/312 Loss 1.143 Prec@(1,3) (72.7%, 97.3%), ce_loss 0.927, lat_loss 6.672
09/19 01:52:05 AM | Valid: [ 51/180] Step 312/312 Loss 1.138 Prec@(1,3) (72.8%, 97.4%), ce_loss 0.927, lat_loss 6.672
09/19 01:52:05 AM | val: [ 51/180] Final Prec@1 72.8400% Time 29.56
09/19 01:52:05 AM | Best top1 acc by now. Save model
09/19 01:52:05 AM | Start to train weights for epoch 51
09/19 01:52:28 AM | Train: [ 52/180] Step 050/1249 Loss 0.896 Prec@(1,3) (77.0%, 98.6%), ce_loss 0.927, lat_loss 6.672
09/19 01:52:44 AM | Train: [ 52/180] Step 100/1249 Loss 0.893 Prec@(1,3) (77.2%, 98.6%), ce_loss 0.927, lat_loss 6.672
09/19 01:52:59 AM | Train: [ 52/180] Step 150/1249 Loss 0.899 Prec@(1,3) (76.8%, 98.5%), ce_loss 0.927, lat_loss 6.672
09/19 01:53:15 AM | Train: [ 52/180] Step 200/1249 Loss 0.908 Prec@(1,3) (76.9%, 98.5%), ce_loss 0.926, lat_loss 6.672
09/19 01:53:31 AM | Train: [ 52/180] Step 250/1249 Loss 0.919 Prec@(1,3) (76.5%, 98.5%), ce_loss 0.926, lat_loss 6.672
09/19 01:53:47 AM | Train: [ 52/180] Step 300/1249 Loss 0.920 Prec@(1,3) (76.6%, 98.5%), ce_loss 0.926, lat_loss 6.672
09/19 01:54:03 AM | Train: [ 52/180] Step 350/1249 Loss 0.918 Prec@(1,3) (76.6%, 98.5%), ce_loss 0.926, lat_loss 6.672
09/19 01:54:19 AM | Train: [ 52/180] Step 400/1249 Loss 0.911 Prec@(1,3) (76.9%, 98.6%), ce_loss 0.926, lat_loss 6.672
09/19 01:54:35 AM | Train: [ 52/180] Step 450/1249 Loss 0.911 Prec@(1,3) (76.9%, 98.6%), ce_loss 0.926, lat_loss 6.672
09/19 01:54:51 AM | Train: [ 52/180] Step 500/1249 Loss 0.908 Prec@(1,3) (77.0%, 98.5%), ce_loss 0.926, lat_loss 6.672
09/19 01:55:07 AM | Train: [ 52/180] Step 550/1249 Loss 0.908 Prec@(1,3) (76.9%, 98.6%), ce_loss 0.925, lat_loss 6.672
09/19 01:55:23 AM | Train: [ 52/180] Step 600/1249 Loss 0.909 Prec@(1,3) (76.9%, 98.5%), ce_loss 0.925, lat_loss 6.672
09/19 01:55:39 AM | Train: [ 52/180] Step 650/1249 Loss 0.905 Prec@(1,3) (77.0%, 98.5%), ce_loss 0.925, lat_loss 6.672
09/19 01:55:55 AM | Train: [ 52/180] Step 700/1249 Loss 0.904 Prec@(1,3) (77.1%, 98.5%), ce_loss 0.925, lat_loss 6.672
09/19 01:56:11 AM | Train: [ 52/180] Step 750/1249 Loss 0.906 Prec@(1,3) (77.0%, 98.5%), ce_loss 0.925, lat_loss 6.672
09/19 01:56:29 AM | Train: [ 52/180] Step 800/1249 Loss 0.907 Prec@(1,3) (77.0%, 98.5%), ce_loss 0.925, lat_loss 6.672
09/19 01:56:51 AM | Train: [ 52/180] Step 850/1249 Loss 0.905 Prec@(1,3) (77.1%, 98.6%), ce_loss 0.925, lat_loss 6.672
09/19 01:57:14 AM | Train: [ 52/180] Step 900/1249 Loss 0.910 Prec@(1,3) (76.9%, 98.5%), ce_loss 0.924, lat_loss 6.672
09/19 01:57:38 AM | Train: [ 52/180] Step 950/1249 Loss 0.908 Prec@(1,3) (77.0%, 98.6%), ce_loss 0.924, lat_loss 6.672
09/19 01:58:01 AM | Train: [ 52/180] Step 1000/1249 Loss 0.907 Prec@(1,3) (77.1%, 98.6%), ce_loss 0.924, lat_loss 6.672
09/19 01:58:23 AM | Train: [ 52/180] Step 1050/1249 Loss 0.905 Prec@(1,3) (77.1%, 98.5%), ce_loss 0.924, lat_loss 6.672
09/19 01:58:44 AM | Train: [ 52/180] Step 1100/1249 Loss 0.907 Prec@(1,3) (77.0%, 98.5%), ce_loss 0.924, lat_loss 6.672
09/19 01:59:07 AM | Train: [ 52/180] Step 1150/1249 Loss 0.905 Prec@(1,3) (77.1%, 98.6%), ce_loss 0.924, lat_loss 6.672
09/19 01:59:30 AM | Train: [ 52/180] Step 1200/1249 Loss 0.906 Prec@(1,3) (77.1%, 98.5%), ce_loss 0.924, lat_loss 6.672
09/19 01:59:55 AM | Train: [ 52/180] Step 1249/1249 Loss 0.908 Prec@(1,3) (77.1%, 98.5%), ce_loss 0.923, lat_loss 6.672
09/19 01:59:55 AM | _w_step_train: [ 52/180] Final Prec@1 77.1300% Time 469.75
09/19 01:59:55 AM | Start to train theta for epoch 51
09/19 02:00:16 AM | Train: [ 52/180] Step 050/312 Loss 1.059 Prec@(1,3) (73.8%, 98.2%), ce_loss 0.923, lat_loss 6.672
09/19 02:00:37 AM | Train: [ 52/180] Step 100/312 Loss 1.032 Prec@(1,3) (73.9%, 98.4%), ce_loss 0.923, lat_loss 6.672
09/19 02:00:58 AM | Train: [ 52/180] Step 150/312 Loss 1.000 Prec@(1,3) (74.8%, 98.3%), ce_loss 0.923, lat_loss 6.672
09/19 02:01:19 AM | Train: [ 52/180] Step 200/312 Loss 1.005 Prec@(1,3) (74.6%, 98.3%), ce_loss 0.923, lat_loss 6.672
09/19 02:01:39 AM | Train: [ 52/180] Step 250/312 Loss 0.990 Prec@(1,3) (75.0%, 98.2%), ce_loss 0.923, lat_loss 6.672
09/19 02:02:00 AM | Train: [ 52/180] Step 300/312 Loss 0.997 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.923, lat_loss 6.672
09/19 02:02:04 AM | Train: [ 52/180] Step 312/312 Loss 0.999 Prec@(1,3) (74.9%, 98.1%), ce_loss 0.923, lat_loss 6.672
09/19 02:02:05 AM | _theta_step_train: [ 52/180] Final Prec@1 74.9400% Time 129.84
09/19 02:02:10 AM | Valid: [ 52/180] Step 050/312 Loss 1.104 Prec@(1,3) (73.3%, 98.2%), ce_loss 0.923, lat_loss 6.672
09/19 02:02:15 AM | Valid: [ 52/180] Step 100/312 Loss 1.054 Prec@(1,3) (74.7%, 98.0%), ce_loss 0.923, lat_loss 6.672
09/19 02:02:19 AM | Valid: [ 52/180] Step 150/312 Loss 1.048 Prec@(1,3) (74.7%, 98.0%), ce_loss 0.923, lat_loss 6.672
09/19 02:02:24 AM | Valid: [ 52/180] Step 200/312 Loss 1.082 Prec@(1,3) (74.2%, 97.8%), ce_loss 0.923, lat_loss 6.672
09/19 02:02:29 AM | Valid: [ 52/180] Step 250/312 Loss 1.079 Prec@(1,3) (74.1%, 97.8%), ce_loss 0.923, lat_loss 6.672
09/19 02:02:33 AM | Valid: [ 52/180] Step 300/312 Loss 1.072 Prec@(1,3) (74.2%, 97.9%), ce_loss 0.922, lat_loss 6.672
09/19 02:02:34 AM | Valid: [ 52/180] Step 312/312 Loss 1.074 Prec@(1,3) (74.0%, 97.9%), ce_loss 0.922, lat_loss 6.672
09/19 02:02:34 AM | val: [ 52/180] Final Prec@1 74.0200% Time 29.35
09/19 02:02:34 AM | Best top1 acc by now. Save model
09/19 02:02:35 AM | Start to train weights for epoch 52
09/19 02:03:00 AM | Train: [ 53/180] Step 050/1249 Loss 0.935 Prec@(1,3) (76.5%, 98.2%), ce_loss 0.922, lat_loss 6.672
09/19 02:03:22 AM | Train: [ 53/180] Step 100/1249 Loss 0.889 Prec@(1,3) (77.7%, 98.2%), ce_loss 0.922, lat_loss 6.672
09/19 02:03:37 AM | Train: [ 53/180] Step 150/1249 Loss 0.900 Prec@(1,3) (77.5%, 98.3%), ce_loss 0.922, lat_loss 6.673
09/19 02:03:51 AM | Train: [ 53/180] Step 200/1249 Loss 0.926 Prec@(1,3) (76.8%, 98.1%), ce_loss 0.922, lat_loss 6.673
09/19 02:04:06 AM | Train: [ 53/180] Step 250/1249 Loss 0.924 Prec@(1,3) (76.8%, 98.1%), ce_loss 0.922, lat_loss 6.673
09/19 02:04:20 AM | Train: [ 53/180] Step 300/1249 Loss 0.925 Prec@(1,3) (76.6%, 98.2%), ce_loss 0.922, lat_loss 6.673
09/19 02:04:35 AM | Train: [ 53/180] Step 350/1249 Loss 0.925 Prec@(1,3) (76.7%, 98.2%), ce_loss 0.922, lat_loss 6.673
09/19 02:04:49 AM | Train: [ 53/180] Step 400/1249 Loss 0.920 Prec@(1,3) (76.7%, 98.3%), ce_loss 0.921, lat_loss 6.673
09/19 02:05:04 AM | Train: [ 53/180] Step 450/1249 Loss 0.922 Prec@(1,3) (76.7%, 98.3%), ce_loss 0.921, lat_loss 6.673
09/19 02:05:18 AM | Train: [ 53/180] Step 500/1249 Loss 0.918 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.921, lat_loss 6.673
09/19 02:05:33 AM | Train: [ 53/180] Step 550/1249 Loss 0.919 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.921, lat_loss 6.673
09/19 02:05:47 AM | Train: [ 53/180] Step 600/1249 Loss 0.921 Prec@(1,3) (76.8%, 98.3%), ce_loss 0.921, lat_loss 6.673
09/19 02:06:02 AM | Train: [ 53/180] Step 650/1249 Loss 0.915 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.921, lat_loss 6.673
09/19 02:06:16 AM | Train: [ 53/180] Step 700/1249 Loss 0.918 Prec@(1,3) (76.8%, 98.3%), ce_loss 0.921, lat_loss 6.673
09/19 02:06:30 AM | Train: [ 53/180] Step 750/1249 Loss 0.919 Prec@(1,3) (76.8%, 98.3%), ce_loss 0.920, lat_loss 6.673
09/19 02:06:45 AM | Train: [ 53/180] Step 800/1249 Loss 0.920 Prec@(1,3) (76.8%, 98.3%), ce_loss 0.920, lat_loss 6.673
09/19 02:06:59 AM | Train: [ 53/180] Step 850/1249 Loss 0.917 Prec@(1,3) (76.8%, 98.3%), ce_loss 0.920, lat_loss 6.673
09/19 02:07:14 AM | Train: [ 53/180] Step 900/1249 Loss 0.918 Prec@(1,3) (76.9%, 98.3%), ce_loss 0.920, lat_loss 6.673
09/19 02:07:28 AM | Train: [ 53/180] Step 950/1249 Loss 0.920 Prec@(1,3) (76.8%, 98.2%), ce_loss 0.920, lat_loss 6.673
09/19 02:07:43 AM | Train: [ 53/180] Step 1000/1249 Loss 0.919 Prec@(1,3) (76.8%, 98.2%), ce_loss 0.920, lat_loss 6.673
09/19 02:07:57 AM | Train: [ 53/180] Step 1050/1249 Loss 0.917 Prec@(1,3) (76.8%, 98.2%), ce_loss 0.920, lat_loss 6.673
09/19 02:08:12 AM | Train: [ 53/180] Step 1100/1249 Loss 0.916 Prec@(1,3) (76.9%, 98.2%), ce_loss 0.920, lat_loss 6.673
09/19 02:08:26 AM | Train: [ 53/180] Step 1150/1249 Loss 0.915 Prec@(1,3) (76.9%, 98.2%), ce_loss 0.919, lat_loss 6.673
09/19 02:08:41 AM | Train: [ 53/180] Step 1200/1249 Loss 0.914 Prec@(1,3) (77.0%, 98.2%), ce_loss 0.919, lat_loss 6.673
09/19 02:08:55 AM | Train: [ 53/180] Step 1249/1249 Loss 0.913 Prec@(1,3) (77.0%, 98.2%), ce_loss 0.919, lat_loss 6.673
09/19 02:08:55 AM | _w_step_train: [ 53/180] Final Prec@1 76.9925% Time 380.24
09/19 02:08:55 AM | Start to train theta for epoch 52
09/19 02:09:15 AM | Train: [ 53/180] Step 050/312 Loss 0.945 Prec@(1,3) (75.8%, 97.5%), ce_loss 0.919, lat_loss 6.673
09/19 02:09:35 AM | Train: [ 53/180] Step 100/312 Loss 0.944 Prec@(1,3) (76.3%, 97.9%), ce_loss 0.919, lat_loss 6.673
09/19 02:09:55 AM | Train: [ 53/180] Step 150/312 Loss 0.954 Prec@(1,3) (76.0%, 98.0%), ce_loss 0.919, lat_loss 6.673
09/19 02:10:14 AM | Train: [ 53/180] Step 200/312 Loss 0.961 Prec@(1,3) (76.0%, 98.0%), ce_loss 0.919, lat_loss 6.673
09/19 02:10:34 AM | Train: [ 53/180] Step 250/312 Loss 0.955 Prec@(1,3) (76.1%, 98.1%), ce_loss 0.919, lat_loss 6.673
09/19 02:10:54 AM | Train: [ 53/180] Step 300/312 Loss 0.962 Prec@(1,3) (75.9%, 98.2%), ce_loss 0.919, lat_loss 6.673
09/19 02:10:59 AM | Train: [ 53/180] Step 312/312 Loss 0.958 Prec@(1,3) (76.0%, 98.2%), ce_loss 0.918, lat_loss 6.673
09/19 02:10:59 AM | _theta_step_train: [ 53/180] Final Prec@1 76.0200% Time 123.91
09/19 02:11:04 AM | Valid: [ 53/180] Step 050/312 Loss 1.061 Prec@(1,3) (74.5%, 98.3%), ce_loss 0.918, lat_loss 6.673
09/19 02:11:09 AM | Valid: [ 53/180] Step 100/312 Loss 1.135 Prec@(1,3) (72.6%, 97.1%), ce_loss 0.918, lat_loss 6.673
09/19 02:11:14 AM | Valid: [ 53/180] Step 150/312 Loss 1.138 Prec@(1,3) (72.8%, 97.2%), ce_loss 0.918, lat_loss 6.673
09/19 02:11:18 AM | Valid: [ 53/180] Step 200/312 Loss 1.102 Prec@(1,3) (73.5%, 97.5%), ce_loss 0.918, lat_loss 6.673
09/19 02:11:23 AM | Valid: [ 53/180] Step 250/312 Loss 1.095 Prec@(1,3) (73.5%, 97.6%), ce_loss 0.918, lat_loss 6.673
09/19 02:11:27 AM | Valid: [ 53/180] Step 300/312 Loss 1.082 Prec@(1,3) (73.8%, 97.7%), ce_loss 0.918, lat_loss 6.673
09/19 02:11:29 AM | Valid: [ 53/180] Step 312/312 Loss 1.083 Prec@(1,3) (73.8%, 97.6%), ce_loss 0.918, lat_loss 6.673
09/19 02:11:29 AM | val: [ 53/180] Final Prec@1 73.8200% Time 29.41
09/19 02:11:29 AM | Start to train weights for epoch 53
09/19 02:11:46 AM | Train: [ 54/180] Step 050/1249 Loss 0.941 Prec@(1,3) (76.1%, 98.0%), ce_loss 0.918, lat_loss 6.673
09/19 02:12:02 AM | Train: [ 54/180] Step 100/1249 Loss 0.933 Prec@(1,3) (76.9%, 97.9%), ce_loss 0.918, lat_loss 6.673
09/19 02:12:18 AM | Train: [ 54/180] Step 150/1249 Loss 0.916 Prec@(1,3) (77.3%, 98.2%), ce_loss 0.918, lat_loss 6.673
09/19 02:12:34 AM | Train: [ 54/180] Step 200/1249 Loss 0.904 Prec@(1,3) (77.4%, 98.3%), ce_loss 0.918, lat_loss 6.673
09/19 02:12:50 AM | Train: [ 54/180] Step 250/1249 Loss 0.899 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.917, lat_loss 6.673
09/19 02:13:06 AM | Train: [ 54/180] Step 300/1249 Loss 0.891 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.917, lat_loss 6.673
09/19 02:13:22 AM | Train: [ 54/180] Step 350/1249 Loss 0.891 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.917, lat_loss 6.673
09/19 02:13:38 AM | Train: [ 54/180] Step 400/1249 Loss 0.892 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.917, lat_loss 6.673
09/19 02:13:54 AM | Train: [ 54/180] Step 450/1249 Loss 0.895 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.917, lat_loss 6.673
09/19 02:14:10 AM | Train: [ 54/180] Step 500/1249 Loss 0.896 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.917, lat_loss 6.673
09/19 02:14:26 AM | Train: [ 54/180] Step 550/1249 Loss 0.897 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.917, lat_loss 6.673
09/19 02:14:42 AM | Train: [ 54/180] Step 600/1249 Loss 0.895 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.916, lat_loss 6.673
09/19 02:14:57 AM | Train: [ 54/180] Step 650/1249 Loss 0.891 Prec@(1,3) (77.5%, 98.6%), ce_loss 0.916, lat_loss 6.674
09/19 02:15:13 AM | Train: [ 54/180] Step 700/1249 Loss 0.890 Prec@(1,3) (77.5%, 98.6%), ce_loss 0.916, lat_loss 6.674
09/19 02:15:29 AM | Train: [ 54/180] Step 750/1249 Loss 0.887 Prec@(1,3) (77.6%, 98.5%), ce_loss 0.916, lat_loss 6.674
09/19 02:15:45 AM | Train: [ 54/180] Step 800/1249 Loss 0.891 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.916, lat_loss 6.674
09/19 02:16:01 AM | Train: [ 54/180] Step 850/1249 Loss 0.889 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.916, lat_loss 6.674
09/19 02:16:17 AM | Train: [ 54/180] Step 900/1249 Loss 0.892 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.916, lat_loss 6.674
09/19 02:16:33 AM | Train: [ 54/180] Step 950/1249 Loss 0.892 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.916, lat_loss 6.674
09/19 02:16:49 AM | Train: [ 54/180] Step 1000/1249 Loss 0.892 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.915, lat_loss 6.674
09/19 02:17:05 AM | Train: [ 54/180] Step 1050/1249 Loss 0.893 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.915, lat_loss 6.674
09/19 02:17:21 AM | Train: [ 54/180] Step 1100/1249 Loss 0.895 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.915, lat_loss 6.674
09/19 02:17:37 AM | Train: [ 54/180] Step 1150/1249 Loss 0.895 Prec@(1,3) (77.4%, 98.5%), ce_loss 0.915, lat_loss 6.674
09/19 02:17:53 AM | Train: [ 54/180] Step 1200/1249 Loss 0.894 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.915, lat_loss 6.674
09/19 02:18:09 AM | Train: [ 54/180] Step 1249/1249 Loss 0.893 Prec@(1,3) (77.5%, 98.5%), ce_loss 0.915, lat_loss 6.674
09/19 02:18:09 AM | _w_step_train: [ 54/180] Final Prec@1 77.4850% Time 400.30
09/19 02:18:09 AM | Start to train theta for epoch 53
09/19 02:18:30 AM | Train: [ 54/180] Step 050/312 Loss 0.881 Prec@(1,3) (77.5%, 98.6%), ce_loss 0.915, lat_loss 6.674
09/19 02:18:51 AM | Train: [ 54/180] Step 100/312 Loss 0.921 Prec@(1,3) (77.4%, 98.3%), ce_loss 0.915, lat_loss 6.674
09/19 02:19:11 AM | Train: [ 54/180] Step 150/312 Loss 0.943 Prec@(1,3) (76.7%, 98.0%), ce_loss 0.914, lat_loss 6.674
09/19 02:19:31 AM | Train: [ 54/180] Step 200/312 Loss 0.934 Prec@(1,3) (76.9%, 98.0%), ce_loss 0.914, lat_loss 6.674
09/19 02:19:52 AM | Train: [ 54/180] Step 250/312 Loss 0.934 Prec@(1,3) (76.7%, 98.1%), ce_loss 0.914, lat_loss 6.674
09/19 02:20:12 AM | Train: [ 54/180] Step 300/312 Loss 0.933 Prec@(1,3) (76.7%, 98.1%), ce_loss 0.914, lat_loss 6.674
09/19 02:20:17 AM | Train: [ 54/180] Step 312/312 Loss 0.934 Prec@(1,3) (76.6%, 98.1%), ce_loss 0.914, lat_loss 6.674
09/19 02:20:17 AM | _theta_step_train: [ 54/180] Final Prec@1 76.6500% Time 128.31
09/19 02:20:23 AM | Valid: [ 54/180] Step 050/312 Loss 1.081 Prec@(1,3) (72.7%, 97.9%), ce_loss 0.914, lat_loss 6.674
09/19 02:20:27 AM | Valid: [ 54/180] Step 100/312 Loss 1.084 Prec@(1,3) (72.8%, 97.7%), ce_loss 0.914, lat_loss 6.674
09/19 02:20:32 AM | Valid: [ 54/180] Step 150/312 Loss 1.070 Prec@(1,3) (73.6%, 97.9%), ce_loss 0.914, lat_loss 6.674
09/19 02:20:37 AM | Valid: [ 54/180] Step 200/312 Loss 1.069 Prec@(1,3) (73.6%, 97.8%), ce_loss 0.914, lat_loss 6.674
09/19 02:20:41 AM | Valid: [ 54/180] Step 250/312 Loss 1.081 Prec@(1,3) (73.5%, 97.7%), ce_loss 0.914, lat_loss 6.674
09/19 02:20:46 AM | Valid: [ 54/180] Step 300/312 Loss 1.084 Prec@(1,3) (73.6%, 97.6%), ce_loss 0.914, lat_loss 6.674
09/19 02:20:47 AM | Valid: [ 54/180] Step 312/312 Loss 1.087 Prec@(1,3) (73.5%, 97.5%), ce_loss 0.914, lat_loss 6.674
09/19 02:20:47 AM | val: [ 54/180] Final Prec@1 73.4500% Time 29.93
09/19 02:20:47 AM | Start to train weights for epoch 54
09/19 02:21:10 AM | Train: [ 55/180] Step 050/1249 Loss 0.895 Prec@(1,3) (77.6%, 98.3%), ce_loss 0.914, lat_loss 6.674
09/19 02:21:31 AM | Train: [ 55/180] Step 100/1249 Loss 0.866 Prec@(1,3) (78.3%, 98.5%), ce_loss 0.913, lat_loss 6.674
09/19 02:21:51 AM | Train: [ 55/180] Step 150/1249 Loss 0.859 Prec@(1,3) (78.5%, 98.4%), ce_loss 0.913, lat_loss 6.674
09/19 02:22:11 AM | Train: [ 55/180] Step 200/1249 Loss 0.854 Prec@(1,3) (78.6%, 98.4%), ce_loss 0.913, lat_loss 6.674
09/19 02:22:31 AM | Train: [ 55/180] Step 250/1249 Loss 0.854 Prec@(1,3) (78.5%, 98.3%), ce_loss 0.913, lat_loss 6.674
09/19 02:22:51 AM | Train: [ 55/180] Step 300/1249 Loss 0.885 Prec@(1,3) (77.7%, 98.2%), ce_loss 0.913, lat_loss 6.674
09/19 02:23:12 AM | Train: [ 55/180] Step 350/1249 Loss 0.888 Prec@(1,3) (77.6%, 98.3%), ce_loss 0.913, lat_loss 6.674
09/19 02:23:32 AM | Train: [ 55/180] Step 400/1249 Loss 0.890 Prec@(1,3) (77.6%, 98.3%), ce_loss 0.913, lat_loss 6.674
09/19 02:23:54 AM | Train: [ 55/180] Step 450/1249 Loss 0.889 Prec@(1,3) (77.5%, 98.3%), ce_loss 0.912, lat_loss 6.674
09/19 02:24:18 AM | Train: [ 55/180] Step 500/1249 Loss 0.884 Prec@(1,3) (77.7%, 98.3%), ce_loss 0.912, lat_loss 6.674
09/19 02:24:42 AM | Train: [ 55/180] Step 550/1249 Loss 0.881 Prec@(1,3) (77.8%, 98.3%), ce_loss 0.912, lat_loss 6.674
09/19 02:25:07 AM | Train: [ 55/180] Step 600/1249 Loss 0.879 Prec@(1,3) (77.9%, 98.3%), ce_loss 0.912, lat_loss 6.674
09/19 02:25:31 AM | Train: [ 55/180] Step 650/1249 Loss 0.884 Prec@(1,3) (77.9%, 98.3%), ce_loss 0.912, lat_loss 6.674
09/19 02:25:55 AM | Train: [ 55/180] Step 700/1249 Loss 0.882 Prec@(1,3) (77.9%, 98.3%), ce_loss 0.912, lat_loss 6.674
09/19 02:26:20 AM | Train: [ 55/180] Step 750/1249 Loss 0.879 Prec@(1,3) (77.9%, 98.3%), ce_loss 0.912, lat_loss 6.674
09/19 02:26:44 AM | Train: [ 55/180] Step 800/1249 Loss 0.882 Prec@(1,3) (77.9%, 98.3%), ce_loss 0.912, lat_loss 6.674
09/19 02:27:08 AM | Train: [ 55/180] Step 850/1249 Loss 0.882 Prec@(1,3) (77.9%, 98.3%), ce_loss 0.911, lat_loss 6.674
09/19 02:27:31 AM | Train: [ 55/180] Step 900/1249 Loss 0.883 Prec@(1,3) (77.8%, 98.3%), ce_loss 0.911, lat_loss 6.674
09/19 02:27:55 AM | Train: [ 55/180] Step 950/1249 Loss 0.886 Prec@(1,3) (77.8%, 98.3%), ce_loss 0.911, lat_loss 6.674
09/19 02:28:19 AM | Train: [ 55/180] Step 1000/1249 Loss 0.888 Prec@(1,3) (77.7%, 98.3%), ce_loss 0.911, lat_loss 6.674
09/19 02:28:43 AM | Train: [ 55/180] Step 1050/1249 Loss 0.887 Prec@(1,3) (77.7%, 98.3%), ce_loss 0.911, lat_loss 6.674
09/19 02:29:07 AM | Train: [ 55/180] Step 1100/1249 Loss 0.886 Prec@(1,3) (77.7%, 98.3%), ce_loss 0.911, lat_loss 6.674
09/19 02:29:31 AM | Train: [ 55/180] Step 1150/1249 Loss 0.887 Prec@(1,3) (77.6%, 98.4%), ce_loss 0.911, lat_loss 6.674
09/19 02:29:55 AM | Train: [ 55/180] Step 1200/1249 Loss 0.886 Prec@(1,3) (77.7%, 98.4%), ce_loss 0.911, lat_loss 6.674
09/19 02:30:19 AM | Train: [ 55/180] Step 1249/1249 Loss 0.885 Prec@(1,3) (77.7%, 98.4%), ce_loss 0.910, lat_loss 6.675
09/19 02:30:19 AM | _w_step_train: [ 55/180] Final Prec@1 77.7225% Time 571.71
09/19 02:30:19 AM | Start to train theta for epoch 54
09/19 02:30:40 AM | Train: [ 55/180] Step 050/312 Loss 0.973 Prec@(1,3) (74.8%, 98.1%), ce_loss 0.910, lat_loss 6.675
09/19 02:31:00 AM | Train: [ 55/180] Step 100/312 Loss 0.934 Prec@(1,3) (76.4%, 98.1%), ce_loss 0.910, lat_loss 6.675
09/19 02:31:20 AM | Train: [ 55/180] Step 150/312 Loss 0.930 Prec@(1,3) (76.2%, 98.2%), ce_loss 0.910, lat_loss 6.675
09/19 02:31:41 AM | Train: [ 55/180] Step 200/312 Loss 0.921 Prec@(1,3) (76.4%, 98.2%), ce_loss 0.910, lat_loss 6.675
09/19 02:32:01 AM | Train: [ 55/180] Step 250/312 Loss 0.929 Prec@(1,3) (76.4%, 98.1%), ce_loss 0.910, lat_loss 6.675
09/19 02:32:21 AM | Train: [ 55/180] Step 300/312 Loss 0.923 Prec@(1,3) (76.5%, 98.1%), ce_loss 0.910, lat_loss 6.675
09/19 02:32:26 AM | Train: [ 55/180] Step 312/312 Loss 0.921 Prec@(1,3) (76.6%, 98.1%), ce_loss 0.910, lat_loss 6.675
09/19 02:32:26 AM | _theta_step_train: [ 55/180] Final Prec@1 76.5600% Time 127.13
09/19 02:32:31 AM | Valid: [ 55/180] Step 050/312 Loss 0.961 Prec@(1,3) (75.4%, 98.3%), ce_loss 0.910, lat_loss 6.675
09/19 02:32:36 AM | Valid: [ 55/180] Step 100/312 Loss 0.971 Prec@(1,3) (75.8%, 98.1%), ce_loss 0.909, lat_loss 6.675
09/19 02:32:41 AM | Valid: [ 55/180] Step 150/312 Loss 0.979 Prec@(1,3) (75.7%, 98.0%), ce_loss 0.909, lat_loss 6.675
09/19 02:32:45 AM | Valid: [ 55/180] Step 200/312 Loss 1.001 Prec@(1,3) (75.2%, 97.9%), ce_loss 0.909, lat_loss 6.675
09/19 02:32:50 AM | Valid: [ 55/180] Step 250/312 Loss 0.997 Prec@(1,3) (75.3%, 97.9%), ce_loss 0.909, lat_loss 6.675
09/19 02:32:54 AM | Valid: [ 55/180] Step 300/312 Loss 0.982 Prec@(1,3) (75.9%, 98.0%), ce_loss 0.909, lat_loss 6.675
09/19 02:32:56 AM | Valid: [ 55/180] Step 312/312 Loss 0.983 Prec@(1,3) (75.9%, 98.1%), ce_loss 0.909, lat_loss 6.675
09/19 02:32:56 AM | val: [ 55/180] Final Prec@1 75.9500% Time 29.52
09/19 02:32:56 AM | Best top1 acc by now. Save model
09/19 02:32:56 AM | Start to train weights for epoch 55
09/19 02:33:21 AM | Train: [ 56/180] Step 050/1249 Loss 0.851 Prec@(1,3) (78.2%, 98.8%), ce_loss 0.909, lat_loss 6.675
09/19 02:33:42 AM | Train: [ 56/180] Step 100/1249 Loss 0.856 Prec@(1,3) (77.9%, 98.8%), ce_loss 0.909, lat_loss 6.675
09/19 02:34:05 AM | Train: [ 56/180] Step 150/1249 Loss 0.851 Prec@(1,3) (78.2%, 98.7%), ce_loss 0.909, lat_loss 6.675
09/19 02:34:27 AM | Train: [ 56/180] Step 200/1249 Loss 0.867 Prec@(1,3) (78.0%, 98.7%), ce_loss 0.909, lat_loss 6.675
09/19 02:34:49 AM | Train: [ 56/180] Step 250/1249 Loss 0.860 Prec@(1,3) (78.2%, 98.6%), ce_loss 0.908, lat_loss 6.675
09/19 02:35:09 AM | Train: [ 56/180] Step 300/1249 Loss 0.864 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.908, lat_loss 6.675
09/19 02:35:32 AM | Train: [ 56/180] Step 350/1249 Loss 0.864 Prec@(1,3) (78.3%, 98.6%), ce_loss 0.908, lat_loss 6.675
09/19 02:35:55 AM | Train: [ 56/180] Step 400/1249 Loss 0.859 Prec@(1,3) (78.5%, 98.6%), ce_loss 0.908, lat_loss 6.675
09/19 02:36:17 AM | Train: [ 56/180] Step 450/1249 Loss 0.862 Prec@(1,3) (78.3%, 98.6%), ce_loss 0.908, lat_loss 6.675
09/19 02:36:38 AM | Train: [ 56/180] Step 500/1249 Loss 0.856 Prec@(1,3) (78.5%, 98.6%), ce_loss 0.908, lat_loss 6.675
09/19 02:37:00 AM | Train: [ 56/180] Step 550/1249 Loss 0.855 Prec@(1,3) (78.5%, 98.6%), ce_loss 0.908, lat_loss 6.675
09/19 02:37:23 AM | Train: [ 56/180] Step 600/1249 Loss 0.856 Prec@(1,3) (78.4%, 98.7%), ce_loss 0.907, lat_loss 6.675
09/19 02:37:46 AM | Train: [ 56/180] Step 650/1249 Loss 0.857 Prec@(1,3) (78.4%, 98.7%), ce_loss 0.907, lat_loss 6.675
09/19 02:38:09 AM | Train: [ 56/180] Step 700/1249 Loss 0.855 Prec@(1,3) (78.5%, 98.7%), ce_loss 0.907, lat_loss 6.675
09/19 02:38:32 AM | Train: [ 56/180] Step 750/1249 Loss 0.863 Prec@(1,3) (78.3%, 98.6%), ce_loss 0.907, lat_loss 6.675
09/19 02:38:54 AM | Train: [ 56/180] Step 800/1249 Loss 0.865 Prec@(1,3) (78.2%, 98.6%), ce_loss 0.907, lat_loss 6.675
09/19 02:39:17 AM | Train: [ 56/180] Step 850/1249 Loss 0.865 Prec@(1,3) (78.3%, 98.6%), ce_loss 0.907, lat_loss 6.675
09/19 02:39:40 AM | Train: [ 56/180] Step 900/1249 Loss 0.863 Prec@(1,3) (78.4%, 98.6%), ce_loss 0.907, lat_loss 6.675
09/19 02:40:03 AM | Train: [ 56/180] Step 950/1249 Loss 0.863 Prec@(1,3) (78.4%, 98.6%), ce_loss 0.906, lat_loss 6.675
09/19 02:40:26 AM | Train: [ 56/180] Step 1000/1249 Loss 0.864 Prec@(1,3) (78.3%, 98.6%), ce_loss 0.906, lat_loss 6.675
09/19 02:40:48 AM | Train: [ 56/180] Step 1050/1249 Loss 0.867 Prec@(1,3) (78.3%, 98.6%), ce_loss 0.906, lat_loss 6.675
09/19 02:41:10 AM | Train: [ 56/180] Step 1100/1249 Loss 0.868 Prec@(1,3) (78.2%, 98.6%), ce_loss 0.906, lat_loss 6.675
09/19 02:41:33 AM | Train: [ 56/180] Step 1150/1249 Loss 0.870 Prec@(1,3) (78.2%, 98.6%), ce_loss 0.906, lat_loss 6.675
09/19 02:41:57 AM | Train: [ 56/180] Step 1200/1249 Loss 0.868 Prec@(1,3) (78.2%, 98.6%), ce_loss 0.906, lat_loss 6.675
09/19 02:42:22 AM | Train: [ 56/180] Step 1249/1249 Loss 0.868 Prec@(1,3) (78.2%, 98.6%), ce_loss 0.906, lat_loss 6.675
09/19 02:42:22 AM | _w_step_train: [ 56/180] Final Prec@1 78.2150% Time 565.94
09/19 02:42:22 AM | Start to train theta for epoch 55
09/19 02:42:43 AM | Train: [ 56/180] Step 050/312 Loss 0.821 Prec@(1,3) (80.0%, 98.8%), ce_loss 0.906, lat_loss 6.675
09/19 02:43:04 AM | Train: [ 56/180] Step 100/312 Loss 0.874 Prec@(1,3) (78.2%, 98.5%), ce_loss 0.905, lat_loss 6.675
09/19 02:43:24 AM | Train: [ 56/180] Step 150/312 Loss 0.868 Prec@(1,3) (78.0%, 98.6%), ce_loss 0.905, lat_loss 6.675
09/19 02:43:44 AM | Train: [ 56/180] Step 200/312 Loss 0.871 Prec@(1,3) (77.9%, 98.6%), ce_loss 0.905, lat_loss 6.675
09/19 02:44:04 AM | Train: [ 56/180] Step 250/312 Loss 0.886 Prec@(1,3) (77.7%, 98.5%), ce_loss 0.905, lat_loss 6.675
09/19 02:44:25 AM | Train: [ 56/180] Step 300/312 Loss 0.893 Prec@(1,3) (77.6%, 98.4%), ce_loss 0.905, lat_loss 6.675
09/19 02:44:30 AM | Train: [ 56/180] Step 312/312 Loss 0.891 Prec@(1,3) (77.7%, 98.4%), ce_loss 0.905, lat_loss 6.675
09/19 02:44:30 AM | _theta_step_train: [ 56/180] Final Prec@1 77.6800% Time 128.50
09/19 02:44:36 AM | Valid: [ 56/180] Step 050/312 Loss 1.079 Prec@(1,3) (73.8%, 97.2%), ce_loss 0.905, lat_loss 6.675
09/19 02:44:40 AM | Valid: [ 56/180] Step 100/312 Loss 1.070 Prec@(1,3) (74.1%, 97.4%), ce_loss 0.905, lat_loss 6.675
09/19 02:44:45 AM | Valid: [ 56/180] Step 150/312 Loss 1.066 Prec@(1,3) (74.2%, 97.2%), ce_loss 0.905, lat_loss 6.675
09/19 02:44:49 AM | Valid: [ 56/180] Step 200/312 Loss 1.055 Prec@(1,3) (74.5%, 97.5%), ce_loss 0.905, lat_loss 6.675
09/19 02:44:54 AM | Valid: [ 56/180] Step 250/312 Loss 1.029 Prec@(1,3) (75.1%, 97.7%), ce_loss 0.905, lat_loss 6.675
09/19 02:44:59 AM | Valid: [ 56/180] Step 300/312 Loss 1.011 Prec@(1,3) (75.4%, 97.8%), ce_loss 0.905, lat_loss 6.675
09/19 02:45:00 AM | Valid: [ 56/180] Step 312/312 Loss 1.007 Prec@(1,3) (75.5%, 97.8%), ce_loss 0.904, lat_loss 6.675
09/19 02:45:00 AM | val: [ 56/180] Final Prec@1 75.4800% Time 29.93
09/19 02:45:00 AM | Start to train weights for epoch 56
09/19 02:45:26 AM | Train: [ 57/180] Step 050/1249 Loss 0.912 Prec@(1,3) (76.6%, 98.5%), ce_loss 0.904, lat_loss 6.676
09/19 02:45:51 AM | Train: [ 57/180] Step 100/1249 Loss 0.859 Prec@(1,3) (78.2%, 98.5%), ce_loss 0.904, lat_loss 6.676
09/19 02:46:15 AM | Train: [ 57/180] Step 150/1249 Loss 0.841 Prec@(1,3) (78.7%, 98.6%), ce_loss 0.904, lat_loss 6.676
09/19 02:46:38 AM | Train: [ 57/180] Step 200/1249 Loss 0.843 Prec@(1,3) (78.6%, 98.6%), ce_loss 0.904, lat_loss 6.676
09/19 02:47:01 AM | Train: [ 57/180] Step 250/1249 Loss 0.848 Prec@(1,3) (78.6%, 98.6%), ce_loss 0.904, lat_loss 6.676
09/19 02:47:25 AM | Train: [ 57/180] Step 300/1249 Loss 0.849 Prec@(1,3) (78.7%, 98.7%), ce_loss 0.904, lat_loss 6.676
09/19 02:47:47 AM | Train: [ 57/180] Step 350/1249 Loss 0.846 Prec@(1,3) (78.7%, 98.7%), ce_loss 0.904, lat_loss 6.676
09/19 02:48:10 AM | Train: [ 57/180] Step 400/1249 Loss 0.847 Prec@(1,3) (78.7%, 98.7%), ce_loss 0.903, lat_loss 6.676
09/19 02:48:33 AM | Train: [ 57/180] Step 450/1249 Loss 0.848 Prec@(1,3) (78.7%, 98.7%), ce_loss 0.903, lat_loss 6.676
09/19 02:48:52 AM | Train: [ 57/180] Step 500/1249 Loss 0.844 Prec@(1,3) (78.8%, 98.7%), ce_loss 0.903, lat_loss 6.676
09/19 02:49:12 AM | Train: [ 57/180] Step 550/1249 Loss 0.846 Prec@(1,3) (78.8%, 98.7%), ce_loss 0.903, lat_loss 6.676
09/19 02:49:35 AM | Train: [ 57/180] Step 600/1249 Loss 0.847 Prec@(1,3) (78.8%, 98.7%), ce_loss 0.903, lat_loss 6.676
09/19 02:49:59 AM | Train: [ 57/180] Step 650/1249 Loss 0.852 Prec@(1,3) (78.7%, 98.7%), ce_loss 0.903, lat_loss 6.676
09/19 02:50:23 AM | Train: [ 57/180] Step 700/1249 Loss 0.854 Prec@(1,3) (78.6%, 98.6%), ce_loss 0.903, lat_loss 6.676
09/19 02:50:45 AM | Train: [ 57/180] Step 750/1249 Loss 0.853 Prec@(1,3) (78.7%, 98.6%), ce_loss 0.902, lat_loss 6.676
09/19 02:51:08 AM | Train: [ 57/180] Step 800/1249 Loss 0.853 Prec@(1,3) (78.7%, 98.6%), ce_loss 0.902, lat_loss 6.676
09/19 02:51:32 AM | Train: [ 57/180] Step 850/1249 Loss 0.851 Prec@(1,3) (78.7%, 98.6%), ce_loss 0.902, lat_loss 6.676
09/19 02:51:56 AM | Train: [ 57/180] Step 900/1249 Loss 0.849 Prec@(1,3) (78.8%, 98.6%), ce_loss 0.902, lat_loss 6.676
09/19 02:52:20 AM | Train: [ 57/180] Step 950/1249 Loss 0.849 Prec@(1,3) (78.8%, 98.6%), ce_loss 0.902, lat_loss 6.676
09/19 02:52:42 AM | Train: [ 57/180] Step 1000/1249 Loss 0.850 Prec@(1,3) (78.8%, 98.6%), ce_loss 0.902, lat_loss 6.676
09/19 02:53:04 AM | Train: [ 57/180] Step 1050/1249 Loss 0.848 Prec@(1,3) (78.8%, 98.6%), ce_loss 0.902, lat_loss 6.676
09/19 02:53:27 AM | Train: [ 57/180] Step 1100/1249 Loss 0.850 Prec@(1,3) (78.7%, 98.6%), ce_loss 0.901, lat_loss 6.676
09/19 02:53:50 AM | Train: [ 57/180] Step 1150/1249 Loss 0.850 Prec@(1,3) (78.7%, 98.6%), ce_loss 0.901, lat_loss 6.676
09/19 02:54:14 AM | Train: [ 57/180] Step 1200/1249 Loss 0.849 Prec@(1,3) (78.7%, 98.6%), ce_loss 0.901, lat_loss 6.676
09/19 02:54:38 AM | Train: [ 57/180] Step 1249/1249 Loss 0.848 Prec@(1,3) (78.7%, 98.6%), ce_loss 0.901, lat_loss 6.676
09/19 02:54:39 AM | _w_step_train: [ 57/180] Final Prec@1 78.7400% Time 578.29
09/19 02:54:39 AM | Start to train theta for epoch 56
09/19 02:54:59 AM | Train: [ 57/180] Step 050/312 Loss 0.987 Prec@(1,3) (76.5%, 98.0%), ce_loss 0.901, lat_loss 6.676
09/19 02:55:19 AM | Train: [ 57/180] Step 100/312 Loss 0.963 Prec@(1,3) (76.3%, 97.9%), ce_loss 0.901, lat_loss 6.676
09/19 02:55:39 AM | Train: [ 57/180] Step 150/312 Loss 0.941 Prec@(1,3) (76.8%, 98.2%), ce_loss 0.901, lat_loss 6.676
09/19 02:55:57 AM | Train: [ 57/180] Step 200/312 Loss 0.921 Prec@(1,3) (77.1%, 98.2%), ce_loss 0.901, lat_loss 6.676
09/19 02:56:17 AM | Train: [ 57/180] Step 250/312 Loss 0.920 Prec@(1,3) (77.0%, 98.3%), ce_loss 0.901, lat_loss 6.676
09/19 02:56:38 AM | Train: [ 57/180] Step 300/312 Loss 0.908 Prec@(1,3) (77.3%, 98.3%), ce_loss 0.900, lat_loss 6.676
09/19 02:56:43 AM | Train: [ 57/180] Step 312/312 Loss 0.906 Prec@(1,3) (77.3%, 98.3%), ce_loss 0.900, lat_loss 6.676
09/19 02:56:43 AM | _theta_step_train: [ 57/180] Final Prec@1 77.2800% Time 124.79
09/19 02:56:49 AM | Valid: [ 57/180] Step 050/312 Loss 0.940 Prec@(1,3) (77.8%, 98.7%), ce_loss 0.900, lat_loss 6.676
09/19 02:56:53 AM | Valid: [ 57/180] Step 100/312 Loss 1.090 Prec@(1,3) (75.5%, 97.9%), ce_loss 0.900, lat_loss 6.676
09/19 02:56:58 AM | Valid: [ 57/180] Step 150/312 Loss 1.050 Prec@(1,3) (76.1%, 97.9%), ce_loss 0.900, lat_loss 6.676
09/19 02:57:02 AM | Valid: [ 57/180] Step 200/312 Loss 1.036 Prec@(1,3) (76.2%, 98.1%), ce_loss 0.900, lat_loss 6.676
09/19 02:57:07 AM | Valid: [ 57/180] Step 250/312 Loss 1.018 Prec@(1,3) (76.3%, 98.1%), ce_loss 0.900, lat_loss 6.676
09/19 02:57:12 AM | Valid: [ 57/180] Step 300/312 Loss 1.008 Prec@(1,3) (76.5%, 98.2%), ce_loss 0.900, lat_loss 6.676
09/19 02:57:13 AM | Valid: [ 57/180] Step 312/312 Loss 1.003 Prec@(1,3) (76.5%, 98.2%), ce_loss 0.900, lat_loss 6.676
09/19 02:57:13 AM | val: [ 57/180] Final Prec@1 76.5300% Time 29.50
09/19 02:57:13 AM | Best top1 acc by now. Save model
09/19 02:57:13 AM | Start to train weights for epoch 57
09/19 02:57:37 AM | Train: [ 58/180] Step 050/1249 Loss 0.832 Prec@(1,3) (79.2%, 98.5%), ce_loss 0.900, lat_loss 6.676
09/19 02:58:00 AM | Train: [ 58/180] Step 100/1249 Loss 0.825 Prec@(1,3) (79.1%, 98.5%), ce_loss 0.900, lat_loss 6.676
09/19 02:58:22 AM | Train: [ 58/180] Step 150/1249 Loss 0.813 Prec@(1,3) (79.4%, 98.5%), ce_loss 0.899, lat_loss 6.676
09/19 02:58:43 AM | Train: [ 58/180] Step 200/1249 Loss 0.829 Prec@(1,3) (79.4%, 98.4%), ce_loss 0.899, lat_loss 6.676
09/19 02:59:06 AM | Train: [ 58/180] Step 250/1249 Loss 0.829 Prec@(1,3) (79.3%, 98.6%), ce_loss 0.899, lat_loss 6.676
09/19 02:59:29 AM | Train: [ 58/180] Step 300/1249 Loss 0.829 Prec@(1,3) (79.2%, 98.7%), ce_loss 0.899, lat_loss 6.676
09/19 02:59:53 AM | Train: [ 58/180] Step 350/1249 Loss 0.830 Prec@(1,3) (79.1%, 98.7%), ce_loss 0.899, lat_loss 6.676
09/19 03:00:16 AM | Train: [ 58/180] Step 400/1249 Loss 0.825 Prec@(1,3) (79.1%, 98.7%), ce_loss 0.899, lat_loss 6.676
09/19 03:00:39 AM | Train: [ 58/180] Step 450/1249 Loss 0.823 Prec@(1,3) (79.2%, 98.7%), ce_loss 0.899, lat_loss 6.676
09/19 03:01:03 AM | Train: [ 58/180] Step 500/1249 Loss 0.831 Prec@(1,3) (79.0%, 98.6%), ce_loss 0.899, lat_loss 6.676
09/19 03:01:26 AM | Train: [ 58/180] Step 550/1249 Loss 0.831 Prec@(1,3) (79.0%, 98.6%), ce_loss 0.898, lat_loss 6.676
09/19 03:01:49 AM | Train: [ 58/180] Step 600/1249 Loss 0.829 Prec@(1,3) (79.0%, 98.7%), ce_loss 0.898, lat_loss 6.676
09/19 03:02:12 AM | Train: [ 58/180] Step 650/1249 Loss 0.828 Prec@(1,3) (79.0%, 98.7%), ce_loss 0.898, lat_loss 6.676
09/19 03:02:36 AM | Train: [ 58/180] Step 700/1249 Loss 0.824 Prec@(1,3) (79.1%, 98.7%), ce_loss 0.898, lat_loss 6.676
09/19 03:02:59 AM | Train: [ 58/180] Step 750/1249 Loss 0.826 Prec@(1,3) (79.1%, 98.7%), ce_loss 0.898, lat_loss 6.676
09/19 03:03:22 AM | Train: [ 58/180] Step 800/1249 Loss 0.831 Prec@(1,3) (79.0%, 98.7%), ce_loss 0.898, lat_loss 6.676
09/19 03:03:45 AM | Train: [ 58/180] Step 850/1249 Loss 0.830 Prec@(1,3) (79.0%, 98.7%), ce_loss 0.898, lat_loss 6.676
09/19 03:04:09 AM | Train: [ 58/180] Step 900/1249 Loss 0.832 Prec@(1,3) (79.0%, 98.6%), ce_loss 0.897, lat_loss 6.676
09/19 03:04:32 AM | Train: [ 58/180] Step 950/1249 Loss 0.831 Prec@(1,3) (79.0%, 98.7%), ce_loss 0.897, lat_loss 6.676
09/19 03:04:55 AM | Train: [ 58/180] Step 1000/1249 Loss 0.834 Prec@(1,3) (79.0%, 98.6%), ce_loss 0.897, lat_loss 6.676
09/19 03:05:18 AM | Train: [ 58/180] Step 1050/1249 Loss 0.833 Prec@(1,3) (79.0%, 98.7%), ce_loss 0.897, lat_loss 6.676
09/19 03:05:41 AM | Train: [ 58/180] Step 1100/1249 Loss 0.833 Prec@(1,3) (79.0%, 98.6%), ce_loss 0.897, lat_loss 6.676
09/19 03:06:05 AM | Train: [ 58/180] Step 1150/1249 Loss 0.832 Prec@(1,3) (79.0%, 98.6%), ce_loss 0.897, lat_loss 6.676
09/19 03:06:27 AM | Train: [ 58/180] Step 1200/1249 Loss 0.837 Prec@(1,3) (78.9%, 98.6%), ce_loss 0.897, lat_loss 6.677
09/19 03:06:49 AM | Train: [ 58/180] Step 1249/1249 Loss 0.840 Prec@(1,3) (78.8%, 98.6%), ce_loss 0.897, lat_loss 6.677
09/19 03:06:49 AM | _w_step_train: [ 58/180] Final Prec@1 78.7875% Time 576.07
09/19 03:06:49 AM | Start to train theta for epoch 57
09/19 03:07:10 AM | Train: [ 58/180] Step 050/312 Loss 0.882 Prec@(1,3) (77.6%, 98.7%), ce_loss 0.896, lat_loss 6.677
09/19 03:07:30 AM | Train: [ 58/180] Step 100/312 Loss 0.883 Prec@(1,3) (77.9%, 98.3%), ce_loss 0.896, lat_loss 6.677
09/19 03:07:50 AM | Train: [ 58/180] Step 150/312 Loss 0.892 Prec@(1,3) (77.6%, 98.4%), ce_loss 0.896, lat_loss 6.677
09/19 03:08:11 AM | Train: [ 58/180] Step 200/312 Loss 0.892 Prec@(1,3) (77.6%, 98.2%), ce_loss 0.896, lat_loss 6.677
09/19 03:08:32 AM | Train: [ 58/180] Step 250/312 Loss 0.896 Prec@(1,3) (77.6%, 98.3%), ce_loss 0.896, lat_loss 6.677
09/19 03:08:52 AM | Train: [ 58/180] Step 300/312 Loss 0.896 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.896, lat_loss 6.677
09/19 03:08:57 AM | Train: [ 58/180] Step 312/312 Loss 0.892 Prec@(1,3) (77.5%, 98.4%), ce_loss 0.896, lat_loss 6.677
09/19 03:08:57 AM | _theta_step_train: [ 58/180] Final Prec@1 77.5000% Time 127.74
09/19 03:09:02 AM | Valid: [ 58/180] Step 050/312 Loss 1.040 Prec@(1,3) (74.1%, 97.9%), ce_loss 0.896, lat_loss 6.677
09/19 03:09:07 AM | Valid: [ 58/180] Step 100/312 Loss 0.984 Prec@(1,3) (76.1%, 98.2%), ce_loss 0.896, lat_loss 6.677
09/19 03:09:11 AM | Valid: [ 58/180] Step 150/312 Loss 1.008 Prec@(1,3) (75.7%, 97.7%), ce_loss 0.896, lat_loss 6.677
09/19 03:09:16 AM | Valid: [ 58/180] Step 200/312 Loss 0.999 Prec@(1,3) (75.9%, 97.9%), ce_loss 0.896, lat_loss 6.677
09/19 03:09:21 AM | Valid: [ 58/180] Step 250/312 Loss 0.986 Prec@(1,3) (76.2%, 98.0%), ce_loss 0.895, lat_loss 6.677
09/19 03:09:25 AM | Valid: [ 58/180] Step 300/312 Loss 0.974 Prec@(1,3) (76.4%, 98.2%), ce_loss 0.895, lat_loss 6.677
09/19 03:09:27 AM | Valid: [ 58/180] Step 312/312 Loss 0.974 Prec@(1,3) (76.4%, 98.2%), ce_loss 0.895, lat_loss 6.677
09/19 03:09:27 AM | val: [ 58/180] Final Prec@1 76.4300% Time 29.86
09/19 03:09:27 AM | Start to train weights for epoch 58
09/19 03:09:51 AM | Train: [ 59/180] Step 050/1249 Loss 0.881 Prec@(1,3) (78.1%, 98.5%), ce_loss 0.895, lat_loss 6.677
09/19 03:10:09 AM | Train: [ 59/180] Step 100/1249 Loss 0.851 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.895, lat_loss 6.677
09/19 03:10:25 AM | Train: [ 59/180] Step 150/1249 Loss 0.829 Prec@(1,3) (79.2%, 98.8%), ce_loss 0.895, lat_loss 6.677
09/19 03:10:41 AM | Train: [ 59/180] Step 200/1249 Loss 0.830 Prec@(1,3) (79.3%, 98.9%), ce_loss 0.895, lat_loss 6.677
09/19 03:10:57 AM | Train: [ 59/180] Step 250/1249 Loss 0.829 Prec@(1,3) (79.2%, 98.9%), ce_loss 0.895, lat_loss 6.677
09/19 03:11:13 AM | Train: [ 59/180] Step 300/1249 Loss 0.823 Prec@(1,3) (79.2%, 98.9%), ce_loss 0.894, lat_loss 6.677
09/19 03:11:28 AM | Train: [ 59/180] Step 350/1249 Loss 0.823 Prec@(1,3) (79.2%, 98.8%), ce_loss 0.894, lat_loss 6.677
09/19 03:11:44 AM | Train: [ 59/180] Step 400/1249 Loss 0.819 Prec@(1,3) (79.4%, 98.8%), ce_loss 0.894, lat_loss 6.677
09/19 03:12:00 AM | Train: [ 59/180] Step 450/1249 Loss 0.816 Prec@(1,3) (79.5%, 98.8%), ce_loss 0.894, lat_loss 6.677
09/19 03:12:16 AM | Train: [ 59/180] Step 500/1249 Loss 0.814 Prec@(1,3) (79.6%, 98.8%), ce_loss 0.894, lat_loss 6.677
09/19 03:12:32 AM | Train: [ 59/180] Step 550/1249 Loss 0.815 Prec@(1,3) (79.5%, 98.7%), ce_loss 0.894, lat_loss 6.677
09/19 03:12:48 AM | Train: [ 59/180] Step 600/1249 Loss 0.818 Prec@(1,3) (79.4%, 98.7%), ce_loss 0.894, lat_loss 6.677
09/19 03:13:05 AM | Train: [ 59/180] Step 650/1249 Loss 0.822 Prec@(1,3) (79.2%, 98.7%), ce_loss 0.894, lat_loss 6.677
09/19 03:13:21 AM | Train: [ 59/180] Step 700/1249 Loss 0.822 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.893, lat_loss 6.677
09/19 03:13:36 AM | Train: [ 59/180] Step 750/1249 Loss 0.824 Prec@(1,3) (79.3%, 98.6%), ce_loss 0.893, lat_loss 6.677
09/19 03:13:52 AM | Train: [ 59/180] Step 800/1249 Loss 0.826 Prec@(1,3) (79.2%, 98.7%), ce_loss 0.893, lat_loss 6.677
09/19 03:14:08 AM | Train: [ 59/180] Step 850/1249 Loss 0.828 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.893, lat_loss 6.677
09/19 03:14:24 AM | Train: [ 59/180] Step 900/1249 Loss 0.830 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.893, lat_loss 6.677
09/19 03:14:40 AM | Train: [ 59/180] Step 950/1249 Loss 0.833 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.893, lat_loss 6.677
09/19 03:14:56 AM | Train: [ 59/180] Step 1000/1249 Loss 0.833 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.893, lat_loss 6.677
09/19 03:15:12 AM | Train: [ 59/180] Step 1050/1249 Loss 0.833 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.893, lat_loss 6.677
09/19 03:15:28 AM | Train: [ 59/180] Step 1100/1249 Loss 0.831 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.892, lat_loss 6.677
09/19 03:15:44 AM | Train: [ 59/180] Step 1150/1249 Loss 0.833 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.892, lat_loss 6.677
09/19 03:16:00 AM | Train: [ 59/180] Step 1200/1249 Loss 0.832 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.892, lat_loss 6.677
09/19 03:16:15 AM | Train: [ 59/180] Step 1249/1249 Loss 0.832 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.892, lat_loss 6.677
09/19 03:16:16 AM | _w_step_train: [ 59/180] Final Prec@1 79.1525% Time 408.87
09/19 03:16:16 AM | Start to train theta for epoch 58
09/19 03:16:36 AM | Train: [ 59/180] Step 050/312 Loss 0.874 Prec@(1,3) (77.9%, 98.2%), ce_loss 0.892, lat_loss 6.677
09/19 03:16:49 AM | Train: [ 59/180] Step 100/312 Loss 0.892 Prec@(1,3) (77.6%, 98.3%), ce_loss 0.892, lat_loss 6.677
09/19 03:17:01 AM | Train: [ 59/180] Step 150/312 Loss 0.898 Prec@(1,3) (77.4%, 98.3%), ce_loss 0.892, lat_loss 6.677
09/19 03:17:13 AM | Train: [ 59/180] Step 200/312 Loss 0.891 Prec@(1,3) (77.4%, 98.4%), ce_loss 0.892, lat_loss 6.677
09/19 03:17:26 AM | Train: [ 59/180] Step 250/312 Loss 0.884 Prec@(1,3) (77.7%, 98.5%), ce_loss 0.891, lat_loss 6.677
09/19 03:17:38 AM | Train: [ 59/180] Step 300/312 Loss 0.881 Prec@(1,3) (77.7%, 98.5%), ce_loss 0.891, lat_loss 6.677
09/19 03:17:41 AM | Train: [ 59/180] Step 312/312 Loss 0.883 Prec@(1,3) (77.7%, 98.5%), ce_loss 0.891, lat_loss 6.677
09/19 03:17:41 AM | _theta_step_train: [ 59/180] Final Prec@1 77.6600% Time 85.53
09/19 03:17:46 AM | Valid: [ 59/180] Step 050/312 Loss 1.048 Prec@(1,3) (75.7%, 98.1%), ce_loss 0.891, lat_loss 6.677
09/19 03:17:50 AM | Valid: [ 59/180] Step 100/312 Loss 0.978 Prec@(1,3) (77.1%, 98.4%), ce_loss 0.891, lat_loss 6.677
09/19 03:17:55 AM | Valid: [ 59/180] Step 150/312 Loss 0.971 Prec@(1,3) (77.3%, 98.0%), ce_loss 0.891, lat_loss 6.677
09/19 03:17:59 AM | Valid: [ 59/180] Step 200/312 Loss 0.973 Prec@(1,3) (77.1%, 98.1%), ce_loss 0.891, lat_loss 6.677
09/19 03:18:04 AM | Valid: [ 59/180] Step 250/312 Loss 0.997 Prec@(1,3) (76.9%, 98.0%), ce_loss 0.891, lat_loss 6.677
09/19 03:18:08 AM | Valid: [ 59/180] Step 300/312 Loss 1.002 Prec@(1,3) (76.9%, 97.9%), ce_loss 0.891, lat_loss 6.677
09/19 03:18:09 AM | Valid: [ 59/180] Step 312/312 Loss 0.997 Prec@(1,3) (77.0%, 98.0%), ce_loss 0.891, lat_loss 6.677
09/19 03:18:10 AM | val: [ 59/180] Final Prec@1 76.9800% Time 28.40
09/19 03:18:10 AM | Best top1 acc by now. Save model
09/19 03:18:10 AM | Start to train weights for epoch 59
09/19 03:18:36 AM | Train: [ 60/180] Step 050/1249 Loss 0.781 Prec@(1,3) (80.5%, 99.0%), ce_loss 0.891, lat_loss 6.677
09/19 03:18:59 AM | Train: [ 60/180] Step 100/1249 Loss 0.779 Prec@(1,3) (79.8%, 99.0%), ce_loss 0.891, lat_loss 6.677
09/19 03:19:22 AM | Train: [ 60/180] Step 150/1249 Loss 0.816 Prec@(1,3) (79.1%, 98.9%), ce_loss 0.890, lat_loss 6.677
09/19 03:19:45 AM | Train: [ 60/180] Step 200/1249 Loss 0.832 Prec@(1,3) (78.9%, 98.7%), ce_loss 0.890, lat_loss 6.677
09/19 03:20:09 AM | Train: [ 60/180] Step 250/1249 Loss 0.827 Prec@(1,3) (78.9%, 98.8%), ce_loss 0.890, lat_loss 6.677
09/19 03:20:32 AM | Train: [ 60/180] Step 300/1249 Loss 0.826 Prec@(1,3) (78.9%, 98.7%), ce_loss 0.890, lat_loss 6.677
09/19 03:20:55 AM | Train: [ 60/180] Step 350/1249 Loss 0.821 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.890, lat_loss 6.677
09/19 03:21:19 AM | Train: [ 60/180] Step 400/1249 Loss 0.817 Prec@(1,3) (79.3%, 98.7%), ce_loss 0.890, lat_loss 6.677
09/19 03:21:44 AM | Train: [ 60/180] Step 450/1249 Loss 0.820 Prec@(1,3) (79.3%, 98.7%), ce_loss 0.890, lat_loss 6.677
09/19 03:22:07 AM | Train: [ 60/180] Step 500/1249 Loss 0.825 Prec@(1,3) (79.2%, 98.7%), ce_loss 0.890, lat_loss 6.677
09/19 03:22:30 AM | Train: [ 60/180] Step 550/1249 Loss 0.823 Prec@(1,3) (79.3%, 98.7%), ce_loss 0.889, lat_loss 6.677
09/19 03:22:54 AM | Train: [ 60/180] Step 600/1249 Loss 0.830 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.889, lat_loss 6.677
09/19 03:23:17 AM | Train: [ 60/180] Step 650/1249 Loss 0.830 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.889, lat_loss 6.677
09/19 03:23:42 AM | Train: [ 60/180] Step 700/1249 Loss 0.834 Prec@(1,3) (79.0%, 98.6%), ce_loss 0.889, lat_loss 6.677
09/19 03:24:07 AM | Train: [ 60/180] Step 750/1249 Loss 0.835 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.889, lat_loss 6.677
09/19 03:24:32 AM | Train: [ 60/180] Step 800/1249 Loss 0.832 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.889, lat_loss 6.677
09/19 03:24:57 AM | Train: [ 60/180] Step 850/1249 Loss 0.831 Prec@(1,3) (79.3%, 98.7%), ce_loss 0.889, lat_loss 6.677
09/19 03:25:21 AM | Train: [ 60/180] Step 900/1249 Loss 0.829 Prec@(1,3) (79.3%, 98.7%), ce_loss 0.889, lat_loss 6.677
09/19 03:25:46 AM | Train: [ 60/180] Step 950/1249 Loss 0.826 Prec@(1,3) (79.4%, 98.7%), ce_loss 0.888, lat_loss 6.678
09/19 03:26:09 AM | Train: [ 60/180] Step 1000/1249 Loss 0.823 Prec@(1,3) (79.4%, 98.7%), ce_loss 0.888, lat_loss 6.678
09/19 03:26:33 AM | Train: [ 60/180] Step 1050/1249 Loss 0.823 Prec@(1,3) (79.4%, 98.7%), ce_loss 0.888, lat_loss 6.678
09/19 03:26:58 AM | Train: [ 60/180] Step 1100/1249 Loss 0.824 Prec@(1,3) (79.4%, 98.7%), ce_loss 0.888, lat_loss 6.678
09/19 03:27:19 AM | Train: [ 60/180] Step 1150/1249 Loss 0.826 Prec@(1,3) (79.3%, 98.7%), ce_loss 0.888, lat_loss 6.678
09/19 03:27:44 AM | Train: [ 60/180] Step 1200/1249 Loss 0.824 Prec@(1,3) (79.4%, 98.7%), ce_loss 0.888, lat_loss 6.678
09/19 03:28:09 AM | Train: [ 60/180] Step 1249/1249 Loss 0.823 Prec@(1,3) (79.4%, 98.7%), ce_loss 0.888, lat_loss 6.678
09/19 03:28:09 AM | _w_step_train: [ 60/180] Final Prec@1 79.4225% Time 598.92
09/19 03:28:09 AM | Start to train theta for epoch 59
09/19 03:28:30 AM | Train: [ 60/180] Step 050/312 Loss 0.869 Prec@(1,3) (78.0%, 98.7%), ce_loss 0.887, lat_loss 6.678
09/19 03:28:51 AM | Train: [ 60/180] Step 100/312 Loss 0.828 Prec@(1,3) (78.7%, 98.7%), ce_loss 0.887, lat_loss 6.678
09/19 03:29:12 AM | Train: [ 60/180] Step 150/312 Loss 0.830 Prec@(1,3) (78.8%, 98.7%), ce_loss 0.887, lat_loss 6.678
09/19 03:29:32 AM | Train: [ 60/180] Step 200/312 Loss 0.817 Prec@(1,3) (79.1%, 98.7%), ce_loss 0.887, lat_loss 6.678
09/19 03:29:53 AM | Train: [ 60/180] Step 250/312 Loss 0.826 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.887, lat_loss 6.678
09/19 03:30:14 AM | Train: [ 60/180] Step 300/312 Loss 0.832 Prec@(1,3) (78.9%, 98.6%), ce_loss 0.887, lat_loss 6.678
09/19 03:30:19 AM | Train: [ 60/180] Step 312/312 Loss 0.831 Prec@(1,3) (79.0%, 98.7%), ce_loss 0.887, lat_loss 6.678
09/19 03:30:19 AM | _theta_step_train: [ 60/180] Final Prec@1 78.9700% Time 130.31
09/19 03:30:24 AM | Valid: [ 60/180] Step 050/312 Loss 0.864 Prec@(1,3) (79.5%, 98.8%), ce_loss 0.887, lat_loss 6.678
09/19 03:30:29 AM | Valid: [ 60/180] Step 100/312 Loss 0.895 Prec@(1,3) (78.4%, 98.5%), ce_loss 0.887, lat_loss 6.678
09/19 03:30:33 AM | Valid: [ 60/180] Step 150/312 Loss 0.909 Prec@(1,3) (77.9%, 98.0%), ce_loss 0.886, lat_loss 6.678
09/19 03:30:38 AM | Valid: [ 60/180] Step 200/312 Loss 0.929 Prec@(1,3) (77.9%, 98.1%), ce_loss 0.886, lat_loss 6.678
09/19 03:30:43 AM | Valid: [ 60/180] Step 250/312 Loss 0.948 Prec@(1,3) (77.2%, 98.1%), ce_loss 0.886, lat_loss 6.678
09/19 03:30:47 AM | Valid: [ 60/180] Step 300/312 Loss 0.952 Prec@(1,3) (77.2%, 98.1%), ce_loss 0.886, lat_loss 6.678
09/19 03:30:48 AM | Valid: [ 60/180] Step 312/312 Loss 0.948 Prec@(1,3) (77.3%, 98.2%), ce_loss 0.886, lat_loss 6.678
09/19 03:30:48 AM | val: [ 60/180] Final Prec@1 77.3000% Time 29.45
09/19 03:30:48 AM | Best top1 acc by now. Save model
09/19 03:30:49 AM | Start to train weights for epoch 60
09/19 03:31:15 AM | Train: [ 61/180] Step 050/1249 Loss 0.838 Prec@(1,3) (78.0%, 98.8%), ce_loss 0.886, lat_loss 6.678
09/19 03:31:38 AM | Train: [ 61/180] Step 100/1249 Loss 0.789 Prec@(1,3) (79.8%, 99.1%), ce_loss 0.886, lat_loss 6.678
09/19 03:32:02 AM | Train: [ 61/180] Step 150/1249 Loss 0.772 Prec@(1,3) (80.2%, 99.1%), ce_loss 0.886, lat_loss 6.678
09/19 03:32:26 AM | Train: [ 61/180] Step 200/1249 Loss 0.781 Prec@(1,3) (80.2%, 99.0%), ce_loss 0.886, lat_loss 6.678
09/19 03:32:49 AM | Train: [ 61/180] Step 250/1249 Loss 0.777 Prec@(1,3) (80.2%, 99.0%), ce_loss 0.886, lat_loss 6.678
09/19 03:33:12 AM | Train: [ 61/180] Step 300/1249 Loss 0.788 Prec@(1,3) (80.0%, 98.9%), ce_loss 0.885, lat_loss 6.678
09/19 03:33:37 AM | Train: [ 61/180] Step 350/1249 Loss 0.811 Prec@(1,3) (79.5%, 98.8%), ce_loss 0.885, lat_loss 6.678
09/19 03:33:59 AM | Train: [ 61/180] Step 400/1249 Loss 0.819 Prec@(1,3) (79.3%, 98.8%), ce_loss 0.885, lat_loss 6.678
09/19 03:34:23 AM | Train: [ 61/180] Step 450/1249 Loss 0.818 Prec@(1,3) (79.4%, 98.7%), ce_loss 0.885, lat_loss 6.678
09/19 03:34:48 AM | Train: [ 61/180] Step 500/1249 Loss 0.816 Prec@(1,3) (79.5%, 98.7%), ce_loss 0.885, lat_loss 6.678
09/19 03:35:12 AM | Train: [ 61/180] Step 550/1249 Loss 0.814 Prec@(1,3) (79.6%, 98.7%), ce_loss 0.885, lat_loss 6.678
09/19 03:35:36 AM | Train: [ 61/180] Step 600/1249 Loss 0.809 Prec@(1,3) (79.7%, 98.7%), ce_loss 0.885, lat_loss 6.678
09/19 03:36:01 AM | Train: [ 61/180] Step 650/1249 Loss 0.812 Prec@(1,3) (79.7%, 98.7%), ce_loss 0.885, lat_loss 6.678
09/19 03:36:26 AM | Train: [ 61/180] Step 700/1249 Loss 0.811 Prec@(1,3) (79.7%, 98.7%), ce_loss 0.884, lat_loss 6.678
09/19 03:36:51 AM | Train: [ 61/180] Step 750/1249 Loss 0.815 Prec@(1,3) (79.6%, 98.7%), ce_loss 0.884, lat_loss 6.678
09/19 03:37:16 AM | Train: [ 61/180] Step 800/1249 Loss 0.817 Prec@(1,3) (79.6%, 98.7%), ce_loss 0.884, lat_loss 6.678
09/19 03:37:41 AM | Train: [ 61/180] Step 850/1249 Loss 0.818 Prec@(1,3) (79.5%, 98.7%), ce_loss 0.884, lat_loss 6.678
09/19 03:38:06 AM | Train: [ 61/180] Step 900/1249 Loss 0.816 Prec@(1,3) (79.5%, 98.7%), ce_loss 0.884, lat_loss 6.678
09/19 03:38:23 AM | Train: [ 61/180] Step 950/1249 Loss 0.816 Prec@(1,3) (79.5%, 98.7%), ce_loss 0.884, lat_loss 6.678
09/19 03:38:37 AM | Train: [ 61/180] Step 1000/1249 Loss 0.815 Prec@(1,3) (79.5%, 98.7%), ce_loss 0.884, lat_loss 6.678
09/19 03:38:52 AM | Train: [ 61/180] Step 1050/1249 Loss 0.814 Prec@(1,3) (79.6%, 98.7%), ce_loss 0.884, lat_loss 6.678
09/19 03:39:07 AM | Train: [ 61/180] Step 1100/1249 Loss 0.812 Prec@(1,3) (79.7%, 98.7%), ce_loss 0.883, lat_loss 6.678
09/19 03:39:21 AM | Train: [ 61/180] Step 1150/1249 Loss 0.812 Prec@(1,3) (79.6%, 98.7%), ce_loss 0.883, lat_loss 6.678
09/19 03:39:36 AM | Train: [ 61/180] Step 1200/1249 Loss 0.811 Prec@(1,3) (79.7%, 98.7%), ce_loss 0.883, lat_loss 6.678
09/19 03:39:50 AM | Train: [ 61/180] Step 1249/1249 Loss 0.809 Prec@(1,3) (79.7%, 98.7%), ce_loss 0.883, lat_loss 6.678
09/19 03:39:50 AM | _w_step_train: [ 61/180] Final Prec@1 79.7125% Time 541.29
09/19 03:39:50 AM | Start to train theta for epoch 60
09/19 03:40:11 AM | Train: [ 61/180] Step 050/312 Loss 0.842 Prec@(1,3) (78.9%, 98.6%), ce_loss 0.883, lat_loss 6.678
09/19 03:40:31 AM | Train: [ 61/180] Step 100/312 Loss 0.839 Prec@(1,3) (78.8%, 98.6%), ce_loss 0.883, lat_loss 6.678
09/19 03:40:51 AM | Train: [ 61/180] Step 150/312 Loss 0.842 Prec@(1,3) (78.6%, 98.6%), ce_loss 0.883, lat_loss 6.678
09/19 03:41:12 AM | Train: [ 61/180] Step 200/312 Loss 0.838 Prec@(1,3) (78.7%, 98.6%), ce_loss 0.882, lat_loss 6.678
09/19 03:41:31 AM | Train: [ 61/180] Step 250/312 Loss 0.842 Prec@(1,3) (78.8%, 98.6%), ce_loss 0.882, lat_loss 6.678
09/19 03:41:51 AM | Train: [ 61/180] Step 300/312 Loss 0.831 Prec@(1,3) (79.0%, 98.6%), ce_loss 0.882, lat_loss 6.678
09/19 03:41:56 AM | Train: [ 61/180] Step 312/312 Loss 0.830 Prec@(1,3) (79.0%, 98.6%), ce_loss 0.882, lat_loss 6.678
09/19 03:41:56 AM | _theta_step_train: [ 61/180] Final Prec@1 78.9500% Time 126.16
09/19 03:42:01 AM | Valid: [ 61/180] Step 050/312 Loss 0.941 Prec@(1,3) (77.6%, 97.7%), ce_loss 0.882, lat_loss 6.678
09/19 03:42:06 AM | Valid: [ 61/180] Step 100/312 Loss 0.932 Prec@(1,3) (77.3%, 97.8%), ce_loss 0.882, lat_loss 6.678
09/19 03:42:10 AM | Valid: [ 61/180] Step 150/312 Loss 0.952 Prec@(1,3) (77.3%, 97.6%), ce_loss 0.882, lat_loss 6.678
09/19 03:42:15 AM | Valid: [ 61/180] Step 200/312 Loss 0.966 Prec@(1,3) (77.4%, 97.7%), ce_loss 0.882, lat_loss 6.678
09/19 03:42:19 AM | Valid: [ 61/180] Step 250/312 Loss 0.977 Prec@(1,3) (77.0%, 97.6%), ce_loss 0.882, lat_loss 6.678
09/19 03:42:24 AM | Valid: [ 61/180] Step 300/312 Loss 0.961 Prec@(1,3) (77.1%, 97.6%), ce_loss 0.882, lat_loss 6.678
09/19 03:42:25 AM | Valid: [ 61/180] Step 312/312 Loss 0.956 Prec@(1,3) (77.3%, 97.7%), ce_loss 0.882, lat_loss 6.678
09/19 03:42:25 AM | val: [ 61/180] Final Prec@1 77.3000% Time 29.08
09/19 03:42:25 AM | Start to train weights for epoch 61
09/19 03:42:51 AM | Train: [ 62/180] Step 050/1249 Loss 0.742 Prec@(1,3) (80.9%, 99.2%), ce_loss 0.882, lat_loss 6.678
09/19 03:43:15 AM | Train: [ 62/180] Step 100/1249 Loss 0.765 Prec@(1,3) (80.4%, 99.1%), ce_loss 0.881, lat_loss 6.678
09/19 03:43:38 AM | Train: [ 62/180] Step 150/1249 Loss 0.769 Prec@(1,3) (80.1%, 99.0%), ce_loss 0.881, lat_loss 6.678
09/19 03:44:03 AM | Train: [ 62/180] Step 200/1249 Loss 0.767 Prec@(1,3) (80.1%, 99.0%), ce_loss 0.881, lat_loss 6.678
09/19 03:44:27 AM | Train: [ 62/180] Step 250/1249 Loss 0.762 Prec@(1,3) (80.3%, 99.0%), ce_loss 0.881, lat_loss 6.678
09/19 03:44:52 AM | Train: [ 62/180] Step 300/1249 Loss 0.774 Prec@(1,3) (80.1%, 99.0%), ce_loss 0.881, lat_loss 6.678
09/19 03:45:17 AM | Train: [ 62/180] Step 350/1249 Loss 0.776 Prec@(1,3) (80.1%, 99.0%), ce_loss 0.881, lat_loss 6.678
09/19 03:45:42 AM | Train: [ 62/180] Step 400/1249 Loss 0.779 Prec@(1,3) (80.2%, 98.9%), ce_loss 0.881, lat_loss 6.678
09/19 03:46:07 AM | Train: [ 62/180] Step 450/1249 Loss 0.789 Prec@(1,3) (79.9%, 98.9%), ce_loss 0.880, lat_loss 6.678
09/19 03:46:32 AM | Train: [ 62/180] Step 500/1249 Loss 0.795 Prec@(1,3) (79.8%, 98.9%), ce_loss 0.880, lat_loss 6.678
09/19 03:46:57 AM | Train: [ 62/180] Step 550/1249 Loss 0.796 Prec@(1,3) (79.6%, 98.8%), ce_loss 0.880, lat_loss 6.678
09/19 03:47:21 AM | Train: [ 62/180] Step 600/1249 Loss 0.795 Prec@(1,3) (79.7%, 98.9%), ce_loss 0.880, lat_loss 6.678
09/19 03:47:45 AM | Train: [ 62/180] Step 650/1249 Loss 0.794 Prec@(1,3) (79.8%, 98.9%), ce_loss 0.880, lat_loss 6.678
09/19 03:48:10 AM | Train: [ 62/180] Step 700/1249 Loss 0.799 Prec@(1,3) (79.8%, 98.8%), ce_loss 0.880, lat_loss 6.679
09/19 03:48:35 AM | Train: [ 62/180] Step 750/1249 Loss 0.801 Prec@(1,3) (79.8%, 98.8%), ce_loss 0.880, lat_loss 6.679
09/19 03:49:00 AM | Train: [ 62/180] Step 800/1249 Loss 0.806 Prec@(1,3) (79.7%, 98.8%), ce_loss 0.880, lat_loss 6.679
09/19 03:49:24 AM | Train: [ 62/180] Step 850/1249 Loss 0.804 Prec@(1,3) (79.7%, 98.8%), ce_loss 0.880, lat_loss 6.679
09/19 03:49:49 AM | Train: [ 62/180] Step 900/1249 Loss 0.804 Prec@(1,3) (79.7%, 98.8%), ce_loss 0.879, lat_loss 6.679
09/19 03:50:14 AM | Train: [ 62/180] Step 950/1249 Loss 0.803 Prec@(1,3) (79.7%, 98.8%), ce_loss 0.879, lat_loss 6.679
09/19 03:50:39 AM | Train: [ 62/180] Step 1000/1249 Loss 0.801 Prec@(1,3) (79.7%, 98.8%), ce_loss 0.879, lat_loss 6.679
09/19 03:51:03 AM | Train: [ 62/180] Step 1050/1249 Loss 0.798 Prec@(1,3) (79.8%, 98.8%), ce_loss 0.879, lat_loss 6.679
09/19 03:51:27 AM | Train: [ 62/180] Step 1100/1249 Loss 0.798 Prec@(1,3) (79.8%, 98.8%), ce_loss 0.879, lat_loss 6.679
09/19 03:51:51 AM | Train: [ 62/180] Step 1150/1249 Loss 0.800 Prec@(1,3) (79.8%, 98.8%), ce_loss 0.879, lat_loss 6.679
09/19 03:52:15 AM | Train: [ 62/180] Step 1200/1249 Loss 0.801 Prec@(1,3) (79.7%, 98.8%), ce_loss 0.879, lat_loss 6.679
09/19 03:52:38 AM | Train: [ 62/180] Step 1249/1249 Loss 0.802 Prec@(1,3) (79.7%, 98.8%), ce_loss 0.878, lat_loss 6.679
09/19 03:52:38 AM | _w_step_train: [ 62/180] Final Prec@1 79.7200% Time 612.80
09/19 03:52:38 AM | Start to train theta for epoch 61
09/19 03:52:51 AM | Train: [ 62/180] Step 050/312 Loss 0.861 Prec@(1,3) (78.2%, 99.0%), ce_loss 0.878, lat_loss 6.679
09/19 03:53:03 AM | Train: [ 62/180] Step 100/312 Loss 0.844 Prec@(1,3) (78.9%, 98.8%), ce_loss 0.878, lat_loss 6.679
09/19 03:53:15 AM | Train: [ 62/180] Step 150/312 Loss 0.825 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.878, lat_loss 6.679
09/19 03:53:27 AM | Train: [ 62/180] Step 200/312 Loss 0.845 Prec@(1,3) (78.5%, 98.6%), ce_loss 0.878, lat_loss 6.679
09/19 03:53:40 AM | Train: [ 62/180] Step 250/312 Loss 0.848 Prec@(1,3) (78.6%, 98.7%), ce_loss 0.878, lat_loss 6.679
09/19 03:53:52 AM | Train: [ 62/180] Step 300/312 Loss 0.843 Prec@(1,3) (78.8%, 98.7%), ce_loss 0.878, lat_loss 6.679
09/19 03:53:55 AM | Train: [ 62/180] Step 312/312 Loss 0.843 Prec@(1,3) (78.8%, 98.7%), ce_loss 0.878, lat_loss 6.679
09/19 03:53:55 AM | _theta_step_train: [ 62/180] Final Prec@1 78.7800% Time 76.79
09/19 03:54:00 AM | Valid: [ 62/180] Step 050/312 Loss 0.932 Prec@(1,3) (77.0%, 98.2%), ce_loss 0.878, lat_loss 6.679
09/19 03:54:04 AM | Valid: [ 62/180] Step 100/312 Loss 0.955 Prec@(1,3) (77.8%, 98.1%), ce_loss 0.878, lat_loss 6.679
09/19 03:54:09 AM | Valid: [ 62/180] Step 150/312 Loss 0.920 Prec@(1,3) (78.4%, 98.3%), ce_loss 0.877, lat_loss 6.679
09/19 03:54:14 AM | Valid: [ 62/180] Step 200/312 Loss 0.918 Prec@(1,3) (78.3%, 98.4%), ce_loss 0.877, lat_loss 6.679
09/19 03:54:18 AM | Valid: [ 62/180] Step 250/312 Loss 0.932 Prec@(1,3) (77.7%, 98.3%), ce_loss 0.877, lat_loss 6.679
09/19 03:54:23 AM | Valid: [ 62/180] Step 300/312 Loss 0.924 Prec@(1,3) (77.9%, 98.5%), ce_loss 0.877, lat_loss 6.679
09/19 03:54:24 AM | Valid: [ 62/180] Step 312/312 Loss 0.921 Prec@(1,3) (77.9%, 98.5%), ce_loss 0.877, lat_loss 6.679
09/19 03:54:24 AM | val: [ 62/180] Final Prec@1 77.8900% Time 29.62
09/19 03:54:24 AM | Best top1 acc by now. Save model
09/19 03:54:25 AM | Start to train weights for epoch 62
09/19 03:54:49 AM | Train: [ 63/180] Step 050/1249 Loss 0.748 Prec@(1,3) (80.6%, 99.4%), ce_loss 0.877, lat_loss 6.679
09/19 03:55:12 AM | Train: [ 63/180] Step 100/1249 Loss 0.740 Prec@(1,3) (81.7%, 99.1%), ce_loss 0.877, lat_loss 6.679
09/19 03:55:38 AM | Train: [ 63/180] Step 150/1249 Loss 0.758 Prec@(1,3) (81.6%, 98.9%), ce_loss 0.877, lat_loss 6.679
09/19 03:56:03 AM | Train: [ 63/180] Step 200/1249 Loss 0.748 Prec@(1,3) (81.5%, 99.0%), ce_loss 0.877, lat_loss 6.679
09/19 03:56:28 AM | Train: [ 63/180] Step 250/1249 Loss 0.750 Prec@(1,3) (81.4%, 99.0%), ce_loss 0.876, lat_loss 6.679
09/19 03:56:53 AM | Train: [ 63/180] Step 300/1249 Loss 0.758 Prec@(1,3) (81.2%, 99.0%), ce_loss 0.876, lat_loss 6.679
09/19 03:57:18 AM | Train: [ 63/180] Step 350/1249 Loss 0.762 Prec@(1,3) (81.1%, 99.0%), ce_loss 0.876, lat_loss 6.679
09/19 03:57:43 AM | Train: [ 63/180] Step 400/1249 Loss 0.761 Prec@(1,3) (81.1%, 98.9%), ce_loss 0.876, lat_loss 6.679
09/19 03:58:09 AM | Train: [ 63/180] Step 450/1249 Loss 0.758 Prec@(1,3) (81.2%, 99.0%), ce_loss 0.876, lat_loss 6.679
09/19 03:58:33 AM | Train: [ 63/180] Step 500/1249 Loss 0.765 Prec@(1,3) (81.0%, 98.9%), ce_loss 0.876, lat_loss 6.679
09/19 03:58:56 AM | Train: [ 63/180] Step 550/1249 Loss 0.770 Prec@(1,3) (80.9%, 98.8%), ce_loss 0.876, lat_loss 6.679
09/19 03:59:19 AM | Train: [ 63/180] Step 600/1249 Loss 0.770 Prec@(1,3) (80.9%, 98.8%), ce_loss 0.876, lat_loss 6.679
09/19 03:59:43 AM | Train: [ 63/180] Step 650/1249 Loss 0.768 Prec@(1,3) (80.9%, 98.9%), ce_loss 0.875, lat_loss 6.679
09/19 04:00:09 AM | Train: [ 63/180] Step 700/1249 Loss 0.766 Prec@(1,3) (80.9%, 98.9%), ce_loss 0.875, lat_loss 6.679
09/19 04:00:32 AM | Train: [ 63/180] Step 750/1249 Loss 0.771 Prec@(1,3) (80.8%, 98.9%), ce_loss 0.875, lat_loss 6.679
09/19 04:00:55 AM | Train: [ 63/180] Step 800/1249 Loss 0.772 Prec@(1,3) (80.9%, 98.8%), ce_loss 0.875, lat_loss 6.679
09/19 04:01:18 AM | Train: [ 63/180] Step 850/1249 Loss 0.776 Prec@(1,3) (80.8%, 98.9%), ce_loss 0.875, lat_loss 6.679
09/19 04:01:43 AM | Train: [ 63/180] Step 900/1249 Loss 0.776 Prec@(1,3) (80.7%, 98.9%), ce_loss 0.875, lat_loss 6.679
09/19 04:02:08 AM | Train: [ 63/180] Step 950/1249 Loss 0.776 Prec@(1,3) (80.7%, 98.9%), ce_loss 0.875, lat_loss 6.679
09/19 04:02:33 AM | Train: [ 63/180] Step 1000/1249 Loss 0.775 Prec@(1,3) (80.8%, 98.9%), ce_loss 0.875, lat_loss 6.679
09/19 04:02:58 AM | Train: [ 63/180] Step 1050/1249 Loss 0.775 Prec@(1,3) (80.7%, 98.8%), ce_loss 0.874, lat_loss 6.679
09/19 04:03:21 AM | Train: [ 63/180] Step 1100/1249 Loss 0.774 Prec@(1,3) (80.8%, 98.9%), ce_loss 0.874, lat_loss 6.679
09/19 04:03:45 AM | Train: [ 63/180] Step 1150/1249 Loss 0.777 Prec@(1,3) (80.7%, 98.8%), ce_loss 0.874, lat_loss 6.679
09/19 04:04:08 AM | Train: [ 63/180] Step 1200/1249 Loss 0.776 Prec@(1,3) (80.8%, 98.8%), ce_loss 0.874, lat_loss 6.679
09/19 04:04:33 AM | Train: [ 63/180] Step 1249/1249 Loss 0.774 Prec@(1,3) (80.7%, 98.9%), ce_loss 0.874, lat_loss 6.679
09/19 04:04:33 AM | _w_step_train: [ 63/180] Final Prec@1 80.7350% Time 608.44
09/19 04:04:33 AM | Start to train theta for epoch 62
09/19 04:04:53 AM | Train: [ 63/180] Step 050/312 Loss 0.864 Prec@(1,3) (79.4%, 98.7%), ce_loss 0.874, lat_loss 6.679
09/19 04:05:12 AM | Train: [ 63/180] Step 100/312 Loss 0.858 Prec@(1,3) (78.7%, 98.5%), ce_loss 0.874, lat_loss 6.679
09/19 04:05:32 AM | Train: [ 63/180] Step 150/312 Loss 0.846 Prec@(1,3) (79.0%, 98.6%), ce_loss 0.874, lat_loss 6.679
09/19 04:05:53 AM | Train: [ 63/180] Step 200/312 Loss 0.833 Prec@(1,3) (79.3%, 98.7%), ce_loss 0.873, lat_loss 6.679
09/19 04:06:13 AM | Train: [ 63/180] Step 250/312 Loss 0.843 Prec@(1,3) (79.0%, 98.6%), ce_loss 0.873, lat_loss 6.679
09/19 04:06:34 AM | Train: [ 63/180] Step 300/312 Loss 0.835 Prec@(1,3) (79.2%, 98.6%), ce_loss 0.873, lat_loss 6.679
09/19 04:06:39 AM | Train: [ 63/180] Step 312/312 Loss 0.837 Prec@(1,3) (79.1%, 98.6%), ce_loss 0.873, lat_loss 6.679
09/19 04:06:39 AM | _theta_step_train: [ 63/180] Final Prec@1 79.0700% Time 125.94
09/19 04:06:44 AM | Valid: [ 63/180] Step 050/312 Loss 0.830 Prec@(1,3) (79.9%, 98.2%), ce_loss 0.873, lat_loss 6.679
09/19 04:06:49 AM | Valid: [ 63/180] Step 100/312 Loss 0.929 Prec@(1,3) (77.2%, 97.7%), ce_loss 0.873, lat_loss 6.679
09/19 04:06:54 AM | Valid: [ 63/180] Step 150/312 Loss 0.996 Prec@(1,3) (75.6%, 96.7%), ce_loss 0.873, lat_loss 6.679
09/19 04:06:58 AM | Valid: [ 63/180] Step 200/312 Loss 0.980 Prec@(1,3) (76.0%, 97.1%), ce_loss 0.873, lat_loss 6.679
09/19 04:07:03 AM | Valid: [ 63/180] Step 250/312 Loss 0.954 Prec@(1,3) (76.6%, 97.4%), ce_loss 0.873, lat_loss 6.679
09/19 04:07:08 AM | Valid: [ 63/180] Step 300/312 Loss 0.937 Prec@(1,3) (77.0%, 97.5%), ce_loss 0.873, lat_loss 6.679
09/19 04:07:09 AM | Valid: [ 63/180] Step 312/312 Loss 0.932 Prec@(1,3) (77.2%, 97.6%), ce_loss 0.873, lat_loss 6.679
09/19 04:07:09 AM | val: [ 63/180] Final Prec@1 77.2100% Time 29.77
09/19 04:07:09 AM | Start to train weights for epoch 63
09/19 04:07:33 AM | Train: [ 64/180] Step 050/1249 Loss 0.724 Prec@(1,3) (81.2%, 99.3%), ce_loss 0.872, lat_loss 6.679
09/19 04:07:56 AM | Train: [ 64/180] Step 100/1249 Loss 0.732 Prec@(1,3) (81.0%, 99.1%), ce_loss 0.872, lat_loss 6.679
09/19 04:08:19 AM | Train: [ 64/180] Step 150/1249 Loss 0.718 Prec@(1,3) (81.2%, 99.2%), ce_loss 0.872, lat_loss 6.679
09/19 04:08:43 AM | Train: [ 64/180] Step 200/1249 Loss 0.726 Prec@(1,3) (81.1%, 99.1%), ce_loss 0.872, lat_loss 6.679
09/19 04:09:08 AM | Train: [ 64/180] Step 250/1249 Loss 0.761 Prec@(1,3) (80.5%, 98.9%), ce_loss 0.872, lat_loss 6.679
09/19 04:09:31 AM | Train: [ 64/180] Step 300/1249 Loss 0.754 Prec@(1,3) (80.6%, 98.9%), ce_loss 0.872, lat_loss 6.679
09/19 04:09:52 AM | Train: [ 64/180] Step 350/1249 Loss 0.760 Prec@(1,3) (80.5%, 98.9%), ce_loss 0.872, lat_loss 6.679
09/19 04:10:16 AM | Train: [ 64/180] Step 400/1249 Loss 0.762 Prec@(1,3) (80.4%, 98.9%), ce_loss 0.872, lat_loss 6.679
09/19 04:10:36 AM | Train: [ 64/180] Step 450/1249 Loss 0.771 Prec@(1,3) (80.4%, 98.8%), ce_loss 0.871, lat_loss 6.679
09/19 04:10:57 AM | Train: [ 64/180] Step 500/1249 Loss 0.768 Prec@(1,3) (80.5%, 98.9%), ce_loss 0.871, lat_loss 6.680
09/19 04:11:21 AM | Train: [ 64/180] Step 550/1249 Loss 0.768 Prec@(1,3) (80.6%, 98.9%), ce_loss 0.871, lat_loss 6.680
09/19 04:11:44 AM | Train: [ 64/180] Step 600/1249 Loss 0.767 Prec@(1,3) (80.6%, 98.9%), ce_loss 0.871, lat_loss 6.680
09/19 04:12:08 AM | Train: [ 64/180] Step 650/1249 Loss 0.766 Prec@(1,3) (80.7%, 98.9%), ce_loss 0.871, lat_loss 6.680
09/19 04:12:30 AM | Train: [ 64/180] Step 700/1249 Loss 0.766 Prec@(1,3) (80.6%, 98.9%), ce_loss 0.871, lat_loss 6.680
09/19 04:12:54 AM | Train: [ 64/180] Step 750/1249 Loss 0.772 Prec@(1,3) (80.5%, 98.9%), ce_loss 0.871, lat_loss 6.680
09/19 04:13:18 AM | Train: [ 64/180] Step 800/1249 Loss 0.771 Prec@(1,3) (80.6%, 98.9%), ce_loss 0.871, lat_loss 6.680
09/19 04:13:43 AM | Train: [ 64/180] Step 850/1249 Loss 0.770 Prec@(1,3) (80.6%, 98.9%), ce_loss 0.870, lat_loss 6.680
09/19 04:14:08 AM | Train: [ 64/180] Step 900/1249 Loss 0.771 Prec@(1,3) (80.6%, 98.9%), ce_loss 0.870, lat_loss 6.680
09/19 04:14:33 AM | Train: [ 64/180] Step 950/1249 Loss 0.771 Prec@(1,3) (80.6%, 98.9%), ce_loss 0.870, lat_loss 6.680
09/19 04:14:58 AM | Train: [ 64/180] Step 1000/1249 Loss 0.770 Prec@(1,3) (80.6%, 98.9%), ce_loss 0.870, lat_loss 6.680
09/19 04:15:23 AM | Train: [ 64/180] Step 1050/1249 Loss 0.771 Prec@(1,3) (80.6%, 98.9%), ce_loss 0.870, lat_loss 6.680
09/19 04:15:48 AM | Train: [ 64/180] Step 1100/1249 Loss 0.769 Prec@(1,3) (80.6%, 98.9%), ce_loss 0.870, lat_loss 6.680
09/19 04:16:13 AM | Train: [ 64/180] Step 1150/1249 Loss 0.766 Prec@(1,3) (80.6%, 98.9%), ce_loss 0.870, lat_loss 6.680
09/19 04:16:38 AM | Train: [ 64/180] Step 1200/1249 Loss 0.764 Prec@(1,3) (80.7%, 98.9%), ce_loss 0.869, lat_loss 6.680
09/19 04:17:02 AM | Train: [ 64/180] Step 1249/1249 Loss 0.770 Prec@(1,3) (80.6%, 98.8%), ce_loss 0.869, lat_loss 6.680
09/19 04:17:02 AM | _w_step_train: [ 64/180] Final Prec@1 80.6000% Time 593.60
09/19 04:17:02 AM | Start to train theta for epoch 63
09/19 04:17:24 AM | Train: [ 64/180] Step 050/312 Loss 0.773 Prec@(1,3) (81.0%, 98.6%), ce_loss 0.869, lat_loss 6.680
09/19 04:17:43 AM | Train: [ 64/180] Step 100/312 Loss 0.817 Prec@(1,3) (80.0%, 98.4%), ce_loss 0.869, lat_loss 6.680
09/19 04:18:02 AM | Train: [ 64/180] Step 150/312 Loss 0.830 Prec@(1,3) (79.6%, 98.4%), ce_loss 0.869, lat_loss 6.680
09/19 04:18:23 AM | Train: [ 64/180] Step 200/312 Loss 0.842 Prec@(1,3) (79.2%, 98.5%), ce_loss 0.869, lat_loss 6.680
09/19 04:18:43 AM | Train: [ 64/180] Step 250/312 Loss 0.853 Prec@(1,3) (78.8%, 98.4%), ce_loss 0.869, lat_loss 6.680
09/19 04:19:04 AM | Train: [ 64/180] Step 300/312 Loss 0.854 Prec@(1,3) (78.7%, 98.4%), ce_loss 0.869, lat_loss 6.680
09/19 04:19:09 AM | Train: [ 64/180] Step 312/312 Loss 0.850 Prec@(1,3) (78.8%, 98.4%), ce_loss 0.869, lat_loss 6.680
09/19 04:19:10 AM | _theta_step_train: [ 64/180] Final Prec@1 78.7900% Time 127.14
09/19 04:19:15 AM | Valid: [ 64/180] Step 050/312 Loss 0.815 Prec@(1,3) (80.3%, 98.9%), ce_loss 0.869, lat_loss 6.680
09/19 04:19:19 AM | Valid: [ 64/180] Step 100/312 Loss 0.876 Prec@(1,3) (78.6%, 98.6%), ce_loss 0.868, lat_loss 6.680
09/19 04:19:24 AM | Valid: [ 64/180] Step 150/312 Loss 0.908 Prec@(1,3) (77.4%, 98.3%), ce_loss 0.868, lat_loss 6.680
09/19 04:19:29 AM | Valid: [ 64/180] Step 200/312 Loss 0.900 Prec@(1,3) (77.8%, 98.4%), ce_loss 0.868, lat_loss 6.680
09/19 04:19:33 AM | Valid: [ 64/180] Step 250/312 Loss 0.901 Prec@(1,3) (77.6%, 98.5%), ce_loss 0.868, lat_loss 6.680
09/19 04:19:38 AM | Valid: [ 64/180] Step 300/312 Loss 0.889 Prec@(1,3) (77.9%, 98.5%), ce_loss 0.868, lat_loss 6.680
09/19 04:19:39 AM | Valid: [ 64/180] Step 312/312 Loss 0.893 Prec@(1,3) (77.8%, 98.5%), ce_loss 0.868, lat_loss 6.680
09/19 04:19:39 AM | val: [ 64/180] Final Prec@1 77.8000% Time 29.33
09/19 04:19:39 AM | Start to train weights for epoch 64
09/19 04:20:03 AM | Train: [ 65/180] Step 050/1249 Loss 0.756 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.868, lat_loss 6.680
09/19 04:20:27 AM | Train: [ 65/180] Step 100/1249 Loss 0.779 Prec@(1,3) (81.1%, 98.6%), ce_loss 0.868, lat_loss 6.680
09/19 04:20:52 AM | Train: [ 65/180] Step 150/1249 Loss 0.763 Prec@(1,3) (81.2%, 98.6%), ce_loss 0.868, lat_loss 6.680
09/19 04:21:15 AM | Train: [ 65/180] Step 200/1249 Loss 0.765 Prec@(1,3) (81.0%, 98.7%), ce_loss 0.868, lat_loss 6.680
09/19 04:21:39 AM | Train: [ 65/180] Step 250/1249 Loss 0.758 Prec@(1,3) (81.2%, 98.8%), ce_loss 0.867, lat_loss 6.680
09/19 04:22:03 AM | Train: [ 65/180] Step 300/1249 Loss 0.759 Prec@(1,3) (81.1%, 98.8%), ce_loss 0.867, lat_loss 6.680
09/19 04:22:26 AM | Train: [ 65/180] Step 350/1249 Loss 0.764 Prec@(1,3) (81.1%, 98.8%), ce_loss 0.867, lat_loss 6.680
09/19 04:22:50 AM | Train: [ 65/180] Step 400/1249 Loss 0.762 Prec@(1,3) (81.2%, 98.8%), ce_loss 0.867, lat_loss 6.680
09/19 04:23:15 AM | Train: [ 65/180] Step 450/1249 Loss 0.757 Prec@(1,3) (81.2%, 98.8%), ce_loss 0.867, lat_loss 6.680
09/19 04:23:39 AM | Train: [ 65/180] Step 500/1249 Loss 0.753 Prec@(1,3) (81.4%, 98.8%), ce_loss 0.867, lat_loss 6.680
09/19 04:24:01 AM | Train: [ 65/180] Step 550/1249 Loss 0.750 Prec@(1,3) (81.4%, 98.9%), ce_loss 0.867, lat_loss 6.680
09/19 04:24:26 AM | Train: [ 65/180] Step 600/1249 Loss 0.751 Prec@(1,3) (81.4%, 98.8%), ce_loss 0.867, lat_loss 6.680
09/19 04:24:51 AM | Train: [ 65/180] Step 650/1249 Loss 0.750 Prec@(1,3) (81.3%, 98.9%), ce_loss 0.866, lat_loss 6.680
09/19 04:25:14 AM | Train: [ 65/180] Step 700/1249 Loss 0.746 Prec@(1,3) (81.5%, 98.9%), ce_loss 0.866, lat_loss 6.680
09/19 04:25:39 AM | Train: [ 65/180] Step 750/1249 Loss 0.746 Prec@(1,3) (81.4%, 98.9%), ce_loss 0.866, lat_loss 6.680
09/19 04:26:03 AM | Train: [ 65/180] Step 800/1249 Loss 0.748 Prec@(1,3) (81.3%, 98.9%), ce_loss 0.866, lat_loss 6.680
09/19 04:26:26 AM | Train: [ 65/180] Step 850/1249 Loss 0.747 Prec@(1,3) (81.3%, 98.9%), ce_loss 0.866, lat_loss 6.680
09/19 04:26:47 AM | Train: [ 65/180] Step 900/1249 Loss 0.749 Prec@(1,3) (81.3%, 98.9%), ce_loss 0.866, lat_loss 6.680
09/19 04:27:09 AM | Train: [ 65/180] Step 950/1249 Loss 0.750 Prec@(1,3) (81.3%, 98.9%), ce_loss 0.866, lat_loss 6.680
09/19 04:27:31 AM | Train: [ 65/180] Step 1000/1249 Loss 0.754 Prec@(1,3) (81.2%, 98.9%), ce_loss 0.865, lat_loss 6.680
09/19 04:27:53 AM | Train: [ 65/180] Step 1050/1249 Loss 0.753 Prec@(1,3) (81.3%, 98.9%), ce_loss 0.865, lat_loss 6.680
09/19 04:28:15 AM | Train: [ 65/180] Step 1100/1249 Loss 0.756 Prec@(1,3) (81.2%, 98.9%), ce_loss 0.865, lat_loss 6.680
09/19 04:28:36 AM | Train: [ 65/180] Step 1150/1249 Loss 0.757 Prec@(1,3) (81.2%, 98.9%), ce_loss 0.865, lat_loss 6.680
09/19 04:28:59 AM | Train: [ 65/180] Step 1200/1249 Loss 0.759 Prec@(1,3) (81.1%, 98.8%), ce_loss 0.865, lat_loss 6.680
09/19 04:29:23 AM | Train: [ 65/180] Step 1249/1249 Loss 0.759 Prec@(1,3) (81.1%, 98.8%), ce_loss 0.865, lat_loss 6.680
09/19 04:29:23 AM | _w_step_train: [ 65/180] Final Prec@1 81.0575% Time 584.17
09/19 04:29:23 AM | Start to train theta for epoch 64
09/19 04:29:42 AM | Train: [ 65/180] Step 050/312 Loss 0.787 Prec@(1,3) (81.1%, 98.4%), ce_loss 0.865, lat_loss 6.680
09/19 04:30:02 AM | Train: [ 65/180] Step 100/312 Loss 0.828 Prec@(1,3) (79.5%, 98.4%), ce_loss 0.865, lat_loss 6.680
09/19 04:30:22 AM | Train: [ 65/180] Step 150/312 Loss 0.842 Prec@(1,3) (79.0%, 98.3%), ce_loss 0.865, lat_loss 6.680
09/19 04:30:42 AM | Train: [ 65/180] Step 200/312 Loss 0.844 Prec@(1,3) (78.9%, 98.3%), ce_loss 0.864, lat_loss 6.680
09/19 04:31:01 AM | Train: [ 65/180] Step 250/312 Loss 0.834 Prec@(1,3) (79.1%, 98.4%), ce_loss 0.864, lat_loss 6.680
09/19 04:31:21 AM | Train: [ 65/180] Step 300/312 Loss 0.830 Prec@(1,3) (79.3%, 98.4%), ce_loss 0.864, lat_loss 6.680
09/19 04:31:26 AM | Train: [ 65/180] Step 312/312 Loss 0.830 Prec@(1,3) (79.3%, 98.4%), ce_loss 0.864, lat_loss 6.680
09/19 04:31:26 AM | _theta_step_train: [ 65/180] Final Prec@1 79.3100% Time 123.13
09/19 04:31:32 AM | Valid: [ 65/180] Step 050/312 Loss 1.019 Prec@(1,3) (76.5%, 97.2%), ce_loss 0.864, lat_loss 6.680
09/19 04:31:36 AM | Valid: [ 65/180] Step 100/312 Loss 0.960 Prec@(1,3) (78.3%, 97.5%), ce_loss 0.864, lat_loss 6.680
09/19 04:31:41 AM | Valid: [ 65/180] Step 150/312 Loss 0.966 Prec@(1,3) (77.8%, 97.4%), ce_loss 0.864, lat_loss 6.680
09/19 04:31:45 AM | Valid: [ 65/180] Step 200/312 Loss 0.948 Prec@(1,3) (78.4%, 97.7%), ce_loss 0.864, lat_loss 6.680
09/19 04:31:50 AM | Valid: [ 65/180] Step 250/312 Loss 0.941 Prec@(1,3) (78.2%, 97.8%), ce_loss 0.864, lat_loss 6.680
09/19 04:31:55 AM | Valid: [ 65/180] Step 300/312 Loss 0.941 Prec@(1,3) (78.4%, 97.7%), ce_loss 0.864, lat_loss 6.680
09/19 04:31:56 AM | Valid: [ 65/180] Step 312/312 Loss 0.940 Prec@(1,3) (78.4%, 97.8%), ce_loss 0.864, lat_loss 6.680
09/19 04:31:56 AM | val: [ 65/180] Final Prec@1 78.4400% Time 29.63
09/19 04:31:56 AM | Best top1 acc by now. Save model
09/19 04:31:56 AM | Start to train weights for epoch 65
09/19 04:32:22 AM | Train: [ 66/180] Step 050/1249 Loss 0.733 Prec@(1,3) (82.5%, 98.7%), ce_loss 0.864, lat_loss 6.680
09/19 04:32:47 AM | Train: [ 66/180] Step 100/1249 Loss 0.709 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.863, lat_loss 6.680
09/19 04:33:11 AM | Train: [ 66/180] Step 150/1249 Loss 0.738 Prec@(1,3) (81.6%, 99.1%), ce_loss 0.863, lat_loss 6.680
09/19 04:33:35 AM | Train: [ 66/180] Step 200/1249 Loss 0.732 Prec@(1,3) (81.7%, 99.2%), ce_loss 0.863, lat_loss 6.680
09/19 04:33:54 AM | Train: [ 66/180] Step 250/1249 Loss 0.737 Prec@(1,3) (81.4%, 99.1%), ce_loss 0.863, lat_loss 6.680
09/19 04:34:10 AM | Train: [ 66/180] Step 300/1249 Loss 0.741 Prec@(1,3) (81.5%, 99.1%), ce_loss 0.863, lat_loss 6.680
09/19 04:34:26 AM | Train: [ 66/180] Step 350/1249 Loss 0.742 Prec@(1,3) (81.4%, 99.1%), ce_loss 0.863, lat_loss 6.680
09/19 04:34:42 AM | Train: [ 66/180] Step 400/1249 Loss 0.751 Prec@(1,3) (81.2%, 99.1%), ce_loss 0.863, lat_loss 6.680
09/19 04:34:58 AM | Train: [ 66/180] Step 450/1249 Loss 0.747 Prec@(1,3) (81.2%, 99.1%), ce_loss 0.863, lat_loss 6.680
09/19 04:35:14 AM | Train: [ 66/180] Step 500/1249 Loss 0.744 Prec@(1,3) (81.3%, 99.1%), ce_loss 0.862, lat_loss 6.680
09/19 04:35:30 AM | Train: [ 66/180] Step 550/1249 Loss 0.748 Prec@(1,3) (81.3%, 99.1%), ce_loss 0.862, lat_loss 6.680
09/19 04:35:46 AM | Train: [ 66/180] Step 600/1249 Loss 0.748 Prec@(1,3) (81.3%, 99.1%), ce_loss 0.862, lat_loss 6.680
09/19 04:36:07 AM | Train: [ 66/180] Step 650/1249 Loss 0.752 Prec@(1,3) (81.2%, 99.0%), ce_loss 0.862, lat_loss 6.680
09/19 04:36:31 AM | Train: [ 66/180] Step 700/1249 Loss 0.760 Prec@(1,3) (81.0%, 99.0%), ce_loss 0.862, lat_loss 6.680
09/19 04:36:52 AM | Train: [ 66/180] Step 750/1249 Loss 0.760 Prec@(1,3) (81.0%, 99.0%), ce_loss 0.862, lat_loss 6.680
09/19 04:37:14 AM | Train: [ 66/180] Step 800/1249 Loss 0.759 Prec@(1,3) (81.0%, 99.0%), ce_loss 0.862, lat_loss 6.680
09/19 04:37:35 AM | Train: [ 66/180] Step 850/1249 Loss 0.758 Prec@(1,3) (81.0%, 99.0%), ce_loss 0.862, lat_loss 6.680
09/19 04:37:58 AM | Train: [ 66/180] Step 900/1249 Loss 0.760 Prec@(1,3) (80.9%, 99.0%), ce_loss 0.861, lat_loss 6.680
09/19 04:38:19 AM | Train: [ 66/180] Step 950/1249 Loss 0.760 Prec@(1,3) (80.9%, 98.9%), ce_loss 0.861, lat_loss 6.680
09/19 04:38:40 AM | Train: [ 66/180] Step 1000/1249 Loss 0.760 Prec@(1,3) (80.9%, 99.0%), ce_loss 0.861, lat_loss 6.680
09/19 04:39:03 AM | Train: [ 66/180] Step 1050/1249 Loss 0.759 Prec@(1,3) (80.9%, 99.0%), ce_loss 0.861, lat_loss 6.680
09/19 04:39:25 AM | Train: [ 66/180] Step 1100/1249 Loss 0.757 Prec@(1,3) (80.9%, 99.0%), ce_loss 0.861, lat_loss 6.680
09/19 04:39:46 AM | Train: [ 66/180] Step 1150/1249 Loss 0.754 Prec@(1,3) (80.9%, 99.0%), ce_loss 0.861, lat_loss 6.680
09/19 04:40:07 AM | Train: [ 66/180] Step 1200/1249 Loss 0.753 Prec@(1,3) (81.0%, 99.0%), ce_loss 0.861, lat_loss 6.680
09/19 04:40:29 AM | Train: [ 66/180] Step 1249/1249 Loss 0.752 Prec@(1,3) (81.0%, 99.0%), ce_loss 0.861, lat_loss 6.680
09/19 04:40:30 AM | _w_step_train: [ 66/180] Final Prec@1 81.0200% Time 513.53
09/19 04:40:30 AM | Start to train theta for epoch 65
09/19 04:40:43 AM | Train: [ 66/180] Step 050/312 Loss 0.890 Prec@(1,3) (77.5%, 98.3%), ce_loss 0.860, lat_loss 6.680
09/19 04:40:55 AM | Train: [ 66/180] Step 100/312 Loss 0.859 Prec@(1,3) (78.2%, 98.4%), ce_loss 0.860, lat_loss 6.680
09/19 04:41:07 AM | Train: [ 66/180] Step 150/312 Loss 0.844 Prec@(1,3) (78.5%, 98.5%), ce_loss 0.860, lat_loss 6.680
09/19 04:41:19 AM | Train: [ 66/180] Step 200/312 Loss 0.832 Prec@(1,3) (78.9%, 98.5%), ce_loss 0.860, lat_loss 6.680
09/19 04:41:32 AM | Train: [ 66/180] Step 250/312 Loss 0.830 Prec@(1,3) (78.9%, 98.5%), ce_loss 0.860, lat_loss 6.680
09/19 04:41:45 AM | Train: [ 66/180] Step 300/312 Loss 0.822 Prec@(1,3) (79.1%, 98.5%), ce_loss 0.860, lat_loss 6.680
09/19 04:41:48 AM | Train: [ 66/180] Step 312/312 Loss 0.818 Prec@(1,3) (79.2%, 98.5%), ce_loss 0.860, lat_loss 6.680
09/19 04:41:48 AM | _theta_step_train: [ 66/180] Final Prec@1 79.2500% Time 78.01
09/19 04:41:53 AM | Valid: [ 66/180] Step 050/312 Loss 0.781 Prec@(1,3) (81.4%, 98.9%), ce_loss 0.860, lat_loss 6.681
09/19 04:41:58 AM | Valid: [ 66/180] Step 100/312 Loss 0.873 Prec@(1,3) (78.4%, 98.3%), ce_loss 0.860, lat_loss 6.681
09/19 04:42:02 AM | Valid: [ 66/180] Step 150/312 Loss 0.942 Prec@(1,3) (77.4%, 97.8%), ce_loss 0.860, lat_loss 6.681
09/19 04:42:07 AM | Valid: [ 66/180] Step 200/312 Loss 1.017 Prec@(1,3) (76.3%, 97.0%), ce_loss 0.860, lat_loss 6.681
09/19 04:42:12 AM | Valid: [ 66/180] Step 250/312 Loss 0.992 Prec@(1,3) (76.6%, 97.3%), ce_loss 0.860, lat_loss 6.681
09/19 04:42:16 AM | Valid: [ 66/180] Step 300/312 Loss 0.985 Prec@(1,3) (76.7%, 97.3%), ce_loss 0.860, lat_loss 6.681
09/19 04:42:17 AM | Valid: [ 66/180] Step 312/312 Loss 0.983 Prec@(1,3) (76.8%, 97.4%), ce_loss 0.860, lat_loss 6.681
09/19 04:42:17 AM | val: [ 66/180] Final Prec@1 76.7700% Time 29.80
09/19 04:42:17 AM | Start to train weights for epoch 66
09/19 04:42:43 AM | Train: [ 67/180] Step 050/1249 Loss 0.686 Prec@(1,3) (81.5%, 99.1%), ce_loss 0.859, lat_loss 6.681
09/19 04:43:06 AM | Train: [ 67/180] Step 100/1249 Loss 0.700 Prec@(1,3) (81.6%, 99.0%), ce_loss 0.859, lat_loss 6.681
09/19 04:43:30 AM | Train: [ 67/180] Step 150/1249 Loss 0.713 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.859, lat_loss 6.681
09/19 04:43:54 AM | Train: [ 67/180] Step 200/1249 Loss 0.702 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.859, lat_loss 6.681
09/19 04:44:18 AM | Train: [ 67/180] Step 250/1249 Loss 0.725 Prec@(1,3) (81.8%, 98.9%), ce_loss 0.859, lat_loss 6.681
09/19 04:44:42 AM | Train: [ 67/180] Step 300/1249 Loss 0.726 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.859, lat_loss 6.681
09/19 04:45:06 AM | Train: [ 67/180] Step 350/1249 Loss 0.732 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.859, lat_loss 6.681
09/19 04:45:29 AM | Train: [ 67/180] Step 400/1249 Loss 0.735 Prec@(1,3) (81.6%, 98.8%), ce_loss 0.858, lat_loss 6.681
09/19 04:45:54 AM | Train: [ 67/180] Step 450/1249 Loss 0.737 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.858, lat_loss 6.681
09/19 04:46:18 AM | Train: [ 67/180] Step 500/1249 Loss 0.741 Prec@(1,3) (81.6%, 98.9%), ce_loss 0.858, lat_loss 6.681
09/19 04:46:43 AM | Train: [ 67/180] Step 550/1249 Loss 0.739 Prec@(1,3) (81.6%, 98.9%), ce_loss 0.858, lat_loss 6.681
09/19 04:47:07 AM | Train: [ 67/180] Step 600/1249 Loss 0.740 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.858, lat_loss 6.681
09/19 04:47:32 AM | Train: [ 67/180] Step 650/1249 Loss 0.738 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.858, lat_loss 6.681
09/19 04:47:54 AM | Train: [ 67/180] Step 700/1249 Loss 0.734 Prec@(1,3) (81.8%, 98.9%), ce_loss 0.858, lat_loss 6.681
09/19 04:48:19 AM | Train: [ 67/180] Step 750/1249 Loss 0.736 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.858, lat_loss 6.681
09/19 04:48:42 AM | Train: [ 67/180] Step 800/1249 Loss 0.740 Prec@(1,3) (81.6%, 98.9%), ce_loss 0.857, lat_loss 6.681
09/19 04:49:02 AM | Train: [ 67/180] Step 850/1249 Loss 0.738 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.857, lat_loss 6.681
09/19 04:49:25 AM | Train: [ 67/180] Step 900/1249 Loss 0.738 Prec@(1,3) (81.6%, 98.9%), ce_loss 0.857, lat_loss 6.681
09/19 04:49:50 AM | Train: [ 67/180] Step 950/1249 Loss 0.739 Prec@(1,3) (81.6%, 98.9%), ce_loss 0.857, lat_loss 6.681
09/19 04:50:13 AM | Train: [ 67/180] Step 1000/1249 Loss 0.737 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.857, lat_loss 6.681
09/19 04:50:35 AM | Train: [ 67/180] Step 1050/1249 Loss 0.739 Prec@(1,3) (81.6%, 98.9%), ce_loss 0.857, lat_loss 6.681
09/19 04:50:57 AM | Train: [ 67/180] Step 1100/1249 Loss 0.741 Prec@(1,3) (81.6%, 98.9%), ce_loss 0.857, lat_loss 6.681
09/19 04:51:20 AM | Train: [ 67/180] Step 1150/1249 Loss 0.742 Prec@(1,3) (81.5%, 98.9%), ce_loss 0.857, lat_loss 6.681
09/19 04:51:43 AM | Train: [ 67/180] Step 1200/1249 Loss 0.742 Prec@(1,3) (81.5%, 98.9%), ce_loss 0.856, lat_loss 6.681
09/19 04:52:03 AM | Train: [ 67/180] Step 1249/1249 Loss 0.745 Prec@(1,3) (81.4%, 98.9%), ce_loss 0.856, lat_loss 6.681
09/19 04:52:03 AM | _w_step_train: [ 67/180] Final Prec@1 81.4425% Time 585.40
09/19 04:52:03 AM | Start to train theta for epoch 66
09/19 04:52:23 AM | Train: [ 67/180] Step 050/312 Loss 0.837 Prec@(1,3) (79.8%, 98.5%), ce_loss 0.856, lat_loss 6.681
09/19 04:52:43 AM | Train: [ 67/180] Step 100/312 Loss 0.795 Prec@(1,3) (80.3%, 98.5%), ce_loss 0.856, lat_loss 6.681
09/19 04:53:02 AM | Train: [ 67/180] Step 150/312 Loss 0.797 Prec@(1,3) (80.1%, 98.5%), ce_loss 0.856, lat_loss 6.681
09/19 04:53:21 AM | Train: [ 67/180] Step 200/312 Loss 0.805 Prec@(1,3) (80.0%, 98.4%), ce_loss 0.856, lat_loss 6.681
09/19 04:53:41 AM | Train: [ 67/180] Step 250/312 Loss 0.803 Prec@(1,3) (80.0%, 98.5%), ce_loss 0.856, lat_loss 6.681
09/19 04:53:59 AM | Train: [ 67/180] Step 300/312 Loss 0.806 Prec@(1,3) (79.8%, 98.5%), ce_loss 0.856, lat_loss 6.681
09/19 04:54:04 AM | Train: [ 67/180] Step 312/312 Loss 0.799 Prec@(1,3) (80.0%, 98.5%), ce_loss 0.856, lat_loss 6.681
09/19 04:54:04 AM | _theta_step_train: [ 67/180] Final Prec@1 79.9700% Time 120.88
09/19 04:54:09 AM | Valid: [ 67/180] Step 050/312 Loss 0.830 Prec@(1,3) (79.9%, 98.7%), ce_loss 0.856, lat_loss 6.681
09/19 04:54:14 AM | Valid: [ 67/180] Step 100/312 Loss 0.860 Prec@(1,3) (80.0%, 98.6%), ce_loss 0.855, lat_loss 6.681
09/19 04:54:19 AM | Valid: [ 67/180] Step 150/312 Loss 0.886 Prec@(1,3) (79.7%, 98.2%), ce_loss 0.855, lat_loss 6.681
09/19 04:54:24 AM | Valid: [ 67/180] Step 200/312 Loss 0.881 Prec@(1,3) (79.9%, 98.2%), ce_loss 0.855, lat_loss 6.681
09/19 04:54:28 AM | Valid: [ 67/180] Step 250/312 Loss 0.859 Prec@(1,3) (80.3%, 98.3%), ce_loss 0.855, lat_loss 6.681
09/19 04:54:33 AM | Valid: [ 67/180] Step 300/312 Loss 0.896 Prec@(1,3) (79.9%, 98.1%), ce_loss 0.855, lat_loss 6.681
09/19 04:54:34 AM | Valid: [ 67/180] Step 312/312 Loss 0.892 Prec@(1,3) (79.9%, 98.2%), ce_loss 0.855, lat_loss 6.681
09/19 04:54:34 AM | val: [ 67/180] Final Prec@1 79.9300% Time 30.61
09/19 04:54:34 AM | Best top1 acc by now. Save model
09/19 04:54:35 AM | Start to train weights for epoch 67
09/19 04:54:59 AM | Train: [ 68/180] Step 050/1249 Loss 0.719 Prec@(1,3) (82.1%, 98.8%), ce_loss 0.855, lat_loss 6.681
09/19 04:55:20 AM | Train: [ 68/180] Step 100/1249 Loss 0.721 Prec@(1,3) (81.8%, 99.0%), ce_loss 0.855, lat_loss 6.681
09/19 04:55:36 AM | Train: [ 68/180] Step 150/1249 Loss 0.696 Prec@(1,3) (82.7%, 99.1%), ce_loss 0.855, lat_loss 6.681
09/19 04:55:52 AM | Train: [ 68/180] Step 200/1249 Loss 0.702 Prec@(1,3) (82.3%, 99.1%), ce_loss 0.855, lat_loss 6.681
09/19 04:56:14 AM | Train: [ 68/180] Step 250/1249 Loss 0.726 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.854, lat_loss 6.681
09/19 04:56:37 AM | Train: [ 68/180] Step 300/1249 Loss 0.739 Prec@(1,3) (81.5%, 98.9%), ce_loss 0.854, lat_loss 6.681
09/19 04:57:00 AM | Train: [ 68/180] Step 350/1249 Loss 0.746 Prec@(1,3) (81.3%, 98.8%), ce_loss 0.854, lat_loss 6.681
09/19 04:57:23 AM | Train: [ 68/180] Step 400/1249 Loss 0.747 Prec@(1,3) (81.3%, 98.9%), ce_loss 0.854, lat_loss 6.681
09/19 04:57:46 AM | Train: [ 68/180] Step 450/1249 Loss 0.745 Prec@(1,3) (81.4%, 98.8%), ce_loss 0.854, lat_loss 6.681
09/19 04:58:10 AM | Train: [ 68/180] Step 500/1249 Loss 0.738 Prec@(1,3) (81.6%, 98.8%), ce_loss 0.854, lat_loss 6.681
09/19 04:58:32 AM | Train: [ 68/180] Step 550/1249 Loss 0.734 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.854, lat_loss 6.681
09/19 04:58:55 AM | Train: [ 68/180] Step 600/1249 Loss 0.735 Prec@(1,3) (81.6%, 98.9%), ce_loss 0.854, lat_loss 6.681
09/19 04:59:18 AM | Train: [ 68/180] Step 650/1249 Loss 0.732 Prec@(1,3) (81.6%, 98.9%), ce_loss 0.853, lat_loss 6.681
09/19 04:59:41 AM | Train: [ 68/180] Step 700/1249 Loss 0.734 Prec@(1,3) (81.6%, 98.9%), ce_loss 0.853, lat_loss 6.681
09/19 05:00:02 AM | Train: [ 68/180] Step 750/1249 Loss 0.738 Prec@(1,3) (81.4%, 98.9%), ce_loss 0.853, lat_loss 6.681
09/19 05:00:20 AM | Train: [ 68/180] Step 800/1249 Loss 0.734 Prec@(1,3) (81.5%, 99.0%), ce_loss 0.853, lat_loss 6.681
09/19 05:00:40 AM | Train: [ 68/180] Step 850/1249 Loss 0.732 Prec@(1,3) (81.6%, 99.0%), ce_loss 0.853, lat_loss 6.681
09/19 05:01:03 AM | Train: [ 68/180] Step 900/1249 Loss 0.735 Prec@(1,3) (81.5%, 99.0%), ce_loss 0.853, lat_loss 6.681
09/19 05:01:23 AM | Train: [ 68/180] Step 950/1249 Loss 0.732 Prec@(1,3) (81.6%, 99.0%), ce_loss 0.853, lat_loss 6.681
09/19 05:01:45 AM | Train: [ 68/180] Step 1000/1249 Loss 0.730 Prec@(1,3) (81.6%, 99.0%), ce_loss 0.853, lat_loss 6.681
09/19 05:02:07 AM | Train: [ 68/180] Step 1050/1249 Loss 0.731 Prec@(1,3) (81.6%, 99.0%), ce_loss 0.852, lat_loss 6.681
09/19 05:02:27 AM | Train: [ 68/180] Step 1100/1249 Loss 0.729 Prec@(1,3) (81.7%, 99.0%), ce_loss 0.852, lat_loss 6.681
09/19 05:02:50 AM | Train: [ 68/180] Step 1150/1249 Loss 0.728 Prec@(1,3) (81.7%, 99.0%), ce_loss 0.852, lat_loss 6.681
09/19 05:03:12 AM | Train: [ 68/180] Step 1200/1249 Loss 0.729 Prec@(1,3) (81.6%, 99.0%), ce_loss 0.852, lat_loss 6.681
09/19 05:03:35 AM | Train: [ 68/180] Step 1249/1249 Loss 0.728 Prec@(1,3) (81.6%, 99.0%), ce_loss 0.852, lat_loss 6.681
09/19 05:03:35 AM | _w_step_train: [ 68/180] Final Prec@1 81.6350% Time 540.30
09/19 05:03:35 AM | Start to train theta for epoch 67
09/19 05:03:55 AM | Train: [ 68/180] Step 050/312 Loss 0.928 Prec@(1,3) (77.6%, 98.3%), ce_loss 0.852, lat_loss 6.681
09/19 05:04:13 AM | Train: [ 68/180] Step 100/312 Loss 0.873 Prec@(1,3) (78.8%, 98.3%), ce_loss 0.852, lat_loss 6.681
09/19 05:04:32 AM | Train: [ 68/180] Step 150/312 Loss 0.862 Prec@(1,3) (78.8%, 98.4%), ce_loss 0.852, lat_loss 6.681
09/19 05:04:51 AM | Train: [ 68/180] Step 200/312 Loss 0.852 Prec@(1,3) (79.1%, 98.4%), ce_loss 0.852, lat_loss 6.681
09/19 05:05:10 AM | Train: [ 68/180] Step 250/312 Loss 0.846 Prec@(1,3) (79.2%, 98.3%), ce_loss 0.851, lat_loss 6.681
09/19 05:05:27 AM | Train: [ 68/180] Step 300/312 Loss 0.827 Prec@(1,3) (79.6%, 98.5%), ce_loss 0.851, lat_loss 6.681
09/19 05:05:32 AM | Train: [ 68/180] Step 312/312 Loss 0.822 Prec@(1,3) (79.7%, 98.5%), ce_loss 0.851, lat_loss 6.681
09/19 05:05:32 AM | _theta_step_train: [ 68/180] Final Prec@1 79.7200% Time 117.31
09/19 05:05:37 AM | Valid: [ 68/180] Step 050/312 Loss 0.789 Prec@(1,3) (80.3%, 98.7%), ce_loss 0.851, lat_loss 6.681
09/19 05:05:42 AM | Valid: [ 68/180] Step 100/312 Loss 0.876 Prec@(1,3) (78.7%, 98.0%), ce_loss 0.851, lat_loss 6.681
09/19 05:05:47 AM | Valid: [ 68/180] Step 150/312 Loss 0.908 Prec@(1,3) (77.9%, 97.5%), ce_loss 0.851, lat_loss 6.681
09/19 05:05:52 AM | Valid: [ 68/180] Step 200/312 Loss 0.883 Prec@(1,3) (78.5%, 97.8%), ce_loss 0.851, lat_loss 6.681
09/19 05:05:56 AM | Valid: [ 68/180] Step 250/312 Loss 0.903 Prec@(1,3) (78.3%, 97.8%), ce_loss 0.851, lat_loss 6.681
09/19 05:06:01 AM | Valid: [ 68/180] Step 300/312 Loss 0.912 Prec@(1,3) (78.2%, 97.8%), ce_loss 0.851, lat_loss 6.681
09/19 05:06:02 AM | Valid: [ 68/180] Step 312/312 Loss 0.922 Prec@(1,3) (77.8%, 97.7%), ce_loss 0.851, lat_loss 6.681
09/19 05:06:02 AM | val: [ 68/180] Final Prec@1 77.8500% Time 29.90
09/19 05:06:02 AM | Start to train weights for epoch 68
09/19 05:06:26 AM | Train: [ 69/180] Step 050/1249 Loss 0.749 Prec@(1,3) (80.8%, 98.8%), ce_loss 0.851, lat_loss 6.681
09/19 05:06:42 AM | Train: [ 69/180] Step 100/1249 Loss 0.731 Prec@(1,3) (82.0%, 99.0%), ce_loss 0.851, lat_loss 6.681
09/19 05:06:58 AM | Train: [ 69/180] Step 150/1249 Loss 0.712 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.850, lat_loss 6.681
09/19 05:07:15 AM | Train: [ 69/180] Step 200/1249 Loss 0.708 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.850, lat_loss 6.681
09/19 05:07:33 AM | Train: [ 69/180] Step 250/1249 Loss 0.702 Prec@(1,3) (82.5%, 99.0%), ce_loss 0.850, lat_loss 6.681
09/19 05:07:56 AM | Train: [ 69/180] Step 300/1249 Loss 0.716 Prec@(1,3) (82.2%, 98.9%), ce_loss 0.850, lat_loss 6.681
09/19 05:08:16 AM | Train: [ 69/180] Step 350/1249 Loss 0.725 Prec@(1,3) (82.0%, 98.8%), ce_loss 0.850, lat_loss 6.681
09/19 05:08:33 AM | Train: [ 69/180] Step 400/1249 Loss 0.720 Prec@(1,3) (82.0%, 98.9%), ce_loss 0.850, lat_loss 6.681
09/19 05:08:50 AM | Train: [ 69/180] Step 450/1249 Loss 0.714 Prec@(1,3) (82.1%, 98.9%), ce_loss 0.850, lat_loss 6.681
09/19 05:09:13 AM | Train: [ 69/180] Step 500/1249 Loss 0.709 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.850, lat_loss 6.681
09/19 05:09:36 AM | Train: [ 69/180] Step 550/1249 Loss 0.711 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.849, lat_loss 6.681
09/19 05:10:00 AM | Train: [ 69/180] Step 600/1249 Loss 0.710 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.849, lat_loss 6.681
09/19 05:10:23 AM | Train: [ 69/180] Step 650/1249 Loss 0.705 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.849, lat_loss 6.681
09/19 05:10:47 AM | Train: [ 69/180] Step 700/1249 Loss 0.703 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.849, lat_loss 6.681
09/19 05:11:03 AM | Train: [ 69/180] Step 750/1249 Loss 0.700 Prec@(1,3) (82.4%, 99.0%), ce_loss 0.849, lat_loss 6.681
09/19 05:11:20 AM | Train: [ 69/180] Step 800/1249 Loss 0.698 Prec@(1,3) (82.4%, 99.0%), ce_loss 0.849, lat_loss 6.681
09/19 05:11:36 AM | Train: [ 69/180] Step 850/1249 Loss 0.703 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.849, lat_loss 6.681
09/19 05:11:52 AM | Train: [ 69/180] Step 900/1249 Loss 0.707 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.849, lat_loss 6.681
09/19 05:12:09 AM | Train: [ 69/180] Step 950/1249 Loss 0.707 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.848, lat_loss 6.681
09/19 05:12:25 AM | Train: [ 69/180] Step 1000/1249 Loss 0.708 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.848, lat_loss 6.681
09/19 05:12:42 AM | Train: [ 69/180] Step 1050/1249 Loss 0.708 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.848, lat_loss 6.681
09/19 05:12:58 AM | Train: [ 69/180] Step 1100/1249 Loss 0.709 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.848, lat_loss 6.681
09/19 05:13:15 AM | Train: [ 69/180] Step 1150/1249 Loss 0.709 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.848, lat_loss 6.681
09/19 05:13:31 AM | Train: [ 69/180] Step 1200/1249 Loss 0.709 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.848, lat_loss 6.681
09/19 05:13:47 AM | Train: [ 69/180] Step 1249/1249 Loss 0.710 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.848, lat_loss 6.681
09/19 05:13:47 AM | _w_step_train: [ 69/180] Final Prec@1 82.1375% Time 464.88
09/19 05:13:47 AM | Start to train theta for epoch 68
09/19 05:14:00 AM | Train: [ 69/180] Step 050/312 Loss 0.807 Prec@(1,3) (80.0%, 98.0%), ce_loss 0.848, lat_loss 6.681
09/19 05:14:13 AM | Train: [ 69/180] Step 100/312 Loss 0.799 Prec@(1,3) (80.2%, 98.4%), ce_loss 0.847, lat_loss 6.681
09/19 05:14:25 AM | Train: [ 69/180] Step 150/312 Loss 0.805 Prec@(1,3) (79.9%, 98.6%), ce_loss 0.847, lat_loss 6.681
09/19 05:14:38 AM | Train: [ 69/180] Step 200/312 Loss 0.788 Prec@(1,3) (80.2%, 98.8%), ce_loss 0.847, lat_loss 6.681
09/19 05:14:50 AM | Train: [ 69/180] Step 250/312 Loss 0.783 Prec@(1,3) (80.4%, 98.8%), ce_loss 0.847, lat_loss 6.681
09/19 05:15:03 AM | Train: [ 69/180] Step 300/312 Loss 0.778 Prec@(1,3) (80.7%, 98.8%), ce_loss 0.847, lat_loss 6.681
09/19 05:15:06 AM | Train: [ 69/180] Step 312/312 Loss 0.778 Prec@(1,3) (80.8%, 98.8%), ce_loss 0.847, lat_loss 6.681
09/19 05:15:06 AM | _theta_step_train: [ 69/180] Final Prec@1 80.7700% Time 78.94
09/19 05:15:11 AM | Valid: [ 69/180] Step 050/312 Loss 0.844 Prec@(1,3) (79.9%, 98.8%), ce_loss 0.847, lat_loss 6.681
09/19 05:15:16 AM | Valid: [ 69/180] Step 100/312 Loss 0.825 Prec@(1,3) (80.1%, 98.9%), ce_loss 0.847, lat_loss 6.681
09/19 05:15:21 AM | Valid: [ 69/180] Step 150/312 Loss 0.876 Prec@(1,3) (79.6%, 98.3%), ce_loss 0.847, lat_loss 6.681
09/19 05:15:25 AM | Valid: [ 69/180] Step 200/312 Loss 0.885 Prec@(1,3) (79.6%, 98.2%), ce_loss 0.847, lat_loss 6.681
09/19 05:15:30 AM | Valid: [ 69/180] Step 250/312 Loss 0.859 Prec@(1,3) (79.8%, 98.3%), ce_loss 0.847, lat_loss 6.681
09/19 05:15:35 AM | Valid: [ 69/180] Step 300/312 Loss 0.834 Prec@(1,3) (80.3%, 98.5%), ce_loss 0.846, lat_loss 6.681
09/19 05:15:36 AM | Valid: [ 69/180] Step 312/312 Loss 0.849 Prec@(1,3) (80.2%, 98.4%), ce_loss 0.846, lat_loss 6.681
09/19 05:15:36 AM | val: [ 69/180] Final Prec@1 80.1600% Time 30.13
09/19 05:15:36 AM | Best top1 acc by now. Save model
09/19 05:15:36 AM | Start to train weights for epoch 69
09/19 05:16:00 AM | Train: [ 70/180] Step 050/1249 Loss 0.711 Prec@(1,3) (82.1%, 99.3%), ce_loss 0.846, lat_loss 6.681
09/19 05:16:16 AM | Train: [ 70/180] Step 100/1249 Loss 0.706 Prec@(1,3) (81.9%, 99.2%), ce_loss 0.846, lat_loss 6.681
09/19 05:16:32 AM | Train: [ 70/180] Step 150/1249 Loss 0.708 Prec@(1,3) (82.0%, 99.1%), ce_loss 0.846, lat_loss 6.681
09/19 05:16:49 AM | Train: [ 70/180] Step 200/1249 Loss 0.707 Prec@(1,3) (81.8%, 99.2%), ce_loss 0.846, lat_loss 6.681
09/19 05:17:05 AM | Train: [ 70/180] Step 250/1249 Loss 0.712 Prec@(1,3) (81.8%, 99.1%), ce_loss 0.846, lat_loss 6.681
09/19 05:17:23 AM | Train: [ 70/180] Step 300/1249 Loss 0.711 Prec@(1,3) (81.9%, 99.1%), ce_loss 0.846, lat_loss 6.681
09/19 05:17:47 AM | Train: [ 70/180] Step 350/1249 Loss 0.704 Prec@(1,3) (82.1%, 99.1%), ce_loss 0.845, lat_loss 6.681
09/19 05:18:06 AM | Train: [ 70/180] Step 400/1249 Loss 0.696 Prec@(1,3) (82.2%, 99.1%), ce_loss 0.845, lat_loss 6.681
09/19 05:18:23 AM | Train: [ 70/180] Step 450/1249 Loss 0.692 Prec@(1,3) (82.3%, 99.1%), ce_loss 0.845, lat_loss 6.681
09/19 05:18:39 AM | Train: [ 70/180] Step 500/1249 Loss 0.690 Prec@(1,3) (82.2%, 99.1%), ce_loss 0.845, lat_loss 6.681
09/19 05:18:56 AM | Train: [ 70/180] Step 550/1249 Loss 0.693 Prec@(1,3) (82.2%, 99.1%), ce_loss 0.845, lat_loss 6.681
09/19 05:19:12 AM | Train: [ 70/180] Step 600/1249 Loss 0.690 Prec@(1,3) (82.3%, 99.1%), ce_loss 0.845, lat_loss 6.681
09/19 05:19:29 AM | Train: [ 70/180] Step 650/1249 Loss 0.691 Prec@(1,3) (82.2%, 99.1%), ce_loss 0.845, lat_loss 6.681
09/19 05:19:46 AM | Train: [ 70/180] Step 700/1249 Loss 0.693 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.845, lat_loss 6.681
09/19 05:20:02 AM | Train: [ 70/180] Step 750/1249 Loss 0.692 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.844, lat_loss 6.681
09/19 05:20:18 AM | Train: [ 70/180] Step 800/1249 Loss 0.691 Prec@(1,3) (82.3%, 99.1%), ce_loss 0.844, lat_loss 6.681
09/19 05:20:34 AM | Train: [ 70/180] Step 850/1249 Loss 0.693 Prec@(1,3) (82.2%, 99.1%), ce_loss 0.844, lat_loss 6.681
09/19 05:20:51 AM | Train: [ 70/180] Step 900/1249 Loss 0.691 Prec@(1,3) (82.3%, 99.1%), ce_loss 0.844, lat_loss 6.681
09/19 05:21:14 AM | Train: [ 70/180] Step 950/1249 Loss 0.693 Prec@(1,3) (82.3%, 99.1%), ce_loss 0.844, lat_loss 6.681
09/19 05:21:37 AM | Train: [ 70/180] Step 1000/1249 Loss 0.693 Prec@(1,3) (82.3%, 99.1%), ce_loss 0.844, lat_loss 6.681
09/19 05:22:00 AM | Train: [ 70/180] Step 1050/1249 Loss 0.695 Prec@(1,3) (82.3%, 99.1%), ce_loss 0.844, lat_loss 6.681
09/19 05:22:18 AM | Train: [ 70/180] Step 1100/1249 Loss 0.695 Prec@(1,3) (82.3%, 99.1%), ce_loss 0.843, lat_loss 6.681
09/19 05:22:34 AM | Train: [ 70/180] Step 1150/1249 Loss 0.695 Prec@(1,3) (82.3%, 99.1%), ce_loss 0.843, lat_loss 6.681
09/19 05:22:51 AM | Train: [ 70/180] Step 1200/1249 Loss 0.698 Prec@(1,3) (82.3%, 99.1%), ce_loss 0.843, lat_loss 6.681
09/19 05:23:07 AM | Train: [ 70/180] Step 1249/1249 Loss 0.696 Prec@(1,3) (82.3%, 99.1%), ce_loss 0.843, lat_loss 6.681
09/19 05:23:07 AM | _w_step_train: [ 70/180] Final Prec@1 82.3500% Time 451.04
09/19 05:23:07 AM | Start to train theta for epoch 69
09/19 05:23:27 AM | Train: [ 70/180] Step 050/312 Loss 0.742 Prec@(1,3) (81.8%, 98.7%), ce_loss 0.843, lat_loss 6.681
09/19 05:23:48 AM | Train: [ 70/180] Step 100/312 Loss 0.745 Prec@(1,3) (82.0%, 98.6%), ce_loss 0.843, lat_loss 6.681
09/19 05:24:09 AM | Train: [ 70/180] Step 150/312 Loss 0.759 Prec@(1,3) (81.0%, 98.6%), ce_loss 0.843, lat_loss 6.681
09/19 05:24:28 AM | Train: [ 70/180] Step 200/312 Loss 0.756 Prec@(1,3) (81.4%, 98.6%), ce_loss 0.843, lat_loss 6.681
09/19 05:24:48 AM | Train: [ 70/180] Step 250/312 Loss 0.763 Prec@(1,3) (81.2%, 98.6%), ce_loss 0.843, lat_loss 6.681
09/19 05:25:08 AM | Train: [ 70/180] Step 300/312 Loss 0.764 Prec@(1,3) (81.1%, 98.6%), ce_loss 0.842, lat_loss 6.681
09/19 05:25:13 AM | Train: [ 70/180] Step 312/312 Loss 0.777 Prec@(1,3) (80.8%, 98.6%), ce_loss 0.842, lat_loss 6.681
09/19 05:25:13 AM | _theta_step_train: [ 70/180] Final Prec@1 80.7700% Time 126.07
09/19 05:25:19 AM | Valid: [ 70/180] Step 050/312 Loss 0.862 Prec@(1,3) (80.7%, 98.6%), ce_loss 0.842, lat_loss 6.681
09/19 05:25:23 AM | Valid: [ 70/180] Step 100/312 Loss 0.878 Prec@(1,3) (80.4%, 98.5%), ce_loss 0.842, lat_loss 6.681
09/19 05:25:28 AM | Valid: [ 70/180] Step 150/312 Loss 0.876 Prec@(1,3) (80.5%, 98.4%), ce_loss 0.842, lat_loss 6.681
09/19 05:25:33 AM | Valid: [ 70/180] Step 200/312 Loss 0.922 Prec@(1,3) (79.8%, 98.2%), ce_loss 0.842, lat_loss 6.681
09/19 05:25:37 AM | Valid: [ 70/180] Step 250/312 Loss 0.890 Prec@(1,3) (79.9%, 98.4%), ce_loss 0.842, lat_loss 6.681
09/19 05:25:42 AM | Valid: [ 70/180] Step 300/312 Loss 0.880 Prec@(1,3) (80.1%, 98.6%), ce_loss 0.842, lat_loss 6.681
09/19 05:25:43 AM | Valid: [ 70/180] Step 312/312 Loss 0.877 Prec@(1,3) (80.1%, 98.6%), ce_loss 0.842, lat_loss 6.681
09/19 05:25:43 AM | val: [ 70/180] Final Prec@1 80.1000% Time 29.71
09/19 05:25:43 AM | Start to train weights for epoch 70
09/19 05:26:08 AM | Train: [ 71/180] Step 050/1249 Loss 0.645 Prec@(1,3) (83.1%, 99.2%), ce_loss 0.842, lat_loss 6.681
09/19 05:26:29 AM | Train: [ 71/180] Step 100/1249 Loss 0.638 Prec@(1,3) (83.8%, 99.2%), ce_loss 0.842, lat_loss 6.681
09/19 05:26:50 AM | Train: [ 71/180] Step 150/1249 Loss 0.652 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.842, lat_loss 6.681
09/19 05:27:11 AM | Train: [ 71/180] Step 200/1249 Loss 0.652 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.841, lat_loss 6.681
09/19 05:27:32 AM | Train: [ 71/180] Step 250/1249 Loss 0.662 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.841, lat_loss 6.681
09/19 05:27:53 AM | Train: [ 71/180] Step 300/1249 Loss 0.662 Prec@(1,3) (83.1%, 99.2%), ce_loss 0.841, lat_loss 6.681
09/19 05:28:14 AM | Train: [ 71/180] Step 350/1249 Loss 0.662 Prec@(1,3) (83.3%, 99.2%), ce_loss 0.841, lat_loss 6.681
09/19 05:28:36 AM | Train: [ 71/180] Step 400/1249 Loss 0.665 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.841, lat_loss 6.681
09/19 05:29:01 AM | Train: [ 71/180] Step 450/1249 Loss 0.684 Prec@(1,3) (82.8%, 99.1%), ce_loss 0.841, lat_loss 6.681
09/19 05:29:26 AM | Train: [ 71/180] Step 500/1249 Loss 0.683 Prec@(1,3) (82.8%, 99.0%), ce_loss 0.841, lat_loss 6.681
09/19 05:29:51 AM | Train: [ 71/180] Step 550/1249 Loss 0.686 Prec@(1,3) (82.7%, 99.0%), ce_loss 0.841, lat_loss 6.681
09/19 05:30:16 AM | Train: [ 71/180] Step 600/1249 Loss 0.691 Prec@(1,3) (82.4%, 99.1%), ce_loss 0.840, lat_loss 6.681
09/19 05:30:41 AM | Train: [ 71/180] Step 650/1249 Loss 0.687 Prec@(1,3) (82.5%, 99.1%), ce_loss 0.840, lat_loss 6.681
09/19 05:31:06 AM | Train: [ 71/180] Step 700/1249 Loss 0.685 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.840, lat_loss 6.681
09/19 05:31:31 AM | Train: [ 71/180] Step 750/1249 Loss 0.688 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.840, lat_loss 6.681
09/19 05:31:56 AM | Train: [ 71/180] Step 800/1249 Loss 0.688 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.840, lat_loss 6.681
09/19 05:32:21 AM | Train: [ 71/180] Step 850/1249 Loss 0.686 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.840, lat_loss 6.682
09/19 05:32:46 AM | Train: [ 71/180] Step 900/1249 Loss 0.690 Prec@(1,3) (82.6%, 99.0%), ce_loss 0.840, lat_loss 6.682
09/19 05:33:11 AM | Train: [ 71/180] Step 950/1249 Loss 0.692 Prec@(1,3) (82.5%, 99.0%), ce_loss 0.840, lat_loss 6.682
09/19 05:33:36 AM | Train: [ 71/180] Step 1000/1249 Loss 0.690 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.839, lat_loss 6.682
09/19 05:34:01 AM | Train: [ 71/180] Step 1050/1249 Loss 0.689 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.839, lat_loss 6.682
09/19 05:34:26 AM | Train: [ 71/180] Step 1100/1249 Loss 0.689 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.839, lat_loss 6.682
09/19 05:34:51 AM | Train: [ 71/180] Step 1150/1249 Loss 0.691 Prec@(1,3) (82.5%, 99.1%), ce_loss 0.839, lat_loss 6.682
09/19 05:35:15 AM | Train: [ 71/180] Step 1200/1249 Loss 0.690 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.839, lat_loss 6.682
09/19 05:35:40 AM | Train: [ 71/180] Step 1249/1249 Loss 0.687 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.839, lat_loss 6.682
09/19 05:35:40 AM | _w_step_train: [ 71/180] Final Prec@1 82.6450% Time 596.48
09/19 05:35:40 AM | Start to train theta for epoch 70
09/19 05:36:01 AM | Train: [ 71/180] Step 050/312 Loss 0.766 Prec@(1,3) (81.2%, 98.8%), ce_loss 0.839, lat_loss 6.682
09/19 05:36:20 AM | Train: [ 71/180] Step 100/312 Loss 0.778 Prec@(1,3) (81.4%, 98.7%), ce_loss 0.839, lat_loss 6.682
09/19 05:36:40 AM | Train: [ 71/180] Step 150/312 Loss 0.773 Prec@(1,3) (81.0%, 98.7%), ce_loss 0.838, lat_loss 6.682
09/19 05:36:59 AM | Train: [ 71/180] Step 200/312 Loss 0.760 Prec@(1,3) (81.2%, 98.9%), ce_loss 0.838, lat_loss 6.682
09/19 05:37:19 AM | Train: [ 71/180] Step 250/312 Loss 0.766 Prec@(1,3) (81.2%, 98.8%), ce_loss 0.838, lat_loss 6.682
09/19 05:37:39 AM | Train: [ 71/180] Step 300/312 Loss 0.769 Prec@(1,3) (81.1%, 98.8%), ce_loss 0.838, lat_loss 6.682
09/19 05:37:44 AM | Train: [ 71/180] Step 312/312 Loss 0.769 Prec@(1,3) (81.0%, 98.8%), ce_loss 0.838, lat_loss 6.682
09/19 05:37:44 AM | _theta_step_train: [ 71/180] Final Prec@1 81.0300% Time 123.96
09/19 05:37:49 AM | Valid: [ 71/180] Step 050/312 Loss 0.901 Prec@(1,3) (78.0%, 97.2%), ce_loss 0.838, lat_loss 6.682
09/19 05:37:54 AM | Valid: [ 71/180] Step 100/312 Loss 0.865 Prec@(1,3) (79.2%, 97.7%), ce_loss 0.838, lat_loss 6.682
09/19 05:37:58 AM | Valid: [ 71/180] Step 150/312 Loss 0.845 Prec@(1,3) (79.6%, 98.0%), ce_loss 0.838, lat_loss 6.682
09/19 05:38:03 AM | Valid: [ 71/180] Step 200/312 Loss 0.844 Prec@(1,3) (79.4%, 98.0%), ce_loss 0.838, lat_loss 6.682
09/19 05:38:08 AM | Valid: [ 71/180] Step 250/312 Loss 0.854 Prec@(1,3) (79.2%, 97.9%), ce_loss 0.838, lat_loss 6.682
09/19 05:38:12 AM | Valid: [ 71/180] Step 300/312 Loss 0.832 Prec@(1,3) (79.9%, 98.0%), ce_loss 0.838, lat_loss 6.682
09/19 05:38:14 AM | Valid: [ 71/180] Step 312/312 Loss 0.836 Prec@(1,3) (79.7%, 98.1%), ce_loss 0.838, lat_loss 6.682
09/19 05:38:14 AM | val: [ 71/180] Final Prec@1 79.6700% Time 30.04
09/19 05:38:14 AM | Start to train weights for epoch 71
09/19 05:38:37 AM | Train: [ 72/180] Step 050/1249 Loss 0.684 Prec@(1,3) (83.5%, 99.3%), ce_loss 0.837, lat_loss 6.682
09/19 05:38:58 AM | Train: [ 72/180] Step 100/1249 Loss 0.682 Prec@(1,3) (83.3%, 99.2%), ce_loss 0.837, lat_loss 6.682
09/19 05:39:22 AM | Train: [ 72/180] Step 150/1249 Loss 0.670 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.837, lat_loss 6.682
09/19 05:39:45 AM | Train: [ 72/180] Step 200/1249 Loss 0.682 Prec@(1,3) (82.8%, 99.2%), ce_loss 0.837, lat_loss 6.682
09/19 05:40:05 AM | Train: [ 72/180] Step 250/1249 Loss 0.683 Prec@(1,3) (82.9%, 99.2%), ce_loss 0.837, lat_loss 6.682
09/19 05:40:27 AM | Train: [ 72/180] Step 300/1249 Loss 0.673 Prec@(1,3) (83.1%, 99.2%), ce_loss 0.837, lat_loss 6.682
09/19 05:40:49 AM | Train: [ 72/180] Step 350/1249 Loss 0.677 Prec@(1,3) (83.0%, 99.2%), ce_loss 0.837, lat_loss 6.682
09/19 05:41:12 AM | Train: [ 72/180] Step 400/1249 Loss 0.673 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.837, lat_loss 6.682
09/19 05:41:34 AM | Train: [ 72/180] Step 450/1249 Loss 0.672 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.836, lat_loss 6.682
09/19 05:41:57 AM | Train: [ 72/180] Step 500/1249 Loss 0.676 Prec@(1,3) (83.1%, 99.2%), ce_loss 0.836, lat_loss 6.682
09/19 05:42:20 AM | Train: [ 72/180] Step 550/1249 Loss 0.677 Prec@(1,3) (83.1%, 99.2%), ce_loss 0.836, lat_loss 6.682
09/19 05:42:43 AM | Train: [ 72/180] Step 600/1249 Loss 0.676 Prec@(1,3) (83.1%, 99.2%), ce_loss 0.836, lat_loss 6.682
09/19 05:43:05 AM | Train: [ 72/180] Step 650/1249 Loss 0.682 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.836, lat_loss 6.682
09/19 05:43:28 AM | Train: [ 72/180] Step 700/1249 Loss 0.682 Prec@(1,3) (82.9%, 99.1%), ce_loss 0.836, lat_loss 6.682
09/19 05:43:51 AM | Train: [ 72/180] Step 750/1249 Loss 0.680 Prec@(1,3) (82.9%, 99.2%), ce_loss 0.836, lat_loss 6.682
09/19 05:44:14 AM | Train: [ 72/180] Step 800/1249 Loss 0.679 Prec@(1,3) (83.0%, 99.2%), ce_loss 0.835, lat_loss 6.682
09/19 05:44:35 AM | Train: [ 72/180] Step 850/1249 Loss 0.680 Prec@(1,3) (82.8%, 99.2%), ce_loss 0.835, lat_loss 6.682
09/19 05:44:57 AM | Train: [ 72/180] Step 900/1249 Loss 0.687 Prec@(1,3) (82.7%, 99.1%), ce_loss 0.835, lat_loss 6.682
09/19 05:45:21 AM | Train: [ 72/180] Step 950/1249 Loss 0.686 Prec@(1,3) (82.7%, 99.1%), ce_loss 0.835, lat_loss 6.682
09/19 05:45:45 AM | Train: [ 72/180] Step 1000/1249 Loss 0.684 Prec@(1,3) (82.8%, 99.2%), ce_loss 0.835, lat_loss 6.682
09/19 05:46:09 AM | Train: [ 72/180] Step 1050/1249 Loss 0.687 Prec@(1,3) (82.7%, 99.1%), ce_loss 0.835, lat_loss 6.682
09/19 05:46:34 AM | Train: [ 72/180] Step 1100/1249 Loss 0.688 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.835, lat_loss 6.682
09/19 05:46:58 AM | Train: [ 72/180] Step 1150/1249 Loss 0.686 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.835, lat_loss 6.682
09/19 05:47:20 AM | Train: [ 72/180] Step 1200/1249 Loss 0.686 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.835, lat_loss 6.682
09/19 05:47:45 AM | Train: [ 72/180] Step 1249/1249 Loss 0.685 Prec@(1,3) (82.7%, 99.1%), ce_loss 0.834, lat_loss 6.682
09/19 05:47:45 AM | _w_step_train: [ 72/180] Final Prec@1 82.6600% Time 571.18
09/19 05:47:45 AM | Start to train theta for epoch 71
09/19 05:48:06 AM | Train: [ 72/180] Step 050/312 Loss 0.809 Prec@(1,3) (80.4%, 99.2%), ce_loss 0.834, lat_loss 6.682
09/19 05:48:27 AM | Train: [ 72/180] Step 100/312 Loss 0.793 Prec@(1,3) (80.8%, 98.9%), ce_loss 0.834, lat_loss 6.682
09/19 05:48:48 AM | Train: [ 72/180] Step 150/312 Loss 0.804 Prec@(1,3) (80.4%, 98.8%), ce_loss 0.834, lat_loss 6.682
09/19 05:49:08 AM | Train: [ 72/180] Step 200/312 Loss 0.803 Prec@(1,3) (80.3%, 98.8%), ce_loss 0.834, lat_loss 6.682
09/19 05:49:29 AM | Train: [ 72/180] Step 250/312 Loss 0.803 Prec@(1,3) (80.2%, 98.7%), ce_loss 0.834, lat_loss 6.682
09/19 05:49:50 AM | Train: [ 72/180] Step 300/312 Loss 0.792 Prec@(1,3) (80.5%, 98.8%), ce_loss 0.834, lat_loss 6.682
09/19 05:49:55 AM | Train: [ 72/180] Step 312/312 Loss 0.789 Prec@(1,3) (80.5%, 98.8%), ce_loss 0.834, lat_loss 6.682
09/19 05:49:55 AM | _theta_step_train: [ 72/180] Final Prec@1 80.5200% Time 129.94
09/19 05:50:01 AM | Valid: [ 72/180] Step 050/312 Loss 0.815 Prec@(1,3) (81.0%, 98.2%), ce_loss 0.834, lat_loss 6.682
09/19 05:50:05 AM | Valid: [ 72/180] Step 100/312 Loss 0.914 Prec@(1,3) (78.6%, 97.5%), ce_loss 0.834, lat_loss 6.682
09/19 05:50:10 AM | Valid: [ 72/180] Step 150/312 Loss 0.863 Prec@(1,3) (79.3%, 97.8%), ce_loss 0.834, lat_loss 6.682
09/19 05:50:15 AM | Valid: [ 72/180] Step 200/312 Loss 0.907 Prec@(1,3) (78.9%, 97.5%), ce_loss 0.834, lat_loss 6.682
09/19 05:50:19 AM | Valid: [ 72/180] Step 250/312 Loss 0.889 Prec@(1,3) (79.2%, 97.6%), ce_loss 0.833, lat_loss 6.682
09/19 05:50:24 AM | Valid: [ 72/180] Step 300/312 Loss 0.873 Prec@(1,3) (79.5%, 97.8%), ce_loss 0.833, lat_loss 6.682
09/19 05:50:25 AM | Valid: [ 72/180] Step 312/312 Loss 0.871 Prec@(1,3) (79.5%, 97.9%), ce_loss 0.833, lat_loss 6.682
09/19 05:50:25 AM | val: [ 72/180] Final Prec@1 79.4500% Time 29.65
09/19 05:50:25 AM | Start to train weights for epoch 72
09/19 05:50:51 AM | Train: [ 73/180] Step 050/1249 Loss 0.683 Prec@(1,3) (82.8%, 99.0%), ce_loss 0.833, lat_loss 6.682
09/19 05:51:15 AM | Train: [ 73/180] Step 100/1249 Loss 0.671 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.833, lat_loss 6.682
09/19 05:51:40 AM | Train: [ 73/180] Step 150/1249 Loss 0.666 Prec@(1,3) (83.5%, 99.0%), ce_loss 0.833, lat_loss 6.682
09/19 05:52:05 AM | Train: [ 73/180] Step 200/1249 Loss 0.671 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.833, lat_loss 6.682
09/19 05:52:29 AM | Train: [ 73/180] Step 250/1249 Loss 0.675 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.833, lat_loss 6.682
09/19 05:52:54 AM | Train: [ 73/180] Step 300/1249 Loss 0.670 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.833, lat_loss 6.682
09/19 05:53:18 AM | Train: [ 73/180] Step 350/1249 Loss 0.677 Prec@(1,3) (82.8%, 99.0%), ce_loss 0.832, lat_loss 6.682
09/19 05:53:42 AM | Train: [ 73/180] Step 400/1249 Loss 0.682 Prec@(1,3) (82.8%, 98.9%), ce_loss 0.832, lat_loss 6.682
09/19 05:54:06 AM | Train: [ 73/180] Step 450/1249 Loss 0.680 Prec@(1,3) (82.7%, 98.9%), ce_loss 0.832, lat_loss 6.682
09/19 05:54:30 AM | Train: [ 73/180] Step 500/1249 Loss 0.680 Prec@(1,3) (82.6%, 99.0%), ce_loss 0.832, lat_loss 6.682
09/19 05:54:54 AM | Train: [ 73/180] Step 550/1249 Loss 0.676 Prec@(1,3) (82.7%, 99.0%), ce_loss 0.832, lat_loss 6.682
09/19 05:55:18 AM | Train: [ 73/180] Step 600/1249 Loss 0.671 Prec@(1,3) (82.8%, 99.0%), ce_loss 0.832, lat_loss 6.682
09/19 05:55:43 AM | Train: [ 73/180] Step 650/1249 Loss 0.672 Prec@(1,3) (82.8%, 99.0%), ce_loss 0.832, lat_loss 6.682
09/19 05:56:08 AM | Train: [ 73/180] Step 700/1249 Loss 0.668 Prec@(1,3) (82.9%, 99.0%), ce_loss 0.832, lat_loss 6.682
09/19 05:56:33 AM | Train: [ 73/180] Step 750/1249 Loss 0.667 Prec@(1,3) (82.9%, 99.1%), ce_loss 0.831, lat_loss 6.682
09/19 05:56:58 AM | Train: [ 73/180] Step 800/1249 Loss 0.668 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.831, lat_loss 6.682
09/19 05:57:22 AM | Train: [ 73/180] Step 850/1249 Loss 0.665 Prec@(1,3) (83.1%, 99.1%), ce_loss 0.831, lat_loss 6.682
09/19 05:57:47 AM | Train: [ 73/180] Step 900/1249 Loss 0.664 Prec@(1,3) (83.1%, 99.1%), ce_loss 0.831, lat_loss 6.682
09/19 05:58:11 AM | Train: [ 73/180] Step 950/1249 Loss 0.669 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.831, lat_loss 6.682
09/19 05:58:36 AM | Train: [ 73/180] Step 1000/1249 Loss 0.672 Prec@(1,3) (82.9%, 99.1%), ce_loss 0.831, lat_loss 6.682
09/19 05:59:01 AM | Train: [ 73/180] Step 1050/1249 Loss 0.676 Prec@(1,3) (82.8%, 99.1%), ce_loss 0.831, lat_loss 6.682
09/19 05:59:26 AM | Train: [ 73/180] Step 1100/1249 Loss 0.677 Prec@(1,3) (82.8%, 99.1%), ce_loss 0.831, lat_loss 6.682
09/19 05:59:50 AM | Train: [ 73/180] Step 1150/1249 Loss 0.673 Prec@(1,3) (82.9%, 99.1%), ce_loss 0.830, lat_loss 6.682
09/19 06:00:14 AM | Train: [ 73/180] Step 1200/1249 Loss 0.676 Prec@(1,3) (82.9%, 99.1%), ce_loss 0.830, lat_loss 6.682
09/19 06:00:39 AM | Train: [ 73/180] Step 1249/1249 Loss 0.677 Prec@(1,3) (82.8%, 99.1%), ce_loss 0.830, lat_loss 6.682
09/19 06:00:39 AM | _w_step_train: [ 73/180] Final Prec@1 82.8225% Time 614.05
09/19 06:00:39 AM | Start to train theta for epoch 72
09/19 06:01:00 AM | Train: [ 73/180] Step 050/312 Loss 0.765 Prec@(1,3) (80.0%, 98.5%), ce_loss 0.830, lat_loss 6.682
09/19 06:01:20 AM | Train: [ 73/180] Step 100/312 Loss 0.760 Prec@(1,3) (80.3%, 98.8%), ce_loss 0.830, lat_loss 6.682
09/19 06:01:41 AM | Train: [ 73/180] Step 150/312 Loss 0.741 Prec@(1,3) (80.9%, 98.8%), ce_loss 0.830, lat_loss 6.682
09/19 06:02:02 AM | Train: [ 73/180] Step 200/312 Loss 0.752 Prec@(1,3) (80.5%, 98.8%), ce_loss 0.830, lat_loss 6.682
09/19 06:02:22 AM | Train: [ 73/180] Step 250/312 Loss 0.752 Prec@(1,3) (80.4%, 98.7%), ce_loss 0.830, lat_loss 6.682
09/19 06:02:43 AM | Train: [ 73/180] Step 300/312 Loss 0.753 Prec@(1,3) (80.5%, 98.7%), ce_loss 0.830, lat_loss 6.682
09/19 06:02:48 AM | Train: [ 73/180] Step 312/312 Loss 0.753 Prec@(1,3) (80.5%, 98.7%), ce_loss 0.830, lat_loss 6.682
09/19 06:02:48 AM | _theta_step_train: [ 73/180] Final Prec@1 80.5100% Time 129.22
09/19 06:02:53 AM | Valid: [ 73/180] Step 050/312 Loss 0.745 Prec@(1,3) (81.2%, 99.1%), ce_loss 0.829, lat_loss 6.682
09/19 06:02:57 AM | Valid: [ 73/180] Step 100/312 Loss 0.787 Prec@(1,3) (81.1%, 98.7%), ce_loss 0.829, lat_loss 6.682
09/19 06:03:02 AM | Valid: [ 73/180] Step 150/312 Loss 0.795 Prec@(1,3) (81.1%, 98.6%), ce_loss 0.829, lat_loss 6.682
09/19 06:03:06 AM | Valid: [ 73/180] Step 200/312 Loss 0.790 Prec@(1,3) (81.1%, 98.7%), ce_loss 0.829, lat_loss 6.682
09/19 06:03:10 AM | Valid: [ 73/180] Step 250/312 Loss 0.793 Prec@(1,3) (81.1%, 98.6%), ce_loss 0.829, lat_loss 6.682
09/19 06:03:14 AM | Valid: [ 73/180] Step 300/312 Loss 0.777 Prec@(1,3) (81.3%, 98.7%), ce_loss 0.829, lat_loss 6.682
09/19 06:03:15 AM | Valid: [ 73/180] Step 312/312 Loss 0.792 Prec@(1,3) (81.0%, 98.6%), ce_loss 0.829, lat_loss 6.682
09/19 06:03:15 AM | val: [ 73/180] Final Prec@1 80.9900% Time 26.97
09/19 06:03:15 AM | Best top1 acc by now. Save model
09/19 06:03:15 AM | Start to train weights for epoch 73
09/19 06:03:41 AM | Train: [ 74/180] Step 050/1249 Loss 0.664 Prec@(1,3) (84.4%, 98.8%), ce_loss 0.829, lat_loss 6.682
09/19 06:04:06 AM | Train: [ 74/180] Step 100/1249 Loss 0.657 Prec@(1,3) (83.4%, 99.0%), ce_loss 0.829, lat_loss 6.682
09/19 06:04:31 AM | Train: [ 74/180] Step 150/1249 Loss 0.656 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.829, lat_loss 6.682
09/19 06:04:55 AM | Train: [ 74/180] Step 200/1249 Loss 0.647 Prec@(1,3) (83.9%, 99.2%), ce_loss 0.828, lat_loss 6.682
09/19 06:05:21 AM | Train: [ 74/180] Step 250/1249 Loss 0.638 Prec@(1,3) (84.0%, 99.3%), ce_loss 0.828, lat_loss 6.682
09/19 06:05:45 AM | Train: [ 74/180] Step 300/1249 Loss 0.645 Prec@(1,3) (83.8%, 99.2%), ce_loss 0.828, lat_loss 6.682
09/19 06:06:10 AM | Train: [ 74/180] Step 350/1249 Loss 0.649 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.828, lat_loss 6.682
09/19 06:06:35 AM | Train: [ 74/180] Step 400/1249 Loss 0.650 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.828, lat_loss 6.682
09/19 06:07:00 AM | Train: [ 74/180] Step 450/1249 Loss 0.653 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.828, lat_loss 6.682
09/19 06:07:25 AM | Train: [ 74/180] Step 500/1249 Loss 0.658 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.828, lat_loss 6.682
09/19 06:07:49 AM | Train: [ 74/180] Step 550/1249 Loss 0.664 Prec@(1,3) (83.2%, 99.0%), ce_loss 0.828, lat_loss 6.682
09/19 06:08:14 AM | Train: [ 74/180] Step 600/1249 Loss 0.660 Prec@(1,3) (83.3%, 99.0%), ce_loss 0.827, lat_loss 6.682
09/19 06:08:39 AM | Train: [ 74/180] Step 650/1249 Loss 0.660 Prec@(1,3) (83.3%, 99.0%), ce_loss 0.827, lat_loss 6.682
09/19 06:09:03 AM | Train: [ 74/180] Step 700/1249 Loss 0.666 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.827, lat_loss 6.682
09/19 06:09:27 AM | Train: [ 74/180] Step 750/1249 Loss 0.669 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.827, lat_loss 6.682
09/19 06:09:52 AM | Train: [ 74/180] Step 800/1249 Loss 0.666 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.827, lat_loss 6.682
09/19 06:10:16 AM | Train: [ 74/180] Step 850/1249 Loss 0.667 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.827, lat_loss 6.682
09/19 06:10:40 AM | Train: [ 74/180] Step 900/1249 Loss 0.666 Prec@(1,3) (83.1%, 99.1%), ce_loss 0.827, lat_loss 6.682
09/19 06:11:05 AM | Train: [ 74/180] Step 950/1249 Loss 0.667 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.827, lat_loss 6.682
09/19 06:11:29 AM | Train: [ 74/180] Step 1000/1249 Loss 0.664 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.826, lat_loss 6.682
09/19 06:11:53 AM | Train: [ 74/180] Step 1050/1249 Loss 0.664 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.826, lat_loss 6.682
09/19 06:12:16 AM | Train: [ 74/180] Step 1100/1249 Loss 0.661 Prec@(1,3) (83.1%, 99.1%), ce_loss 0.826, lat_loss 6.682
09/19 06:12:41 AM | Train: [ 74/180] Step 1150/1249 Loss 0.661 Prec@(1,3) (83.1%, 99.1%), ce_loss 0.826, lat_loss 6.682
09/19 06:13:05 AM | Train: [ 74/180] Step 1200/1249 Loss 0.662 Prec@(1,3) (83.1%, 99.1%), ce_loss 0.826, lat_loss 6.682
09/19 06:13:29 AM | Train: [ 74/180] Step 1249/1249 Loss 0.667 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.826, lat_loss 6.682
09/19 06:13:30 AM | _w_step_train: [ 74/180] Final Prec@1 83.0250% Time 614.19
09/19 06:13:30 AM | Start to train theta for epoch 73
09/19 06:13:51 AM | Train: [ 74/180] Step 050/312 Loss 0.814 Prec@(1,3) (79.4%, 98.5%), ce_loss 0.826, lat_loss 6.682
09/19 06:14:07 AM | Train: [ 74/180] Step 100/312 Loss 0.769 Prec@(1,3) (80.7%, 98.6%), ce_loss 0.826, lat_loss 6.682
09/19 06:14:20 AM | Train: [ 74/180] Step 150/312 Loss 0.770 Prec@(1,3) (80.6%, 98.7%), ce_loss 0.826, lat_loss 6.682
09/19 06:14:32 AM | Train: [ 74/180] Step 200/312 Loss 0.770 Prec@(1,3) (80.8%, 98.6%), ce_loss 0.825, lat_loss 6.682
09/19 06:14:44 AM | Train: [ 74/180] Step 250/312 Loss 0.781 Prec@(1,3) (80.6%, 98.5%), ce_loss 0.825, lat_loss 6.682
09/19 06:14:56 AM | Train: [ 74/180] Step 300/312 Loss 0.787 Prec@(1,3) (80.4%, 98.5%), ce_loss 0.825, lat_loss 6.682
09/19 06:14:59 AM | Train: [ 74/180] Step 312/312 Loss 0.784 Prec@(1,3) (80.4%, 98.5%), ce_loss 0.825, lat_loss 6.682
09/19 06:14:59 AM | _theta_step_train: [ 74/180] Final Prec@1 80.4400% Time 89.72
09/19 06:15:05 AM | Valid: [ 74/180] Step 050/312 Loss 0.730 Prec@(1,3) (82.8%, 99.3%), ce_loss 0.825, lat_loss 6.682
09/19 06:15:09 AM | Valid: [ 74/180] Step 100/312 Loss 0.751 Prec@(1,3) (81.4%, 99.0%), ce_loss 0.825, lat_loss 6.682
09/19 06:15:14 AM | Valid: [ 74/180] Step 150/312 Loss 0.803 Prec@(1,3) (80.6%, 98.3%), ce_loss 0.825, lat_loss 6.682
09/19 06:15:18 AM | Valid: [ 74/180] Step 200/312 Loss 0.820 Prec@(1,3) (80.2%, 98.3%), ce_loss 0.825, lat_loss 6.682
09/19 06:15:23 AM | Valid: [ 74/180] Step 250/312 Loss 0.807 Prec@(1,3) (80.4%, 98.5%), ce_loss 0.825, lat_loss 6.682
09/19 06:15:28 AM | Valid: [ 74/180] Step 300/312 Loss 0.795 Prec@(1,3) (80.8%, 98.5%), ce_loss 0.825, lat_loss 6.682
09/19 06:15:29 AM | Valid: [ 74/180] Step 312/312 Loss 0.791 Prec@(1,3) (80.8%, 98.5%), ce_loss 0.825, lat_loss 6.682
09/19 06:15:29 AM | val: [ 74/180] Final Prec@1 80.8000% Time 29.52
09/19 06:15:29 AM | Start to train weights for epoch 74
09/19 06:15:55 AM | Train: [ 75/180] Step 050/1249 Loss 0.705 Prec@(1,3) (81.6%, 99.3%), ce_loss 0.825, lat_loss 6.682
09/19 06:16:19 AM | Train: [ 75/180] Step 100/1249 Loss 0.718 Prec@(1,3) (82.1%, 98.9%), ce_loss 0.825, lat_loss 6.682
09/19 06:16:44 AM | Train: [ 75/180] Step 150/1249 Loss 0.666 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.824, lat_loss 6.682
09/19 06:17:09 AM | Train: [ 75/180] Step 200/1249 Loss 0.659 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.824, lat_loss 6.682
09/19 06:17:33 AM | Train: [ 75/180] Step 250/1249 Loss 0.650 Prec@(1,3) (83.7%, 99.2%), ce_loss 0.824, lat_loss 6.682
09/19 06:17:58 AM | Train: [ 75/180] Step 300/1249 Loss 0.650 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.824, lat_loss 6.682
09/19 06:18:22 AM | Train: [ 75/180] Step 350/1249 Loss 0.651 Prec@(1,3) (83.4%, 99.2%), ce_loss 0.824, lat_loss 6.682
09/19 06:18:47 AM | Train: [ 75/180] Step 400/1249 Loss 0.644 Prec@(1,3) (83.7%, 99.3%), ce_loss 0.824, lat_loss 6.682
09/19 06:19:11 AM | Train: [ 75/180] Step 450/1249 Loss 0.642 Prec@(1,3) (83.6%, 99.3%), ce_loss 0.824, lat_loss 6.682
09/19 06:19:35 AM | Train: [ 75/180] Step 500/1249 Loss 0.648 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.823, lat_loss 6.682
09/19 06:20:00 AM | Train: [ 75/180] Step 550/1249 Loss 0.649 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.823, lat_loss 6.682
09/19 06:20:18 AM | Train: [ 75/180] Step 600/1249 Loss 0.652 Prec@(1,3) (83.4%, 99.2%), ce_loss 0.823, lat_loss 6.682
09/19 06:20:34 AM | Train: [ 75/180] Step 650/1249 Loss 0.650 Prec@(1,3) (83.4%, 99.2%), ce_loss 0.823, lat_loss 6.682
09/19 06:20:50 AM | Train: [ 75/180] Step 700/1249 Loss 0.653 Prec@(1,3) (83.4%, 99.2%), ce_loss 0.823, lat_loss 6.682
09/19 06:21:06 AM | Train: [ 75/180] Step 750/1249 Loss 0.650 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.823, lat_loss 6.682
09/19 06:21:22 AM | Train: [ 75/180] Step 800/1249 Loss 0.648 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.823, lat_loss 6.682
09/19 06:21:38 AM | Train: [ 75/180] Step 850/1249 Loss 0.651 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.823, lat_loss 6.682
09/19 06:21:54 AM | Train: [ 75/180] Step 900/1249 Loss 0.650 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.822, lat_loss 6.682
09/19 06:22:10 AM | Train: [ 75/180] Step 950/1249 Loss 0.649 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.822, lat_loss 6.682
09/19 06:22:26 AM | Train: [ 75/180] Step 1000/1249 Loss 0.651 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.822, lat_loss 6.682
09/19 06:22:42 AM | Train: [ 75/180] Step 1050/1249 Loss 0.648 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.822, lat_loss 6.682
09/19 06:22:58 AM | Train: [ 75/180] Step 1100/1249 Loss 0.653 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.822, lat_loss 6.682
09/19 06:23:14 AM | Train: [ 75/180] Step 1150/1249 Loss 0.653 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.822, lat_loss 6.682
09/19 06:23:30 AM | Train: [ 75/180] Step 1200/1249 Loss 0.654 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.822, lat_loss 6.682
09/19 06:23:46 AM | Train: [ 75/180] Step 1249/1249 Loss 0.652 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.822, lat_loss 6.682
09/19 06:23:46 AM | _w_step_train: [ 75/180] Final Prec@1 83.4800% Time 496.90
09/19 06:23:46 AM | Start to train theta for epoch 74
09/19 06:24:07 AM | Train: [ 75/180] Step 050/312 Loss 0.826 Prec@(1,3) (79.2%, 98.8%), ce_loss 0.822, lat_loss 6.682
09/19 06:24:27 AM | Train: [ 75/180] Step 100/312 Loss 0.781 Prec@(1,3) (80.3%, 98.5%), ce_loss 0.821, lat_loss 6.682
09/19 06:24:48 AM | Train: [ 75/180] Step 150/312 Loss 0.778 Prec@(1,3) (80.0%, 98.7%), ce_loss 0.821, lat_loss 6.682
09/19 06:25:08 AM | Train: [ 75/180] Step 200/312 Loss 0.761 Prec@(1,3) (80.6%, 98.7%), ce_loss 0.821, lat_loss 6.682
09/19 06:25:28 AM | Train: [ 75/180] Step 250/312 Loss 0.772 Prec@(1,3) (80.6%, 98.7%), ce_loss 0.821, lat_loss 6.682
09/19 06:25:49 AM | Train: [ 75/180] Step 300/312 Loss 0.775 Prec@(1,3) (80.5%, 98.6%), ce_loss 0.821, lat_loss 6.682
09/19 06:25:54 AM | Train: [ 75/180] Step 312/312 Loss 0.774 Prec@(1,3) (80.5%, 98.6%), ce_loss 0.821, lat_loss 6.682
09/19 06:25:54 AM | _theta_step_train: [ 75/180] Final Prec@1 80.4500% Time 128.50
09/19 06:26:00 AM | Valid: [ 75/180] Step 050/312 Loss 0.862 Prec@(1,3) (78.6%, 97.7%), ce_loss 0.821, lat_loss 6.682
09/19 06:26:04 AM | Valid: [ 75/180] Step 100/312 Loss 0.833 Prec@(1,3) (79.8%, 97.8%), ce_loss 0.821, lat_loss 6.682
09/19 06:26:09 AM | Valid: [ 75/180] Step 150/312 Loss 0.791 Prec@(1,3) (80.9%, 98.2%), ce_loss 0.821, lat_loss 6.682
09/19 06:26:13 AM | Valid: [ 75/180] Step 200/312 Loss 0.827 Prec@(1,3) (79.8%, 97.7%), ce_loss 0.821, lat_loss 6.682
09/19 06:26:18 AM | Valid: [ 75/180] Step 250/312 Loss 0.819 Prec@(1,3) (79.8%, 97.9%), ce_loss 0.821, lat_loss 6.682
09/19 06:26:23 AM | Valid: [ 75/180] Step 300/312 Loss 0.813 Prec@(1,3) (80.1%, 97.9%), ce_loss 0.821, lat_loss 6.682
09/19 06:26:24 AM | Valid: [ 75/180] Step 312/312 Loss 0.811 Prec@(1,3) (80.2%, 98.0%), ce_loss 0.821, lat_loss 6.682
09/19 06:26:24 AM | val: [ 75/180] Final Prec@1 80.1900% Time 29.49
09/19 06:26:24 AM | Start to train weights for epoch 75
09/19 06:26:50 AM | Train: [ 76/180] Step 050/1249 Loss 0.658 Prec@(1,3) (83.3%, 99.0%), ce_loss 0.820, lat_loss 6.682
09/19 06:27:15 AM | Train: [ 76/180] Step 100/1249 Loss 0.645 Prec@(1,3) (84.0%, 99.2%), ce_loss 0.820, lat_loss 6.682
09/19 06:27:40 AM | Train: [ 76/180] Step 150/1249 Loss 0.647 Prec@(1,3) (83.8%, 99.2%), ce_loss 0.820, lat_loss 6.682
09/19 06:28:05 AM | Train: [ 76/180] Step 200/1249 Loss 0.659 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.820, lat_loss 6.682
09/19 06:28:30 AM | Train: [ 76/180] Step 250/1249 Loss 0.662 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.820, lat_loss 6.682
09/19 06:28:55 AM | Train: [ 76/180] Step 300/1249 Loss 0.662 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.820, lat_loss 6.682
09/19 06:29:20 AM | Train: [ 76/180] Step 350/1249 Loss 0.662 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.820, lat_loss 6.682
09/19 06:29:45 AM | Train: [ 76/180] Step 400/1249 Loss 0.661 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.820, lat_loss 6.682
09/19 06:30:10 AM | Train: [ 76/180] Step 450/1249 Loss 0.654 Prec@(1,3) (83.4%, 99.2%), ce_loss 0.819, lat_loss 6.682
09/19 06:30:35 AM | Train: [ 76/180] Step 500/1249 Loss 0.652 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.819, lat_loss 6.682
09/19 06:31:00 AM | Train: [ 76/180] Step 550/1249 Loss 0.653 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.819, lat_loss 6.682
09/19 06:31:24 AM | Train: [ 76/180] Step 600/1249 Loss 0.652 Prec@(1,3) (83.7%, 99.2%), ce_loss 0.819, lat_loss 6.682
09/19 06:31:48 AM | Train: [ 76/180] Step 650/1249 Loss 0.657 Prec@(1,3) (83.6%, 99.1%), ce_loss 0.819, lat_loss 6.682
09/19 06:32:13 AM | Train: [ 76/180] Step 700/1249 Loss 0.654 Prec@(1,3) (83.6%, 99.1%), ce_loss 0.819, lat_loss 6.682
09/19 06:32:38 AM | Train: [ 76/180] Step 750/1249 Loss 0.652 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.819, lat_loss 6.682
09/19 06:33:03 AM | Train: [ 76/180] Step 800/1249 Loss 0.653 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.819, lat_loss 6.682
09/19 06:33:28 AM | Train: [ 76/180] Step 850/1249 Loss 0.653 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.818, lat_loss 6.682
09/19 06:33:53 AM | Train: [ 76/180] Step 900/1249 Loss 0.651 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.818, lat_loss 6.682
09/19 06:34:17 AM | Train: [ 76/180] Step 950/1249 Loss 0.648 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.818, lat_loss 6.682
09/19 06:34:42 AM | Train: [ 76/180] Step 1000/1249 Loss 0.647 Prec@(1,3) (83.7%, 99.2%), ce_loss 0.818, lat_loss 6.682
09/19 06:35:06 AM | Train: [ 76/180] Step 1050/1249 Loss 0.650 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.818, lat_loss 6.682
09/19 06:35:31 AM | Train: [ 76/180] Step 1100/1249 Loss 0.650 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.818, lat_loss 6.682
09/19 06:35:55 AM | Train: [ 76/180] Step 1150/1249 Loss 0.651 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.818, lat_loss 6.682
09/19 06:36:20 AM | Train: [ 76/180] Step 1200/1249 Loss 0.653 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.818, lat_loss 6.682
09/19 06:36:44 AM | Train: [ 76/180] Step 1249/1249 Loss 0.651 Prec@(1,3) (83.6%, 99.2%), ce_loss 0.817, lat_loss 6.682
09/19 06:36:44 AM | _w_step_train: [ 76/180] Final Prec@1 83.6250% Time 620.47
09/19 06:36:44 AM | Start to train theta for epoch 75
09/19 06:37:06 AM | Train: [ 76/180] Step 050/312 Loss 0.790 Prec@(1,3) (80.1%, 99.0%), ce_loss 0.817, lat_loss 6.682
09/19 06:37:27 AM | Train: [ 76/180] Step 100/312 Loss 0.791 Prec@(1,3) (80.6%, 98.9%), ce_loss 0.817, lat_loss 6.682
09/19 06:37:48 AM | Train: [ 76/180] Step 150/312 Loss 0.772 Prec@(1,3) (81.1%, 98.8%), ce_loss 0.817, lat_loss 6.682
09/19 06:38:09 AM | Train: [ 76/180] Step 200/312 Loss 0.779 Prec@(1,3) (80.7%, 98.7%), ce_loss 0.817, lat_loss 6.682
09/19 06:38:29 AM | Train: [ 76/180] Step 250/312 Loss 0.770 Prec@(1,3) (80.7%, 98.8%), ce_loss 0.817, lat_loss 6.682
09/19 06:38:50 AM | Train: [ 76/180] Step 300/312 Loss 0.749 Prec@(1,3) (81.3%, 98.9%), ce_loss 0.817, lat_loss 6.682
09/19 06:38:55 AM | Train: [ 76/180] Step 312/312 Loss 0.749 Prec@(1,3) (81.3%, 98.9%), ce_loss 0.817, lat_loss 6.682
09/19 06:38:55 AM | _theta_step_train: [ 76/180] Final Prec@1 81.2900% Time 130.85
09/19 06:39:00 AM | Valid: [ 76/180] Step 050/312 Loss 0.778 Prec@(1,3) (80.2%, 98.7%), ce_loss 0.817, lat_loss 6.682
09/19 06:39:05 AM | Valid: [ 76/180] Step 100/312 Loss 0.828 Prec@(1,3) (79.8%, 98.1%), ce_loss 0.817, lat_loss 6.682
09/19 06:39:10 AM | Valid: [ 76/180] Step 150/312 Loss 0.832 Prec@(1,3) (79.6%, 98.2%), ce_loss 0.817, lat_loss 6.682
09/19 06:39:14 AM | Valid: [ 76/180] Step 200/312 Loss 0.837 Prec@(1,3) (79.6%, 98.1%), ce_loss 0.817, lat_loss 6.682
09/19 06:39:19 AM | Valid: [ 76/180] Step 250/312 Loss 0.805 Prec@(1,3) (80.4%, 98.4%), ce_loss 0.816, lat_loss 6.682
09/19 06:39:23 AM | Valid: [ 76/180] Step 300/312 Loss 0.787 Prec@(1,3) (80.8%, 98.6%), ce_loss 0.816, lat_loss 6.682
09/19 06:39:25 AM | Valid: [ 76/180] Step 312/312 Loss 0.802 Prec@(1,3) (80.6%, 98.4%), ce_loss 0.816, lat_loss 6.682
09/19 06:39:25 AM | val: [ 76/180] Final Prec@1 80.6300% Time 29.49
09/19 06:39:25 AM | Start to train weights for epoch 76
09/19 06:39:49 AM | Train: [ 77/180] Step 050/1249 Loss 0.622 Prec@(1,3) (84.3%, 99.6%), ce_loss 0.816, lat_loss 6.682
09/19 06:40:11 AM | Train: [ 77/180] Step 100/1249 Loss 0.614 Prec@(1,3) (85.1%, 99.5%), ce_loss 0.816, lat_loss 6.682
09/19 06:40:33 AM | Train: [ 77/180] Step 150/1249 Loss 0.618 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.816, lat_loss 6.682
09/19 06:40:55 AM | Train: [ 77/180] Step 200/1249 Loss 0.614 Prec@(1,3) (84.5%, 99.3%), ce_loss 0.816, lat_loss 6.682
09/19 06:41:17 AM | Train: [ 77/180] Step 250/1249 Loss 0.610 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.816, lat_loss 6.682
09/19 06:41:38 AM | Train: [ 77/180] Step 300/1249 Loss 0.613 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.816, lat_loss 6.682
09/19 06:41:59 AM | Train: [ 77/180] Step 350/1249 Loss 0.611 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.815, lat_loss 6.682
09/19 06:42:20 AM | Train: [ 77/180] Step 400/1249 Loss 0.611 Prec@(1,3) (84.6%, 99.4%), ce_loss 0.815, lat_loss 6.682
09/19 06:42:43 AM | Train: [ 77/180] Step 450/1249 Loss 0.614 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.815, lat_loss 6.682
09/19 06:43:06 AM | Train: [ 77/180] Step 500/1249 Loss 0.617 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.815, lat_loss 6.682
09/19 06:43:27 AM | Train: [ 77/180] Step 550/1249 Loss 0.614 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.815, lat_loss 6.682
09/19 06:43:49 AM | Train: [ 77/180] Step 600/1249 Loss 0.614 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.815, lat_loss 6.682
09/19 06:44:11 AM | Train: [ 77/180] Step 650/1249 Loss 0.615 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.815, lat_loss 6.682
09/19 06:44:33 AM | Train: [ 77/180] Step 700/1249 Loss 0.615 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.815, lat_loss 6.682
09/19 06:44:56 AM | Train: [ 77/180] Step 750/1249 Loss 0.614 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.814, lat_loss 6.682
09/19 06:45:18 AM | Train: [ 77/180] Step 800/1249 Loss 0.615 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.814, lat_loss 6.682
09/19 06:45:40 AM | Train: [ 77/180] Step 850/1249 Loss 0.616 Prec@(1,3) (84.5%, 99.3%), ce_loss 0.814, lat_loss 6.682
09/19 06:46:01 AM | Train: [ 77/180] Step 900/1249 Loss 0.616 Prec@(1,3) (84.4%, 99.3%), ce_loss 0.814, lat_loss 6.682
09/19 06:46:23 AM | Train: [ 77/180] Step 950/1249 Loss 0.619 Prec@(1,3) (84.4%, 99.3%), ce_loss 0.814, lat_loss 6.682
09/19 06:46:45 AM | Train: [ 77/180] Step 1000/1249 Loss 0.617 Prec@(1,3) (84.4%, 99.3%), ce_loss 0.814, lat_loss 6.682
09/19 06:47:06 AM | Train: [ 77/180] Step 1050/1249 Loss 0.620 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.814, lat_loss 6.682
09/19 06:47:28 AM | Train: [ 77/180] Step 1100/1249 Loss 0.623 Prec@(1,3) (84.2%, 99.3%), ce_loss 0.814, lat_loss 6.682
09/19 06:47:49 AM | Train: [ 77/180] Step 1150/1249 Loss 0.625 Prec@(1,3) (84.2%, 99.3%), ce_loss 0.813, lat_loss 6.682
09/19 06:48:12 AM | Train: [ 77/180] Step 1200/1249 Loss 0.629 Prec@(1,3) (84.1%, 99.3%), ce_loss 0.813, lat_loss 6.682
09/19 06:48:36 AM | Train: [ 77/180] Step 1249/1249 Loss 0.630 Prec@(1,3) (84.1%, 99.3%), ce_loss 0.813, lat_loss 6.682
09/19 06:48:36 AM | _w_step_train: [ 77/180] Final Prec@1 84.0600% Time 551.57
09/19 06:48:36 AM | Start to train theta for epoch 76
09/19 06:48:57 AM | Train: [ 77/180] Step 050/312 Loss 0.733 Prec@(1,3) (81.7%, 98.8%), ce_loss 0.813, lat_loss 6.682
09/19 06:49:17 AM | Train: [ 77/180] Step 100/312 Loss 0.758 Prec@(1,3) (80.9%, 98.9%), ce_loss 0.813, lat_loss 6.682
09/19 06:49:36 AM | Train: [ 77/180] Step 150/312 Loss 0.767 Prec@(1,3) (80.7%, 98.8%), ce_loss 0.813, lat_loss 6.682
09/19 06:49:56 AM | Train: [ 77/180] Step 200/312 Loss 0.757 Prec@(1,3) (81.0%, 98.9%), ce_loss 0.813, lat_loss 6.682
09/19 06:50:17 AM | Train: [ 77/180] Step 250/312 Loss 0.757 Prec@(1,3) (81.0%, 98.9%), ce_loss 0.813, lat_loss 6.682
09/19 06:50:36 AM | Train: [ 77/180] Step 300/312 Loss 0.750 Prec@(1,3) (81.0%, 98.9%), ce_loss 0.813, lat_loss 6.682
09/19 06:50:41 AM | Train: [ 77/180] Step 312/312 Loss 0.749 Prec@(1,3) (81.0%, 98.9%), ce_loss 0.813, lat_loss 6.682
09/19 06:50:42 AM | _theta_step_train: [ 77/180] Final Prec@1 81.0500% Time 125.59
09/19 06:50:47 AM | Valid: [ 77/180] Step 050/312 Loss 0.763 Prec@(1,3) (81.1%, 98.8%), ce_loss 0.813, lat_loss 6.682
09/19 06:50:51 AM | Valid: [ 77/180] Step 100/312 Loss 0.845 Prec@(1,3) (80.5%, 98.2%), ce_loss 0.813, lat_loss 6.682
09/19 06:50:55 AM | Valid: [ 77/180] Step 150/312 Loss 0.862 Prec@(1,3) (79.7%, 97.8%), ce_loss 0.812, lat_loss 6.682
09/19 06:50:59 AM | Valid: [ 77/180] Step 200/312 Loss 0.848 Prec@(1,3) (79.9%, 98.1%), ce_loss 0.812, lat_loss 6.682
09/19 06:51:04 AM | Valid: [ 77/180] Step 250/312 Loss 0.823 Prec@(1,3) (80.2%, 98.3%), ce_loss 0.812, lat_loss 6.682
09/19 06:51:08 AM | Valid: [ 77/180] Step 300/312 Loss 0.831 Prec@(1,3) (80.2%, 98.2%), ce_loss 0.812, lat_loss 6.682
09/19 06:51:09 AM | Valid: [ 77/180] Step 312/312 Loss 0.830 Prec@(1,3) (80.2%, 98.3%), ce_loss 0.812, lat_loss 6.682
09/19 06:51:09 AM | val: [ 77/180] Final Prec@1 80.2300% Time 27.13
09/19 06:51:09 AM | Start to train weights for epoch 77
09/19 06:51:32 AM | Train: [ 78/180] Step 050/1249 Loss 0.557 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.812, lat_loss 6.682
09/19 06:51:56 AM | Train: [ 78/180] Step 100/1249 Loss 0.588 Prec@(1,3) (85.0%, 99.6%), ce_loss 0.812, lat_loss 6.682
09/19 06:52:19 AM | Train: [ 78/180] Step 150/1249 Loss 0.592 Prec@(1,3) (84.8%, 99.5%), ce_loss 0.812, lat_loss 6.682
09/19 06:52:44 AM | Train: [ 78/180] Step 200/1249 Loss 0.617 Prec@(1,3) (84.3%, 99.4%), ce_loss 0.812, lat_loss 6.682
09/19 06:53:08 AM | Train: [ 78/180] Step 250/1249 Loss 0.611 Prec@(1,3) (84.4%, 99.4%), ce_loss 0.812, lat_loss 6.682
09/19 06:53:32 AM | Train: [ 78/180] Step 300/1249 Loss 0.601 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.811, lat_loss 6.682
09/19 06:53:56 AM | Train: [ 78/180] Step 350/1249 Loss 0.609 Prec@(1,3) (84.6%, 99.4%), ce_loss 0.811, lat_loss 6.682
09/19 06:54:21 AM | Train: [ 78/180] Step 400/1249 Loss 0.615 Prec@(1,3) (84.4%, 99.3%), ce_loss 0.811, lat_loss 6.682
09/19 06:54:46 AM | Train: [ 78/180] Step 450/1249 Loss 0.613 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.811, lat_loss 6.682
09/19 06:55:11 AM | Train: [ 78/180] Step 500/1249 Loss 0.616 Prec@(1,3) (84.4%, 99.3%), ce_loss 0.811, lat_loss 6.682
09/19 06:55:35 AM | Train: [ 78/180] Step 550/1249 Loss 0.617 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.811, lat_loss 6.682
09/19 06:55:59 AM | Train: [ 78/180] Step 600/1249 Loss 0.619 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.811, lat_loss 6.682
09/19 06:56:24 AM | Train: [ 78/180] Step 650/1249 Loss 0.621 Prec@(1,3) (84.2%, 99.3%), ce_loss 0.811, lat_loss 6.682
09/19 06:56:49 AM | Train: [ 78/180] Step 700/1249 Loss 0.618 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.810, lat_loss 6.682
09/19 06:57:13 AM | Train: [ 78/180] Step 750/1249 Loss 0.616 Prec@(1,3) (84.4%, 99.3%), ce_loss 0.810, lat_loss 6.682
09/19 06:57:38 AM | Train: [ 78/180] Step 800/1249 Loss 0.616 Prec@(1,3) (84.4%, 99.3%), ce_loss 0.810, lat_loss 6.682
09/19 06:58:03 AM | Train: [ 78/180] Step 850/1249 Loss 0.617 Prec@(1,3) (84.4%, 99.3%), ce_loss 0.810, lat_loss 6.682
09/19 06:58:25 AM | Train: [ 78/180] Step 900/1249 Loss 0.618 Prec@(1,3) (84.4%, 99.3%), ce_loss 0.810, lat_loss 6.682
09/19 06:58:41 AM | Train: [ 78/180] Step 950/1249 Loss 0.619 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.810, lat_loss 6.682
09/19 06:58:57 AM | Train: [ 78/180] Step 1000/1249 Loss 0.620 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.810, lat_loss 6.682
09/19 06:59:13 AM | Train: [ 78/180] Step 1050/1249 Loss 0.622 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.810, lat_loss 6.682
09/19 06:59:35 AM | Train: [ 78/180] Step 1100/1249 Loss 0.622 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.809, lat_loss 6.682
09/19 06:59:55 AM | Train: [ 78/180] Step 1150/1249 Loss 0.622 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.809, lat_loss 6.682
09/19 07:00:17 AM | Train: [ 78/180] Step 1200/1249 Loss 0.625 Prec@(1,3) (84.2%, 99.3%), ce_loss 0.809, lat_loss 6.682
09/19 07:00:41 AM | Train: [ 78/180] Step 1249/1249 Loss 0.625 Prec@(1,3) (84.2%, 99.3%), ce_loss 0.809, lat_loss 6.682
09/19 07:00:41 AM | _w_step_train: [ 78/180] Final Prec@1 84.2000% Time 572.03
09/19 07:00:41 AM | Start to train theta for epoch 77
09/19 07:01:02 AM | Train: [ 78/180] Step 050/312 Loss 0.789 Prec@(1,3) (80.3%, 98.5%), ce_loss 0.809, lat_loss 6.682
09/19 07:01:23 AM | Train: [ 78/180] Step 100/312 Loss 0.754 Prec@(1,3) (81.2%, 98.6%), ce_loss 0.809, lat_loss 6.682
09/19 07:01:44 AM | Train: [ 78/180] Step 150/312 Loss 0.750 Prec@(1,3) (81.2%, 98.7%), ce_loss 0.809, lat_loss 6.682
09/19 07:02:00 AM | Train: [ 78/180] Step 200/312 Loss 0.758 Prec@(1,3) (81.0%, 98.7%), ce_loss 0.809, lat_loss 6.682
09/19 07:02:12 AM | Train: [ 78/180] Step 250/312 Loss 0.747 Prec@(1,3) (81.5%, 98.7%), ce_loss 0.809, lat_loss 6.682
09/19 07:02:24 AM | Train: [ 78/180] Step 300/312 Loss 0.756 Prec@(1,3) (81.3%, 98.7%), ce_loss 0.809, lat_loss 6.682
09/19 07:02:27 AM | Train: [ 78/180] Step 312/312 Loss 0.755 Prec@(1,3) (81.3%, 98.7%), ce_loss 0.809, lat_loss 6.682
09/19 07:02:27 AM | _theta_step_train: [ 78/180] Final Prec@1 81.2600% Time 106.40
09/19 07:02:33 AM | Valid: [ 78/180] Step 050/312 Loss 0.748 Prec@(1,3) (81.9%, 99.0%), ce_loss 0.808, lat_loss 6.682
09/19 07:02:38 AM | Valid: [ 78/180] Step 100/312 Loss 0.747 Prec@(1,3) (82.2%, 99.0%), ce_loss 0.808, lat_loss 6.682
09/19 07:02:42 AM | Valid: [ 78/180] Step 150/312 Loss 0.769 Prec@(1,3) (81.8%, 98.7%), ce_loss 0.808, lat_loss 6.682
09/19 07:02:47 AM | Valid: [ 78/180] Step 200/312 Loss 0.793 Prec@(1,3) (81.6%, 98.6%), ce_loss 0.808, lat_loss 6.682
09/19 07:02:52 AM | Valid: [ 78/180] Step 250/312 Loss 0.801 Prec@(1,3) (81.0%, 98.5%), ce_loss 0.808, lat_loss 6.682
09/19 07:02:57 AM | Valid: [ 78/180] Step 300/312 Loss 0.786 Prec@(1,3) (81.3%, 98.6%), ce_loss 0.808, lat_loss 6.682
09/19 07:02:59 AM | Valid: [ 78/180] Step 312/312 Loss 0.784 Prec@(1,3) (81.3%, 98.7%), ce_loss 0.808, lat_loss 6.682
09/19 07:02:59 AM | val: [ 78/180] Final Prec@1 81.3300% Time 31.43
09/19 07:02:59 AM | Best top1 acc by now. Save model
09/19 07:02:59 AM | Start to train weights for epoch 78
09/19 07:03:25 AM | Train: [ 79/180] Step 050/1249 Loss 0.557 Prec@(1,3) (85.6%, 99.1%), ce_loss 0.808, lat_loss 6.682
09/19 07:03:49 AM | Train: [ 79/180] Step 100/1249 Loss 0.643 Prec@(1,3) (84.2%, 98.9%), ce_loss 0.808, lat_loss 6.682
09/19 07:04:14 AM | Train: [ 79/180] Step 150/1249 Loss 0.642 Prec@(1,3) (84.1%, 99.0%), ce_loss 0.808, lat_loss 6.682
09/19 07:04:37 AM | Train: [ 79/180] Step 200/1249 Loss 0.649 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.808, lat_loss 6.682
09/19 07:05:00 AM | Train: [ 79/180] Step 250/1249 Loss 0.643 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.808, lat_loss 6.682
09/19 07:05:23 AM | Train: [ 79/180] Step 300/1249 Loss 0.640 Prec@(1,3) (84.0%, 99.1%), ce_loss 0.807, lat_loss 6.682
09/19 07:05:46 AM | Train: [ 79/180] Step 350/1249 Loss 0.641 Prec@(1,3) (83.9%, 99.2%), ce_loss 0.807, lat_loss 6.682
09/19 07:06:09 AM | Train: [ 79/180] Step 400/1249 Loss 0.641 Prec@(1,3) (83.8%, 99.2%), ce_loss 0.807, lat_loss 6.682
09/19 07:06:33 AM | Train: [ 79/180] Step 450/1249 Loss 0.643 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.807, lat_loss 6.682
09/19 07:06:54 AM | Train: [ 79/180] Step 500/1249 Loss 0.634 Prec@(1,3) (84.0%, 99.1%), ce_loss 0.807, lat_loss 6.682
09/19 07:07:17 AM | Train: [ 79/180] Step 550/1249 Loss 0.634 Prec@(1,3) (84.0%, 99.1%), ce_loss 0.807, lat_loss 6.682
09/19 07:07:40 AM | Train: [ 79/180] Step 600/1249 Loss 0.628 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.807, lat_loss 6.682
09/19 07:08:04 AM | Train: [ 79/180] Step 650/1249 Loss 0.623 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.807, lat_loss 6.682
09/19 07:08:27 AM | Train: [ 79/180] Step 700/1249 Loss 0.622 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.806, lat_loss 6.682
09/19 07:08:50 AM | Train: [ 79/180] Step 750/1249 Loss 0.620 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.806, lat_loss 6.682
09/19 07:09:12 AM | Train: [ 79/180] Step 800/1249 Loss 0.623 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.806, lat_loss 6.682
09/19 07:09:35 AM | Train: [ 79/180] Step 850/1249 Loss 0.622 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.806, lat_loss 6.682
09/19 07:09:58 AM | Train: [ 79/180] Step 900/1249 Loss 0.622 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.806, lat_loss 6.682
09/19 07:10:22 AM | Train: [ 79/180] Step 950/1249 Loss 0.620 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.806, lat_loss 6.682
09/19 07:10:47 AM | Train: [ 79/180] Step 1000/1249 Loss 0.619 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.806, lat_loss 6.682
09/19 07:11:12 AM | Train: [ 79/180] Step 1050/1249 Loss 0.619 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.806, lat_loss 6.682
09/19 07:11:37 AM | Train: [ 79/180] Step 1100/1249 Loss 0.618 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.805, lat_loss 6.682
09/19 07:12:02 AM | Train: [ 79/180] Step 1150/1249 Loss 0.617 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.805, lat_loss 6.682
09/19 07:12:26 AM | Train: [ 79/180] Step 1200/1249 Loss 0.618 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.805, lat_loss 6.682
09/19 07:12:51 AM | Train: [ 79/180] Step 1249/1249 Loss 0.618 Prec@(1,3) (84.2%, 99.3%), ce_loss 0.805, lat_loss 6.682
09/19 07:12:51 AM | _w_step_train: [ 79/180] Final Prec@1 84.2375% Time 591.74
09/19 07:12:51 AM | Start to train theta for epoch 78
09/19 07:13:12 AM | Train: [ 79/180] Step 050/312 Loss 0.711 Prec@(1,3) (82.6%, 98.6%), ce_loss 0.805, lat_loss 6.682
09/19 07:13:33 AM | Train: [ 79/180] Step 100/312 Loss 0.720 Prec@(1,3) (82.5%, 98.5%), ce_loss 0.805, lat_loss 6.682
09/19 07:13:54 AM | Train: [ 79/180] Step 150/312 Loss 0.756 Prec@(1,3) (81.8%, 98.4%), ce_loss 0.805, lat_loss 6.682
09/19 07:14:14 AM | Train: [ 79/180] Step 200/312 Loss 0.767 Prec@(1,3) (81.6%, 98.4%), ce_loss 0.805, lat_loss 6.682
09/19 07:14:35 AM | Train: [ 79/180] Step 250/312 Loss 0.755 Prec@(1,3) (81.7%, 98.5%), ce_loss 0.805, lat_loss 6.682
09/19 07:14:55 AM | Train: [ 79/180] Step 300/312 Loss 0.759 Prec@(1,3) (81.5%, 98.6%), ce_loss 0.805, lat_loss 6.682
09/19 07:15:00 AM | Train: [ 79/180] Step 312/312 Loss 0.758 Prec@(1,3) (81.6%, 98.6%), ce_loss 0.804, lat_loss 6.682
09/19 07:15:00 AM | _theta_step_train: [ 79/180] Final Prec@1 81.5900% Time 129.52
09/19 07:15:06 AM | Valid: [ 79/180] Step 050/312 Loss 0.982 Prec@(1,3) (77.3%, 97.2%), ce_loss 0.804, lat_loss 6.682
09/19 07:15:10 AM | Valid: [ 79/180] Step 100/312 Loss 0.990 Prec@(1,3) (77.4%, 97.3%), ce_loss 0.804, lat_loss 6.682
09/19 07:15:15 AM | Valid: [ 79/180] Step 150/312 Loss 0.948 Prec@(1,3) (78.1%, 97.6%), ce_loss 0.804, lat_loss 6.682
09/19 07:15:19 AM | Valid: [ 79/180] Step 200/312 Loss 0.917 Prec@(1,3) (78.5%, 97.9%), ce_loss 0.804, lat_loss 6.682
09/19 07:15:24 AM | Valid: [ 79/180] Step 250/312 Loss 0.903 Prec@(1,3) (78.8%, 98.1%), ce_loss 0.804, lat_loss 6.682
09/19 07:15:29 AM | Valid: [ 79/180] Step 300/312 Loss 0.868 Prec@(1,3) (79.5%, 98.2%), ce_loss 0.804, lat_loss 6.682
09/19 07:15:30 AM | Valid: [ 79/180] Step 312/312 Loss 0.865 Prec@(1,3) (79.7%, 98.2%), ce_loss 0.804, lat_loss 6.682
09/19 07:15:30 AM | val: [ 79/180] Final Prec@1 79.6600% Time 29.43
09/19 07:15:30 AM | Start to train weights for epoch 79
09/19 07:15:47 AM | Train: [ 80/180] Step 050/1249 Loss 0.649 Prec@(1,3) (84.7%, 99.0%), ce_loss 0.804, lat_loss 6.682
09/19 07:16:03 AM | Train: [ 80/180] Step 100/1249 Loss 0.603 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.804, lat_loss 6.682
09/19 07:16:19 AM | Train: [ 80/180] Step 150/1249 Loss 0.609 Prec@(1,3) (84.4%, 99.3%), ce_loss 0.804, lat_loss 6.682
09/19 07:16:35 AM | Train: [ 80/180] Step 200/1249 Loss 0.597 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.804, lat_loss 6.682
09/19 07:16:51 AM | Train: [ 80/180] Step 250/1249 Loss 0.592 Prec@(1,3) (84.9%, 99.4%), ce_loss 0.804, lat_loss 6.682
09/19 07:17:07 AM | Train: [ 80/180] Step 300/1249 Loss 0.585 Prec@(1,3) (85.0%, 99.4%), ce_loss 0.803, lat_loss 6.682
09/19 07:17:23 AM | Train: [ 80/180] Step 350/1249 Loss 0.588 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.803, lat_loss 6.682
09/19 07:17:39 AM | Train: [ 80/180] Step 400/1249 Loss 0.595 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.803, lat_loss 6.682
09/19 07:17:55 AM | Train: [ 80/180] Step 450/1249 Loss 0.593 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.803, lat_loss 6.682
09/19 07:18:11 AM | Train: [ 80/180] Step 500/1249 Loss 0.604 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.803, lat_loss 6.682
09/19 07:18:27 AM | Train: [ 80/180] Step 550/1249 Loss 0.610 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.803, lat_loss 6.682
09/19 07:18:43 AM | Train: [ 80/180] Step 600/1249 Loss 0.611 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.803, lat_loss 6.682
09/19 07:18:59 AM | Train: [ 80/180] Step 650/1249 Loss 0.610 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.803, lat_loss 6.682
09/19 07:19:15 AM | Train: [ 80/180] Step 700/1249 Loss 0.612 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.802, lat_loss 6.682
09/19 07:19:31 AM | Train: [ 80/180] Step 750/1249 Loss 0.612 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.802, lat_loss 6.682
09/19 07:19:47 AM | Train: [ 80/180] Step 800/1249 Loss 0.608 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.802, lat_loss 6.682
09/19 07:20:03 AM | Train: [ 80/180] Step 850/1249 Loss 0.608 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.802, lat_loss 6.682
09/19 07:20:19 AM | Train: [ 80/180] Step 900/1249 Loss 0.613 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.802, lat_loss 6.682
09/19 07:20:35 AM | Train: [ 80/180] Step 950/1249 Loss 0.611 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.802, lat_loss 6.682
09/19 07:20:53 AM | Train: [ 80/180] Step 1000/1249 Loss 0.615 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.802, lat_loss 6.682
09/19 07:21:13 AM | Train: [ 80/180] Step 1050/1249 Loss 0.617 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.802, lat_loss 6.682
09/19 07:21:35 AM | Train: [ 80/180] Step 1100/1249 Loss 0.615 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.802, lat_loss 6.682
09/19 07:21:56 AM | Train: [ 80/180] Step 1150/1249 Loss 0.612 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.801, lat_loss 6.682
09/19 07:22:18 AM | Train: [ 80/180] Step 1200/1249 Loss 0.618 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.801, lat_loss 6.682
09/19 07:22:43 AM | Train: [ 80/180] Step 1249/1249 Loss 0.622 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.801, lat_loss 6.682
09/19 07:22:43 AM | _w_step_train: [ 80/180] Final Prec@1 84.3700% Time 433.03
09/19 07:22:43 AM | Start to train theta for epoch 79
09/19 07:23:05 AM | Train: [ 80/180] Step 050/312 Loss 0.753 Prec@(1,3) (81.7%, 98.6%), ce_loss 0.801, lat_loss 6.682
09/19 07:23:25 AM | Train: [ 80/180] Step 100/312 Loss 0.748 Prec@(1,3) (81.5%, 98.9%), ce_loss 0.801, lat_loss 6.682
09/19 07:23:46 AM | Train: [ 80/180] Step 150/312 Loss 0.728 Prec@(1,3) (81.6%, 99.0%), ce_loss 0.801, lat_loss 6.682
09/19 07:24:06 AM | Train: [ 80/180] Step 200/312 Loss 0.743 Prec@(1,3) (81.3%, 99.0%), ce_loss 0.801, lat_loss 6.682
09/19 07:24:27 AM | Train: [ 80/180] Step 250/312 Loss 0.734 Prec@(1,3) (81.5%, 99.0%), ce_loss 0.801, lat_loss 6.682
09/19 07:24:47 AM | Train: [ 80/180] Step 300/312 Loss 0.733 Prec@(1,3) (81.5%, 98.9%), ce_loss 0.801, lat_loss 6.682
09/19 07:24:52 AM | Train: [ 80/180] Step 312/312 Loss 0.737 Prec@(1,3) (81.4%, 98.9%), ce_loss 0.801, lat_loss 6.682
09/19 07:24:53 AM | _theta_step_train: [ 80/180] Final Prec@1 81.4100% Time 129.67
09/19 07:24:58 AM | Valid: [ 80/180] Step 050/312 Loss 0.804 Prec@(1,3) (80.9%, 98.5%), ce_loss 0.801, lat_loss 6.682
09/19 07:25:03 AM | Valid: [ 80/180] Step 100/312 Loss 0.840 Prec@(1,3) (79.9%, 98.0%), ce_loss 0.801, lat_loss 6.682
09/19 07:25:07 AM | Valid: [ 80/180] Step 150/312 Loss 0.879 Prec@(1,3) (79.7%, 97.6%), ce_loss 0.800, lat_loss 6.682
09/19 07:25:12 AM | Valid: [ 80/180] Step 200/312 Loss 0.848 Prec@(1,3) (80.4%, 98.0%), ce_loss 0.800, lat_loss 6.682
09/19 07:25:16 AM | Valid: [ 80/180] Step 250/312 Loss 0.841 Prec@(1,3) (80.4%, 97.9%), ce_loss 0.800, lat_loss 6.682
09/19 07:25:21 AM | Valid: [ 80/180] Step 300/312 Loss 0.860 Prec@(1,3) (80.0%, 97.6%), ce_loss 0.800, lat_loss 6.682
09/19 07:25:22 AM | Valid: [ 80/180] Step 312/312 Loss 0.859 Prec@(1,3) (79.9%, 97.7%), ce_loss 0.800, lat_loss 6.682
09/19 07:25:22 AM | val: [ 80/180] Final Prec@1 79.9300% Time 29.66
09/19 07:25:22 AM | Start to train weights for epoch 80
09/19 07:25:49 AM | Train: [ 81/180] Step 050/1249 Loss 0.612 Prec@(1,3) (84.4%, 99.4%), ce_loss 0.800, lat_loss 6.682
09/19 07:26:13 AM | Train: [ 81/180] Step 100/1249 Loss 0.584 Prec@(1,3) (85.0%, 99.4%), ce_loss 0.800, lat_loss 6.682
09/19 07:26:38 AM | Train: [ 81/180] Step 150/1249 Loss 0.587 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.800, lat_loss 6.682
09/19 07:27:03 AM | Train: [ 81/180] Step 200/1249 Loss 0.611 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.800, lat_loss 6.682
09/19 07:27:28 AM | Train: [ 81/180] Step 250/1249 Loss 0.608 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.800, lat_loss 6.682
09/19 07:27:52 AM | Train: [ 81/180] Step 300/1249 Loss 0.608 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.800, lat_loss 6.682
09/19 07:28:17 AM | Train: [ 81/180] Step 350/1249 Loss 0.605 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.799, lat_loss 6.682
09/19 07:28:42 AM | Train: [ 81/180] Step 400/1249 Loss 0.599 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.799, lat_loss 6.682
09/19 07:29:07 AM | Train: [ 81/180] Step 450/1249 Loss 0.606 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.799, lat_loss 6.682
09/19 07:29:32 AM | Train: [ 81/180] Step 500/1249 Loss 0.603 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.799, lat_loss 6.682
09/19 07:29:56 AM | Train: [ 81/180] Step 550/1249 Loss 0.597 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.799, lat_loss 6.682
09/19 07:30:21 AM | Train: [ 81/180] Step 600/1249 Loss 0.603 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.799, lat_loss 6.682
09/19 07:30:44 AM | Train: [ 81/180] Step 650/1249 Loss 0.609 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.799, lat_loss 6.682
09/19 07:31:08 AM | Train: [ 81/180] Step 700/1249 Loss 0.609 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.799, lat_loss 6.682
09/19 07:31:32 AM | Train: [ 81/180] Step 750/1249 Loss 0.607 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.798, lat_loss 6.682
09/19 07:31:56 AM | Train: [ 81/180] Step 800/1249 Loss 0.610 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.798, lat_loss 6.682
09/19 07:32:19 AM | Train: [ 81/180] Step 850/1249 Loss 0.609 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.798, lat_loss 6.682
09/19 07:32:43 AM | Train: [ 81/180] Step 900/1249 Loss 0.608 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.798, lat_loss 6.682
09/19 07:33:08 AM | Train: [ 81/180] Step 950/1249 Loss 0.608 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.798, lat_loss 6.682
09/19 07:33:32 AM | Train: [ 81/180] Step 1000/1249 Loss 0.609 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.798, lat_loss 6.682
09/19 07:33:54 AM | Train: [ 81/180] Step 1050/1249 Loss 0.607 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.798, lat_loss 6.682
09/19 07:34:19 AM | Train: [ 81/180] Step 1100/1249 Loss 0.608 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.798, lat_loss 6.682
09/19 07:34:43 AM | Train: [ 81/180] Step 1150/1249 Loss 0.610 Prec@(1,3) (84.5%, 99.3%), ce_loss 0.798, lat_loss 6.682
09/19 07:35:07 AM | Train: [ 81/180] Step 1200/1249 Loss 0.612 Prec@(1,3) (84.5%, 99.3%), ce_loss 0.797, lat_loss 6.682
09/19 07:35:32 AM | Train: [ 81/180] Step 1249/1249 Loss 0.610 Prec@(1,3) (84.5%, 99.3%), ce_loss 0.797, lat_loss 6.682
09/19 07:35:32 AM | _w_step_train: [ 81/180] Final Prec@1 84.5225% Time 609.53
09/19 07:35:32 AM | Start to train theta for epoch 80
09/19 07:35:53 AM | Train: [ 81/180] Step 050/312 Loss 0.728 Prec@(1,3) (81.5%, 99.1%), ce_loss 0.797, lat_loss 6.682
09/19 07:36:13 AM | Train: [ 81/180] Step 100/312 Loss 0.746 Prec@(1,3) (81.2%, 99.0%), ce_loss 0.797, lat_loss 6.682
09/19 07:36:34 AM | Train: [ 81/180] Step 150/312 Loss 0.739 Prec@(1,3) (81.5%, 98.8%), ce_loss 0.797, lat_loss 6.682
09/19 07:36:54 AM | Train: [ 81/180] Step 200/312 Loss 0.732 Prec@(1,3) (81.8%, 98.8%), ce_loss 0.797, lat_loss 6.682
09/19 07:37:15 AM | Train: [ 81/180] Step 250/312 Loss 0.730 Prec@(1,3) (81.8%, 98.8%), ce_loss 0.797, lat_loss 6.682
09/19 07:37:35 AM | Train: [ 81/180] Step 300/312 Loss 0.748 Prec@(1,3) (81.6%, 98.8%), ce_loss 0.797, lat_loss 6.682
09/19 07:37:40 AM | Train: [ 81/180] Step 312/312 Loss 0.744 Prec@(1,3) (81.7%, 98.8%), ce_loss 0.797, lat_loss 6.682
09/19 07:37:40 AM | _theta_step_train: [ 81/180] Final Prec@1 81.6900% Time 128.68
09/19 07:37:46 AM | Valid: [ 81/180] Step 050/312 Loss 0.733 Prec@(1,3) (82.5%, 98.9%), ce_loss 0.797, lat_loss 6.682
09/19 07:37:50 AM | Valid: [ 81/180] Step 100/312 Loss 0.799 Prec@(1,3) (80.6%, 98.3%), ce_loss 0.797, lat_loss 6.682
09/19 07:37:55 AM | Valid: [ 81/180] Step 150/312 Loss 0.768 Prec@(1,3) (81.2%, 98.4%), ce_loss 0.797, lat_loss 6.682
09/19 07:38:00 AM | Valid: [ 81/180] Step 200/312 Loss 0.774 Prec@(1,3) (81.6%, 98.5%), ce_loss 0.797, lat_loss 6.682
09/19 07:38:04 AM | Valid: [ 81/180] Step 250/312 Loss 0.793 Prec@(1,3) (81.3%, 98.2%), ce_loss 0.796, lat_loss 6.682
09/19 07:38:09 AM | Valid: [ 81/180] Step 300/312 Loss 0.770 Prec@(1,3) (81.7%, 98.5%), ce_loss 0.796, lat_loss 6.682
09/19 07:38:10 AM | Valid: [ 81/180] Step 312/312 Loss 0.762 Prec@(1,3) (81.8%, 98.5%), ce_loss 0.796, lat_loss 6.682
09/19 07:38:10 AM | val: [ 81/180] Final Prec@1 81.7600% Time 29.49
09/19 07:38:10 AM | Best top1 acc by now. Save model
09/19 07:38:10 AM | Start to train weights for epoch 81
09/19 07:38:36 AM | Train: [ 82/180] Step 050/1249 Loss 0.583 Prec@(1,3) (85.4%, 99.4%), ce_loss 0.796, lat_loss 6.682
09/19 07:38:58 AM | Train: [ 82/180] Step 100/1249 Loss 0.593 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.796, lat_loss 6.682
09/19 07:39:23 AM | Train: [ 82/180] Step 150/1249 Loss 0.582 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.796, lat_loss 6.682
09/19 07:39:49 AM | Train: [ 82/180] Step 200/1249 Loss 0.590 Prec@(1,3) (84.8%, 99.4%), ce_loss 0.796, lat_loss 6.682
09/19 07:40:14 AM | Train: [ 82/180] Step 250/1249 Loss 0.592 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.796, lat_loss 6.682
09/19 07:40:39 AM | Train: [ 82/180] Step 300/1249 Loss 0.582 Prec@(1,3) (85.1%, 99.4%), ce_loss 0.796, lat_loss 6.682
09/19 07:41:04 AM | Train: [ 82/180] Step 350/1249 Loss 0.589 Prec@(1,3) (84.9%, 99.4%), ce_loss 0.795, lat_loss 6.682
09/19 07:41:29 AM | Train: [ 82/180] Step 400/1249 Loss 0.596 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.795, lat_loss 6.682
09/19 07:41:54 AM | Train: [ 82/180] Step 450/1249 Loss 0.599 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.795, lat_loss 6.682
09/19 07:42:19 AM | Train: [ 82/180] Step 500/1249 Loss 0.601 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.795, lat_loss 6.682
09/19 07:42:44 AM | Train: [ 82/180] Step 550/1249 Loss 0.604 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.795, lat_loss 6.682
09/19 07:43:09 AM | Train: [ 82/180] Step 600/1249 Loss 0.603 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.795, lat_loss 6.682
09/19 07:43:34 AM | Train: [ 82/180] Step 650/1249 Loss 0.604 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.795, lat_loss 6.682
09/19 07:43:59 AM | Train: [ 82/180] Step 700/1249 Loss 0.601 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.795, lat_loss 6.682
09/19 07:44:24 AM | Train: [ 82/180] Step 750/1249 Loss 0.601 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.795, lat_loss 6.682
09/19 07:44:49 AM | Train: [ 82/180] Step 800/1249 Loss 0.600 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.794, lat_loss 6.682
09/19 07:45:14 AM | Train: [ 82/180] Step 850/1249 Loss 0.597 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.794, lat_loss 6.682
09/19 07:45:39 AM | Train: [ 82/180] Step 900/1249 Loss 0.594 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.794, lat_loss 6.683
09/19 07:46:05 AM | Train: [ 82/180] Step 950/1249 Loss 0.595 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.794, lat_loss 6.683
09/19 07:46:30 AM | Train: [ 82/180] Step 1000/1249 Loss 0.598 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.794, lat_loss 6.683
09/19 07:46:55 AM | Train: [ 82/180] Step 1050/1249 Loss 0.599 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.794, lat_loss 6.683
09/19 07:47:20 AM | Train: [ 82/180] Step 1100/1249 Loss 0.602 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.794, lat_loss 6.683
09/19 07:47:45 AM | Train: [ 82/180] Step 1150/1249 Loss 0.601 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.794, lat_loss 6.683
09/19 07:48:10 AM | Train: [ 82/180] Step 1200/1249 Loss 0.599 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.793, lat_loss 6.683
09/19 07:48:34 AM | Train: [ 82/180] Step 1249/1249 Loss 0.599 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.793, lat_loss 6.683
09/19 07:48:34 AM | _w_step_train: [ 82/180] Final Prec@1 84.8550% Time 624.06
09/19 07:48:34 AM | Start to train theta for epoch 81
09/19 07:48:56 AM | Train: [ 82/180] Step 050/312 Loss 0.780 Prec@(1,3) (80.8%, 98.8%), ce_loss 0.793, lat_loss 6.683
09/19 07:49:16 AM | Train: [ 82/180] Step 100/312 Loss 0.758 Prec@(1,3) (81.7%, 98.8%), ce_loss 0.793, lat_loss 6.683
09/19 07:49:36 AM | Train: [ 82/180] Step 150/312 Loss 0.746 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.793, lat_loss 6.683
09/19 07:49:56 AM | Train: [ 82/180] Step 200/312 Loss 0.748 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.793, lat_loss 6.683
09/19 07:50:16 AM | Train: [ 82/180] Step 250/312 Loss 0.744 Prec@(1,3) (81.9%, 98.9%), ce_loss 0.793, lat_loss 6.683
09/19 07:50:36 AM | Train: [ 82/180] Step 300/312 Loss 0.740 Prec@(1,3) (81.9%, 98.8%), ce_loss 0.793, lat_loss 6.683
09/19 07:50:41 AM | Train: [ 82/180] Step 312/312 Loss 0.742 Prec@(1,3) (81.9%, 98.9%), ce_loss 0.793, lat_loss 6.683
09/19 07:50:41 AM | _theta_step_train: [ 82/180] Final Prec@1 81.8600% Time 126.87
09/19 07:50:46 AM | Valid: [ 82/180] Step 050/312 Loss 0.749 Prec@(1,3) (80.9%, 99.1%), ce_loss 0.793, lat_loss 6.683
09/19 07:50:51 AM | Valid: [ 82/180] Step 100/312 Loss 0.734 Prec@(1,3) (81.6%, 99.1%), ce_loss 0.793, lat_loss 6.683
09/19 07:50:56 AM | Valid: [ 82/180] Step 150/312 Loss 0.713 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.793, lat_loss 6.683
09/19 07:51:00 AM | Valid: [ 82/180] Step 200/312 Loss 0.710 Prec@(1,3) (82.8%, 99.0%), ce_loss 0.792, lat_loss 6.683
09/19 07:51:05 AM | Valid: [ 82/180] Step 250/312 Loss 0.715 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.792, lat_loss 6.683
09/19 07:51:10 AM | Valid: [ 82/180] Step 300/312 Loss 0.712 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.792, lat_loss 6.683
09/19 07:51:11 AM | Valid: [ 82/180] Step 312/312 Loss 0.733 Prec@(1,3) (82.2%, 98.9%), ce_loss 0.792, lat_loss 6.683
09/19 07:51:11 AM | val: [ 82/180] Final Prec@1 82.1800% Time 29.89
09/19 07:51:11 AM | Best top1 acc by now. Save model
09/19 07:51:11 AM | Start to train weights for epoch 82
09/19 07:51:34 AM | Train: [ 83/180] Step 050/1249 Loss 0.556 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.792, lat_loss 6.683
09/19 07:51:54 AM | Train: [ 83/180] Step 100/1249 Loss 0.589 Prec@(1,3) (84.6%, 99.4%), ce_loss 0.792, lat_loss 6.683
09/19 07:52:14 AM | Train: [ 83/180] Step 150/1249 Loss 0.585 Prec@(1,3) (84.6%, 99.4%), ce_loss 0.792, lat_loss 6.683
09/19 07:52:34 AM | Train: [ 83/180] Step 200/1249 Loss 0.600 Prec@(1,3) (84.4%, 99.4%), ce_loss 0.792, lat_loss 6.683
09/19 07:52:58 AM | Train: [ 83/180] Step 250/1249 Loss 0.592 Prec@(1,3) (84.6%, 99.4%), ce_loss 0.792, lat_loss 6.683
09/19 07:53:23 AM | Train: [ 83/180] Step 300/1249 Loss 0.588 Prec@(1,3) (84.8%, 99.4%), ce_loss 0.792, lat_loss 6.683
09/19 07:53:47 AM | Train: [ 83/180] Step 350/1249 Loss 0.589 Prec@(1,3) (84.8%, 99.4%), ce_loss 0.791, lat_loss 6.683
09/19 07:54:11 AM | Train: [ 83/180] Step 400/1249 Loss 0.585 Prec@(1,3) (84.9%, 99.4%), ce_loss 0.791, lat_loss 6.683
09/19 07:54:36 AM | Train: [ 83/180] Step 450/1249 Loss 0.584 Prec@(1,3) (85.0%, 99.4%), ce_loss 0.791, lat_loss 6.683
09/19 07:55:01 AM | Train: [ 83/180] Step 500/1249 Loss 0.587 Prec@(1,3) (84.9%, 99.4%), ce_loss 0.791, lat_loss 6.683
09/19 07:55:26 AM | Train: [ 83/180] Step 550/1249 Loss 0.589 Prec@(1,3) (84.8%, 99.4%), ce_loss 0.791, lat_loss 6.683
09/19 07:55:51 AM | Train: [ 83/180] Step 600/1249 Loss 0.588 Prec@(1,3) (84.8%, 99.4%), ce_loss 0.791, lat_loss 6.683
09/19 07:56:13 AM | Train: [ 83/180] Step 650/1249 Loss 0.588 Prec@(1,3) (84.8%, 99.4%), ce_loss 0.791, lat_loss 6.683
09/19 07:56:29 AM | Train: [ 83/180] Step 700/1249 Loss 0.588 Prec@(1,3) (84.8%, 99.4%), ce_loss 0.791, lat_loss 6.683
09/19 07:56:45 AM | Train: [ 83/180] Step 750/1249 Loss 0.593 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.791, lat_loss 6.683
09/19 07:57:01 AM | Train: [ 83/180] Step 800/1249 Loss 0.595 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.790, lat_loss 6.683
09/19 07:57:17 AM | Train: [ 83/180] Step 850/1249 Loss 0.595 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.790, lat_loss 6.683
09/19 07:57:33 AM | Train: [ 83/180] Step 900/1249 Loss 0.595 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.790, lat_loss 6.683
09/19 07:57:49 AM | Train: [ 83/180] Step 950/1249 Loss 0.595 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.790, lat_loss 6.683
09/19 07:58:05 AM | Train: [ 83/180] Step 1000/1249 Loss 0.593 Prec@(1,3) (84.8%, 99.4%), ce_loss 0.790, lat_loss 6.683
09/19 07:58:21 AM | Train: [ 83/180] Step 1050/1249 Loss 0.593 Prec@(1,3) (84.8%, 99.4%), ce_loss 0.790, lat_loss 6.683
09/19 07:58:37 AM | Train: [ 83/180] Step 1100/1249 Loss 0.596 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.790, lat_loss 6.683
09/19 07:58:53 AM | Train: [ 83/180] Step 1150/1249 Loss 0.597 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.790, lat_loss 6.683
09/19 07:59:09 AM | Train: [ 83/180] Step 1200/1249 Loss 0.598 Prec@(1,3) (84.7%, 99.4%), ce_loss 0.790, lat_loss 6.683
09/19 07:59:25 AM | Train: [ 83/180] Step 1249/1249 Loss 0.600 Prec@(1,3) (84.6%, 99.4%), ce_loss 0.789, lat_loss 6.683
09/19 07:59:25 AM | _w_step_train: [ 83/180] Final Prec@1 84.6350% Time 493.96
09/19 07:59:25 AM | Start to train theta for epoch 82
09/19 07:59:45 AM | Train: [ 83/180] Step 050/312 Loss 0.698 Prec@(1,3) (82.2%, 99.2%), ce_loss 0.789, lat_loss 6.683
09/19 08:00:04 AM | Train: [ 83/180] Step 100/312 Loss 0.717 Prec@(1,3) (82.0%, 99.1%), ce_loss 0.789, lat_loss 6.683
09/19 08:00:25 AM | Train: [ 83/180] Step 150/312 Loss 0.691 Prec@(1,3) (82.3%, 99.1%), ce_loss 0.789, lat_loss 6.683
09/19 08:00:45 AM | Train: [ 83/180] Step 200/312 Loss 0.694 Prec@(1,3) (82.6%, 99.0%), ce_loss 0.789, lat_loss 6.683
09/19 08:01:06 AM | Train: [ 83/180] Step 250/312 Loss 0.703 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.789, lat_loss 6.683
09/19 08:01:26 AM | Train: [ 83/180] Step 300/312 Loss 0.708 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.789, lat_loss 6.683
09/19 08:01:32 AM | Train: [ 83/180] Step 312/312 Loss 0.712 Prec@(1,3) (82.0%, 99.0%), ce_loss 0.789, lat_loss 6.683
09/19 08:01:32 AM | _theta_step_train: [ 83/180] Final Prec@1 82.0300% Time 126.92
09/19 08:01:38 AM | Valid: [ 83/180] Step 050/312 Loss 0.669 Prec@(1,3) (83.2%, 99.3%), ce_loss 0.789, lat_loss 6.683
09/19 08:01:42 AM | Valid: [ 83/180] Step 100/312 Loss 0.720 Prec@(1,3) (82.6%, 98.9%), ce_loss 0.789, lat_loss 6.683
09/19 08:01:47 AM | Valid: [ 83/180] Step 150/312 Loss 0.751 Prec@(1,3) (81.8%, 98.8%), ce_loss 0.789, lat_loss 6.683
09/19 08:01:52 AM | Valid: [ 83/180] Step 200/312 Loss 0.726 Prec@(1,3) (82.5%, 98.9%), ce_loss 0.789, lat_loss 6.683
09/19 08:01:56 AM | Valid: [ 83/180] Step 250/312 Loss 0.735 Prec@(1,3) (82.2%, 98.9%), ce_loss 0.788, lat_loss 6.683
09/19 08:02:01 AM | Valid: [ 83/180] Step 300/312 Loss 0.741 Prec@(1,3) (82.0%, 98.9%), ce_loss 0.788, lat_loss 6.683
09/19 08:02:02 AM | Valid: [ 83/180] Step 312/312 Loss 0.743 Prec@(1,3) (81.9%, 98.9%), ce_loss 0.788, lat_loss 6.683
09/19 08:02:02 AM | val: [ 83/180] Final Prec@1 81.9000% Time 30.00
09/19 08:02:02 AM | Start to train weights for epoch 83
09/19 08:02:28 AM | Train: [ 84/180] Step 050/1249 Loss 0.666 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.788, lat_loss 6.683
09/19 08:02:52 AM | Train: [ 84/180] Step 100/1249 Loss 0.679 Prec@(1,3) (82.9%, 98.9%), ce_loss 0.788, lat_loss 6.683
09/19 08:03:16 AM | Train: [ 84/180] Step 150/1249 Loss 0.642 Prec@(1,3) (83.9%, 99.0%), ce_loss 0.788, lat_loss 6.683
09/19 08:03:39 AM | Train: [ 84/180] Step 200/1249 Loss 0.638 Prec@(1,3) (84.1%, 99.1%), ce_loss 0.788, lat_loss 6.683
09/19 08:04:04 AM | Train: [ 84/180] Step 250/1249 Loss 0.624 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.788, lat_loss 6.683
09/19 08:04:28 AM | Train: [ 84/180] Step 300/1249 Loss 0.621 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.788, lat_loss 6.683
09/19 08:04:53 AM | Train: [ 84/180] Step 350/1249 Loss 0.623 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.788, lat_loss 6.683
09/19 08:05:17 AM | Train: [ 84/180] Step 400/1249 Loss 0.620 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.788, lat_loss 6.683
09/19 08:05:42 AM | Train: [ 84/180] Step 450/1249 Loss 0.618 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.787, lat_loss 6.683
09/19 08:06:06 AM | Train: [ 84/180] Step 500/1249 Loss 0.620 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.787, lat_loss 6.683
09/19 08:06:30 AM | Train: [ 84/180] Step 550/1249 Loss 0.625 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.787, lat_loss 6.683
09/19 08:06:53 AM | Train: [ 84/180] Step 600/1249 Loss 0.621 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.787, lat_loss 6.683
09/19 08:07:16 AM | Train: [ 84/180] Step 650/1249 Loss 0.617 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.787, lat_loss 6.683
09/19 08:07:41 AM | Train: [ 84/180] Step 700/1249 Loss 0.610 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.787, lat_loss 6.683
09/19 08:08:05 AM | Train: [ 84/180] Step 750/1249 Loss 0.610 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.787, lat_loss 6.683
09/19 08:08:29 AM | Train: [ 84/180] Step 800/1249 Loss 0.612 Prec@(1,3) (84.5%, 99.3%), ce_loss 0.787, lat_loss 6.683
09/19 08:08:52 AM | Train: [ 84/180] Step 850/1249 Loss 0.612 Prec@(1,3) (84.5%, 99.3%), ce_loss 0.787, lat_loss 6.683
09/19 08:09:15 AM | Train: [ 84/180] Step 900/1249 Loss 0.608 Prec@(1,3) (84.6%, 99.3%), ce_loss 0.786, lat_loss 6.683
09/19 08:09:37 AM | Train: [ 84/180] Step 950/1249 Loss 0.606 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.786, lat_loss 6.683
09/19 08:10:00 AM | Train: [ 84/180] Step 1000/1249 Loss 0.601 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.786, lat_loss 6.683
09/19 08:10:21 AM | Train: [ 84/180] Step 1050/1249 Loss 0.603 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.786, lat_loss 6.683
09/19 08:10:43 AM | Train: [ 84/180] Step 1100/1249 Loss 0.603 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.786, lat_loss 6.683
09/19 08:11:06 AM | Train: [ 84/180] Step 1150/1249 Loss 0.606 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.786, lat_loss 6.683
09/19 08:11:28 AM | Train: [ 84/180] Step 1200/1249 Loss 0.605 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.786, lat_loss 6.683
09/19 08:11:53 AM | Train: [ 84/180] Step 1249/1249 Loss 0.605 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.786, lat_loss 6.683
09/19 08:11:53 AM | _w_step_train: [ 84/180] Final Prec@1 84.7375% Time 590.95
09/19 08:11:53 AM | Start to train theta for epoch 83
09/19 08:12:14 AM | Train: [ 84/180] Step 050/312 Loss 0.713 Prec@(1,3) (82.2%, 99.1%), ce_loss 0.786, lat_loss 6.683
09/19 08:12:34 AM | Train: [ 84/180] Step 100/312 Loss 0.728 Prec@(1,3) (81.5%, 99.0%), ce_loss 0.785, lat_loss 6.683
09/19 08:12:55 AM | Train: [ 84/180] Step 150/312 Loss 0.711 Prec@(1,3) (81.7%, 99.0%), ce_loss 0.785, lat_loss 6.683
09/19 08:13:15 AM | Train: [ 84/180] Step 200/312 Loss 0.709 Prec@(1,3) (81.7%, 99.0%), ce_loss 0.785, lat_loss 6.683
09/19 08:13:36 AM | Train: [ 84/180] Step 250/312 Loss 0.712 Prec@(1,3) (81.7%, 98.9%), ce_loss 0.785, lat_loss 6.683
09/19 08:13:57 AM | Train: [ 84/180] Step 300/312 Loss 0.700 Prec@(1,3) (82.1%, 99.0%), ce_loss 0.785, lat_loss 6.683
09/19 08:14:02 AM | Train: [ 84/180] Step 312/312 Loss 0.705 Prec@(1,3) (82.0%, 99.0%), ce_loss 0.785, lat_loss 6.683
09/19 08:14:02 AM | _theta_step_train: [ 84/180] Final Prec@1 82.0200% Time 128.58
09/19 08:14:07 AM | Valid: [ 84/180] Step 050/312 Loss 0.922 Prec@(1,3) (77.4%, 97.4%), ce_loss 0.785, lat_loss 6.683
09/19 08:14:11 AM | Valid: [ 84/180] Step 100/312 Loss 0.894 Prec@(1,3) (78.4%, 97.4%), ce_loss 0.785, lat_loss 6.683
09/19 08:14:15 AM | Valid: [ 84/180] Step 150/312 Loss 0.849 Prec@(1,3) (79.3%, 97.8%), ce_loss 0.785, lat_loss 6.683
09/19 08:14:20 AM | Valid: [ 84/180] Step 200/312 Loss 0.818 Prec@(1,3) (80.3%, 98.2%), ce_loss 0.785, lat_loss 6.683
09/19 08:14:24 AM | Valid: [ 84/180] Step 250/312 Loss 0.799 Prec@(1,3) (80.5%, 98.4%), ce_loss 0.785, lat_loss 6.683
09/19 08:14:28 AM | Valid: [ 84/180] Step 300/312 Loss 0.782 Prec@(1,3) (80.9%, 98.5%), ce_loss 0.785, lat_loss 6.683
09/19 08:14:29 AM | Valid: [ 84/180] Step 312/312 Loss 0.779 Prec@(1,3) (80.9%, 98.5%), ce_loss 0.785, lat_loss 6.683
09/19 08:14:29 AM | val: [ 84/180] Final Prec@1 80.8800% Time 27.58
09/19 08:14:29 AM | Start to train weights for epoch 84
09/19 08:14:45 AM | Train: [ 85/180] Step 050/1249 Loss 0.579 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.785, lat_loss 6.683
09/19 08:14:59 AM | Train: [ 85/180] Step 100/1249 Loss 0.538 Prec@(1,3) (87.5%, 99.4%), ce_loss 0.784, lat_loss 6.683
09/19 08:15:14 AM | Train: [ 85/180] Step 150/1249 Loss 0.537 Prec@(1,3) (87.0%, 99.5%), ce_loss 0.784, lat_loss 6.683
09/19 08:15:28 AM | Train: [ 85/180] Step 200/1249 Loss 0.533 Prec@(1,3) (86.8%, 99.5%), ce_loss 0.784, lat_loss 6.683
09/19 08:15:43 AM | Train: [ 85/180] Step 250/1249 Loss 0.550 Prec@(1,3) (86.4%, 99.5%), ce_loss 0.784, lat_loss 6.683
09/19 08:15:58 AM | Train: [ 85/180] Step 300/1249 Loss 0.559 Prec@(1,3) (86.3%, 99.5%), ce_loss 0.784, lat_loss 6.683
09/19 08:16:12 AM | Train: [ 85/180] Step 350/1249 Loss 0.553 Prec@(1,3) (86.4%, 99.5%), ce_loss 0.784, lat_loss 6.683
09/19 08:16:27 AM | Train: [ 85/180] Step 400/1249 Loss 0.556 Prec@(1,3) (86.4%, 99.5%), ce_loss 0.784, lat_loss 6.683
09/19 08:16:41 AM | Train: [ 85/180] Step 450/1249 Loss 0.553 Prec@(1,3) (86.3%, 99.5%), ce_loss 0.784, lat_loss 6.683
09/19 08:16:56 AM | Train: [ 85/180] Step 500/1249 Loss 0.556 Prec@(1,3) (86.1%, 99.5%), ce_loss 0.783, lat_loss 6.683
09/19 08:17:10 AM | Train: [ 85/180] Step 550/1249 Loss 0.564 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.783, lat_loss 6.683
09/19 08:17:25 AM | Train: [ 85/180] Step 600/1249 Loss 0.565 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.783, lat_loss 6.683
09/19 08:17:39 AM | Train: [ 85/180] Step 650/1249 Loss 0.573 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.783, lat_loss 6.683
09/19 08:17:54 AM | Train: [ 85/180] Step 700/1249 Loss 0.576 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.783, lat_loss 6.683
09/19 08:18:08 AM | Train: [ 85/180] Step 750/1249 Loss 0.576 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.783, lat_loss 6.683
09/19 08:18:23 AM | Train: [ 85/180] Step 800/1249 Loss 0.576 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.783, lat_loss 6.683
09/19 08:18:37 AM | Train: [ 85/180] Step 850/1249 Loss 0.582 Prec@(1,3) (85.3%, 99.4%), ce_loss 0.783, lat_loss 6.683
09/19 08:18:52 AM | Train: [ 85/180] Step 900/1249 Loss 0.586 Prec@(1,3) (85.3%, 99.4%), ce_loss 0.783, lat_loss 6.683
09/19 08:19:06 AM | Train: [ 85/180] Step 950/1249 Loss 0.589 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.783, lat_loss 6.683
09/19 08:19:21 AM | Train: [ 85/180] Step 1000/1249 Loss 0.593 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.782, lat_loss 6.683
09/19 08:19:36 AM | Train: [ 85/180] Step 1050/1249 Loss 0.591 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.782, lat_loss 6.683
09/19 08:19:50 AM | Train: [ 85/180] Step 1100/1249 Loss 0.592 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.782, lat_loss 6.683
09/19 08:20:05 AM | Train: [ 85/180] Step 1150/1249 Loss 0.590 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.782, lat_loss 6.683
09/19 08:20:19 AM | Train: [ 85/180] Step 1200/1249 Loss 0.588 Prec@(1,3) (85.3%, 99.4%), ce_loss 0.782, lat_loss 6.683
09/19 08:20:33 AM | Train: [ 85/180] Step 1249/1249 Loss 0.587 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.782, lat_loss 6.683
09/19 08:20:33 AM | _w_step_train: [ 85/180] Final Prec@1 85.2725% Time 364.08
09/19 08:20:33 AM | Start to train theta for epoch 84
09/19 08:20:54 AM | Train: [ 85/180] Step 050/312 Loss 0.740 Prec@(1,3) (82.0%, 98.8%), ce_loss 0.782, lat_loss 6.683
09/19 08:21:10 AM | Train: [ 85/180] Step 100/312 Loss 0.719 Prec@(1,3) (82.8%, 98.9%), ce_loss 0.782, lat_loss 6.683
09/19 08:21:27 AM | Train: [ 85/180] Step 150/312 Loss 0.714 Prec@(1,3) (82.9%, 99.1%), ce_loss 0.782, lat_loss 6.683
09/19 08:21:45 AM | Train: [ 85/180] Step 200/312 Loss 0.738 Prec@(1,3) (82.2%, 98.9%), ce_loss 0.782, lat_loss 6.683
09/19 08:22:02 AM | Train: [ 85/180] Step 250/312 Loss 0.728 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.781, lat_loss 6.683
09/19 08:22:19 AM | Train: [ 85/180] Step 300/312 Loss 0.720 Prec@(1,3) (82.5%, 98.9%), ce_loss 0.781, lat_loss 6.683
09/19 08:22:24 AM | Train: [ 85/180] Step 312/312 Loss 0.719 Prec@(1,3) (82.5%, 98.9%), ce_loss 0.781, lat_loss 6.683
09/19 08:22:24 AM | _theta_step_train: [ 85/180] Final Prec@1 82.5300% Time 111.05
09/19 08:22:30 AM | Valid: [ 85/180] Step 050/312 Loss 0.735 Prec@(1,3) (81.6%, 98.8%), ce_loss 0.781, lat_loss 6.683
09/19 08:22:34 AM | Valid: [ 85/180] Step 100/312 Loss 0.795 Prec@(1,3) (79.7%, 98.5%), ce_loss 0.781, lat_loss 6.683
09/19 08:22:39 AM | Valid: [ 85/180] Step 150/312 Loss 0.766 Prec@(1,3) (81.1%, 98.4%), ce_loss 0.781, lat_loss 6.683
09/19 08:22:44 AM | Valid: [ 85/180] Step 200/312 Loss 0.818 Prec@(1,3) (80.4%, 98.2%), ce_loss 0.781, lat_loss 6.683
09/19 08:22:49 AM | Valid: [ 85/180] Step 250/312 Loss 0.822 Prec@(1,3) (80.6%, 98.1%), ce_loss 0.781, lat_loss 6.683
09/19 08:22:53 AM | Valid: [ 85/180] Step 300/312 Loss 0.810 Prec@(1,3) (80.8%, 98.2%), ce_loss 0.781, lat_loss 6.683
09/19 08:22:54 AM | Valid: [ 85/180] Step 312/312 Loss 0.812 Prec@(1,3) (80.7%, 98.2%), ce_loss 0.781, lat_loss 6.683
09/19 08:22:54 AM | val: [ 85/180] Final Prec@1 80.7000% Time 29.95
09/19 08:22:54 AM | Start to train weights for epoch 85
09/19 08:23:12 AM | Train: [ 86/180] Step 050/1249 Loss 0.557 Prec@(1,3) (86.3%, 99.6%), ce_loss 0.781, lat_loss 6.683
09/19 08:23:28 AM | Train: [ 86/180] Step 100/1249 Loss 0.580 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.781, lat_loss 6.683
09/19 08:23:48 AM | Train: [ 86/180] Step 150/1249 Loss 0.588 Prec@(1,3) (85.4%, 99.4%), ce_loss 0.781, lat_loss 6.683
09/19 08:24:04 AM | Train: [ 86/180] Step 200/1249 Loss 0.576 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.781, lat_loss 6.683
09/19 08:24:19 AM | Train: [ 86/180] Step 250/1249 Loss 0.585 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.780, lat_loss 6.683
09/19 08:24:35 AM | Train: [ 86/180] Step 300/1249 Loss 0.574 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.780, lat_loss 6.683
09/19 08:25:00 AM | Train: [ 86/180] Step 350/1249 Loss 0.575 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.780, lat_loss 6.683
09/19 08:25:25 AM | Train: [ 86/180] Step 400/1249 Loss 0.577 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.780, lat_loss 6.683
09/19 08:25:50 AM | Train: [ 86/180] Step 450/1249 Loss 0.580 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.780, lat_loss 6.683
09/19 08:26:15 AM | Train: [ 86/180] Step 500/1249 Loss 0.583 Prec@(1,3) (85.4%, 99.3%), ce_loss 0.780, lat_loss 6.683
09/19 08:26:40 AM | Train: [ 86/180] Step 550/1249 Loss 0.592 Prec@(1,3) (85.1%, 99.4%), ce_loss 0.780, lat_loss 6.683
09/19 08:27:05 AM | Train: [ 86/180] Step 600/1249 Loss 0.594 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.780, lat_loss 6.683
09/19 08:27:30 AM | Train: [ 86/180] Step 650/1249 Loss 0.597 Prec@(1,3) (84.9%, 99.4%), ce_loss 0.780, lat_loss 6.683
09/19 08:27:55 AM | Train: [ 86/180] Step 700/1249 Loss 0.597 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.779, lat_loss 6.683
09/19 08:28:19 AM | Train: [ 86/180] Step 750/1249 Loss 0.595 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.779, lat_loss 6.683
09/19 08:28:44 AM | Train: [ 86/180] Step 800/1249 Loss 0.596 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.779, lat_loss 6.683
09/19 08:29:09 AM | Train: [ 86/180] Step 850/1249 Loss 0.593 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.779, lat_loss 6.683
09/19 08:29:34 AM | Train: [ 86/180] Step 900/1249 Loss 0.589 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.779, lat_loss 6.683
09/19 08:29:55 AM | Train: [ 86/180] Step 950/1249 Loss 0.588 Prec@(1,3) (85.1%, 99.4%), ce_loss 0.779, lat_loss 6.683
09/19 08:30:11 AM | Train: [ 86/180] Step 1000/1249 Loss 0.591 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.779, lat_loss 6.683
09/19 08:30:27 AM | Train: [ 86/180] Step 1050/1249 Loss 0.591 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.779, lat_loss 6.683
09/19 08:30:43 AM | Train: [ 86/180] Step 1100/1249 Loss 0.591 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.779, lat_loss 6.683
09/19 08:30:59 AM | Train: [ 86/180] Step 1150/1249 Loss 0.590 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.778, lat_loss 6.683
09/19 08:31:15 AM | Train: [ 86/180] Step 1200/1249 Loss 0.587 Prec@(1,3) (85.2%, 99.3%), ce_loss 0.778, lat_loss 6.683
09/19 08:31:30 AM | Train: [ 86/180] Step 1249/1249 Loss 0.589 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.778, lat_loss 6.683
09/19 08:31:30 AM | _w_step_train: [ 86/180] Final Prec@1 85.1875% Time 515.93
09/19 08:31:30 AM | Start to train theta for epoch 85
09/19 08:31:52 AM | Train: [ 86/180] Step 050/312 Loss 0.677 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.778, lat_loss 6.683
09/19 08:32:13 AM | Train: [ 86/180] Step 100/312 Loss 0.755 Prec@(1,3) (80.7%, 98.8%), ce_loss 0.778, lat_loss 6.683
09/19 08:32:33 AM | Train: [ 86/180] Step 150/312 Loss 0.739 Prec@(1,3) (81.1%, 99.0%), ce_loss 0.778, lat_loss 6.683
09/19 08:32:54 AM | Train: [ 86/180] Step 200/312 Loss 0.726 Prec@(1,3) (81.6%, 98.9%), ce_loss 0.778, lat_loss 6.683
09/19 08:33:15 AM | Train: [ 86/180] Step 250/312 Loss 0.748 Prec@(1,3) (81.2%, 98.7%), ce_loss 0.778, lat_loss 6.683
09/19 08:33:36 AM | Train: [ 86/180] Step 300/312 Loss 0.738 Prec@(1,3) (81.6%, 98.7%), ce_loss 0.778, lat_loss 6.683
09/19 08:33:41 AM | Train: [ 86/180] Step 312/312 Loss 0.731 Prec@(1,3) (81.8%, 98.8%), ce_loss 0.778, lat_loss 6.683
09/19 08:33:41 AM | _theta_step_train: [ 86/180] Final Prec@1 81.7900% Time 130.32
09/19 08:33:46 AM | Valid: [ 86/180] Step 050/312 Loss 0.713 Prec@(1,3) (82.5%, 99.3%), ce_loss 0.778, lat_loss 6.683
09/19 08:33:50 AM | Valid: [ 86/180] Step 100/312 Loss 0.755 Prec@(1,3) (81.6%, 98.6%), ce_loss 0.778, lat_loss 6.683
09/19 08:33:55 AM | Valid: [ 86/180] Step 150/312 Loss 0.744 Prec@(1,3) (81.8%, 98.4%), ce_loss 0.778, lat_loss 6.683
09/19 08:34:00 AM | Valid: [ 86/180] Step 200/312 Loss 0.748 Prec@(1,3) (81.7%, 98.5%), ce_loss 0.777, lat_loss 6.683
09/19 08:34:04 AM | Valid: [ 86/180] Step 250/312 Loss 0.759 Prec@(1,3) (81.4%, 98.4%), ce_loss 0.777, lat_loss 6.683
09/19 08:34:09 AM | Valid: [ 86/180] Step 300/312 Loss 0.746 Prec@(1,3) (81.5%, 98.5%), ce_loss 0.777, lat_loss 6.683
09/19 08:34:10 AM | Valid: [ 86/180] Step 312/312 Loss 0.748 Prec@(1,3) (81.4%, 98.5%), ce_loss 0.777, lat_loss 6.683
09/19 08:34:10 AM | val: [ 86/180] Final Prec@1 81.3700% Time 29.44
09/19 08:34:10 AM | Start to train weights for epoch 86
09/19 08:34:36 AM | Train: [ 87/180] Step 050/1249 Loss 0.594 Prec@(1,3) (84.9%, 99.2%), ce_loss 0.777, lat_loss 6.683
09/19 08:35:01 AM | Train: [ 87/180] Step 100/1249 Loss 0.548 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.777, lat_loss 6.683
09/19 08:35:25 AM | Train: [ 87/180] Step 150/1249 Loss 0.538 Prec@(1,3) (86.3%, 99.5%), ce_loss 0.777, lat_loss 6.683
09/19 08:35:48 AM | Train: [ 87/180] Step 200/1249 Loss 0.545 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.777, lat_loss 6.683
09/19 08:36:12 AM | Train: [ 87/180] Step 250/1249 Loss 0.564 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.777, lat_loss 6.683
09/19 08:36:36 AM | Train: [ 87/180] Step 300/1249 Loss 0.563 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.777, lat_loss 6.683
09/19 08:36:59 AM | Train: [ 87/180] Step 350/1249 Loss 0.564 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.777, lat_loss 6.683
09/19 08:37:22 AM | Train: [ 87/180] Step 400/1249 Loss 0.560 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.776, lat_loss 6.683
09/19 08:37:47 AM | Train: [ 87/180] Step 450/1249 Loss 0.559 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.776, lat_loss 6.683
09/19 08:38:12 AM | Train: [ 87/180] Step 500/1249 Loss 0.559 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.776, lat_loss 6.683
09/19 08:38:35 AM | Train: [ 87/180] Step 550/1249 Loss 0.559 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.776, lat_loss 6.683
09/19 08:39:00 AM | Train: [ 87/180] Step 600/1249 Loss 0.562 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.776, lat_loss 6.683
09/19 08:39:24 AM | Train: [ 87/180] Step 650/1249 Loss 0.564 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.776, lat_loss 6.683
09/19 08:39:48 AM | Train: [ 87/180] Step 700/1249 Loss 0.566 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.776, lat_loss 6.683
09/19 08:40:12 AM | Train: [ 87/180] Step 750/1249 Loss 0.567 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.776, lat_loss 6.683
09/19 08:40:33 AM | Train: [ 87/180] Step 800/1249 Loss 0.564 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.775, lat_loss 6.683
09/19 08:40:57 AM | Train: [ 87/180] Step 850/1249 Loss 0.562 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.775, lat_loss 6.683
09/19 08:41:20 AM | Train: [ 87/180] Step 900/1249 Loss 0.563 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.775, lat_loss 6.683
09/19 08:41:44 AM | Train: [ 87/180] Step 950/1249 Loss 0.570 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.775, lat_loss 6.683
09/19 08:42:07 AM | Train: [ 87/180] Step 1000/1249 Loss 0.569 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.775, lat_loss 6.683
09/19 08:42:31 AM | Train: [ 87/180] Step 1050/1249 Loss 0.567 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.775, lat_loss 6.683
09/19 08:42:54 AM | Train: [ 87/180] Step 1100/1249 Loss 0.567 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.775, lat_loss 6.683
09/19 08:43:17 AM | Train: [ 87/180] Step 1150/1249 Loss 0.570 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.775, lat_loss 6.683
09/19 08:43:42 AM | Train: [ 87/180] Step 1200/1249 Loss 0.571 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.775, lat_loss 6.683
09/19 08:44:06 AM | Train: [ 87/180] Step 1249/1249 Loss 0.573 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.775, lat_loss 6.683
09/19 08:44:07 AM | _w_step_train: [ 87/180] Final Prec@1 85.5425% Time 596.46
09/19 08:44:07 AM | Start to train theta for epoch 86
09/19 08:44:25 AM | Train: [ 87/180] Step 050/312 Loss 0.731 Prec@(1,3) (80.8%, 98.6%), ce_loss 0.774, lat_loss 6.683
09/19 08:44:43 AM | Train: [ 87/180] Step 100/312 Loss 0.715 Prec@(1,3) (81.7%, 98.7%), ce_loss 0.774, lat_loss 6.683
09/19 08:45:00 AM | Train: [ 87/180] Step 150/312 Loss 0.716 Prec@(1,3) (81.9%, 98.8%), ce_loss 0.774, lat_loss 6.683
09/19 08:45:20 AM | Train: [ 87/180] Step 200/312 Loss 0.717 Prec@(1,3) (81.9%, 98.7%), ce_loss 0.774, lat_loss 6.683
09/19 08:45:39 AM | Train: [ 87/180] Step 250/312 Loss 0.713 Prec@(1,3) (82.2%, 98.7%), ce_loss 0.774, lat_loss 6.683
09/19 08:45:59 AM | Train: [ 87/180] Step 300/312 Loss 0.705 Prec@(1,3) (82.6%, 98.7%), ce_loss 0.774, lat_loss 6.683
09/19 08:46:04 AM | Train: [ 87/180] Step 312/312 Loss 0.707 Prec@(1,3) (82.5%, 98.7%), ce_loss 0.774, lat_loss 6.683
09/19 08:46:04 AM | _theta_step_train: [ 87/180] Final Prec@1 82.5200% Time 117.42
09/19 08:46:09 AM | Valid: [ 87/180] Step 050/312 Loss 0.708 Prec@(1,3) (81.6%, 99.3%), ce_loss 0.774, lat_loss 6.683
09/19 08:46:14 AM | Valid: [ 87/180] Step 100/312 Loss 0.730 Prec@(1,3) (81.7%, 98.8%), ce_loss 0.774, lat_loss 6.683
09/19 08:46:19 AM | Valid: [ 87/180] Step 150/312 Loss 0.742 Prec@(1,3) (81.5%, 98.8%), ce_loss 0.774, lat_loss 6.683
09/19 08:46:23 AM | Valid: [ 87/180] Step 200/312 Loss 0.746 Prec@(1,3) (81.4%, 98.7%), ce_loss 0.774, lat_loss 6.683
09/19 08:46:28 AM | Valid: [ 87/180] Step 250/312 Loss 0.744 Prec@(1,3) (81.2%, 98.7%), ce_loss 0.774, lat_loss 6.683
09/19 08:46:32 AM | Valid: [ 87/180] Step 300/312 Loss 0.762 Prec@(1,3) (80.9%, 98.4%), ce_loss 0.774, lat_loss 6.683
09/19 08:46:34 AM | Valid: [ 87/180] Step 312/312 Loss 0.759 Prec@(1,3) (80.9%, 98.5%), ce_loss 0.774, lat_loss 6.683
09/19 08:46:34 AM | val: [ 87/180] Final Prec@1 80.9300% Time 29.61
09/19 08:46:34 AM | Start to train weights for epoch 87
09/19 08:46:59 AM | Train: [ 88/180] Step 050/1249 Loss 0.547 Prec@(1,3) (86.9%, 99.3%), ce_loss 0.773, lat_loss 6.683
09/19 08:47:19 AM | Train: [ 88/180] Step 100/1249 Loss 0.551 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.773, lat_loss 6.683
09/19 08:47:40 AM | Train: [ 88/180] Step 150/1249 Loss 0.546 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.773, lat_loss 6.683
09/19 08:48:00 AM | Train: [ 88/180] Step 200/1249 Loss 0.554 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.773, lat_loss 6.683
09/19 08:48:21 AM | Train: [ 88/180] Step 250/1249 Loss 0.558 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.773, lat_loss 6.683
09/19 08:48:42 AM | Train: [ 88/180] Step 300/1249 Loss 0.552 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.773, lat_loss 6.683
09/19 08:49:02 AM | Train: [ 88/180] Step 350/1249 Loss 0.557 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.773, lat_loss 6.683
09/19 08:49:22 AM | Train: [ 88/180] Step 400/1249 Loss 0.557 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.773, lat_loss 6.683
09/19 08:49:44 AM | Train: [ 88/180] Step 450/1249 Loss 0.559 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.773, lat_loss 6.683
09/19 08:50:04 AM | Train: [ 88/180] Step 500/1249 Loss 0.560 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.772, lat_loss 6.683
09/19 08:50:25 AM | Train: [ 88/180] Step 550/1249 Loss 0.556 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.772, lat_loss 6.683
09/19 08:50:45 AM | Train: [ 88/180] Step 600/1249 Loss 0.557 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.772, lat_loss 6.683
09/19 08:51:07 AM | Train: [ 88/180] Step 650/1249 Loss 0.554 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.772, lat_loss 6.683
09/19 08:51:32 AM | Train: [ 88/180] Step 700/1249 Loss 0.554 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.772, lat_loss 6.683
09/19 08:51:57 AM | Train: [ 88/180] Step 750/1249 Loss 0.559 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.772, lat_loss 6.683
09/19 08:52:21 AM | Train: [ 88/180] Step 800/1249 Loss 0.559 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.772, lat_loss 6.683
09/19 08:52:46 AM | Train: [ 88/180] Step 850/1249 Loss 0.564 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.772, lat_loss 6.683
09/19 08:53:10 AM | Train: [ 88/180] Step 900/1249 Loss 0.564 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.772, lat_loss 6.683
09/19 08:53:34 AM | Train: [ 88/180] Step 950/1249 Loss 0.569 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.772, lat_loss 6.683
09/19 08:53:59 AM | Train: [ 88/180] Step 1000/1249 Loss 0.569 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.771, lat_loss 6.683
09/19 08:54:23 AM | Train: [ 88/180] Step 1050/1249 Loss 0.568 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.771, lat_loss 6.683
09/19 08:54:48 AM | Train: [ 88/180] Step 1100/1249 Loss 0.570 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.771, lat_loss 6.683
09/19 08:55:09 AM | Train: [ 88/180] Step 1150/1249 Loss 0.569 Prec@(1,3) (85.5%, 99.4%), ce_loss 0.771, lat_loss 6.683
09/19 08:55:30 AM | Train: [ 88/180] Step 1200/1249 Loss 0.567 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.771, lat_loss 6.683
09/19 08:55:55 AM | Train: [ 88/180] Step 1249/1249 Loss 0.564 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.771, lat_loss 6.683
09/19 08:55:55 AM | _w_step_train: [ 88/180] Final Prec@1 85.6275% Time 561.24
09/19 08:55:55 AM | Start to train theta for epoch 87
09/19 08:56:16 AM | Train: [ 88/180] Step 050/312 Loss 0.742 Prec@(1,3) (81.0%, 98.8%), ce_loss 0.771, lat_loss 6.683
09/19 08:56:36 AM | Train: [ 88/180] Step 100/312 Loss 0.729 Prec@(1,3) (82.1%, 98.9%), ce_loss 0.771, lat_loss 6.683
09/19 08:56:56 AM | Train: [ 88/180] Step 150/312 Loss 0.705 Prec@(1,3) (82.7%, 98.9%), ce_loss 0.771, lat_loss 6.683
09/19 08:57:16 AM | Train: [ 88/180] Step 200/312 Loss 0.689 Prec@(1,3) (82.9%, 98.9%), ce_loss 0.771, lat_loss 6.683
09/19 08:57:37 AM | Train: [ 88/180] Step 250/312 Loss 0.682 Prec@(1,3) (83.2%, 98.9%), ce_loss 0.770, lat_loss 6.683
09/19 08:57:57 AM | Train: [ 88/180] Step 300/312 Loss 0.682 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.770, lat_loss 6.683
09/19 08:58:02 AM | Train: [ 88/180] Step 312/312 Loss 0.682 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.770, lat_loss 6.683
09/19 08:58:03 AM | _theta_step_train: [ 88/180] Final Prec@1 83.1100% Time 127.76
09/19 08:58:08 AM | Valid: [ 88/180] Step 050/312 Loss 0.798 Prec@(1,3) (81.4%, 98.5%), ce_loss 0.770, lat_loss 6.683
09/19 08:58:13 AM | Valid: [ 88/180] Step 100/312 Loss 0.777 Prec@(1,3) (81.4%, 98.7%), ce_loss 0.770, lat_loss 6.683
09/19 08:58:17 AM | Valid: [ 88/180] Step 150/312 Loss 0.783 Prec@(1,3) (81.3%, 98.7%), ce_loss 0.770, lat_loss 6.683
09/19 08:58:22 AM | Valid: [ 88/180] Step 200/312 Loss 0.770 Prec@(1,3) (81.5%, 98.8%), ce_loss 0.770, lat_loss 6.683
09/19 08:58:26 AM | Valid: [ 88/180] Step 250/312 Loss 0.763 Prec@(1,3) (81.5%, 98.8%), ce_loss 0.770, lat_loss 6.683
09/19 08:58:31 AM | Valid: [ 88/180] Step 300/312 Loss 0.744 Prec@(1,3) (81.9%, 98.9%), ce_loss 0.770, lat_loss 6.683
09/19 08:58:32 AM | Valid: [ 88/180] Step 312/312 Loss 0.747 Prec@(1,3) (81.8%, 98.9%), ce_loss 0.770, lat_loss 6.683
09/19 08:58:32 AM | val: [ 88/180] Final Prec@1 81.7600% Time 29.47
09/19 08:58:32 AM | Start to train weights for epoch 88
09/19 08:58:58 AM | Train: [ 89/180] Step 050/1249 Loss 0.476 Prec@(1,3) (87.7%, 99.7%), ce_loss 0.770, lat_loss 6.683
09/19 08:59:23 AM | Train: [ 89/180] Step 100/1249 Loss 0.525 Prec@(1,3) (86.4%, 99.5%), ce_loss 0.770, lat_loss 6.683
09/19 08:59:48 AM | Train: [ 89/180] Step 150/1249 Loss 0.516 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.770, lat_loss 6.683
09/19 09:00:13 AM | Train: [ 89/180] Step 200/1249 Loss 0.521 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.769, lat_loss 6.683
09/19 09:00:34 AM | Train: [ 89/180] Step 250/1249 Loss 0.514 Prec@(1,3) (86.8%, 99.5%), ce_loss 0.769, lat_loss 6.683
09/19 09:00:58 AM | Train: [ 89/180] Step 300/1249 Loss 0.539 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.769, lat_loss 6.683
09/19 09:01:22 AM | Train: [ 89/180] Step 350/1249 Loss 0.546 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.769, lat_loss 6.683
09/19 09:01:43 AM | Train: [ 89/180] Step 400/1249 Loss 0.552 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.769, lat_loss 6.683
09/19 09:02:08 AM | Train: [ 89/180] Step 450/1249 Loss 0.546 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.769, lat_loss 6.683
09/19 09:02:32 AM | Train: [ 89/180] Step 500/1249 Loss 0.542 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.769, lat_loss 6.683
09/19 09:02:56 AM | Train: [ 89/180] Step 550/1249 Loss 0.549 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.769, lat_loss 6.683
09/19 09:03:21 AM | Train: [ 89/180] Step 600/1249 Loss 0.551 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.769, lat_loss 6.683
09/19 09:03:45 AM | Train: [ 89/180] Step 650/1249 Loss 0.550 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.768, lat_loss 6.683
09/19 09:04:10 AM | Train: [ 89/180] Step 700/1249 Loss 0.549 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.768, lat_loss 6.683
09/19 09:04:35 AM | Train: [ 89/180] Step 750/1249 Loss 0.547 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.768, lat_loss 6.683
09/19 09:04:59 AM | Train: [ 89/180] Step 800/1249 Loss 0.547 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.768, lat_loss 6.683
09/19 09:05:24 AM | Train: [ 89/180] Step 850/1249 Loss 0.552 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.768, lat_loss 6.683
09/19 09:05:49 AM | Train: [ 89/180] Step 900/1249 Loss 0.554 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.768, lat_loss 6.683
09/19 09:06:14 AM | Train: [ 89/180] Step 950/1249 Loss 0.555 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.768, lat_loss 6.683
09/19 09:06:39 AM | Train: [ 89/180] Step 1000/1249 Loss 0.554 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.768, lat_loss 6.683
09/19 09:07:04 AM | Train: [ 89/180] Step 1050/1249 Loss 0.554 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.768, lat_loss 6.683
09/19 09:07:29 AM | Train: [ 89/180] Step 1100/1249 Loss 0.557 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.767, lat_loss 6.683
09/19 09:07:54 AM | Train: [ 89/180] Step 1150/1249 Loss 0.556 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.767, lat_loss 6.683
09/19 09:08:19 AM | Train: [ 89/180] Step 1200/1249 Loss 0.556 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.767, lat_loss 6.683
09/19 09:08:43 AM | Train: [ 89/180] Step 1249/1249 Loss 0.559 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.767, lat_loss 6.683
09/19 09:08:43 AM | _w_step_train: [ 89/180] Final Prec@1 85.7600% Time 610.95
09/19 09:08:43 AM | Start to train theta for epoch 88
09/19 09:09:05 AM | Train: [ 89/180] Step 050/312 Loss 0.692 Prec@(1,3) (82.9%, 99.0%), ce_loss 0.767, lat_loss 6.683
09/19 09:09:25 AM | Train: [ 89/180] Step 100/312 Loss 0.709 Prec@(1,3) (82.3%, 98.9%), ce_loss 0.767, lat_loss 6.683
09/19 09:09:46 AM | Train: [ 89/180] Step 150/312 Loss 0.706 Prec@(1,3) (82.7%, 98.9%), ce_loss 0.767, lat_loss 6.683
09/19 09:10:06 AM | Train: [ 89/180] Step 200/312 Loss 0.692 Prec@(1,3) (82.8%, 99.0%), ce_loss 0.767, lat_loss 6.683
09/19 09:10:26 AM | Train: [ 89/180] Step 250/312 Loss 0.695 Prec@(1,3) (82.6%, 98.9%), ce_loss 0.767, lat_loss 6.683
09/19 09:10:46 AM | Train: [ 89/180] Step 300/312 Loss 0.703 Prec@(1,3) (82.5%, 98.9%), ce_loss 0.767, lat_loss 6.683
09/19 09:10:51 AM | Train: [ 89/180] Step 312/312 Loss 0.702 Prec@(1,3) (82.5%, 98.9%), ce_loss 0.767, lat_loss 6.683
09/19 09:10:51 AM | _theta_step_train: [ 89/180] Final Prec@1 82.5100% Time 128.10
09/19 09:10:57 AM | Valid: [ 89/180] Step 050/312 Loss 0.764 Prec@(1,3) (82.7%, 98.5%), ce_loss 0.767, lat_loss 6.683
09/19 09:11:01 AM | Valid: [ 89/180] Step 100/312 Loss 0.734 Prec@(1,3) (83.2%, 98.6%), ce_loss 0.767, lat_loss 6.683
09/19 09:11:06 AM | Valid: [ 89/180] Step 150/312 Loss 0.722 Prec@(1,3) (83.4%, 98.7%), ce_loss 0.766, lat_loss 6.683
09/19 09:11:10 AM | Valid: [ 89/180] Step 200/312 Loss 0.701 Prec@(1,3) (83.8%, 98.9%), ce_loss 0.766, lat_loss 6.683
09/19 09:11:15 AM | Valid: [ 89/180] Step 250/312 Loss 0.707 Prec@(1,3) (83.6%, 98.8%), ce_loss 0.766, lat_loss 6.683
09/19 09:11:19 AM | Valid: [ 89/180] Step 300/312 Loss 0.699 Prec@(1,3) (83.6%, 98.8%), ce_loss 0.766, lat_loss 6.683
09/19 09:11:20 AM | Valid: [ 89/180] Step 312/312 Loss 0.697 Prec@(1,3) (83.6%, 98.9%), ce_loss 0.766, lat_loss 6.683
09/19 09:11:20 AM | val: [ 89/180] Final Prec@1 83.5700% Time 29.22
09/19 09:11:20 AM | Best top1 acc by now. Save model
09/19 09:11:21 AM | Start to train weights for epoch 89
09/19 09:11:47 AM | Train: [ 90/180] Step 050/1249 Loss 0.681 Prec@(1,3) (83.9%, 98.5%), ce_loss 0.766, lat_loss 6.683
09/19 09:12:10 AM | Train: [ 90/180] Step 100/1249 Loss 0.615 Prec@(1,3) (84.9%, 98.9%), ce_loss 0.766, lat_loss 6.683
09/19 09:12:34 AM | Train: [ 90/180] Step 150/1249 Loss 0.595 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.766, lat_loss 6.683
09/19 09:12:59 AM | Train: [ 90/180] Step 200/1249 Loss 0.576 Prec@(1,3) (85.8%, 99.1%), ce_loss 0.766, lat_loss 6.683
09/19 09:13:24 AM | Train: [ 90/180] Step 250/1249 Loss 0.563 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.766, lat_loss 6.683
09/19 09:13:48 AM | Train: [ 90/180] Step 300/1249 Loss 0.568 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.766, lat_loss 6.683
09/19 09:14:13 AM | Train: [ 90/180] Step 350/1249 Loss 0.560 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.765, lat_loss 6.683
09/19 09:14:34 AM | Train: [ 90/180] Step 400/1249 Loss 0.556 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.765, lat_loss 6.683
09/19 09:14:54 AM | Train: [ 90/180] Step 450/1249 Loss 0.559 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.765, lat_loss 6.683
09/19 09:15:15 AM | Train: [ 90/180] Step 500/1249 Loss 0.566 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.765, lat_loss 6.683
09/19 09:15:40 AM | Train: [ 90/180] Step 550/1249 Loss 0.561 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.765, lat_loss 6.683
09/19 09:16:05 AM | Train: [ 90/180] Step 600/1249 Loss 0.560 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.765, lat_loss 6.683
09/19 09:16:29 AM | Train: [ 90/180] Step 650/1249 Loss 0.559 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.765, lat_loss 6.683
09/19 09:16:54 AM | Train: [ 90/180] Step 700/1249 Loss 0.557 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.765, lat_loss 6.683
09/19 09:17:18 AM | Train: [ 90/180] Step 750/1249 Loss 0.555 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.765, lat_loss 6.683
09/19 09:17:43 AM | Train: [ 90/180] Step 800/1249 Loss 0.556 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.764, lat_loss 6.683
09/19 09:18:07 AM | Train: [ 90/180] Step 850/1249 Loss 0.556 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.764, lat_loss 6.683
09/19 09:18:31 AM | Train: [ 90/180] Step 900/1249 Loss 0.554 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.764, lat_loss 6.683
09/19 09:18:55 AM | Train: [ 90/180] Step 950/1249 Loss 0.553 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.764, lat_loss 6.683
09/19 09:19:19 AM | Train: [ 90/180] Step 1000/1249 Loss 0.554 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.764, lat_loss 6.683
09/19 09:19:43 AM | Train: [ 90/180] Step 1050/1249 Loss 0.553 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.764, lat_loss 6.683
09/19 09:20:07 AM | Train: [ 90/180] Step 1100/1249 Loss 0.551 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.764, lat_loss 6.683
09/19 09:20:32 AM | Train: [ 90/180] Step 1150/1249 Loss 0.552 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.764, lat_loss 6.683
09/19 09:20:56 AM | Train: [ 90/180] Step 1200/1249 Loss 0.554 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.764, lat_loss 6.683
09/19 09:21:21 AM | Train: [ 90/180] Step 1249/1249 Loss 0.553 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.763, lat_loss 6.683
09/19 09:21:21 AM | _w_step_train: [ 90/180] Final Prec@1 85.9650% Time 600.05
09/19 09:21:21 AM | Start to train theta for epoch 89
09/19 09:21:42 AM | Train: [ 90/180] Step 050/312 Loss 0.649 Prec@(1,3) (84.9%, 99.0%), ce_loss 0.763, lat_loss 6.683
09/19 09:22:03 AM | Train: [ 90/180] Step 100/312 Loss 0.703 Prec@(1,3) (83.2%, 98.9%), ce_loss 0.763, lat_loss 6.683
09/19 09:22:23 AM | Train: [ 90/180] Step 150/312 Loss 0.683 Prec@(1,3) (83.2%, 99.0%), ce_loss 0.763, lat_loss 6.683
09/19 09:22:44 AM | Train: [ 90/180] Step 200/312 Loss 0.690 Prec@(1,3) (83.1%, 98.9%), ce_loss 0.763, lat_loss 6.683
09/19 09:23:05 AM | Train: [ 90/180] Step 250/312 Loss 0.684 Prec@(1,3) (83.3%, 98.9%), ce_loss 0.763, lat_loss 6.683
09/19 09:23:26 AM | Train: [ 90/180] Step 300/312 Loss 0.685 Prec@(1,3) (83.3%, 98.9%), ce_loss 0.763, lat_loss 6.683
09/19 09:23:31 AM | Train: [ 90/180] Step 312/312 Loss 0.682 Prec@(1,3) (83.4%, 98.9%), ce_loss 0.763, lat_loss 6.683
09/19 09:23:32 AM | _theta_step_train: [ 90/180] Final Prec@1 83.4000% Time 130.80
09/19 09:23:37 AM | Valid: [ 90/180] Step 050/312 Loss 0.698 Prec@(1,3) (83.4%, 99.2%), ce_loss 0.763, lat_loss 6.683
09/19 09:23:42 AM | Valid: [ 90/180] Step 100/312 Loss 0.687 Prec@(1,3) (83.5%, 99.0%), ce_loss 0.763, lat_loss 6.683
09/19 09:23:46 AM | Valid: [ 90/180] Step 150/312 Loss 0.689 Prec@(1,3) (83.5%, 98.9%), ce_loss 0.763, lat_loss 6.683
09/19 09:23:51 AM | Valid: [ 90/180] Step 200/312 Loss 0.734 Prec@(1,3) (82.6%, 98.7%), ce_loss 0.763, lat_loss 6.683
09/19 09:23:55 AM | Valid: [ 90/180] Step 250/312 Loss 0.736 Prec@(1,3) (82.7%, 98.8%), ce_loss 0.763, lat_loss 6.683
09/19 09:24:00 AM | Valid: [ 90/180] Step 300/312 Loss 0.709 Prec@(1,3) (83.1%, 98.9%), ce_loss 0.763, lat_loss 6.683
09/19 09:24:01 AM | Valid: [ 90/180] Step 312/312 Loss 0.708 Prec@(1,3) (83.1%, 98.9%), ce_loss 0.763, lat_loss 6.683
09/19 09:24:01 AM | val: [ 90/180] Final Prec@1 83.1400% Time 29.66
09/19 09:24:01 AM | Start to train weights for epoch 90
09/19 09:24:27 AM | Train: [ 91/180] Step 050/1249 Loss 0.516 Prec@(1,3) (87.4%, 99.4%), ce_loss 0.762, lat_loss 6.683
09/19 09:24:51 AM | Train: [ 91/180] Step 100/1249 Loss 0.508 Prec@(1,3) (87.4%, 99.3%), ce_loss 0.762, lat_loss 6.683
09/19 09:25:14 AM | Train: [ 91/180] Step 150/1249 Loss 0.506 Prec@(1,3) (87.4%, 99.4%), ce_loss 0.762, lat_loss 6.683
09/19 09:25:38 AM | Train: [ 91/180] Step 200/1249 Loss 0.519 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.762, lat_loss 6.683
09/19 09:26:02 AM | Train: [ 91/180] Step 250/1249 Loss 0.514 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.762, lat_loss 6.683
09/19 09:26:26 AM | Train: [ 91/180] Step 300/1249 Loss 0.521 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.762, lat_loss 6.683
09/19 09:26:50 AM | Train: [ 91/180] Step 350/1249 Loss 0.539 Prec@(1,3) (86.7%, 99.3%), ce_loss 0.762, lat_loss 6.683
09/19 09:27:14 AM | Train: [ 91/180] Step 400/1249 Loss 0.541 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.762, lat_loss 6.683
09/19 09:27:38 AM | Train: [ 91/180] Step 450/1249 Loss 0.540 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.762, lat_loss 6.683
09/19 09:28:02 AM | Train: [ 91/180] Step 500/1249 Loss 0.547 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.761, lat_loss 6.683
09/19 09:28:25 AM | Train: [ 91/180] Step 550/1249 Loss 0.546 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.761, lat_loss 6.683
09/19 09:28:49 AM | Train: [ 91/180] Step 600/1249 Loss 0.552 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.761, lat_loss 6.683
09/19 09:29:13 AM | Train: [ 91/180] Step 650/1249 Loss 0.549 Prec@(1,3) (86.4%, 99.3%), ce_loss 0.761, lat_loss 6.683
09/19 09:29:36 AM | Train: [ 91/180] Step 700/1249 Loss 0.551 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.761, lat_loss 6.683
09/19 09:29:59 AM | Train: [ 91/180] Step 750/1249 Loss 0.555 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.761, lat_loss 6.683
09/19 09:30:23 AM | Train: [ 91/180] Step 800/1249 Loss 0.555 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.761, lat_loss 6.683
09/19 09:30:46 AM | Train: [ 91/180] Step 850/1249 Loss 0.556 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.761, lat_loss 6.683
09/19 09:31:10 AM | Train: [ 91/180] Step 900/1249 Loss 0.556 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.761, lat_loss 6.683
09/19 09:31:33 AM | Train: [ 91/180] Step 950/1249 Loss 0.554 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.761, lat_loss 6.683
09/19 09:31:57 AM | Train: [ 91/180] Step 1000/1249 Loss 0.556 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.760, lat_loss 6.683
09/19 09:32:20 AM | Train: [ 91/180] Step 1050/1249 Loss 0.555 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.760, lat_loss 6.683
09/19 09:32:42 AM | Train: [ 91/180] Step 1100/1249 Loss 0.556 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.760, lat_loss 6.683
09/19 09:33:04 AM | Train: [ 91/180] Step 1150/1249 Loss 0.557 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.760, lat_loss 6.683
09/19 09:33:26 AM | Train: [ 91/180] Step 1200/1249 Loss 0.555 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.760, lat_loss 6.683
09/19 09:33:48 AM | Train: [ 91/180] Step 1249/1249 Loss 0.554 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.760, lat_loss 6.683
09/19 09:33:48 AM | _w_step_train: [ 91/180] Final Prec@1 86.1750% Time 586.99
09/19 09:33:48 AM | Start to train theta for epoch 90
09/19 09:34:06 AM | Train: [ 91/180] Step 050/312 Loss 0.717 Prec@(1,3) (82.3%, 99.0%), ce_loss 0.760, lat_loss 6.683
09/19 09:34:25 AM | Train: [ 91/180] Step 100/312 Loss 0.727 Prec@(1,3) (81.8%, 98.8%), ce_loss 0.760, lat_loss 6.683
09/19 09:34:46 AM | Train: [ 91/180] Step 150/312 Loss 0.710 Prec@(1,3) (82.4%, 98.9%), ce_loss 0.760, lat_loss 6.683
09/19 09:35:06 AM | Train: [ 91/180] Step 200/312 Loss 0.708 Prec@(1,3) (82.5%, 98.9%), ce_loss 0.760, lat_loss 6.683
09/19 09:35:27 AM | Train: [ 91/180] Step 250/312 Loss 0.706 Prec@(1,3) (82.7%, 98.9%), ce_loss 0.760, lat_loss 6.683
09/19 09:35:48 AM | Train: [ 91/180] Step 300/312 Loss 0.699 Prec@(1,3) (82.9%, 98.9%), ce_loss 0.759, lat_loss 6.683
09/19 09:35:53 AM | Train: [ 91/180] Step 312/312 Loss 0.699 Prec@(1,3) (82.9%, 98.9%), ce_loss 0.759, lat_loss 6.683
09/19 09:35:53 AM | _theta_step_train: [ 91/180] Final Prec@1 82.9300% Time 124.83
09/19 09:35:58 AM | Valid: [ 91/180] Step 050/312 Loss 0.754 Prec@(1,3) (81.6%, 98.7%), ce_loss 0.759, lat_loss 6.683
09/19 09:36:03 AM | Valid: [ 91/180] Step 100/312 Loss 0.779 Prec@(1,3) (81.0%, 98.5%), ce_loss 0.759, lat_loss 6.683
09/19 09:36:08 AM | Valid: [ 91/180] Step 150/312 Loss 0.744 Prec@(1,3) (81.9%, 98.6%), ce_loss 0.759, lat_loss 6.683
09/19 09:36:12 AM | Valid: [ 91/180] Step 200/312 Loss 0.756 Prec@(1,3) (82.1%, 98.7%), ce_loss 0.759, lat_loss 6.683
09/19 09:36:17 AM | Valid: [ 91/180] Step 250/312 Loss 0.740 Prec@(1,3) (82.4%, 98.8%), ce_loss 0.759, lat_loss 6.683
09/19 09:36:21 AM | Valid: [ 91/180] Step 300/312 Loss 0.748 Prec@(1,3) (82.4%, 98.6%), ce_loss 0.759, lat_loss 6.683
09/19 09:36:23 AM | Valid: [ 91/180] Step 312/312 Loss 0.746 Prec@(1,3) (82.4%, 98.7%), ce_loss 0.759, lat_loss 6.683
09/19 09:36:23 AM | val: [ 91/180] Final Prec@1 82.4100% Time 29.52
09/19 09:36:23 AM | Start to train weights for epoch 91
09/19 09:36:48 AM | Train: [ 92/180] Step 050/1249 Loss 0.490 Prec@(1,3) (87.7%, 99.6%), ce_loss 0.759, lat_loss 6.683
09/19 09:37:12 AM | Train: [ 92/180] Step 100/1249 Loss 0.535 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.759, lat_loss 6.683
09/19 09:37:35 AM | Train: [ 92/180] Step 150/1249 Loss 0.550 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.759, lat_loss 6.683
09/19 09:38:01 AM | Train: [ 92/180] Step 200/1249 Loss 0.546 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.759, lat_loss 6.683
09/19 09:38:26 AM | Train: [ 92/180] Step 250/1249 Loss 0.548 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.759, lat_loss 6.683
09/19 09:38:51 AM | Train: [ 92/180] Step 300/1249 Loss 0.550 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.758, lat_loss 6.683
09/19 09:39:16 AM | Train: [ 92/180] Step 350/1249 Loss 0.547 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.758, lat_loss 6.683
09/19 09:39:40 AM | Train: [ 92/180] Step 400/1249 Loss 0.543 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.758, lat_loss 6.683
09/19 09:40:03 AM | Train: [ 92/180] Step 450/1249 Loss 0.539 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.758, lat_loss 6.683
09/19 09:40:28 AM | Train: [ 92/180] Step 500/1249 Loss 0.537 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.758, lat_loss 6.683
09/19 09:40:53 AM | Train: [ 92/180] Step 550/1249 Loss 0.533 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.758, lat_loss 6.683
09/19 09:41:18 AM | Train: [ 92/180] Step 600/1249 Loss 0.535 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.758, lat_loss 6.683
09/19 09:41:42 AM | Train: [ 92/180] Step 650/1249 Loss 0.534 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.758, lat_loss 6.683
09/19 09:42:06 AM | Train: [ 92/180] Step 700/1249 Loss 0.536 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.758, lat_loss 6.683
09/19 09:42:30 AM | Train: [ 92/180] Step 750/1249 Loss 0.533 Prec@(1,3) (86.2%, 99.5%), ce_loss 0.757, lat_loss 6.683
09/19 09:42:54 AM | Train: [ 92/180] Step 800/1249 Loss 0.532 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.757, lat_loss 6.683
09/19 09:43:18 AM | Train: [ 92/180] Step 850/1249 Loss 0.530 Prec@(1,3) (86.3%, 99.5%), ce_loss 0.757, lat_loss 6.683
09/19 09:43:41 AM | Train: [ 92/180] Step 900/1249 Loss 0.529 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.757, lat_loss 6.683
09/19 09:44:05 AM | Train: [ 92/180] Step 950/1249 Loss 0.531 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.757, lat_loss 6.683
09/19 09:44:29 AM | Train: [ 92/180] Step 1000/1249 Loss 0.531 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.757, lat_loss 6.683
09/19 09:44:54 AM | Train: [ 92/180] Step 1050/1249 Loss 0.536 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.757, lat_loss 6.683
09/19 09:45:19 AM | Train: [ 92/180] Step 1100/1249 Loss 0.537 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.757, lat_loss 6.683
09/19 09:45:43 AM | Train: [ 92/180] Step 1150/1249 Loss 0.540 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.757, lat_loss 6.683
09/19 09:46:08 AM | Train: [ 92/180] Step 1200/1249 Loss 0.541 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.756, lat_loss 6.683
09/19 09:46:32 AM | Train: [ 92/180] Step 1249/1249 Loss 0.543 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.756, lat_loss 6.683
09/19 09:46:32 AM | _w_step_train: [ 92/180] Final Prec@1 86.0700% Time 609.73
09/19 09:46:32 AM | Start to train theta for epoch 91
09/19 09:46:53 AM | Train: [ 92/180] Step 050/312 Loss 0.704 Prec@(1,3) (83.1%, 98.7%), ce_loss 0.756, lat_loss 6.683
09/19 09:47:14 AM | Train: [ 92/180] Step 100/312 Loss 0.676 Prec@(1,3) (83.4%, 98.8%), ce_loss 0.756, lat_loss 6.683
09/19 09:47:35 AM | Train: [ 92/180] Step 150/312 Loss 0.693 Prec@(1,3) (83.0%, 98.7%), ce_loss 0.756, lat_loss 6.683
09/19 09:47:55 AM | Train: [ 92/180] Step 200/312 Loss 0.683 Prec@(1,3) (83.1%, 98.8%), ce_loss 0.756, lat_loss 6.683
09/19 09:48:16 AM | Train: [ 92/180] Step 250/312 Loss 0.684 Prec@(1,3) (83.1%, 98.9%), ce_loss 0.756, lat_loss 6.683
09/19 09:48:36 AM | Train: [ 92/180] Step 300/312 Loss 0.688 Prec@(1,3) (83.0%, 98.9%), ce_loss 0.756, lat_loss 6.683
09/19 09:48:41 AM | Train: [ 92/180] Step 312/312 Loss 0.686 Prec@(1,3) (83.1%, 98.9%), ce_loss 0.756, lat_loss 6.683
09/19 09:48:41 AM | _theta_step_train: [ 92/180] Final Prec@1 83.1000% Time 128.87
09/19 09:48:47 AM | Valid: [ 92/180] Step 050/312 Loss 0.880 Prec@(1,3) (80.5%, 97.5%), ce_loss 0.756, lat_loss 6.683
09/19 09:48:51 AM | Valid: [ 92/180] Step 100/312 Loss 0.782 Prec@(1,3) (82.2%, 98.2%), ce_loss 0.756, lat_loss 6.683
09/19 09:48:56 AM | Valid: [ 92/180] Step 150/312 Loss 0.739 Prec@(1,3) (82.9%, 98.4%), ce_loss 0.756, lat_loss 6.683
09/19 09:49:01 AM | Valid: [ 92/180] Step 200/312 Loss 0.727 Prec@(1,3) (83.2%, 98.5%), ce_loss 0.756, lat_loss 6.683
09/19 09:49:05 AM | Valid: [ 92/180] Step 250/312 Loss 0.744 Prec@(1,3) (82.5%, 98.4%), ce_loss 0.756, lat_loss 6.683
09/19 09:49:10 AM | Valid: [ 92/180] Step 300/312 Loss 0.726 Prec@(1,3) (82.8%, 98.6%), ce_loss 0.756, lat_loss 6.683
09/19 09:49:11 AM | Valid: [ 92/180] Step 312/312 Loss 0.722 Prec@(1,3) (82.9%, 98.6%), ce_loss 0.756, lat_loss 6.683
09/19 09:49:11 AM | val: [ 92/180] Final Prec@1 82.8600% Time 29.84
09/19 09:49:11 AM | Start to train weights for epoch 92
09/19 09:49:37 AM | Train: [ 93/180] Step 050/1249 Loss 0.469 Prec@(1,3) (87.6%, 99.9%), ce_loss 0.755, lat_loss 6.683
09/19 09:50:02 AM | Train: [ 93/180] Step 100/1249 Loss 0.478 Prec@(1,3) (87.5%, 99.8%), ce_loss 0.755, lat_loss 6.683
09/19 09:50:27 AM | Train: [ 93/180] Step 150/1249 Loss 0.490 Prec@(1,3) (87.2%, 99.8%), ce_loss 0.755, lat_loss 6.683
09/19 09:50:50 AM | Train: [ 93/180] Step 200/1249 Loss 0.522 Prec@(1,3) (86.5%, 99.6%), ce_loss 0.755, lat_loss 6.683
09/19 09:51:14 AM | Train: [ 93/180] Step 250/1249 Loss 0.538 Prec@(1,3) (86.2%, 99.5%), ce_loss 0.755, lat_loss 6.683
09/19 09:51:39 AM | Train: [ 93/180] Step 300/1249 Loss 0.539 Prec@(1,3) (86.1%, 99.5%), ce_loss 0.755, lat_loss 6.683
09/19 09:52:03 AM | Train: [ 93/180] Step 350/1249 Loss 0.536 Prec@(1,3) (86.3%, 99.5%), ce_loss 0.755, lat_loss 6.683
09/19 09:52:27 AM | Train: [ 93/180] Step 400/1249 Loss 0.534 Prec@(1,3) (86.4%, 99.5%), ce_loss 0.755, lat_loss 6.683
09/19 09:52:52 AM | Train: [ 93/180] Step 450/1249 Loss 0.538 Prec@(1,3) (86.3%, 99.5%), ce_loss 0.755, lat_loss 6.683
09/19 09:53:14 AM | Train: [ 93/180] Step 500/1249 Loss 0.543 Prec@(1,3) (86.2%, 99.5%), ce_loss 0.754, lat_loss 6.683
09/19 09:53:34 AM | Train: [ 93/180] Step 550/1249 Loss 0.539 Prec@(1,3) (86.3%, 99.5%), ce_loss 0.754, lat_loss 6.683
09/19 09:53:57 AM | Train: [ 93/180] Step 600/1249 Loss 0.538 Prec@(1,3) (86.3%, 99.5%), ce_loss 0.754, lat_loss 6.683
09/19 09:54:21 AM | Train: [ 93/180] Step 650/1249 Loss 0.537 Prec@(1,3) (86.3%, 99.5%), ce_loss 0.754, lat_loss 6.683
09/19 09:54:46 AM | Train: [ 93/180] Step 700/1249 Loss 0.539 Prec@(1,3) (86.3%, 99.5%), ce_loss 0.754, lat_loss 6.683
09/19 09:55:11 AM | Train: [ 93/180] Step 750/1249 Loss 0.542 Prec@(1,3) (86.2%, 99.5%), ce_loss 0.754, lat_loss 6.683
09/19 09:55:35 AM | Train: [ 93/180] Step 800/1249 Loss 0.543 Prec@(1,3) (86.2%, 99.5%), ce_loss 0.754, lat_loss 6.683
09/19 09:56:00 AM | Train: [ 93/180] Step 850/1249 Loss 0.544 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.754, lat_loss 6.683
09/19 09:56:26 AM | Train: [ 93/180] Step 900/1249 Loss 0.542 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.754, lat_loss 6.683
09/19 09:56:51 AM | Train: [ 93/180] Step 950/1249 Loss 0.543 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.754, lat_loss 6.683
09/19 09:57:15 AM | Train: [ 93/180] Step 1000/1249 Loss 0.544 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.753, lat_loss 6.683
09/19 09:57:40 AM | Train: [ 93/180] Step 1050/1249 Loss 0.541 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.753, lat_loss 6.683
09/19 09:58:05 AM | Train: [ 93/180] Step 1100/1249 Loss 0.540 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.753, lat_loss 6.683
09/19 09:58:30 AM | Train: [ 93/180] Step 1150/1249 Loss 0.541 Prec@(1,3) (86.3%, 99.5%), ce_loss 0.753, lat_loss 6.683
09/19 09:58:54 AM | Train: [ 93/180] Step 1200/1249 Loss 0.539 Prec@(1,3) (86.3%, 99.5%), ce_loss 0.753, lat_loss 6.683
09/19 09:59:19 AM | Train: [ 93/180] Step 1249/1249 Loss 0.536 Prec@(1,3) (86.4%, 99.5%), ce_loss 0.753, lat_loss 6.683
09/19 09:59:19 AM | _w_step_train: [ 93/180] Final Prec@1 86.4250% Time 607.85
09/19 09:59:19 AM | Start to train theta for epoch 92
09/19 09:59:40 AM | Train: [ 93/180] Step 050/312 Loss 0.660 Prec@(1,3) (83.7%, 98.7%), ce_loss 0.753, lat_loss 6.683
09/19 10:00:01 AM | Train: [ 93/180] Step 100/312 Loss 0.663 Prec@(1,3) (83.2%, 98.7%), ce_loss 0.753, lat_loss 6.683
09/19 10:00:21 AM | Train: [ 93/180] Step 150/312 Loss 0.665 Prec@(1,3) (83.1%, 98.9%), ce_loss 0.753, lat_loss 6.683
09/19 10:00:42 AM | Train: [ 93/180] Step 200/312 Loss 0.671 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.753, lat_loss 6.683
09/19 10:01:02 AM | Train: [ 93/180] Step 250/312 Loss 0.674 Prec@(1,3) (82.8%, 99.0%), ce_loss 0.753, lat_loss 6.683
09/19 10:01:22 AM | Train: [ 93/180] Step 300/312 Loss 0.686 Prec@(1,3) (82.7%, 98.9%), ce_loss 0.752, lat_loss 6.683
09/19 10:01:27 AM | Train: [ 93/180] Step 312/312 Loss 0.682 Prec@(1,3) (82.8%, 99.0%), ce_loss 0.752, lat_loss 6.683
09/19 10:01:27 AM | _theta_step_train: [ 93/180] Final Prec@1 82.8200% Time 128.50
09/19 10:01:33 AM | Valid: [ 93/180] Step 050/312 Loss 0.596 Prec@(1,3) (84.6%, 99.4%), ce_loss 0.752, lat_loss 6.683
09/19 10:01:37 AM | Valid: [ 93/180] Step 100/312 Loss 0.638 Prec@(1,3) (83.9%, 99.2%), ce_loss 0.752, lat_loss 6.683
09/19 10:01:42 AM | Valid: [ 93/180] Step 150/312 Loss 0.751 Prec@(1,3) (82.2%, 98.3%), ce_loss 0.752, lat_loss 6.683
09/19 10:01:47 AM | Valid: [ 93/180] Step 200/312 Loss 0.746 Prec@(1,3) (82.5%, 98.5%), ce_loss 0.752, lat_loss 6.683
09/19 10:01:52 AM | Valid: [ 93/180] Step 250/312 Loss 0.736 Prec@(1,3) (82.4%, 98.6%), ce_loss 0.752, lat_loss 6.683
09/19 10:01:57 AM | Valid: [ 93/180] Step 300/312 Loss 0.714 Prec@(1,3) (83.0%, 98.6%), ce_loss 0.752, lat_loss 6.683
09/19 10:01:58 AM | Valid: [ 93/180] Step 312/312 Loss 0.710 Prec@(1,3) (83.0%, 98.7%), ce_loss 0.752, lat_loss 6.683
09/19 10:01:58 AM | val: [ 93/180] Final Prec@1 83.0300% Time 30.78
09/19 10:01:58 AM | Start to train weights for epoch 93
09/19 10:02:24 AM | Train: [ 94/180] Step 050/1249 Loss 0.528 Prec@(1,3) (86.9%, 99.3%), ce_loss 0.752, lat_loss 6.683
09/19 10:02:46 AM | Train: [ 94/180] Step 100/1249 Loss 0.510 Prec@(1,3) (87.7%, 99.3%), ce_loss 0.752, lat_loss 6.683
09/19 10:03:09 AM | Train: [ 94/180] Step 150/1249 Loss 0.534 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.752, lat_loss 6.683
09/19 10:03:30 AM | Train: [ 94/180] Step 200/1249 Loss 0.531 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.752, lat_loss 6.683
09/19 10:03:52 AM | Train: [ 94/180] Step 250/1249 Loss 0.522 Prec@(1,3) (87.0%, 99.5%), ce_loss 0.751, lat_loss 6.683
09/19 10:04:15 AM | Train: [ 94/180] Step 300/1249 Loss 0.550 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.751, lat_loss 6.683
09/19 10:04:37 AM | Train: [ 94/180] Step 350/1249 Loss 0.543 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.751, lat_loss 6.683
09/19 10:04:59 AM | Train: [ 94/180] Step 400/1249 Loss 0.542 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.751, lat_loss 6.683
09/19 10:05:21 AM | Train: [ 94/180] Step 450/1249 Loss 0.538 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.751, lat_loss 6.683
09/19 10:05:42 AM | Train: [ 94/180] Step 500/1249 Loss 0.537 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.751, lat_loss 6.683
09/19 10:06:03 AM | Train: [ 94/180] Step 550/1249 Loss 0.541 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.751, lat_loss 6.683
09/19 10:06:26 AM | Train: [ 94/180] Step 600/1249 Loss 0.542 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.751, lat_loss 6.683
09/19 10:06:48 AM | Train: [ 94/180] Step 650/1249 Loss 0.544 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.751, lat_loss 6.683
09/19 10:07:10 AM | Train: [ 94/180] Step 700/1249 Loss 0.539 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.751, lat_loss 6.683
09/19 10:07:32 AM | Train: [ 94/180] Step 750/1249 Loss 0.541 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.750, lat_loss 6.683
09/19 10:07:56 AM | Train: [ 94/180] Step 800/1249 Loss 0.541 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.750, lat_loss 6.683
09/19 10:08:20 AM | Train: [ 94/180] Step 850/1249 Loss 0.539 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.750, lat_loss 6.683
09/19 10:08:45 AM | Train: [ 94/180] Step 900/1249 Loss 0.541 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.750, lat_loss 6.683
09/19 10:09:09 AM | Train: [ 94/180] Step 950/1249 Loss 0.541 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.750, lat_loss 6.683
09/19 10:09:34 AM | Train: [ 94/180] Step 1000/1249 Loss 0.544 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.750, lat_loss 6.683
09/19 10:09:56 AM | Train: [ 94/180] Step 1050/1249 Loss 0.542 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.750, lat_loss 6.683
09/19 10:10:20 AM | Train: [ 94/180] Step 1100/1249 Loss 0.542 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.750, lat_loss 6.683
09/19 10:10:44 AM | Train: [ 94/180] Step 1150/1249 Loss 0.540 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.750, lat_loss 6.683
09/19 10:11:09 AM | Train: [ 94/180] Step 1200/1249 Loss 0.540 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.750, lat_loss 6.683
09/19 10:11:34 AM | Train: [ 94/180] Step 1249/1249 Loss 0.540 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.749, lat_loss 6.683
09/19 10:11:34 AM | _w_step_train: [ 94/180] Final Prec@1 86.4250% Time 575.51
09/19 10:11:34 AM | Start to train theta for epoch 93
09/19 10:11:55 AM | Train: [ 94/180] Step 050/312 Loss 0.717 Prec@(1,3) (83.2%, 99.1%), ce_loss 0.749, lat_loss 6.683
09/19 10:12:16 AM | Train: [ 94/180] Step 100/312 Loss 0.722 Prec@(1,3) (82.3%, 98.9%), ce_loss 0.749, lat_loss 6.683
09/19 10:12:36 AM | Train: [ 94/180] Step 150/312 Loss 0.707 Prec@(1,3) (82.6%, 99.0%), ce_loss 0.749, lat_loss 6.683
09/19 10:12:56 AM | Train: [ 94/180] Step 200/312 Loss 0.693 Prec@(1,3) (82.8%, 99.1%), ce_loss 0.749, lat_loss 6.683
09/19 10:13:16 AM | Train: [ 94/180] Step 250/312 Loss 0.698 Prec@(1,3) (82.6%, 99.1%), ce_loss 0.749, lat_loss 6.683
09/19 10:13:36 AM | Train: [ 94/180] Step 300/312 Loss 0.692 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.749, lat_loss 6.683
09/19 10:13:41 AM | Train: [ 94/180] Step 312/312 Loss 0.694 Prec@(1,3) (82.8%, 99.1%), ce_loss 0.749, lat_loss 6.683
09/19 10:13:42 AM | _theta_step_train: [ 94/180] Final Prec@1 82.8100% Time 128.14
09/19 10:13:47 AM | Valid: [ 94/180] Step 050/312 Loss 0.744 Prec@(1,3) (82.0%, 98.5%), ce_loss 0.749, lat_loss 6.683
09/19 10:13:52 AM | Valid: [ 94/180] Step 100/312 Loss 0.783 Prec@(1,3) (81.6%, 98.4%), ce_loss 0.749, lat_loss 6.683
09/19 10:13:56 AM | Valid: [ 94/180] Step 150/312 Loss 0.792 Prec@(1,3) (81.6%, 98.2%), ce_loss 0.749, lat_loss 6.683
09/19 10:14:01 AM | Valid: [ 94/180] Step 200/312 Loss 0.772 Prec@(1,3) (81.9%, 98.5%), ce_loss 0.749, lat_loss 6.683
09/19 10:14:06 AM | Valid: [ 94/180] Step 250/312 Loss 0.765 Prec@(1,3) (81.9%, 98.6%), ce_loss 0.749, lat_loss 6.683
09/19 10:14:10 AM | Valid: [ 94/180] Step 300/312 Loss 0.763 Prec@(1,3) (82.1%, 98.5%), ce_loss 0.749, lat_loss 6.683
09/19 10:14:11 AM | Valid: [ 94/180] Step 312/312 Loss 0.758 Prec@(1,3) (82.2%, 98.5%), ce_loss 0.749, lat_loss 6.683
09/19 10:14:12 AM | val: [ 94/180] Final Prec@1 82.2300% Time 29.92
09/19 10:14:12 AM | Start to train weights for epoch 94
09/19 10:14:29 AM | Train: [ 95/180] Step 050/1249 Loss 0.554 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.749, lat_loss 6.683
09/19 10:14:45 AM | Train: [ 95/180] Step 100/1249 Loss 0.567 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.749, lat_loss 6.683
09/19 10:15:01 AM | Train: [ 95/180] Step 150/1249 Loss 0.554 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.748, lat_loss 6.683
09/19 10:15:17 AM | Train: [ 95/180] Step 200/1249 Loss 0.567 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.748, lat_loss 6.683
09/19 10:15:35 AM | Train: [ 95/180] Step 250/1249 Loss 0.556 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.748, lat_loss 6.683
09/19 10:16:00 AM | Train: [ 95/180] Step 300/1249 Loss 0.555 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.748, lat_loss 6.683
09/19 10:16:24 AM | Train: [ 95/180] Step 350/1249 Loss 0.541 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.748, lat_loss 6.683
09/19 10:16:49 AM | Train: [ 95/180] Step 400/1249 Loss 0.536 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.748, lat_loss 6.683
09/19 10:17:13 AM | Train: [ 95/180] Step 450/1249 Loss 0.542 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.748, lat_loss 6.683
09/19 10:17:37 AM | Train: [ 95/180] Step 500/1249 Loss 0.544 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.748, lat_loss 6.683
09/19 10:17:58 AM | Train: [ 95/180] Step 550/1249 Loss 0.542 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.748, lat_loss 6.683
09/19 10:18:18 AM | Train: [ 95/180] Step 600/1249 Loss 0.539 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.747, lat_loss 6.683
09/19 10:18:39 AM | Train: [ 95/180] Step 650/1249 Loss 0.541 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.747, lat_loss 6.683
09/19 10:19:01 AM | Train: [ 95/180] Step 700/1249 Loss 0.537 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.747, lat_loss 6.683
09/19 10:19:18 AM | Train: [ 95/180] Step 750/1249 Loss 0.533 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.747, lat_loss 6.683
09/19 10:19:33 AM | Train: [ 95/180] Step 800/1249 Loss 0.531 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.747, lat_loss 6.683
09/19 10:19:49 AM | Train: [ 95/180] Step 850/1249 Loss 0.531 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.747, lat_loss 6.683
09/19 10:20:05 AM | Train: [ 95/180] Step 900/1249 Loss 0.530 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.747, lat_loss 6.683
09/19 10:20:21 AM | Train: [ 95/180] Step 950/1249 Loss 0.528 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.747, lat_loss 6.683
09/19 10:20:37 AM | Train: [ 95/180] Step 1000/1249 Loss 0.530 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.747, lat_loss 6.683
09/19 10:20:53 AM | Train: [ 95/180] Step 1050/1249 Loss 0.531 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.747, lat_loss 6.683
09/19 10:21:09 AM | Train: [ 95/180] Step 1100/1249 Loss 0.529 Prec@(1,3) (86.4%, 99.4%), ce_loss 0.746, lat_loss 6.683
09/19 10:21:25 AM | Train: [ 95/180] Step 1150/1249 Loss 0.530 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.746, lat_loss 6.683
09/19 10:21:41 AM | Train: [ 95/180] Step 1200/1249 Loss 0.533 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.746, lat_loss 6.683
09/19 10:21:56 AM | Train: [ 95/180] Step 1249/1249 Loss 0.535 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.746, lat_loss 6.683
09/19 10:21:56 AM | _w_step_train: [ 95/180] Final Prec@1 86.2400% Time 464.38
09/19 10:21:56 AM | Start to train theta for epoch 94
09/19 10:22:18 AM | Train: [ 95/180] Step 050/312 Loss 0.641 Prec@(1,3) (84.0%, 99.2%), ce_loss 0.746, lat_loss 6.683
09/19 10:22:39 AM | Train: [ 95/180] Step 100/312 Loss 0.646 Prec@(1,3) (84.4%, 99.0%), ce_loss 0.746, lat_loss 6.683
09/19 10:22:59 AM | Train: [ 95/180] Step 150/312 Loss 0.674 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.746, lat_loss 6.683
09/19 10:23:20 AM | Train: [ 95/180] Step 200/312 Loss 0.680 Prec@(1,3) (83.4%, 99.0%), ce_loss 0.746, lat_loss 6.683
09/19 10:23:41 AM | Train: [ 95/180] Step 250/312 Loss 0.688 Prec@(1,3) (83.0%, 98.9%), ce_loss 0.746, lat_loss 6.683
09/19 10:24:02 AM | Train: [ 95/180] Step 300/312 Loss 0.686 Prec@(1,3) (83.2%, 99.0%), ce_loss 0.746, lat_loss 6.683
09/19 10:24:07 AM | Train: [ 95/180] Step 312/312 Loss 0.686 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.746, lat_loss 6.683
09/19 10:24:08 AM | _theta_step_train: [ 95/180] Final Prec@1 83.1300% Time 131.30
09/19 10:24:13 AM | Valid: [ 95/180] Step 050/312 Loss 0.642 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.746, lat_loss 6.683
09/19 10:24:17 AM | Valid: [ 95/180] Step 100/312 Loss 0.676 Prec@(1,3) (83.9%, 98.9%), ce_loss 0.746, lat_loss 6.683
09/19 10:24:21 AM | Valid: [ 95/180] Step 150/312 Loss 0.708 Prec@(1,3) (83.2%, 98.5%), ce_loss 0.746, lat_loss 6.683
09/19 10:24:25 AM | Valid: [ 95/180] Step 200/312 Loss 0.699 Prec@(1,3) (83.4%, 98.7%), ce_loss 0.745, lat_loss 6.683
09/19 10:24:29 AM | Valid: [ 95/180] Step 250/312 Loss 0.685 Prec@(1,3) (83.5%, 98.8%), ce_loss 0.745, lat_loss 6.683
09/19 10:24:34 AM | Valid: [ 95/180] Step 300/312 Loss 0.688 Prec@(1,3) (83.4%, 98.8%), ce_loss 0.745, lat_loss 6.683
09/19 10:24:35 AM | Valid: [ 95/180] Step 312/312 Loss 0.688 Prec@(1,3) (83.4%, 98.9%), ce_loss 0.745, lat_loss 6.683
09/19 10:24:35 AM | val: [ 95/180] Final Prec@1 83.3500% Time 26.99
09/19 10:24:35 AM | Start to train weights for epoch 95
09/19 10:24:59 AM | Train: [ 96/180] Step 050/1249 Loss 0.496 Prec@(1,3) (86.7%, 99.4%), ce_loss 0.745, lat_loss 6.683
09/19 10:25:23 AM | Train: [ 96/180] Step 100/1249 Loss 0.504 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.745, lat_loss 6.683
09/19 10:25:46 AM | Train: [ 96/180] Step 150/1249 Loss 0.521 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.745, lat_loss 6.683
09/19 10:26:09 AM | Train: [ 96/180] Step 200/1249 Loss 0.517 Prec@(1,3) (86.7%, 99.4%), ce_loss 0.745, lat_loss 6.683
09/19 10:26:33 AM | Train: [ 96/180] Step 250/1249 Loss 0.516 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.745, lat_loss 6.683
09/19 10:26:55 AM | Train: [ 96/180] Step 300/1249 Loss 0.520 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.745, lat_loss 6.683
09/19 10:27:17 AM | Train: [ 96/180] Step 350/1249 Loss 0.519 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.745, lat_loss 6.683
09/19 10:27:41 AM | Train: [ 96/180] Step 400/1249 Loss 0.522 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.744, lat_loss 6.683
09/19 10:28:05 AM | Train: [ 96/180] Step 450/1249 Loss 0.521 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.744, lat_loss 6.683
09/19 10:28:29 AM | Train: [ 96/180] Step 500/1249 Loss 0.522 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.744, lat_loss 6.683
09/19 10:28:52 AM | Train: [ 96/180] Step 550/1249 Loss 0.520 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.744, lat_loss 6.683
09/19 10:29:15 AM | Train: [ 96/180] Step 600/1249 Loss 0.523 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.744, lat_loss 6.683
09/19 10:29:38 AM | Train: [ 96/180] Step 650/1249 Loss 0.523 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.744, lat_loss 6.683
09/19 10:30:01 AM | Train: [ 96/180] Step 700/1249 Loss 0.527 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.744, lat_loss 6.683
09/19 10:30:25 AM | Train: [ 96/180] Step 750/1249 Loss 0.522 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.744, lat_loss 6.683
09/19 10:30:48 AM | Train: [ 96/180] Step 800/1249 Loss 0.520 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.744, lat_loss 6.683
09/19 10:31:12 AM | Train: [ 96/180] Step 850/1249 Loss 0.520 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.744, lat_loss 6.683
09/19 10:31:35 AM | Train: [ 96/180] Step 900/1249 Loss 0.519 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.743, lat_loss 6.683
09/19 10:31:58 AM | Train: [ 96/180] Step 950/1249 Loss 0.517 Prec@(1,3) (87.1%, 99.5%), ce_loss 0.743, lat_loss 6.683
09/19 10:32:22 AM | Train: [ 96/180] Step 1000/1249 Loss 0.520 Prec@(1,3) (87.0%, 99.5%), ce_loss 0.743, lat_loss 6.683
09/19 10:32:45 AM | Train: [ 96/180] Step 1050/1249 Loss 0.521 Prec@(1,3) (87.0%, 99.5%), ce_loss 0.743, lat_loss 6.683
09/19 10:33:08 AM | Train: [ 96/180] Step 1100/1249 Loss 0.521 Prec@(1,3) (86.9%, 99.5%), ce_loss 0.743, lat_loss 6.683
09/19 10:33:32 AM | Train: [ 96/180] Step 1150/1249 Loss 0.524 Prec@(1,3) (86.8%, 99.5%), ce_loss 0.743, lat_loss 6.683
09/19 10:33:56 AM | Train: [ 96/180] Step 1200/1249 Loss 0.525 Prec@(1,3) (86.8%, 99.5%), ce_loss 0.743, lat_loss 6.683
09/19 10:34:20 AM | Train: [ 96/180] Step 1249/1249 Loss 0.526 Prec@(1,3) (86.8%, 99.5%), ce_loss 0.743, lat_loss 6.683
09/19 10:34:21 AM | _w_step_train: [ 96/180] Final Prec@1 86.7650% Time 585.98
09/19 10:34:21 AM | Start to train theta for epoch 95
09/19 10:34:42 AM | Train: [ 96/180] Step 050/312 Loss 0.632 Prec@(1,3) (85.4%, 98.6%), ce_loss 0.743, lat_loss 6.683
09/19 10:35:02 AM | Train: [ 96/180] Step 100/312 Loss 0.628 Prec@(1,3) (84.7%, 98.9%), ce_loss 0.743, lat_loss 6.683
09/19 10:35:21 AM | Train: [ 96/180] Step 150/312 Loss 0.646 Prec@(1,3) (84.0%, 98.9%), ce_loss 0.743, lat_loss 6.683
09/19 10:35:41 AM | Train: [ 96/180] Step 200/312 Loss 0.655 Prec@(1,3) (84.0%, 98.9%), ce_loss 0.742, lat_loss 6.683
09/19 10:36:01 AM | Train: [ 96/180] Step 250/312 Loss 0.663 Prec@(1,3) (83.7%, 98.9%), ce_loss 0.742, lat_loss 6.683
09/19 10:36:21 AM | Train: [ 96/180] Step 300/312 Loss 0.659 Prec@(1,3) (83.8%, 98.9%), ce_loss 0.742, lat_loss 6.683
09/19 10:36:26 AM | Train: [ 96/180] Step 312/312 Loss 0.657 Prec@(1,3) (83.8%, 98.9%), ce_loss 0.742, lat_loss 6.683
09/19 10:36:27 AM | _theta_step_train: [ 96/180] Final Prec@1 83.8400% Time 125.93
09/19 10:36:32 AM | Valid: [ 96/180] Step 050/312 Loss 0.728 Prec@(1,3) (82.9%, 98.3%), ce_loss 0.742, lat_loss 6.683
09/19 10:36:37 AM | Valid: [ 96/180] Step 100/312 Loss 0.726 Prec@(1,3) (82.7%, 98.1%), ce_loss 0.742, lat_loss 6.683
09/19 10:36:41 AM | Valid: [ 96/180] Step 150/312 Loss 0.704 Prec@(1,3) (83.2%, 98.4%), ce_loss 0.742, lat_loss 6.683
09/19 10:36:46 AM | Valid: [ 96/180] Step 200/312 Loss 0.712 Prec@(1,3) (83.2%, 98.4%), ce_loss 0.742, lat_loss 6.683
09/19 10:36:50 AM | Valid: [ 96/180] Step 250/312 Loss 0.733 Prec@(1,3) (82.7%, 98.3%), ce_loss 0.742, lat_loss 6.683
09/19 10:36:55 AM | Valid: [ 96/180] Step 300/312 Loss 0.717 Prec@(1,3) (83.0%, 98.5%), ce_loss 0.742, lat_loss 6.683
09/19 10:36:56 AM | Valid: [ 96/180] Step 312/312 Loss 0.726 Prec@(1,3) (82.8%, 98.4%), ce_loss 0.742, lat_loss 6.683
09/19 10:36:56 AM | val: [ 96/180] Final Prec@1 82.8200% Time 29.70
09/19 10:36:56 AM | Start to train weights for epoch 96
09/19 10:37:13 AM | Train: [ 97/180] Step 050/1249 Loss 0.491 Prec@(1,3) (88.1%, 99.5%), ce_loss 0.742, lat_loss 6.683
09/19 10:37:29 AM | Train: [ 97/180] Step 100/1249 Loss 0.514 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.742, lat_loss 6.683
09/19 10:37:45 AM | Train: [ 97/180] Step 150/1249 Loss 0.501 Prec@(1,3) (87.2%, 99.5%), ce_loss 0.742, lat_loss 6.683
09/19 10:38:01 AM | Train: [ 97/180] Step 200/1249 Loss 0.501 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.742, lat_loss 6.683
09/19 10:38:17 AM | Train: [ 97/180] Step 250/1249 Loss 0.495 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.741, lat_loss 6.683
09/19 10:38:33 AM | Train: [ 97/180] Step 300/1249 Loss 0.493 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.741, lat_loss 6.683
09/19 10:38:49 AM | Train: [ 97/180] Step 350/1249 Loss 0.492 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.741, lat_loss 6.683
09/19 10:39:05 AM | Train: [ 97/180] Step 400/1249 Loss 0.496 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.741, lat_loss 6.683
09/19 10:39:21 AM | Train: [ 97/180] Step 450/1249 Loss 0.502 Prec@(1,3) (87.1%, 99.5%), ce_loss 0.741, lat_loss 6.683
09/19 10:39:37 AM | Train: [ 97/180] Step 500/1249 Loss 0.503 Prec@(1,3) (87.1%, 99.5%), ce_loss 0.741, lat_loss 6.683
09/19 10:39:53 AM | Train: [ 97/180] Step 550/1249 Loss 0.508 Prec@(1,3) (87.0%, 99.5%), ce_loss 0.741, lat_loss 6.683
09/19 10:40:09 AM | Train: [ 97/180] Step 600/1249 Loss 0.511 Prec@(1,3) (86.9%, 99.5%), ce_loss 0.741, lat_loss 6.683
09/19 10:40:25 AM | Train: [ 97/180] Step 650/1249 Loss 0.516 Prec@(1,3) (86.8%, 99.5%), ce_loss 0.741, lat_loss 6.683
09/19 10:40:41 AM | Train: [ 97/180] Step 700/1249 Loss 0.518 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.741, lat_loss 6.683
09/19 10:40:57 AM | Train: [ 97/180] Step 750/1249 Loss 0.518 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.740, lat_loss 6.683
09/19 10:41:13 AM | Train: [ 97/180] Step 800/1249 Loss 0.519 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.740, lat_loss 6.683
09/19 10:41:29 AM | Train: [ 97/180] Step 850/1249 Loss 0.519 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.740, lat_loss 6.683
09/19 10:41:45 AM | Train: [ 97/180] Step 900/1249 Loss 0.518 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.740, lat_loss 6.683
09/19 10:42:01 AM | Train: [ 97/180] Step 950/1249 Loss 0.519 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.740, lat_loss 6.683
09/19 10:42:17 AM | Train: [ 97/180] Step 1000/1249 Loss 0.517 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.740, lat_loss 6.683
09/19 10:42:33 AM | Train: [ 97/180] Step 1050/1249 Loss 0.516 Prec@(1,3) (86.8%, 99.5%), ce_loss 0.740, lat_loss 6.683
09/19 10:42:49 AM | Train: [ 97/180] Step 1100/1249 Loss 0.517 Prec@(1,3) (86.7%, 99.4%), ce_loss 0.740, lat_loss 6.683
09/19 10:43:04 AM | Train: [ 97/180] Step 1150/1249 Loss 0.519 Prec@(1,3) (86.7%, 99.5%), ce_loss 0.740, lat_loss 6.683
09/19 10:43:20 AM | Train: [ 97/180] Step 1200/1249 Loss 0.522 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.740, lat_loss 6.683
09/19 10:43:36 AM | Train: [ 97/180] Step 1249/1249 Loss 0.522 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.739, lat_loss 6.683
09/19 10:43:36 AM | _w_step_train: [ 97/180] Final Prec@1 86.6375% Time 399.72
09/19 10:43:36 AM | Start to train theta for epoch 96
09/19 10:43:49 AM | Train: [ 97/180] Step 050/312 Loss 0.654 Prec@(1,3) (83.3%, 98.7%), ce_loss 0.739, lat_loss 6.683
09/19 10:44:01 AM | Train: [ 97/180] Step 100/312 Loss 0.651 Prec@(1,3) (83.6%, 98.8%), ce_loss 0.739, lat_loss 6.683
09/19 10:44:13 AM | Train: [ 97/180] Step 150/312 Loss 0.666 Prec@(1,3) (83.4%, 98.8%), ce_loss 0.739, lat_loss 6.683
09/19 10:44:26 AM | Train: [ 97/180] Step 200/312 Loss 0.653 Prec@(1,3) (83.6%, 99.0%), ce_loss 0.739, lat_loss 6.683
09/19 10:44:38 AM | Train: [ 97/180] Step 250/312 Loss 0.654 Prec@(1,3) (83.6%, 99.0%), ce_loss 0.739, lat_loss 6.683
09/19 10:44:50 AM | Train: [ 97/180] Step 300/312 Loss 0.652 Prec@(1,3) (83.7%, 99.0%), ce_loss 0.739, lat_loss 6.683
09/19 10:44:53 AM | Train: [ 97/180] Step 312/312 Loss 0.649 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.739, lat_loss 6.683
09/19 10:44:53 AM | _theta_step_train: [ 97/180] Final Prec@1 83.7400% Time 76.99
09/19 10:44:58 AM | Valid: [ 97/180] Step 050/312 Loss 0.691 Prec@(1,3) (81.2%, 98.7%), ce_loss 0.739, lat_loss 6.683
09/19 10:45:03 AM | Valid: [ 97/180] Step 100/312 Loss 0.758 Prec@(1,3) (81.0%, 98.5%), ce_loss 0.739, lat_loss 6.683
09/19 10:45:07 AM | Valid: [ 97/180] Step 150/312 Loss 0.794 Prec@(1,3) (80.3%, 98.4%), ce_loss 0.739, lat_loss 6.683
09/19 10:45:12 AM | Valid: [ 97/180] Step 200/312 Loss 0.790 Prec@(1,3) (80.7%, 98.4%), ce_loss 0.739, lat_loss 6.683
09/19 10:45:17 AM | Valid: [ 97/180] Step 250/312 Loss 0.771 Prec@(1,3) (81.2%, 98.5%), ce_loss 0.739, lat_loss 6.683
09/19 10:45:21 AM | Valid: [ 97/180] Step 300/312 Loss 0.756 Prec@(1,3) (81.5%, 98.6%), ce_loss 0.739, lat_loss 6.683
09/19 10:45:22 AM | Valid: [ 97/180] Step 312/312 Loss 0.753 Prec@(1,3) (81.5%, 98.6%), ce_loss 0.739, lat_loss 6.683
09/19 10:45:22 AM | val: [ 97/180] Final Prec@1 81.4800% Time 29.48
09/19 10:45:22 AM | Start to train weights for epoch 97
09/19 10:45:48 AM | Train: [ 98/180] Step 050/1249 Loss 0.578 Prec@(1,3) (85.7%, 99.6%), ce_loss 0.739, lat_loss 6.683
09/19 10:46:13 AM | Train: [ 98/180] Step 100/1249 Loss 0.554 Prec@(1,3) (85.7%, 99.5%), ce_loss 0.738, lat_loss 6.683
09/19 10:46:38 AM | Train: [ 98/180] Step 150/1249 Loss 0.543 Prec@(1,3) (85.7%, 99.5%), ce_loss 0.738, lat_loss 6.683
09/19 10:47:03 AM | Train: [ 98/180] Step 200/1249 Loss 0.538 Prec@(1,3) (86.0%, 99.6%), ce_loss 0.738, lat_loss 6.683
09/19 10:47:28 AM | Train: [ 98/180] Step 250/1249 Loss 0.536 Prec@(1,3) (86.1%, 99.6%), ce_loss 0.738, lat_loss 6.683
09/19 10:47:53 AM | Train: [ 98/180] Step 300/1249 Loss 0.535 Prec@(1,3) (86.0%, 99.6%), ce_loss 0.738, lat_loss 6.683
09/19 10:48:18 AM | Train: [ 98/180] Step 350/1249 Loss 0.532 Prec@(1,3) (86.1%, 99.5%), ce_loss 0.738, lat_loss 6.683
09/19 10:48:43 AM | Train: [ 98/180] Step 400/1249 Loss 0.531 Prec@(1,3) (86.2%, 99.5%), ce_loss 0.738, lat_loss 6.683
09/19 10:49:08 AM | Train: [ 98/180] Step 450/1249 Loss 0.529 Prec@(1,3) (86.3%, 99.5%), ce_loss 0.738, lat_loss 6.683
09/19 10:49:33 AM | Train: [ 98/180] Step 500/1249 Loss 0.530 Prec@(1,3) (86.3%, 99.5%), ce_loss 0.738, lat_loss 6.683
09/19 10:49:58 AM | Train: [ 98/180] Step 550/1249 Loss 0.527 Prec@(1,3) (86.4%, 99.5%), ce_loss 0.738, lat_loss 6.683
09/19 10:50:23 AM | Train: [ 98/180] Step 600/1249 Loss 0.529 Prec@(1,3) (86.4%, 99.5%), ce_loss 0.738, lat_loss 6.683
09/19 10:50:49 AM | Train: [ 98/180] Step 650/1249 Loss 0.531 Prec@(1,3) (86.4%, 99.5%), ce_loss 0.737, lat_loss 6.683
09/19 10:51:14 AM | Train: [ 98/180] Step 700/1249 Loss 0.529 Prec@(1,3) (86.4%, 99.5%), ce_loss 0.737, lat_loss 6.683
09/19 10:51:38 AM | Train: [ 98/180] Step 750/1249 Loss 0.529 Prec@(1,3) (86.4%, 99.5%), ce_loss 0.737, lat_loss 6.683
09/19 10:52:03 AM | Train: [ 98/180] Step 800/1249 Loss 0.527 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.737, lat_loss 6.683
09/19 10:52:28 AM | Train: [ 98/180] Step 850/1249 Loss 0.526 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.737, lat_loss 6.683
09/19 10:52:54 AM | Train: [ 98/180] Step 900/1249 Loss 0.530 Prec@(1,3) (86.4%, 99.5%), ce_loss 0.737, lat_loss 6.683
09/19 10:53:19 AM | Train: [ 98/180] Step 950/1249 Loss 0.529 Prec@(1,3) (86.4%, 99.5%), ce_loss 0.737, lat_loss 6.683
09/19 10:53:43 AM | Train: [ 98/180] Step 1000/1249 Loss 0.527 Prec@(1,3) (86.4%, 99.5%), ce_loss 0.737, lat_loss 6.683
09/19 10:54:08 AM | Train: [ 98/180] Step 1050/1249 Loss 0.526 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.737, lat_loss 6.683
09/19 10:54:33 AM | Train: [ 98/180] Step 1100/1249 Loss 0.522 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.737, lat_loss 6.683
09/19 10:54:59 AM | Train: [ 98/180] Step 1150/1249 Loss 0.521 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.736, lat_loss 6.683
09/19 10:55:24 AM | Train: [ 98/180] Step 1200/1249 Loss 0.524 Prec@(1,3) (86.6%, 99.5%), ce_loss 0.736, lat_loss 6.683
09/19 10:55:48 AM | Train: [ 98/180] Step 1249/1249 Loss 0.525 Prec@(1,3) (86.5%, 99.5%), ce_loss 0.736, lat_loss 6.683
09/19 10:55:48 AM | _w_step_train: [ 98/180] Final Prec@1 86.5475% Time 625.53
09/19 10:55:48 AM | Start to train theta for epoch 97
09/19 10:56:09 AM | Train: [ 98/180] Step 050/312 Loss 0.647 Prec@(1,3) (83.9%, 99.3%), ce_loss 0.736, lat_loss 6.683
09/19 10:56:29 AM | Train: [ 98/180] Step 100/312 Loss 0.606 Prec@(1,3) (84.9%, 99.2%), ce_loss 0.736, lat_loss 6.683
09/19 10:56:50 AM | Train: [ 98/180] Step 150/312 Loss 0.616 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.736, lat_loss 6.683
09/19 10:57:10 AM | Train: [ 98/180] Step 200/312 Loss 0.609 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.736, lat_loss 6.683
09/19 10:57:30 AM | Train: [ 98/180] Step 250/312 Loss 0.629 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.736, lat_loss 6.683
09/19 10:57:51 AM | Train: [ 98/180] Step 300/312 Loss 0.640 Prec@(1,3) (84.0%, 99.1%), ce_loss 0.736, lat_loss 6.683
09/19 10:57:55 AM | Train: [ 98/180] Step 312/312 Loss 0.639 Prec@(1,3) (84.0%, 99.1%), ce_loss 0.736, lat_loss 6.683
09/19 10:57:56 AM | _theta_step_train: [ 98/180] Final Prec@1 84.0300% Time 128.01
09/19 10:58:01 AM | Valid: [ 98/180] Step 050/312 Loss 0.654 Prec@(1,3) (83.1%, 99.1%), ce_loss 0.736, lat_loss 6.683
09/19 10:58:06 AM | Valid: [ 98/180] Step 100/312 Loss 0.714 Prec@(1,3) (82.7%, 98.5%), ce_loss 0.736, lat_loss 6.683
09/19 10:58:11 AM | Valid: [ 98/180] Step 150/312 Loss 0.696 Prec@(1,3) (83.0%, 98.6%), ce_loss 0.736, lat_loss 6.683
09/19 10:58:15 AM | Valid: [ 98/180] Step 200/312 Loss 0.682 Prec@(1,3) (83.3%, 98.7%), ce_loss 0.736, lat_loss 6.683
09/19 10:58:20 AM | Valid: [ 98/180] Step 250/312 Loss 0.766 Prec@(1,3) (81.6%, 98.2%), ce_loss 0.736, lat_loss 6.683
09/19 10:58:25 AM | Valid: [ 98/180] Step 300/312 Loss 0.775 Prec@(1,3) (81.2%, 98.1%), ce_loss 0.736, lat_loss 6.683
09/19 10:58:26 AM | Valid: [ 98/180] Step 312/312 Loss 0.775 Prec@(1,3) (81.1%, 98.1%), ce_loss 0.736, lat_loss 6.683
09/19 10:58:26 AM | val: [ 98/180] Final Prec@1 81.1000% Time 29.84
09/19 10:58:26 AM | Start to train weights for epoch 98
09/19 10:58:50 AM | Train: [ 99/180] Step 050/1249 Loss 0.530 Prec@(1,3) (86.3%, 99.2%), ce_loss 0.735, lat_loss 6.683
09/19 10:59:11 AM | Train: [ 99/180] Step 100/1249 Loss 0.507 Prec@(1,3) (86.5%, 99.4%), ce_loss 0.735, lat_loss 6.683
09/19 10:59:35 AM | Train: [ 99/180] Step 150/1249 Loss 0.497 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.735, lat_loss 6.683
09/19 10:59:57 AM | Train: [ 99/180] Step 200/1249 Loss 0.482 Prec@(1,3) (87.4%, 99.4%), ce_loss 0.735, lat_loss 6.683
09/19 11:00:23 AM | Train: [ 99/180] Step 250/1249 Loss 0.482 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.735, lat_loss 6.683
09/19 11:00:48 AM | Train: [ 99/180] Step 300/1249 Loss 0.491 Prec@(1,3) (87.3%, 99.4%), ce_loss 0.735, lat_loss 6.683
09/19 11:01:13 AM | Train: [ 99/180] Step 350/1249 Loss 0.499 Prec@(1,3) (87.2%, 99.4%), ce_loss 0.735, lat_loss 6.683
09/19 11:01:38 AM | Train: [ 99/180] Step 400/1249 Loss 0.499 Prec@(1,3) (87.3%, 99.4%), ce_loss 0.735, lat_loss 6.683
09/19 11:02:02 AM | Train: [ 99/180] Step 450/1249 Loss 0.504 Prec@(1,3) (87.1%, 99.3%), ce_loss 0.735, lat_loss 6.683
09/19 11:02:28 AM | Train: [ 99/180] Step 500/1249 Loss 0.506 Prec@(1,3) (87.2%, 99.4%), ce_loss 0.735, lat_loss 6.683
09/19 11:02:53 AM | Train: [ 99/180] Step 550/1249 Loss 0.507 Prec@(1,3) (87.3%, 99.4%), ce_loss 0.734, lat_loss 6.683
09/19 11:03:18 AM | Train: [ 99/180] Step 600/1249 Loss 0.504 Prec@(1,3) (87.3%, 99.4%), ce_loss 0.734, lat_loss 6.683
09/19 11:03:43 AM | Train: [ 99/180] Step 650/1249 Loss 0.511 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.734, lat_loss 6.683
09/19 11:04:08 AM | Train: [ 99/180] Step 700/1249 Loss 0.511 Prec@(1,3) (87.2%, 99.4%), ce_loss 0.734, lat_loss 6.683
09/19 11:04:33 AM | Train: [ 99/180] Step 750/1249 Loss 0.511 Prec@(1,3) (87.2%, 99.4%), ce_loss 0.734, lat_loss 6.683
09/19 11:04:58 AM | Train: [ 99/180] Step 800/1249 Loss 0.515 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.734, lat_loss 6.683
09/19 11:05:23 AM | Train: [ 99/180] Step 850/1249 Loss 0.515 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.734, lat_loss 6.683
09/19 11:05:48 AM | Train: [ 99/180] Step 900/1249 Loss 0.514 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.734, lat_loss 6.683
09/19 11:06:13 AM | Train: [ 99/180] Step 950/1249 Loss 0.512 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.734, lat_loss 6.683
09/19 11:06:38 AM | Train: [ 99/180] Step 1000/1249 Loss 0.512 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.734, lat_loss 6.683
09/19 11:07:03 AM | Train: [ 99/180] Step 1050/1249 Loss 0.512 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.733, lat_loss 6.683
09/19 11:07:28 AM | Train: [ 99/180] Step 1100/1249 Loss 0.512 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.733, lat_loss 6.683
09/19 11:07:54 AM | Train: [ 99/180] Step 1150/1249 Loss 0.512 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.733, lat_loss 6.683
09/19 11:08:19 AM | Train: [ 99/180] Step 1200/1249 Loss 0.513 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.733, lat_loss 6.683
09/19 11:08:43 AM | Train: [ 99/180] Step 1249/1249 Loss 0.512 Prec@(1,3) (87.1%, 99.4%), ce_loss 0.733, lat_loss 6.683
09/19 11:08:43 AM | _w_step_train: [ 99/180] Final Prec@1 87.0625% Time 617.37
09/19 11:08:43 AM | Start to train theta for epoch 98
09/19 11:09:05 AM | Train: [ 99/180] Step 050/312 Loss 0.595 Prec@(1,3) (85.4%, 98.7%), ce_loss 0.733, lat_loss 6.683
09/19 11:09:25 AM | Train: [ 99/180] Step 100/312 Loss 0.648 Prec@(1,3) (84.3%, 98.6%), ce_loss 0.733, lat_loss 6.683
09/19 11:09:45 AM | Train: [ 99/180] Step 150/312 Loss 0.664 Prec@(1,3) (83.9%, 98.7%), ce_loss 0.733, lat_loss 6.683
09/19 11:10:05 AM | Train: [ 99/180] Step 200/312 Loss 0.667 Prec@(1,3) (83.7%, 98.8%), ce_loss 0.733, lat_loss 6.683
09/19 11:10:25 AM | Train: [ 99/180] Step 250/312 Loss 0.675 Prec@(1,3) (83.6%, 98.7%), ce_loss 0.733, lat_loss 6.683
09/19 11:10:45 AM | Train: [ 99/180] Step 300/312 Loss 0.672 Prec@(1,3) (83.6%, 98.7%), ce_loss 0.733, lat_loss 6.683
09/19 11:10:50 AM | Train: [ 99/180] Step 312/312 Loss 0.669 Prec@(1,3) (83.7%, 98.7%), ce_loss 0.733, lat_loss 6.683
09/19 11:10:50 AM | _theta_step_train: [ 99/180] Final Prec@1 83.7100% Time 126.59
09/19 11:10:56 AM | Valid: [ 99/180] Step 050/312 Loss 0.751 Prec@(1,3) (82.4%, 98.0%), ce_loss 0.733, lat_loss 6.683
09/19 11:11:01 AM | Valid: [ 99/180] Step 100/312 Loss 0.777 Prec@(1,3) (81.7%, 97.9%), ce_loss 0.733, lat_loss 6.683
09/19 11:11:05 AM | Valid: [ 99/180] Step 150/312 Loss 0.787 Prec@(1,3) (81.4%, 98.0%), ce_loss 0.733, lat_loss 6.683
09/19 11:11:10 AM | Valid: [ 99/180] Step 200/312 Loss 0.790 Prec@(1,3) (81.3%, 98.1%), ce_loss 0.732, lat_loss 6.683
09/19 11:11:14 AM | Valid: [ 99/180] Step 250/312 Loss 0.768 Prec@(1,3) (81.6%, 98.3%), ce_loss 0.732, lat_loss 6.683
09/19 11:11:19 AM | Valid: [ 99/180] Step 300/312 Loss 0.750 Prec@(1,3) (81.9%, 98.4%), ce_loss 0.732, lat_loss 6.683
09/19 11:11:20 AM | Valid: [ 99/180] Step 312/312 Loss 0.753 Prec@(1,3) (81.8%, 98.4%), ce_loss 0.732, lat_loss 6.683
09/19 11:11:20 AM | val: [ 99/180] Final Prec@1 81.7500% Time 30.47
09/19 11:11:20 AM | Start to train weights for epoch 99
09/19 11:11:47 AM | Train: [100/180] Step 050/1249 Loss 0.530 Prec@(1,3) (87.4%, 99.4%), ce_loss 0.732, lat_loss 6.683
09/19 11:12:11 AM | Train: [100/180] Step 100/1249 Loss 0.536 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.732, lat_loss 6.683
09/19 11:12:35 AM | Train: [100/180] Step 150/1249 Loss 0.535 Prec@(1,3) (86.8%, 99.3%), ce_loss 0.732, lat_loss 6.683
09/19 11:13:00 AM | Train: [100/180] Step 200/1249 Loss 0.539 Prec@(1,3) (86.7%, 99.3%), ce_loss 0.732, lat_loss 6.683
09/19 11:13:23 AM | Train: [100/180] Step 250/1249 Loss 0.529 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.732, lat_loss 6.683
09/19 11:13:47 AM | Train: [100/180] Step 300/1249 Loss 0.522 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.732, lat_loss 6.683
09/19 11:14:10 AM | Train: [100/180] Step 350/1249 Loss 0.515 Prec@(1,3) (87.2%, 99.5%), ce_loss 0.732, lat_loss 6.683
09/19 11:14:34 AM | Train: [100/180] Step 400/1249 Loss 0.519 Prec@(1,3) (87.0%, 99.5%), ce_loss 0.732, lat_loss 6.683
09/19 11:14:59 AM | Train: [100/180] Step 450/1249 Loss 0.520 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.731, lat_loss 6.683
09/19 11:15:23 AM | Train: [100/180] Step 500/1249 Loss 0.524 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.731, lat_loss 6.683
09/19 11:15:46 AM | Train: [100/180] Step 550/1249 Loss 0.522 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.731, lat_loss 6.683
09/19 11:16:08 AM | Train: [100/180] Step 600/1249 Loss 0.523 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.731, lat_loss 6.683
09/19 11:16:29 AM | Train: [100/180] Step 650/1249 Loss 0.524 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.731, lat_loss 6.683
09/19 11:16:51 AM | Train: [100/180] Step 700/1249 Loss 0.521 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.731, lat_loss 6.683
09/19 11:17:11 AM | Train: [100/180] Step 750/1249 Loss 0.520 Prec@(1,3) (87.0%, 99.5%), ce_loss 0.731, lat_loss 6.683
09/19 11:17:31 AM | Train: [100/180] Step 800/1249 Loss 0.520 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.731, lat_loss 6.683
09/19 11:17:51 AM | Train: [100/180] Step 850/1249 Loss 0.520 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.731, lat_loss 6.683
09/19 11:18:11 AM | Train: [100/180] Step 900/1249 Loss 0.519 Prec@(1,3) (87.0%, 99.5%), ce_loss 0.731, lat_loss 6.683
09/19 11:18:33 AM | Train: [100/180] Step 950/1249 Loss 0.520 Prec@(1,3) (87.0%, 99.5%), ce_loss 0.731, lat_loss 6.683
09/19 11:18:54 AM | Train: [100/180] Step 1000/1249 Loss 0.519 Prec@(1,3) (86.9%, 99.5%), ce_loss 0.730, lat_loss 6.683
09/19 11:19:10 AM | Train: [100/180] Step 1050/1249 Loss 0.519 Prec@(1,3) (86.9%, 99.5%), ce_loss 0.730, lat_loss 6.683
09/19 11:19:26 AM | Train: [100/180] Step 1100/1249 Loss 0.521 Prec@(1,3) (86.9%, 99.5%), ce_loss 0.730, lat_loss 6.683
09/19 11:19:42 AM | Train: [100/180] Step 1150/1249 Loss 0.520 Prec@(1,3) (86.9%, 99.5%), ce_loss 0.730, lat_loss 6.683
09/19 11:19:57 AM | Train: [100/180] Step 1200/1249 Loss 0.521 Prec@(1,3) (86.8%, 99.5%), ce_loss 0.730, lat_loss 6.683
09/19 11:20:13 AM | Train: [100/180] Step 1249/1249 Loss 0.520 Prec@(1,3) (86.8%, 99.5%), ce_loss 0.730, lat_loss 6.683
09/19 11:20:13 AM | _w_step_train: [100/180] Final Prec@1 86.8225% Time 532.68
09/19 11:20:13 AM | Start to train theta for epoch 99
09/19 11:20:33 AM | Train: [100/180] Step 050/312 Loss 0.659 Prec@(1,3) (83.1%, 99.1%), ce_loss 0.730, lat_loss 6.683
09/19 11:20:51 AM | Train: [100/180] Step 100/312 Loss 0.643 Prec@(1,3) (83.4%, 99.2%), ce_loss 0.730, lat_loss 6.683
09/19 11:21:10 AM | Train: [100/180] Step 150/312 Loss 0.664 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.730, lat_loss 6.683
09/19 11:21:28 AM | Train: [100/180] Step 200/312 Loss 0.646 Prec@(1,3) (83.8%, 99.1%), ce_loss 0.730, lat_loss 6.683
09/19 11:21:47 AM | Train: [100/180] Step 250/312 Loss 0.661 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.730, lat_loss 6.683
09/19 11:22:06 AM | Train: [100/180] Step 300/312 Loss 0.664 Prec@(1,3) (83.3%, 99.0%), ce_loss 0.730, lat_loss 6.683
09/19 11:22:11 AM | Train: [100/180] Step 312/312 Loss 0.662 Prec@(1,3) (83.4%, 99.0%), ce_loss 0.730, lat_loss 6.683
09/19 11:22:11 AM | _theta_step_train: [100/180] Final Prec@1 83.4000% Time 117.91
09/19 11:22:17 AM | Valid: [100/180] Step 050/312 Loss 0.682 Prec@(1,3) (82.8%, 99.0%), ce_loss 0.730, lat_loss 6.683
09/19 11:22:21 AM | Valid: [100/180] Step 100/312 Loss 0.698 Prec@(1,3) (82.8%, 98.8%), ce_loss 0.729, lat_loss 6.683
09/19 11:22:26 AM | Valid: [100/180] Step 150/312 Loss 0.693 Prec@(1,3) (83.3%, 98.6%), ce_loss 0.729, lat_loss 6.683
09/19 11:22:31 AM | Valid: [100/180] Step 200/312 Loss 0.701 Prec@(1,3) (83.1%, 98.6%), ce_loss 0.729, lat_loss 6.683
09/19 11:22:35 AM | Valid: [100/180] Step 250/312 Loss 0.695 Prec@(1,3) (82.9%, 98.8%), ce_loss 0.729, lat_loss 6.683
09/19 11:22:40 AM | Valid: [100/180] Step 300/312 Loss 0.697 Prec@(1,3) (82.8%, 98.8%), ce_loss 0.729, lat_loss 6.683
09/19 11:22:41 AM | Valid: [100/180] Step 312/312 Loss 0.706 Prec@(1,3) (82.5%, 98.7%), ce_loss 0.729, lat_loss 6.683
09/19 11:22:41 AM | val: [100/180] Final Prec@1 82.5100% Time 30.25
09/19 11:22:41 AM | Start to train weights for epoch 100
09/19 11:23:07 AM | Train: [101/180] Step 050/1249 Loss 0.431 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.729, lat_loss 6.683
09/19 11:23:31 AM | Train: [101/180] Step 100/1249 Loss 0.412 Prec@(1,3) (89.5%, 99.8%), ce_loss 0.729, lat_loss 6.683
09/19 11:23:55 AM | Train: [101/180] Step 150/1249 Loss 0.428 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.729, lat_loss 6.683
09/19 11:24:19 AM | Train: [101/180] Step 200/1249 Loss 0.432 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.729, lat_loss 6.683
09/19 11:24:41 AM | Train: [101/180] Step 250/1249 Loss 0.438 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.729, lat_loss 6.683
09/19 11:25:05 AM | Train: [101/180] Step 300/1249 Loss 0.451 Prec@(1,3) (88.4%, 99.7%), ce_loss 0.729, lat_loss 6.683
09/19 11:25:29 AM | Train: [101/180] Step 350/1249 Loss 0.459 Prec@(1,3) (88.3%, 99.7%), ce_loss 0.728, lat_loss 6.683
09/19 11:25:52 AM | Train: [101/180] Step 400/1249 Loss 0.459 Prec@(1,3) (88.4%, 99.7%), ce_loss 0.728, lat_loss 6.683
09/19 11:26:17 AM | Train: [101/180] Step 450/1249 Loss 0.459 Prec@(1,3) (88.4%, 99.7%), ce_loss 0.728, lat_loss 6.683
09/19 11:26:41 AM | Train: [101/180] Step 500/1249 Loss 0.458 Prec@(1,3) (88.4%, 99.7%), ce_loss 0.728, lat_loss 6.683
09/19 11:27:05 AM | Train: [101/180] Step 550/1249 Loss 0.465 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.728, lat_loss 6.683
09/19 11:27:29 AM | Train: [101/180] Step 600/1249 Loss 0.470 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.728, lat_loss 6.683
09/19 11:27:53 AM | Train: [101/180] Step 650/1249 Loss 0.471 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.728, lat_loss 6.683
09/19 11:28:17 AM | Train: [101/180] Step 700/1249 Loss 0.472 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.728, lat_loss 6.683
09/19 11:28:41 AM | Train: [101/180] Step 750/1249 Loss 0.475 Prec@(1,3) (88.0%, 99.6%), ce_loss 0.728, lat_loss 6.683
09/19 11:29:04 AM | Train: [101/180] Step 800/1249 Loss 0.478 Prec@(1,3) (87.9%, 99.6%), ce_loss 0.728, lat_loss 6.683
09/19 11:29:29 AM | Train: [101/180] Step 850/1249 Loss 0.479 Prec@(1,3) (87.9%, 99.6%), ce_loss 0.727, lat_loss 6.683
09/19 11:29:53 AM | Train: [101/180] Step 900/1249 Loss 0.484 Prec@(1,3) (87.7%, 99.6%), ce_loss 0.727, lat_loss 6.683
09/19 11:30:13 AM | Train: [101/180] Step 950/1249 Loss 0.486 Prec@(1,3) (87.6%, 99.6%), ce_loss 0.727, lat_loss 6.683
09/19 11:30:35 AM | Train: [101/180] Step 1000/1249 Loss 0.487 Prec@(1,3) (87.6%, 99.5%), ce_loss 0.727, lat_loss 6.683
09/19 11:30:58 AM | Train: [101/180] Step 1050/1249 Loss 0.486 Prec@(1,3) (87.7%, 99.5%), ce_loss 0.727, lat_loss 6.683
09/19 11:31:19 AM | Train: [101/180] Step 1100/1249 Loss 0.486 Prec@(1,3) (87.6%, 99.5%), ce_loss 0.727, lat_loss 6.683
09/19 11:31:41 AM | Train: [101/180] Step 1150/1249 Loss 0.488 Prec@(1,3) (87.6%, 99.5%), ce_loss 0.727, lat_loss 6.683
09/19 11:32:04 AM | Train: [101/180] Step 1200/1249 Loss 0.489 Prec@(1,3) (87.6%, 99.5%), ce_loss 0.727, lat_loss 6.683
09/19 11:32:26 AM | Train: [101/180] Step 1249/1249 Loss 0.491 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.727, lat_loss 6.683
09/19 11:32:26 AM | _w_step_train: [101/180] Final Prec@1 87.5175% Time 584.98
09/19 11:32:26 AM | Start to train theta for epoch 100
09/19 11:32:47 AM | Train: [101/180] Step 050/312 Loss 0.623 Prec@(1,3) (84.3%, 99.4%), ce_loss 0.727, lat_loss 6.683
09/19 11:33:06 AM | Train: [101/180] Step 100/312 Loss 0.630 Prec@(1,3) (84.1%, 99.3%), ce_loss 0.727, lat_loss 6.683
09/19 11:33:26 AM | Train: [101/180] Step 150/312 Loss 0.625 Prec@(1,3) (84.3%, 99.3%), ce_loss 0.727, lat_loss 6.683
09/19 11:33:46 AM | Train: [101/180] Step 200/312 Loss 0.636 Prec@(1,3) (84.0%, 99.1%), ce_loss 0.726, lat_loss 6.683
09/19 11:34:04 AM | Train: [101/180] Step 250/312 Loss 0.637 Prec@(1,3) (84.2%, 99.1%), ce_loss 0.726, lat_loss 6.683
09/19 11:34:24 AM | Train: [101/180] Step 300/312 Loss 0.653 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.726, lat_loss 6.683
09/19 11:34:29 AM | Train: [101/180] Step 312/312 Loss 0.655 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.726, lat_loss 6.683
09/19 11:34:29 AM | _theta_step_train: [101/180] Final Prec@1 83.7800% Time 122.36
09/19 11:34:34 AM | Valid: [101/180] Step 050/312 Loss 0.854 Prec@(1,3) (80.8%, 97.1%), ce_loss 0.726, lat_loss 6.683
09/19 11:34:39 AM | Valid: [101/180] Step 100/312 Loss 0.858 Prec@(1,3) (80.8%, 96.8%), ce_loss 0.726, lat_loss 6.683
09/19 11:34:43 AM | Valid: [101/180] Step 150/312 Loss 0.846 Prec@(1,3) (81.4%, 97.0%), ce_loss 0.726, lat_loss 6.683
09/19 11:34:48 AM | Valid: [101/180] Step 200/312 Loss 0.814 Prec@(1,3) (82.1%, 97.3%), ce_loss 0.726, lat_loss 6.683
09/19 11:34:53 AM | Valid: [101/180] Step 250/312 Loss 0.807 Prec@(1,3) (82.0%, 97.4%), ce_loss 0.726, lat_loss 6.683
09/19 11:34:57 AM | Valid: [101/180] Step 300/312 Loss 0.766 Prec@(1,3) (82.8%, 97.7%), ce_loss 0.726, lat_loss 6.683
09/19 11:34:58 AM | Valid: [101/180] Step 312/312 Loss 0.773 Prec@(1,3) (82.7%, 97.7%), ce_loss 0.726, lat_loss 6.683
09/19 11:34:59 AM | val: [101/180] Final Prec@1 82.6700% Time 29.89
09/19 11:34:59 AM | Start to train weights for epoch 101
09/19 11:35:23 AM | Train: [102/180] Step 050/1249 Loss 0.502 Prec@(1,3) (86.9%, 99.3%), ce_loss 0.726, lat_loss 6.683
09/19 11:35:44 AM | Train: [102/180] Step 100/1249 Loss 0.476 Prec@(1,3) (88.0%, 99.4%), ce_loss 0.726, lat_loss 6.683
09/19 11:36:08 AM | Train: [102/180] Step 150/1249 Loss 0.468 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.726, lat_loss 6.683
09/19 11:36:32 AM | Train: [102/180] Step 200/1249 Loss 0.501 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.726, lat_loss 6.683
09/19 11:36:56 AM | Train: [102/180] Step 250/1249 Loss 0.494 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.726, lat_loss 6.683
09/19 11:37:20 AM | Train: [102/180] Step 300/1249 Loss 0.515 Prec@(1,3) (87.0%, 99.4%), ce_loss 0.726, lat_loss 6.683
09/19 11:37:43 AM | Train: [102/180] Step 350/1249 Loss 0.507 Prec@(1,3) (87.1%, 99.5%), ce_loss 0.725, lat_loss 6.683
09/19 11:38:07 AM | Train: [102/180] Step 400/1249 Loss 0.506 Prec@(1,3) (87.1%, 99.5%), ce_loss 0.725, lat_loss 6.683
09/19 11:38:31 AM | Train: [102/180] Step 450/1249 Loss 0.501 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.725, lat_loss 6.683
09/19 11:38:54 AM | Train: [102/180] Step 500/1249 Loss 0.498 Prec@(1,3) (87.2%, 99.5%), ce_loss 0.725, lat_loss 6.683
09/19 11:39:17 AM | Train: [102/180] Step 550/1249 Loss 0.498 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.725, lat_loss 6.683
09/19 11:39:42 AM | Train: [102/180] Step 600/1249 Loss 0.496 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.725, lat_loss 6.683
09/19 11:40:04 AM | Train: [102/180] Step 650/1249 Loss 0.498 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.725, lat_loss 6.683
09/19 11:40:27 AM | Train: [102/180] Step 700/1249 Loss 0.497 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.725, lat_loss 6.683
09/19 11:40:50 AM | Train: [102/180] Step 750/1249 Loss 0.495 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.725, lat_loss 6.683
09/19 11:41:13 AM | Train: [102/180] Step 800/1249 Loss 0.497 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.725, lat_loss 6.683
09/19 11:41:36 AM | Train: [102/180] Step 850/1249 Loss 0.496 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.724, lat_loss 6.683
09/19 11:41:57 AM | Train: [102/180] Step 900/1249 Loss 0.494 Prec@(1,3) (87.6%, 99.5%), ce_loss 0.724, lat_loss 6.683
09/19 11:42:18 AM | Train: [102/180] Step 950/1249 Loss 0.496 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.724, lat_loss 6.683
09/19 11:42:42 AM | Train: [102/180] Step 1000/1249 Loss 0.495 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.724, lat_loss 6.683
09/19 11:43:04 AM | Train: [102/180] Step 1050/1249 Loss 0.495 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.724, lat_loss 6.683
09/19 11:43:29 AM | Train: [102/180] Step 1100/1249 Loss 0.495 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.724, lat_loss 6.683
09/19 11:43:53 AM | Train: [102/180] Step 1150/1249 Loss 0.496 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.724, lat_loss 6.683
09/19 11:44:18 AM | Train: [102/180] Step 1200/1249 Loss 0.497 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.724, lat_loss 6.683
09/19 11:44:42 AM | Train: [102/180] Step 1249/1249 Loss 0.500 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.724, lat_loss 6.683
09/19 11:44:42 AM | _w_step_train: [102/180] Final Prec@1 87.3375% Time 583.53
09/19 11:44:42 AM | Start to train theta for epoch 101
09/19 11:45:04 AM | Train: [102/180] Step 050/312 Loss 0.723 Prec@(1,3) (82.4%, 99.1%), ce_loss 0.724, lat_loss 6.683
09/19 11:45:24 AM | Train: [102/180] Step 100/312 Loss 0.718 Prec@(1,3) (82.9%, 99.0%), ce_loss 0.724, lat_loss 6.683
09/19 11:45:44 AM | Train: [102/180] Step 150/312 Loss 0.712 Prec@(1,3) (82.7%, 99.0%), ce_loss 0.724, lat_loss 6.683
09/19 11:46:05 AM | Train: [102/180] Step 200/312 Loss 0.694 Prec@(1,3) (83.4%, 99.0%), ce_loss 0.723, lat_loss 6.683
09/19 11:46:25 AM | Train: [102/180] Step 250/312 Loss 0.702 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.723, lat_loss 6.683
09/19 11:46:46 AM | Train: [102/180] Step 300/312 Loss 0.701 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.723, lat_loss 6.683
09/19 11:46:51 AM | Train: [102/180] Step 312/312 Loss 0.698 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.723, lat_loss 6.683
09/19 11:46:51 AM | _theta_step_train: [102/180] Final Prec@1 83.0900% Time 129.38
09/19 11:46:57 AM | Valid: [102/180] Step 050/312 Loss 0.823 Prec@(1,3) (79.6%, 98.0%), ce_loss 0.723, lat_loss 6.683
09/19 11:47:01 AM | Valid: [102/180] Step 100/312 Loss 0.851 Prec@(1,3) (79.6%, 97.5%), ce_loss 0.723, lat_loss 6.683
09/19 11:47:06 AM | Valid: [102/180] Step 150/312 Loss 0.838 Prec@(1,3) (80.2%, 97.6%), ce_loss 0.723, lat_loss 6.683
09/19 11:47:11 AM | Valid: [102/180] Step 200/312 Loss 0.796 Prec@(1,3) (81.0%, 98.0%), ce_loss 0.723, lat_loss 6.683
09/19 11:47:15 AM | Valid: [102/180] Step 250/312 Loss 0.794 Prec@(1,3) (80.7%, 98.0%), ce_loss 0.723, lat_loss 6.683
09/19 11:47:20 AM | Valid: [102/180] Step 300/312 Loss 0.763 Prec@(1,3) (81.5%, 98.3%), ce_loss 0.723, lat_loss 6.683
09/19 11:47:21 AM | Valid: [102/180] Step 312/312 Loss 0.756 Prec@(1,3) (81.6%, 98.3%), ce_loss 0.723, lat_loss 6.683
09/19 11:47:21 AM | val: [102/180] Final Prec@1 81.6200% Time 29.76
09/19 11:47:21 AM | Start to train weights for epoch 102
09/19 11:47:47 AM | Train: [103/180] Step 050/1249 Loss 0.431 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.723, lat_loss 6.683
09/19 11:48:11 AM | Train: [103/180] Step 100/1249 Loss 0.438 Prec@(1,3) (88.6%, 99.8%), ce_loss 0.723, lat_loss 6.683
09/19 11:48:35 AM | Train: [103/180] Step 150/1249 Loss 0.443 Prec@(1,3) (88.4%, 99.7%), ce_loss 0.723, lat_loss 6.683
09/19 11:48:59 AM | Train: [103/180] Step 200/1249 Loss 0.431 Prec@(1,3) (88.6%, 99.7%), ce_loss 0.723, lat_loss 6.683
09/19 11:49:23 AM | Train: [103/180] Step 250/1249 Loss 0.443 Prec@(1,3) (88.5%, 99.6%), ce_loss 0.723, lat_loss 6.683
09/19 11:49:48 AM | Train: [103/180] Step 300/1249 Loss 0.450 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.722, lat_loss 6.683
09/19 11:50:12 AM | Train: [103/180] Step 350/1249 Loss 0.462 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.722, lat_loss 6.683
09/19 11:50:35 AM | Train: [103/180] Step 400/1249 Loss 0.470 Prec@(1,3) (87.7%, 99.6%), ce_loss 0.722, lat_loss 6.683
09/19 11:50:58 AM | Train: [103/180] Step 450/1249 Loss 0.467 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.722, lat_loss 6.683
09/19 11:51:20 AM | Train: [103/180] Step 500/1249 Loss 0.474 Prec@(1,3) (87.5%, 99.6%), ce_loss 0.722, lat_loss 6.683
09/19 11:51:44 AM | Train: [103/180] Step 550/1249 Loss 0.480 Prec@(1,3) (87.5%, 99.6%), ce_loss 0.722, lat_loss 6.683
09/19 11:52:08 AM | Train: [103/180] Step 600/1249 Loss 0.488 Prec@(1,3) (87.3%, 99.6%), ce_loss 0.722, lat_loss 6.683
09/19 11:52:32 AM | Train: [103/180] Step 650/1249 Loss 0.488 Prec@(1,3) (87.3%, 99.6%), ce_loss 0.722, lat_loss 6.683
09/19 11:52:56 AM | Train: [103/180] Step 700/1249 Loss 0.485 Prec@(1,3) (87.3%, 99.6%), ce_loss 0.722, lat_loss 6.683
09/19 11:53:21 AM | Train: [103/180] Step 750/1249 Loss 0.489 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.722, lat_loss 6.683
09/19 11:53:45 AM | Train: [103/180] Step 800/1249 Loss 0.488 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.722, lat_loss 6.683
09/19 11:54:09 AM | Train: [103/180] Step 850/1249 Loss 0.489 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.721, lat_loss 6.683
09/19 11:54:33 AM | Train: [103/180] Step 900/1249 Loss 0.491 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.721, lat_loss 6.683
09/19 11:54:58 AM | Train: [103/180] Step 950/1249 Loss 0.492 Prec@(1,3) (87.2%, 99.5%), ce_loss 0.721, lat_loss 6.683
09/19 11:55:21 AM | Train: [103/180] Step 1000/1249 Loss 0.494 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.721, lat_loss 6.683
09/19 11:55:45 AM | Train: [103/180] Step 1050/1249 Loss 0.493 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.721, lat_loss 6.683
09/19 11:56:09 AM | Train: [103/180] Step 1100/1249 Loss 0.494 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.721, lat_loss 6.683
09/19 11:56:33 AM | Train: [103/180] Step 1150/1249 Loss 0.495 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.721, lat_loss 6.683
09/19 11:56:58 AM | Train: [103/180] Step 1200/1249 Loss 0.496 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.721, lat_loss 6.683
09/19 11:57:22 AM | Train: [103/180] Step 1249/1249 Loss 0.496 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.721, lat_loss 6.683
09/19 11:57:23 AM | _w_step_train: [103/180] Final Prec@1 87.3050% Time 601.35
09/19 11:57:23 AM | Start to train theta for epoch 102
09/19 11:57:43 AM | Train: [103/180] Step 050/312 Loss 0.755 Prec@(1,3) (82.4%, 98.3%), ce_loss 0.721, lat_loss 6.683
09/19 11:58:03 AM | Train: [103/180] Step 100/312 Loss 0.710 Prec@(1,3) (82.4%, 98.7%), ce_loss 0.721, lat_loss 6.683
09/19 11:58:22 AM | Train: [103/180] Step 150/312 Loss 0.685 Prec@(1,3) (82.9%, 98.9%), ce_loss 0.721, lat_loss 6.683
09/19 11:58:42 AM | Train: [103/180] Step 200/312 Loss 0.693 Prec@(1,3) (82.9%, 98.8%), ce_loss 0.721, lat_loss 6.683
09/19 11:59:02 AM | Train: [103/180] Step 250/312 Loss 0.687 Prec@(1,3) (82.9%, 98.9%), ce_loss 0.720, lat_loss 6.683
09/19 11:59:22 AM | Train: [103/180] Step 300/312 Loss 0.676 Prec@(1,3) (83.3%, 98.9%), ce_loss 0.720, lat_loss 6.683
09/19 11:59:27 AM | Train: [103/180] Step 312/312 Loss 0.677 Prec@(1,3) (83.2%, 98.8%), ce_loss 0.720, lat_loss 6.683
09/19 11:59:27 AM | _theta_step_train: [103/180] Final Prec@1 83.2200% Time 124.15
09/19 11:59:32 AM | Valid: [103/180] Step 050/312 Loss 0.639 Prec@(1,3) (84.1%, 99.4%), ce_loss 0.720, lat_loss 6.683
09/19 11:59:37 AM | Valid: [103/180] Step 100/312 Loss 0.734 Prec@(1,3) (82.8%, 98.5%), ce_loss 0.720, lat_loss 6.683
09/19 11:59:41 AM | Valid: [103/180] Step 150/312 Loss 0.738 Prec@(1,3) (82.1%, 98.7%), ce_loss 0.720, lat_loss 6.683
09/19 11:59:46 AM | Valid: [103/180] Step 200/312 Loss 0.753 Prec@(1,3) (81.6%, 98.8%), ce_loss 0.720, lat_loss 6.683
09/19 11:59:51 AM | Valid: [103/180] Step 250/312 Loss 0.764 Prec@(1,3) (81.3%, 98.6%), ce_loss 0.720, lat_loss 6.683
09/19 11:59:55 AM | Valid: [103/180] Step 300/312 Loss 0.750 Prec@(1,3) (81.6%, 98.7%), ce_loss 0.720, lat_loss 6.683
09/19 11:59:56 AM | Valid: [103/180] Step 312/312 Loss 0.754 Prec@(1,3) (81.5%, 98.7%), ce_loss 0.720, lat_loss 6.683
09/19 11:59:56 AM | val: [103/180] Final Prec@1 81.4900% Time 29.59
09/19 11:59:56 AM | Start to train weights for epoch 103
09/19 12:00:14 PM | Train: [104/180] Step 050/1249 Loss 0.505 Prec@(1,3) (87.5%, 99.4%), ce_loss 0.720, lat_loss 6.683
09/19 12:00:30 PM | Train: [104/180] Step 100/1249 Loss 0.503 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.720, lat_loss 6.683
09/19 12:00:45 PM | Train: [104/180] Step 150/1249 Loss 0.503 Prec@(1,3) (87.2%, 99.6%), ce_loss 0.720, lat_loss 6.683
09/19 12:01:01 PM | Train: [104/180] Step 200/1249 Loss 0.504 Prec@(1,3) (87.2%, 99.6%), ce_loss 0.720, lat_loss 6.683
09/19 12:01:17 PM | Train: [104/180] Step 250/1249 Loss 0.494 Prec@(1,3) (87.4%, 99.6%), ce_loss 0.720, lat_loss 6.683
09/19 12:01:33 PM | Train: [104/180] Step 300/1249 Loss 0.488 Prec@(1,3) (87.5%, 99.6%), ce_loss 0.720, lat_loss 6.683
09/19 12:01:49 PM | Train: [104/180] Step 350/1249 Loss 0.503 Prec@(1,3) (87.1%, 99.5%), ce_loss 0.719, lat_loss 6.683
09/19 12:02:05 PM | Train: [104/180] Step 400/1249 Loss 0.494 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.719, lat_loss 6.683
09/19 12:02:21 PM | Train: [104/180] Step 450/1249 Loss 0.501 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.719, lat_loss 6.683
09/19 12:02:37 PM | Train: [104/180] Step 500/1249 Loss 0.498 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.719, lat_loss 6.683
09/19 12:02:53 PM | Train: [104/180] Step 550/1249 Loss 0.499 Prec@(1,3) (87.3%, 99.5%), ce_loss 0.719, lat_loss 6.683
09/19 12:03:09 PM | Train: [104/180] Step 600/1249 Loss 0.498 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.719, lat_loss 6.683
09/19 12:03:25 PM | Train: [104/180] Step 650/1249 Loss 0.494 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.719, lat_loss 6.683
09/19 12:03:41 PM | Train: [104/180] Step 700/1249 Loss 0.492 Prec@(1,3) (87.6%, 99.5%), ce_loss 0.719, lat_loss 6.683
09/19 12:03:57 PM | Train: [104/180] Step 750/1249 Loss 0.496 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.719, lat_loss 6.683
09/19 12:04:12 PM | Train: [104/180] Step 800/1249 Loss 0.496 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.719, lat_loss 6.683
09/19 12:04:28 PM | Train: [104/180] Step 850/1249 Loss 0.494 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.719, lat_loss 6.683
09/19 12:04:44 PM | Train: [104/180] Step 900/1249 Loss 0.488 Prec@(1,3) (87.6%, 99.5%), ce_loss 0.718, lat_loss 6.683
09/19 12:05:00 PM | Train: [104/180] Step 950/1249 Loss 0.487 Prec@(1,3) (87.6%, 99.5%), ce_loss 0.718, lat_loss 6.683
09/19 12:05:16 PM | Train: [104/180] Step 1000/1249 Loss 0.490 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.718, lat_loss 6.683
09/19 12:05:32 PM | Train: [104/180] Step 1050/1249 Loss 0.492 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.718, lat_loss 6.683
09/19 12:05:48 PM | Train: [104/180] Step 1100/1249 Loss 0.492 Prec@(1,3) (87.5%, 99.5%), ce_loss 0.718, lat_loss 6.683
09/19 12:06:04 PM | Train: [104/180] Step 1150/1249 Loss 0.494 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.718, lat_loss 6.683
09/19 12:06:20 PM | Train: [104/180] Step 1200/1249 Loss 0.497 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.718, lat_loss 6.683
09/19 12:06:35 PM | Train: [104/180] Step 1249/1249 Loss 0.497 Prec@(1,3) (87.4%, 99.5%), ce_loss 0.718, lat_loss 6.683
09/19 12:06:35 PM | _w_step_train: [104/180] Final Prec@1 87.3850% Time 399.08
09/19 12:06:35 PM | Start to train theta for epoch 103
09/19 12:06:56 PM | Train: [104/180] Step 050/312 Loss 0.662 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.718, lat_loss 6.683
09/19 12:07:17 PM | Train: [104/180] Step 100/312 Loss 0.684 Prec@(1,3) (83.3%, 99.0%), ce_loss 0.718, lat_loss 6.683
09/19 12:07:37 PM | Train: [104/180] Step 150/312 Loss 0.671 Prec@(1,3) (83.7%, 98.9%), ce_loss 0.718, lat_loss 6.683
09/19 12:07:58 PM | Train: [104/180] Step 200/312 Loss 0.662 Prec@(1,3) (83.7%, 99.0%), ce_loss 0.718, lat_loss 6.683
09/19 12:08:18 PM | Train: [104/180] Step 250/312 Loss 0.646 Prec@(1,3) (84.1%, 99.0%), ce_loss 0.718, lat_loss 6.683
09/19 12:08:39 PM | Train: [104/180] Step 300/312 Loss 0.644 Prec@(1,3) (84.1%, 99.0%), ce_loss 0.717, lat_loss 6.683
09/19 12:08:43 PM | Train: [104/180] Step 312/312 Loss 0.644 Prec@(1,3) (84.1%, 99.1%), ce_loss 0.717, lat_loss 6.683
09/19 12:08:44 PM | _theta_step_train: [104/180] Final Prec@1 84.1300% Time 128.06
09/19 12:08:49 PM | Valid: [104/180] Step 050/312 Loss 0.684 Prec@(1,3) (83.0%, 99.0%), ce_loss 0.717, lat_loss 6.683
09/19 12:08:54 PM | Valid: [104/180] Step 100/312 Loss 0.725 Prec@(1,3) (81.8%, 98.6%), ce_loss 0.717, lat_loss 6.683
09/19 12:08:58 PM | Valid: [104/180] Step 150/312 Loss 0.772 Prec@(1,3) (80.9%, 98.1%), ce_loss 0.717, lat_loss 6.683
09/19 12:09:03 PM | Valid: [104/180] Step 200/312 Loss 0.763 Prec@(1,3) (81.2%, 98.2%), ce_loss 0.717, lat_loss 6.683
09/19 12:09:07 PM | Valid: [104/180] Step 250/312 Loss 0.753 Prec@(1,3) (81.5%, 98.3%), ce_loss 0.717, lat_loss 6.683
09/19 12:09:12 PM | Valid: [104/180] Step 300/312 Loss 0.758 Prec@(1,3) (81.7%, 98.1%), ce_loss 0.717, lat_loss 6.683
09/19 12:09:13 PM | Valid: [104/180] Step 312/312 Loss 0.761 Prec@(1,3) (81.4%, 98.2%), ce_loss 0.717, lat_loss 6.683
09/19 12:09:13 PM | val: [104/180] Final Prec@1 81.4400% Time 29.72
09/19 12:09:13 PM | Start to train weights for epoch 104
09/19 12:09:39 PM | Train: [105/180] Step 050/1249 Loss 0.501 Prec@(1,3) (86.1%, 99.6%), ce_loss 0.717, lat_loss 6.683
09/19 12:10:02 PM | Train: [105/180] Step 100/1249 Loss 0.502 Prec@(1,3) (86.3%, 99.7%), ce_loss 0.717, lat_loss 6.683
09/19 12:10:24 PM | Train: [105/180] Step 150/1249 Loss 0.496 Prec@(1,3) (86.7%, 99.6%), ce_loss 0.717, lat_loss 6.683
09/19 12:10:46 PM | Train: [105/180] Step 200/1249 Loss 0.473 Prec@(1,3) (87.6%, 99.6%), ce_loss 0.717, lat_loss 6.683
09/19 12:11:09 PM | Train: [105/180] Step 250/1249 Loss 0.471 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.717, lat_loss 6.683
09/19 12:11:31 PM | Train: [105/180] Step 300/1249 Loss 0.474 Prec@(1,3) (87.7%, 99.6%), ce_loss 0.717, lat_loss 6.683
09/19 12:11:53 PM | Train: [105/180] Step 350/1249 Loss 0.476 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.717, lat_loss 6.683
09/19 12:12:15 PM | Train: [105/180] Step 400/1249 Loss 0.466 Prec@(1,3) (88.0%, 99.6%), ce_loss 0.716, lat_loss 6.683
09/19 12:12:37 PM | Train: [105/180] Step 450/1249 Loss 0.468 Prec@(1,3) (88.0%, 99.7%), ce_loss 0.716, lat_loss 6.683
09/19 12:12:59 PM | Train: [105/180] Step 500/1249 Loss 0.472 Prec@(1,3) (87.9%, 99.6%), ce_loss 0.716, lat_loss 6.683
09/19 12:13:20 PM | Train: [105/180] Step 550/1249 Loss 0.472 Prec@(1,3) (87.9%, 99.6%), ce_loss 0.716, lat_loss 6.683
09/19 12:13:41 PM | Train: [105/180] Step 600/1249 Loss 0.473 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.716, lat_loss 6.683
09/19 12:14:03 PM | Train: [105/180] Step 650/1249 Loss 0.475 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.716, lat_loss 6.683
09/19 12:14:24 PM | Train: [105/180] Step 700/1249 Loss 0.476 Prec@(1,3) (87.7%, 99.6%), ce_loss 0.716, lat_loss 6.683
09/19 12:14:46 PM | Train: [105/180] Step 750/1249 Loss 0.475 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.716, lat_loss 6.683
09/19 12:15:10 PM | Train: [105/180] Step 800/1249 Loss 0.474 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.716, lat_loss 6.683
09/19 12:15:33 PM | Train: [105/180] Step 850/1249 Loss 0.476 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.716, lat_loss 6.683
09/19 12:15:56 PM | Train: [105/180] Step 900/1249 Loss 0.477 Prec@(1,3) (87.7%, 99.6%), ce_loss 0.715, lat_loss 6.683
09/19 12:16:19 PM | Train: [105/180] Step 950/1249 Loss 0.476 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.715, lat_loss 6.683
09/19 12:16:43 PM | Train: [105/180] Step 1000/1249 Loss 0.477 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.715, lat_loss 6.683
09/19 12:17:08 PM | Train: [105/180] Step 1050/1249 Loss 0.479 Prec@(1,3) (87.7%, 99.5%), ce_loss 0.715, lat_loss 6.683
09/19 12:17:32 PM | Train: [105/180] Step 1100/1249 Loss 0.479 Prec@(1,3) (87.7%, 99.6%), ce_loss 0.715, lat_loss 6.683
09/19 12:17:54 PM | Train: [105/180] Step 1150/1249 Loss 0.482 Prec@(1,3) (87.7%, 99.5%), ce_loss 0.715, lat_loss 6.683
09/19 12:18:17 PM | Train: [105/180] Step 1200/1249 Loss 0.481 Prec@(1,3) (87.7%, 99.5%), ce_loss 0.715, lat_loss 6.683
09/19 12:18:41 PM | Train: [105/180] Step 1249/1249 Loss 0.481 Prec@(1,3) (87.7%, 99.5%), ce_loss 0.715, lat_loss 6.683
09/19 12:18:41 PM | _w_step_train: [105/180] Final Prec@1 87.7325% Time 568.22
09/19 12:18:41 PM | Start to train theta for epoch 104
09/19 12:19:01 PM | Train: [105/180] Step 050/312 Loss 0.697 Prec@(1,3) (84.1%, 98.5%), ce_loss 0.715, lat_loss 6.683
09/19 12:19:19 PM | Train: [105/180] Step 100/312 Loss 0.712 Prec@(1,3) (83.1%, 98.7%), ce_loss 0.715, lat_loss 6.683
09/19 12:19:35 PM | Train: [105/180] Step 150/312 Loss 0.691 Prec@(1,3) (83.3%, 98.9%), ce_loss 0.715, lat_loss 6.683
09/19 12:19:52 PM | Train: [105/180] Step 200/312 Loss 0.681 Prec@(1,3) (83.6%, 98.9%), ce_loss 0.715, lat_loss 6.683
09/19 12:20:10 PM | Train: [105/180] Step 250/312 Loss 0.689 Prec@(1,3) (83.5%, 98.9%), ce_loss 0.715, lat_loss 6.683
09/19 12:20:28 PM | Train: [105/180] Step 300/312 Loss 0.673 Prec@(1,3) (83.8%, 98.9%), ce_loss 0.715, lat_loss 6.683
09/19 12:20:33 PM | Train: [105/180] Step 312/312 Loss 0.676 Prec@(1,3) (83.7%, 98.9%), ce_loss 0.714, lat_loss 6.683
09/19 12:20:33 PM | _theta_step_train: [105/180] Final Prec@1 83.7300% Time 111.75
09/19 12:20:38 PM | Valid: [105/180] Step 050/312 Loss 0.599 Prec@(1,3) (84.9%, 99.5%), ce_loss 0.714, lat_loss 6.683
09/19 12:20:43 PM | Valid: [105/180] Step 100/312 Loss 0.643 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.714, lat_loss 6.683
09/19 12:20:48 PM | Valid: [105/180] Step 150/312 Loss 0.688 Prec@(1,3) (82.9%, 98.5%), ce_loss 0.714, lat_loss 6.683
09/19 12:20:52 PM | Valid: [105/180] Step 200/312 Loss 0.693 Prec@(1,3) (83.1%, 98.6%), ce_loss 0.714, lat_loss 6.683
09/19 12:20:57 PM | Valid: [105/180] Step 250/312 Loss 0.709 Prec@(1,3) (82.7%, 98.7%), ce_loss 0.714, lat_loss 6.683
09/19 12:21:02 PM | Valid: [105/180] Step 300/312 Loss 0.697 Prec@(1,3) (82.9%, 98.7%), ce_loss 0.714, lat_loss 6.683
09/19 12:21:03 PM | Valid: [105/180] Step 312/312 Loss 0.700 Prec@(1,3) (82.7%, 98.7%), ce_loss 0.714, lat_loss 6.683
09/19 12:21:03 PM | val: [105/180] Final Prec@1 82.7100% Time 29.66
09/19 12:21:03 PM | Start to train weights for epoch 105
09/19 12:21:28 PM | Train: [106/180] Step 050/1249 Loss 0.496 Prec@(1,3) (88.8%, 99.3%), ce_loss 0.714, lat_loss 6.683
09/19 12:21:49 PM | Train: [106/180] Step 100/1249 Loss 0.483 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.714, lat_loss 6.683
09/19 12:22:11 PM | Train: [106/180] Step 150/1249 Loss 0.479 Prec@(1,3) (88.4%, 99.5%), ce_loss 0.714, lat_loss 6.683
09/19 12:22:32 PM | Train: [106/180] Step 200/1249 Loss 0.474 Prec@(1,3) (88.3%, 99.5%), ce_loss 0.714, lat_loss 6.683
09/19 12:22:54 PM | Train: [106/180] Step 250/1249 Loss 0.474 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.714, lat_loss 6.683
09/19 12:23:16 PM | Train: [106/180] Step 300/1249 Loss 0.463 Prec@(1,3) (88.5%, 99.5%), ce_loss 0.714, lat_loss 6.683
09/19 12:23:37 PM | Train: [106/180] Step 350/1249 Loss 0.468 Prec@(1,3) (88.4%, 99.5%), ce_loss 0.714, lat_loss 6.683
09/19 12:23:57 PM | Train: [106/180] Step 400/1249 Loss 0.471 Prec@(1,3) (88.3%, 99.5%), ce_loss 0.713, lat_loss 6.683
09/19 12:24:19 PM | Train: [106/180] Step 450/1249 Loss 0.471 Prec@(1,3) (88.3%, 99.5%), ce_loss 0.713, lat_loss 6.683
09/19 12:24:42 PM | Train: [106/180] Step 500/1249 Loss 0.473 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.713, lat_loss 6.683
09/19 12:25:04 PM | Train: [106/180] Step 550/1249 Loss 0.469 Prec@(1,3) (88.3%, 99.5%), ce_loss 0.713, lat_loss 6.683
09/19 12:25:28 PM | Train: [106/180] Step 600/1249 Loss 0.472 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.713, lat_loss 6.683
09/19 12:25:52 PM | Train: [106/180] Step 650/1249 Loss 0.472 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.713, lat_loss 6.683
09/19 12:26:16 PM | Train: [106/180] Step 700/1249 Loss 0.472 Prec@(1,3) (88.1%, 99.5%), ce_loss 0.713, lat_loss 6.683
09/19 12:26:39 PM | Train: [106/180] Step 750/1249 Loss 0.471 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.713, lat_loss 6.683
09/19 12:27:04 PM | Train: [106/180] Step 800/1249 Loss 0.470 Prec@(1,3) (88.1%, 99.5%), ce_loss 0.713, lat_loss 6.683
09/19 12:27:28 PM | Train: [106/180] Step 850/1249 Loss 0.469 Prec@(1,3) (88.1%, 99.5%), ce_loss 0.713, lat_loss 6.683
09/19 12:27:53 PM | Train: [106/180] Step 900/1249 Loss 0.466 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.712, lat_loss 6.683
09/19 12:28:16 PM | Train: [106/180] Step 950/1249 Loss 0.467 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.712, lat_loss 6.683
09/19 12:28:39 PM | Train: [106/180] Step 1000/1249 Loss 0.470 Prec@(1,3) (88.1%, 99.5%), ce_loss 0.712, lat_loss 6.683
09/19 12:29:01 PM | Train: [106/180] Step 1050/1249 Loss 0.470 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.712, lat_loss 6.683
09/19 12:29:23 PM | Train: [106/180] Step 1100/1249 Loss 0.467 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.712, lat_loss 6.683
09/19 12:29:45 PM | Train: [106/180] Step 1150/1249 Loss 0.470 Prec@(1,3) (88.1%, 99.5%), ce_loss 0.712, lat_loss 6.683
09/19 12:30:06 PM | Train: [106/180] Step 1200/1249 Loss 0.470 Prec@(1,3) (88.1%, 99.5%), ce_loss 0.712, lat_loss 6.683
09/19 12:30:29 PM | Train: [106/180] Step 1249/1249 Loss 0.468 Prec@(1,3) (88.2%, 99.5%), ce_loss 0.712, lat_loss 6.683
09/19 12:30:29 PM | _w_step_train: [106/180] Final Prec@1 88.1600% Time 565.78
09/19 12:30:29 PM | Start to train theta for epoch 105
09/19 12:30:50 PM | Train: [106/180] Step 050/312 Loss 0.730 Prec@(1,3) (83.1%, 99.0%), ce_loss 0.712, lat_loss 6.683
09/19 12:31:10 PM | Train: [106/180] Step 100/312 Loss 0.740 Prec@(1,3) (82.9%, 98.9%), ce_loss 0.712, lat_loss 6.683
09/19 12:31:30 PM | Train: [106/180] Step 150/312 Loss 0.704 Prec@(1,3) (83.4%, 99.1%), ce_loss 0.712, lat_loss 6.683
09/19 12:31:51 PM | Train: [106/180] Step 200/312 Loss 0.702 Prec@(1,3) (83.4%, 99.0%), ce_loss 0.712, lat_loss 6.683
09/19 12:32:11 PM | Train: [106/180] Step 250/312 Loss 0.678 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.712, lat_loss 6.683
09/19 12:32:31 PM | Train: [106/180] Step 300/312 Loss 0.687 Prec@(1,3) (83.6%, 98.9%), ce_loss 0.712, lat_loss 6.683
09/19 12:32:36 PM | Train: [106/180] Step 312/312 Loss 0.689 Prec@(1,3) (83.5%, 98.9%), ce_loss 0.711, lat_loss 6.683
09/19 12:32:36 PM | _theta_step_train: [106/180] Final Prec@1 83.5200% Time 127.09
09/19 12:32:41 PM | Valid: [106/180] Step 050/312 Loss 0.747 Prec@(1,3) (81.1%, 98.1%), ce_loss 0.711, lat_loss 6.683
09/19 12:32:46 PM | Valid: [106/180] Step 100/312 Loss 0.716 Prec@(1,3) (82.3%, 98.5%), ce_loss 0.711, lat_loss 6.683
09/19 12:32:50 PM | Valid: [106/180] Step 150/312 Loss 0.707 Prec@(1,3) (82.9%, 98.7%), ce_loss 0.711, lat_loss 6.683
09/19 12:32:55 PM | Valid: [106/180] Step 200/312 Loss 0.740 Prec@(1,3) (82.3%, 98.3%), ce_loss 0.711, lat_loss 6.683
09/19 12:33:00 PM | Valid: [106/180] Step 250/312 Loss 0.729 Prec@(1,3) (82.5%, 98.5%), ce_loss 0.711, lat_loss 6.683
09/19 12:33:04 PM | Valid: [106/180] Step 300/312 Loss 0.712 Prec@(1,3) (82.7%, 98.6%), ce_loss 0.711, lat_loss 6.683
09/19 12:33:05 PM | Valid: [106/180] Step 312/312 Loss 0.705 Prec@(1,3) (82.9%, 98.7%), ce_loss 0.711, lat_loss 6.683
09/19 12:33:05 PM | val: [106/180] Final Prec@1 82.8600% Time 29.51
09/19 12:33:05 PM | Start to train weights for epoch 106
09/19 12:33:30 PM | Train: [107/180] Step 050/1249 Loss 0.414 Prec@(1,3) (89.2%, 99.8%), ce_loss 0.711, lat_loss 6.683
09/19 12:33:55 PM | Train: [107/180] Step 100/1249 Loss 0.424 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.711, lat_loss 6.683
09/19 12:34:17 PM | Train: [107/180] Step 150/1249 Loss 0.437 Prec@(1,3) (88.5%, 99.7%), ce_loss 0.711, lat_loss 6.683
09/19 12:34:32 PM | Train: [107/180] Step 200/1249 Loss 0.444 Prec@(1,3) (88.2%, 99.7%), ce_loss 0.711, lat_loss 6.683
09/19 12:34:48 PM | Train: [107/180] Step 250/1249 Loss 0.447 Prec@(1,3) (88.2%, 99.7%), ce_loss 0.711, lat_loss 6.683
09/19 12:35:04 PM | Train: [107/180] Step 300/1249 Loss 0.448 Prec@(1,3) (88.2%, 99.7%), ce_loss 0.711, lat_loss 6.683
09/19 12:35:20 PM | Train: [107/180] Step 350/1249 Loss 0.450 Prec@(1,3) (88.2%, 99.7%), ce_loss 0.711, lat_loss 6.683
09/19 12:35:36 PM | Train: [107/180] Step 400/1249 Loss 0.457 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.710, lat_loss 6.683
09/19 12:35:52 PM | Train: [107/180] Step 450/1249 Loss 0.461 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.710, lat_loss 6.683
09/19 12:36:08 PM | Train: [107/180] Step 500/1249 Loss 0.462 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.710, lat_loss 6.683
09/19 12:36:24 PM | Train: [107/180] Step 550/1249 Loss 0.463 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.710, lat_loss 6.683
09/19 12:36:40 PM | Train: [107/180] Step 600/1249 Loss 0.462 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.710, lat_loss 6.683
09/19 12:36:56 PM | Train: [107/180] Step 650/1249 Loss 0.463 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.710, lat_loss 6.683
09/19 12:37:12 PM | Train: [107/180] Step 700/1249 Loss 0.464 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.710, lat_loss 6.683
09/19 12:37:28 PM | Train: [107/180] Step 750/1249 Loss 0.461 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.710, lat_loss 6.683
09/19 12:37:44 PM | Train: [107/180] Step 800/1249 Loss 0.462 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.710, lat_loss 6.683
09/19 12:38:00 PM | Train: [107/180] Step 850/1249 Loss 0.460 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.710, lat_loss 6.683
09/19 12:38:16 PM | Train: [107/180] Step 900/1249 Loss 0.459 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.709, lat_loss 6.683
09/19 12:38:32 PM | Train: [107/180] Step 950/1249 Loss 0.459 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.709, lat_loss 6.683
09/19 12:38:48 PM | Train: [107/180] Step 1000/1249 Loss 0.459 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.709, lat_loss 6.683
09/19 12:39:04 PM | Train: [107/180] Step 1050/1249 Loss 0.460 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.709, lat_loss 6.683
09/19 12:39:20 PM | Train: [107/180] Step 1100/1249 Loss 0.460 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.709, lat_loss 6.683
09/19 12:39:36 PM | Train: [107/180] Step 1150/1249 Loss 0.459 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.709, lat_loss 6.683
09/19 12:39:52 PM | Train: [107/180] Step 1200/1249 Loss 0.459 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.709, lat_loss 6.683
09/19 12:40:07 PM | Train: [107/180] Step 1249/1249 Loss 0.458 Prec@(1,3) (88.4%, 99.6%), ce_loss 0.709, lat_loss 6.683
09/19 12:40:07 PM | _w_step_train: [107/180] Final Prec@1 88.3525% Time 421.94
09/19 12:40:07 PM | Start to train theta for epoch 106
09/19 12:40:22 PM | Train: [107/180] Step 050/312 Loss 0.650 Prec@(1,3) (83.9%, 99.4%), ce_loss 0.709, lat_loss 6.683
09/19 12:40:35 PM | Train: [107/180] Step 100/312 Loss 0.665 Prec@(1,3) (84.1%, 99.2%), ce_loss 0.709, lat_loss 6.683
09/19 12:40:48 PM | Train: [107/180] Step 150/312 Loss 0.655 Prec@(1,3) (84.1%, 99.1%), ce_loss 0.709, lat_loss 6.683
09/19 12:41:01 PM | Train: [107/180] Step 200/312 Loss 0.650 Prec@(1,3) (84.1%, 99.1%), ce_loss 0.709, lat_loss 6.683
09/19 12:41:19 PM | Train: [107/180] Step 250/312 Loss 0.646 Prec@(1,3) (84.1%, 99.2%), ce_loss 0.709, lat_loss 6.683
09/19 12:41:36 PM | Train: [107/180] Step 300/312 Loss 0.652 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.708, lat_loss 6.683
09/19 12:41:40 PM | Train: [107/180] Step 312/312 Loss 0.651 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.708, lat_loss 6.683
09/19 12:41:40 PM | _theta_step_train: [107/180] Final Prec@1 83.9000% Time 93.15
09/19 12:41:46 PM | Valid: [107/180] Step 050/312 Loss 0.656 Prec@(1,3) (83.0%, 99.1%), ce_loss 0.708, lat_loss 6.683
09/19 12:41:50 PM | Valid: [107/180] Step 100/312 Loss 0.680 Prec@(1,3) (83.4%, 99.0%), ce_loss 0.708, lat_loss 6.683
09/19 12:41:55 PM | Valid: [107/180] Step 150/312 Loss 0.681 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.708, lat_loss 6.683
09/19 12:41:59 PM | Valid: [107/180] Step 200/312 Loss 0.690 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.708, lat_loss 6.683
09/19 12:42:04 PM | Valid: [107/180] Step 250/312 Loss 0.692 Prec@(1,3) (83.6%, 99.1%), ce_loss 0.708, lat_loss 6.683
09/19 12:42:09 PM | Valid: [107/180] Step 300/312 Loss 0.692 Prec@(1,3) (83.4%, 98.9%), ce_loss 0.708, lat_loss 6.683
09/19 12:42:10 PM | Valid: [107/180] Step 312/312 Loss 0.690 Prec@(1,3) (83.5%, 98.9%), ce_loss 0.708, lat_loss 6.683
09/19 12:42:10 PM | val: [107/180] Final Prec@1 83.4500% Time 29.49
09/19 12:42:10 PM | Start to train weights for epoch 107
09/19 12:42:36 PM | Train: [108/180] Step 050/1249 Loss 0.455 Prec@(1,3) (87.9%, 99.8%), ce_loss 0.708, lat_loss 6.683
09/19 12:43:01 PM | Train: [108/180] Step 100/1249 Loss 0.445 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.708, lat_loss 6.683
09/19 12:43:25 PM | Train: [108/180] Step 150/1249 Loss 0.453 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.708, lat_loss 6.683
09/19 12:43:50 PM | Train: [108/180] Step 200/1249 Loss 0.446 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.708, lat_loss 6.683
09/19 12:44:14 PM | Train: [108/180] Step 250/1249 Loss 0.439 Prec@(1,3) (88.4%, 99.7%), ce_loss 0.708, lat_loss 6.683
09/19 12:44:39 PM | Train: [108/180] Step 300/1249 Loss 0.452 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.708, lat_loss 6.683
09/19 12:45:03 PM | Train: [108/180] Step 350/1249 Loss 0.461 Prec@(1,3) (88.0%, 99.6%), ce_loss 0.707, lat_loss 6.683
09/19 12:45:28 PM | Train: [108/180] Step 400/1249 Loss 0.464 Prec@(1,3) (87.9%, 99.6%), ce_loss 0.707, lat_loss 6.683
09/19 12:45:52 PM | Train: [108/180] Step 450/1249 Loss 0.465 Prec@(1,3) (87.9%, 99.6%), ce_loss 0.707, lat_loss 6.683
09/19 12:46:17 PM | Train: [108/180] Step 500/1249 Loss 0.469 Prec@(1,3) (87.8%, 99.6%), ce_loss 0.707, lat_loss 6.683
09/19 12:46:41 PM | Train: [108/180] Step 550/1249 Loss 0.462 Prec@(1,3) (88.0%, 99.6%), ce_loss 0.707, lat_loss 6.683
09/19 12:47:05 PM | Train: [108/180] Step 600/1249 Loss 0.462 Prec@(1,3) (88.0%, 99.6%), ce_loss 0.707, lat_loss 6.683
09/19 12:47:29 PM | Train: [108/180] Step 650/1249 Loss 0.459 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.707, lat_loss 6.683
09/19 12:47:53 PM | Train: [108/180] Step 700/1249 Loss 0.459 Prec@(1,3) (88.0%, 99.6%), ce_loss 0.707, lat_loss 6.683
09/19 12:48:18 PM | Train: [108/180] Step 750/1249 Loss 0.459 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.707, lat_loss 6.683
09/19 12:48:42 PM | Train: [108/180] Step 800/1249 Loss 0.461 Prec@(1,3) (88.0%, 99.6%), ce_loss 0.707, lat_loss 6.683
09/19 12:49:06 PM | Train: [108/180] Step 850/1249 Loss 0.459 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.707, lat_loss 6.683
09/19 12:49:31 PM | Train: [108/180] Step 900/1249 Loss 0.457 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.706, lat_loss 6.683
09/19 12:49:55 PM | Train: [108/180] Step 950/1249 Loss 0.458 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.706, lat_loss 6.683
09/19 12:50:20 PM | Train: [108/180] Step 1000/1249 Loss 0.460 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.706, lat_loss 6.683
09/19 12:50:44 PM | Train: [108/180] Step 1050/1249 Loss 0.461 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.706, lat_loss 6.683
09/19 12:51:08 PM | Train: [108/180] Step 1100/1249 Loss 0.461 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.706, lat_loss 6.683
09/19 12:51:32 PM | Train: [108/180] Step 1150/1249 Loss 0.458 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.706, lat_loss 6.683
09/19 12:51:57 PM | Train: [108/180] Step 1200/1249 Loss 0.462 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.706, lat_loss 6.683
09/19 12:52:21 PM | Train: [108/180] Step 1249/1249 Loss 0.463 Prec@(1,3) (88.1%, 99.6%), ce_loss 0.706, lat_loss 6.683
09/19 12:52:21 PM | _w_step_train: [108/180] Final Prec@1 88.1225% Time 611.46
09/19 12:52:21 PM | Start to train theta for epoch 107
09/19 12:52:43 PM | Train: [108/180] Step 050/312 Loss 0.652 Prec@(1,3) (83.3%, 99.3%), ce_loss 0.706, lat_loss 6.683
09/19 12:53:03 PM | Train: [108/180] Step 100/312 Loss 0.630 Prec@(1,3) (84.1%, 99.3%), ce_loss 0.706, lat_loss 6.683
09/19 12:53:24 PM | Train: [108/180] Step 150/312 Loss 0.628 Prec@(1,3) (84.2%, 99.4%), ce_loss 0.706, lat_loss 6.683
09/19 12:53:44 PM | Train: [108/180] Step 200/312 Loss 0.639 Prec@(1,3) (84.1%, 99.3%), ce_loss 0.706, lat_loss 6.683
09/19 12:54:05 PM | Train: [108/180] Step 250/312 Loss 0.638 Prec@(1,3) (84.1%, 99.2%), ce_loss 0.706, lat_loss 6.683
09/19 12:54:25 PM | Train: [108/180] Step 300/312 Loss 0.640 Prec@(1,3) (84.0%, 99.2%), ce_loss 0.705, lat_loss 6.683
09/19 12:54:30 PM | Train: [108/180] Step 312/312 Loss 0.644 Prec@(1,3) (84.0%, 99.1%), ce_loss 0.705, lat_loss 6.683
09/19 12:54:30 PM | _theta_step_train: [108/180] Final Prec@1 83.9700% Time 128.61
09/19 12:54:35 PM | Valid: [108/180] Step 050/312 Loss 0.753 Prec@(1,3) (81.7%, 97.8%), ce_loss 0.705, lat_loss 6.683
09/19 12:54:40 PM | Valid: [108/180] Step 100/312 Loss 0.693 Prec@(1,3) (82.9%, 98.4%), ce_loss 0.705, lat_loss 6.683
09/19 12:54:45 PM | Valid: [108/180] Step 150/312 Loss 0.715 Prec@(1,3) (83.1%, 98.4%), ce_loss 0.705, lat_loss 6.683
09/19 12:54:49 PM | Valid: [108/180] Step 200/312 Loss 0.697 Prec@(1,3) (83.5%, 98.6%), ce_loss 0.705, lat_loss 6.683
09/19 12:54:54 PM | Valid: [108/180] Step 250/312 Loss 0.702 Prec@(1,3) (83.3%, 98.7%), ce_loss 0.705, lat_loss 6.683
09/19 12:54:59 PM | Valid: [108/180] Step 300/312 Loss 0.686 Prec@(1,3) (83.4%, 98.8%), ce_loss 0.705, lat_loss 6.683
09/19 12:55:00 PM | Valid: [108/180] Step 312/312 Loss 0.693 Prec@(1,3) (83.2%, 98.7%), ce_loss 0.705, lat_loss 6.683
09/19 12:55:00 PM | val: [108/180] Final Prec@1 83.2300% Time 29.71
09/19 12:55:00 PM | Start to train weights for epoch 108
09/19 12:55:25 PM | Train: [109/180] Step 050/1249 Loss 0.466 Prec@(1,3) (87.4%, 99.8%), ce_loss 0.705, lat_loss 6.683
09/19 12:55:50 PM | Train: [109/180] Step 100/1249 Loss 0.432 Prec@(1,3) (88.9%, 99.7%), ce_loss 0.705, lat_loss 6.683
09/19 12:56:11 PM | Train: [109/180] Step 150/1249 Loss 0.449 Prec@(1,3) (88.8%, 99.5%), ce_loss 0.705, lat_loss 6.683
09/19 12:56:36 PM | Train: [109/180] Step 200/1249 Loss 0.447 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.705, lat_loss 6.683
09/19 12:57:01 PM | Train: [109/180] Step 250/1249 Loss 0.444 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.705, lat_loss 6.683
09/19 12:57:26 PM | Train: [109/180] Step 300/1249 Loss 0.448 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.705, lat_loss 6.683
09/19 12:57:51 PM | Train: [109/180] Step 350/1249 Loss 0.461 Prec@(1,3) (88.4%, 99.5%), ce_loss 0.705, lat_loss 6.683
09/19 12:58:16 PM | Train: [109/180] Step 400/1249 Loss 0.458 Prec@(1,3) (88.4%, 99.6%), ce_loss 0.704, lat_loss 6.683
09/19 12:58:41 PM | Train: [109/180] Step 450/1249 Loss 0.450 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.704, lat_loss 6.683
09/19 12:59:06 PM | Train: [109/180] Step 500/1249 Loss 0.451 Prec@(1,3) (88.5%, 99.6%), ce_loss 0.704, lat_loss 6.683
09/19 12:59:31 PM | Train: [109/180] Step 550/1249 Loss 0.454 Prec@(1,3) (88.4%, 99.6%), ce_loss 0.704, lat_loss 6.683
09/19 12:59:53 PM | Train: [109/180] Step 600/1249 Loss 0.453 Prec@(1,3) (88.5%, 99.6%), ce_loss 0.704, lat_loss 6.683
09/19 01:00:16 PM | Train: [109/180] Step 650/1249 Loss 0.455 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.704, lat_loss 6.683
09/19 01:00:38 PM | Train: [109/180] Step 700/1249 Loss 0.457 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.704, lat_loss 6.683
09/19 01:01:01 PM | Train: [109/180] Step 750/1249 Loss 0.453 Prec@(1,3) (88.5%, 99.6%), ce_loss 0.704, lat_loss 6.683
09/19 01:01:23 PM | Train: [109/180] Step 800/1249 Loss 0.454 Prec@(1,3) (88.4%, 99.6%), ce_loss 0.704, lat_loss 6.683
09/19 01:01:45 PM | Train: [109/180] Step 850/1249 Loss 0.452 Prec@(1,3) (88.4%, 99.6%), ce_loss 0.704, lat_loss 6.683
09/19 01:02:09 PM | Train: [109/180] Step 900/1249 Loss 0.450 Prec@(1,3) (88.5%, 99.6%), ce_loss 0.703, lat_loss 6.683
09/19 01:02:32 PM | Train: [109/180] Step 950/1249 Loss 0.448 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.703, lat_loss 6.683
09/19 01:02:55 PM | Train: [109/180] Step 1000/1249 Loss 0.445 Prec@(1,3) (88.6%, 99.7%), ce_loss 0.703, lat_loss 6.683
09/19 01:03:17 PM | Train: [109/180] Step 1050/1249 Loss 0.449 Prec@(1,3) (88.5%, 99.6%), ce_loss 0.703, lat_loss 6.683
09/19 01:03:39 PM | Train: [109/180] Step 1100/1249 Loss 0.453 Prec@(1,3) (88.4%, 99.6%), ce_loss 0.703, lat_loss 6.683
09/19 01:04:01 PM | Train: [109/180] Step 1150/1249 Loss 0.452 Prec@(1,3) (88.4%, 99.6%), ce_loss 0.703, lat_loss 6.683
09/19 01:04:25 PM | Train: [109/180] Step 1200/1249 Loss 0.453 Prec@(1,3) (88.4%, 99.6%), ce_loss 0.703, lat_loss 6.683
09/19 01:04:49 PM | Train: [109/180] Step 1249/1249 Loss 0.455 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.703, lat_loss 6.683
09/19 01:04:49 PM | _w_step_train: [109/180] Final Prec@1 88.3450% Time 589.40
09/19 01:04:49 PM | Start to train theta for epoch 108
09/19 01:05:10 PM | Train: [109/180] Step 050/312 Loss 0.694 Prec@(1,3) (82.8%, 98.9%), ce_loss 0.703, lat_loss 6.683
09/19 01:05:30 PM | Train: [109/180] Step 100/312 Loss 0.694 Prec@(1,3) (82.8%, 99.1%), ce_loss 0.703, lat_loss 6.683
09/19 01:05:50 PM | Train: [109/180] Step 150/312 Loss 0.662 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.703, lat_loss 6.683
09/19 01:06:10 PM | Train: [109/180] Step 200/312 Loss 0.649 Prec@(1,3) (83.8%, 99.2%), ce_loss 0.703, lat_loss 6.683
09/19 01:06:30 PM | Train: [109/180] Step 250/312 Loss 0.651 Prec@(1,3) (83.8%, 99.2%), ce_loss 0.703, lat_loss 6.683
09/19 01:06:51 PM | Train: [109/180] Step 300/312 Loss 0.650 Prec@(1,3) (83.9%, 99.1%), ce_loss 0.703, lat_loss 6.683
09/19 01:06:56 PM | Train: [109/180] Step 312/312 Loss 0.644 Prec@(1,3) (84.0%, 99.2%), ce_loss 0.703, lat_loss 6.683
09/19 01:06:56 PM | _theta_step_train: [109/180] Final Prec@1 84.0400% Time 126.70
09/19 01:07:01 PM | Valid: [109/180] Step 050/312 Loss 0.558 Prec@(1,3) (85.5%, 99.6%), ce_loss 0.702, lat_loss 6.683
09/19 01:07:06 PM | Valid: [109/180] Step 100/312 Loss 0.613 Prec@(1,3) (84.7%, 99.3%), ce_loss 0.702, lat_loss 6.683
09/19 01:07:11 PM | Valid: [109/180] Step 150/312 Loss 0.628 Prec@(1,3) (84.1%, 99.3%), ce_loss 0.702, lat_loss 6.683
09/19 01:07:15 PM | Valid: [109/180] Step 200/312 Loss 0.651 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.702, lat_loss 6.683
09/19 01:07:20 PM | Valid: [109/180] Step 250/312 Loss 0.673 Prec@(1,3) (83.1%, 98.9%), ce_loss 0.702, lat_loss 6.683
09/19 01:07:25 PM | Valid: [109/180] Step 300/312 Loss 0.662 Prec@(1,3) (83.3%, 98.9%), ce_loss 0.702, lat_loss 6.683
09/19 01:07:26 PM | Valid: [109/180] Step 312/312 Loss 0.657 Prec@(1,3) (83.5%, 99.0%), ce_loss 0.702, lat_loss 6.683
09/19 01:07:26 PM | val: [109/180] Final Prec@1 83.4800% Time 29.75
09/19 01:07:26 PM | Start to train weights for epoch 109
09/19 01:07:51 PM | Train: [110/180] Step 050/1249 Loss 0.376 Prec@(1,3) (90.9%, 99.6%), ce_loss 0.702, lat_loss 6.683
09/19 01:08:12 PM | Train: [110/180] Step 100/1249 Loss 0.383 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.702, lat_loss 6.683
09/19 01:08:34 PM | Train: [110/180] Step 150/1249 Loss 0.399 Prec@(1,3) (89.7%, 99.6%), ce_loss 0.702, lat_loss 6.683
09/19 01:08:57 PM | Train: [110/180] Step 200/1249 Loss 0.430 Prec@(1,3) (89.2%, 99.6%), ce_loss 0.702, lat_loss 6.683
09/19 01:09:19 PM | Train: [110/180] Step 250/1249 Loss 0.445 Prec@(1,3) (88.8%, 99.5%), ce_loss 0.702, lat_loss 6.683
09/19 01:09:41 PM | Train: [110/180] Step 300/1249 Loss 0.443 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.702, lat_loss 6.683
09/19 01:09:58 PM | Train: [110/180] Step 350/1249 Loss 0.442 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.702, lat_loss 6.683
09/19 01:10:15 PM | Train: [110/180] Step 400/1249 Loss 0.439 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.701, lat_loss 6.683
09/19 01:10:31 PM | Train: [110/180] Step 450/1249 Loss 0.441 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.701, lat_loss 6.683
09/19 01:10:46 PM | Train: [110/180] Step 500/1249 Loss 0.440 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.701, lat_loss 6.683
09/19 01:11:02 PM | Train: [110/180] Step 550/1249 Loss 0.438 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.701, lat_loss 6.683
09/19 01:11:18 PM | Train: [110/180] Step 600/1249 Loss 0.440 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.701, lat_loss 6.683
09/19 01:11:34 PM | Train: [110/180] Step 650/1249 Loss 0.438 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.701, lat_loss 6.683
09/19 01:11:50 PM | Train: [110/180] Step 700/1249 Loss 0.445 Prec@(1,3) (88.5%, 99.6%), ce_loss 0.701, lat_loss 6.683
09/19 01:12:06 PM | Train: [110/180] Step 750/1249 Loss 0.447 Prec@(1,3) (88.5%, 99.6%), ce_loss 0.701, lat_loss 6.683
09/19 01:12:22 PM | Train: [110/180] Step 800/1249 Loss 0.450 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.701, lat_loss 6.683
09/19 01:12:38 PM | Train: [110/180] Step 850/1249 Loss 0.454 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.701, lat_loss 6.683
09/19 01:12:54 PM | Train: [110/180] Step 900/1249 Loss 0.455 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.701, lat_loss 6.683
09/19 01:13:10 PM | Train: [110/180] Step 950/1249 Loss 0.456 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.700, lat_loss 6.683
09/19 01:13:25 PM | Train: [110/180] Step 1000/1249 Loss 0.456 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.700, lat_loss 6.683
09/19 01:13:41 PM | Train: [110/180] Step 1050/1249 Loss 0.456 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.700, lat_loss 6.683
09/19 01:13:57 PM | Train: [110/180] Step 1100/1249 Loss 0.456 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.700, lat_loss 6.683
09/19 01:14:13 PM | Train: [110/180] Step 1150/1249 Loss 0.455 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.700, lat_loss 6.683
09/19 01:14:29 PM | Train: [110/180] Step 1200/1249 Loss 0.457 Prec@(1,3) (88.2%, 99.6%), ce_loss 0.700, lat_loss 6.683
09/19 01:14:45 PM | Train: [110/180] Step 1249/1249 Loss 0.454 Prec@(1,3) (88.3%, 99.6%), ce_loss 0.700, lat_loss 6.683
09/19 01:14:45 PM | _w_step_train: [110/180] Final Prec@1 88.2775% Time 438.61
09/19 01:14:45 PM | Start to train theta for epoch 109
09/19 01:15:06 PM | Train: [110/180] Step 050/312 Loss 0.601 Prec@(1,3) (86.3%, 99.1%), ce_loss 0.700, lat_loss 6.683
09/19 01:15:27 PM | Train: [110/180] Step 100/312 Loss 0.608 Prec@(1,3) (85.4%, 99.3%), ce_loss 0.700, lat_loss 6.683
09/19 01:15:48 PM | Train: [110/180] Step 150/312 Loss 0.624 Prec@(1,3) (85.1%, 99.2%), ce_loss 0.700, lat_loss 6.683
09/19 01:16:08 PM | Train: [110/180] Step 200/312 Loss 0.632 Prec@(1,3) (85.0%, 99.2%), ce_loss 0.700, lat_loss 6.683
09/19 01:16:29 PM | Train: [110/180] Step 250/312 Loss 0.636 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.700, lat_loss 6.683
09/19 01:16:49 PM | Train: [110/180] Step 300/312 Loss 0.637 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.700, lat_loss 6.683
09/19 01:16:54 PM | Train: [110/180] Step 312/312 Loss 0.638 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.700, lat_loss 6.683
09/19 01:16:54 PM | _theta_step_train: [110/180] Final Prec@1 84.6600% Time 129.71
09/19 01:17:00 PM | Valid: [110/180] Step 050/312 Loss 0.755 Prec@(1,3) (81.9%, 98.3%), ce_loss 0.700, lat_loss 6.683
09/19 01:17:05 PM | Valid: [110/180] Step 100/312 Loss 0.754 Prec@(1,3) (82.6%, 98.3%), ce_loss 0.700, lat_loss 6.683
09/19 01:17:09 PM | Valid: [110/180] Step 150/312 Loss 0.741 Prec@(1,3) (82.7%, 98.4%), ce_loss 0.699, lat_loss 6.683
09/19 01:17:14 PM | Valid: [110/180] Step 200/312 Loss 0.740 Prec@(1,3) (82.7%, 98.4%), ce_loss 0.699, lat_loss 6.683
09/19 01:17:19 PM | Valid: [110/180] Step 250/312 Loss 0.741 Prec@(1,3) (82.6%, 98.5%), ce_loss 0.699, lat_loss 6.683
09/19 01:17:23 PM | Valid: [110/180] Step 300/312 Loss 0.756 Prec@(1,3) (82.5%, 98.3%), ce_loss 0.699, lat_loss 6.683
09/19 01:17:24 PM | Valid: [110/180] Step 312/312 Loss 0.752 Prec@(1,3) (82.6%, 98.4%), ce_loss 0.699, lat_loss 6.683
09/19 01:17:24 PM | val: [110/180] Final Prec@1 82.5700% Time 30.01
09/19 01:17:24 PM | Start to train weights for epoch 110
09/19 01:17:51 PM | Train: [111/180] Step 050/1249 Loss 0.442 Prec@(1,3) (88.8%, 99.8%), ce_loss 0.699, lat_loss 6.683
09/19 01:18:15 PM | Train: [111/180] Step 100/1249 Loss 0.447 Prec@(1,3) (88.4%, 99.8%), ce_loss 0.699, lat_loss 6.683
09/19 01:18:40 PM | Train: [111/180] Step 150/1249 Loss 0.438 Prec@(1,3) (88.7%, 99.8%), ce_loss 0.699, lat_loss 6.683
09/19 01:19:05 PM | Train: [111/180] Step 200/1249 Loss 0.431 Prec@(1,3) (88.8%, 99.8%), ce_loss 0.699, lat_loss 6.683
09/19 01:19:30 PM | Train: [111/180] Step 250/1249 Loss 0.430 Prec@(1,3) (88.8%, 99.8%), ce_loss 0.699, lat_loss 6.683
09/19 01:19:54 PM | Train: [111/180] Step 300/1249 Loss 0.428 Prec@(1,3) (88.9%, 99.7%), ce_loss 0.699, lat_loss 6.683
09/19 01:20:17 PM | Train: [111/180] Step 350/1249 Loss 0.431 Prec@(1,3) (88.9%, 99.7%), ce_loss 0.699, lat_loss 6.683
09/19 01:20:41 PM | Train: [111/180] Step 400/1249 Loss 0.437 Prec@(1,3) (88.8%, 99.7%), ce_loss 0.699, lat_loss 6.683
09/19 01:21:05 PM | Train: [111/180] Step 450/1249 Loss 0.435 Prec@(1,3) (88.9%, 99.7%), ce_loss 0.699, lat_loss 6.683
09/19 01:21:27 PM | Train: [111/180] Step 500/1249 Loss 0.435 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.698, lat_loss 6.683
09/19 01:21:50 PM | Train: [111/180] Step 550/1249 Loss 0.439 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.698, lat_loss 6.683
09/19 01:22:13 PM | Train: [111/180] Step 600/1249 Loss 0.440 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.698, lat_loss 6.683
09/19 01:22:35 PM | Train: [111/180] Step 650/1249 Loss 0.439 Prec@(1,3) (88.8%, 99.7%), ce_loss 0.698, lat_loss 6.683
09/19 01:22:57 PM | Train: [111/180] Step 700/1249 Loss 0.439 Prec@(1,3) (88.8%, 99.7%), ce_loss 0.698, lat_loss 6.683
09/19 01:23:20 PM | Train: [111/180] Step 750/1249 Loss 0.441 Prec@(1,3) (88.8%, 99.7%), ce_loss 0.698, lat_loss 6.683
09/19 01:23:41 PM | Train: [111/180] Step 800/1249 Loss 0.444 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.698, lat_loss 6.683
09/19 01:24:03 PM | Train: [111/180] Step 850/1249 Loss 0.443 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.698, lat_loss 6.683
09/19 01:24:26 PM | Train: [111/180] Step 900/1249 Loss 0.441 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.698, lat_loss 6.683
09/19 01:24:48 PM | Train: [111/180] Step 950/1249 Loss 0.441 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.698, lat_loss 6.683
09/19 01:25:10 PM | Train: [111/180] Step 1000/1249 Loss 0.441 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.698, lat_loss 6.683
09/19 01:25:32 PM | Train: [111/180] Step 1050/1249 Loss 0.442 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.697, lat_loss 6.683
09/19 01:25:55 PM | Train: [111/180] Step 1100/1249 Loss 0.444 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.697, lat_loss 6.683
09/19 01:26:16 PM | Train: [111/180] Step 1150/1249 Loss 0.443 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.697, lat_loss 6.683
09/19 01:26:39 PM | Train: [111/180] Step 1200/1249 Loss 0.442 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.697, lat_loss 6.683
09/19 01:27:04 PM | Train: [111/180] Step 1249/1249 Loss 0.442 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.697, lat_loss 6.683
09/19 01:27:04 PM | _w_step_train: [111/180] Final Prec@1 88.8475% Time 579.37
09/19 01:27:04 PM | Start to train theta for epoch 110
09/19 01:27:25 PM | Train: [111/180] Step 050/312 Loss 0.678 Prec@(1,3) (84.0%, 98.8%), ce_loss 0.697, lat_loss 6.683
09/19 01:27:45 PM | Train: [111/180] Step 100/312 Loss 0.654 Prec@(1,3) (84.2%, 99.1%), ce_loss 0.697, lat_loss 6.683
09/19 01:28:06 PM | Train: [111/180] Step 150/312 Loss 0.656 Prec@(1,3) (84.0%, 99.2%), ce_loss 0.697, lat_loss 6.683
09/19 01:28:26 PM | Train: [111/180] Step 200/312 Loss 0.662 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.697, lat_loss 6.683
09/19 01:28:47 PM | Train: [111/180] Step 250/312 Loss 0.668 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.697, lat_loss 6.683
09/19 01:29:08 PM | Train: [111/180] Step 300/312 Loss 0.674 Prec@(1,3) (83.5%, 99.0%), ce_loss 0.697, lat_loss 6.683
09/19 01:29:13 PM | Train: [111/180] Step 312/312 Loss 0.667 Prec@(1,3) (83.6%, 99.1%), ce_loss 0.697, lat_loss 6.683
09/19 01:29:13 PM | _theta_step_train: [111/180] Final Prec@1 83.5800% Time 128.69
09/19 01:29:18 PM | Valid: [111/180] Step 050/312 Loss 0.765 Prec@(1,3) (82.4%, 98.0%), ce_loss 0.697, lat_loss 6.683
09/19 01:29:23 PM | Valid: [111/180] Step 100/312 Loss 0.724 Prec@(1,3) (82.9%, 98.3%), ce_loss 0.697, lat_loss 6.683
09/19 01:29:27 PM | Valid: [111/180] Step 150/312 Loss 0.745 Prec@(1,3) (83.0%, 98.2%), ce_loss 0.697, lat_loss 6.683
09/19 01:29:32 PM | Valid: [111/180] Step 200/312 Loss 0.711 Prec@(1,3) (83.9%, 98.4%), ce_loss 0.697, lat_loss 6.683
09/19 01:29:36 PM | Valid: [111/180] Step 250/312 Loss 0.751 Prec@(1,3) (83.0%, 98.1%), ce_loss 0.697, lat_loss 6.683
09/19 01:29:41 PM | Valid: [111/180] Step 300/312 Loss 0.738 Prec@(1,3) (83.0%, 98.2%), ce_loss 0.697, lat_loss 6.683
09/19 01:29:42 PM | Valid: [111/180] Step 312/312 Loss 0.732 Prec@(1,3) (83.0%, 98.3%), ce_loss 0.697, lat_loss 6.683
09/19 01:29:42 PM | val: [111/180] Final Prec@1 83.0400% Time 29.69
09/19 01:29:42 PM | Start to train weights for epoch 111
09/19 01:30:08 PM | Train: [112/180] Step 050/1249 Loss 0.475 Prec@(1,3) (88.1%, 99.7%), ce_loss 0.696, lat_loss 6.683
09/19 01:30:33 PM | Train: [112/180] Step 100/1249 Loss 0.439 Prec@(1,3) (88.9%, 99.7%), ce_loss 0.696, lat_loss 6.683
09/19 01:30:57 PM | Train: [112/180] Step 150/1249 Loss 0.415 Prec@(1,3) (89.5%, 99.8%), ce_loss 0.696, lat_loss 6.683
09/19 01:31:22 PM | Train: [112/180] Step 200/1249 Loss 0.429 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.696, lat_loss 6.683
09/19 01:31:46 PM | Train: [112/180] Step 250/1249 Loss 0.428 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.696, lat_loss 6.683
09/19 01:32:12 PM | Train: [112/180] Step 300/1249 Loss 0.429 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.696, lat_loss 6.683
09/19 01:32:36 PM | Train: [112/180] Step 350/1249 Loss 0.428 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.696, lat_loss 6.683
09/19 01:33:01 PM | Train: [112/180] Step 400/1249 Loss 0.436 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.696, lat_loss 6.683
09/19 01:33:26 PM | Train: [112/180] Step 450/1249 Loss 0.435 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.696, lat_loss 6.683
09/19 01:33:50 PM | Train: [112/180] Step 500/1249 Loss 0.436 Prec@(1,3) (88.9%, 99.7%), ce_loss 0.696, lat_loss 6.683
09/19 01:34:15 PM | Train: [112/180] Step 550/1249 Loss 0.440 Prec@(1,3) (88.8%, 99.7%), ce_loss 0.696, lat_loss 6.683
09/19 01:34:40 PM | Train: [112/180] Step 600/1249 Loss 0.443 Prec@(1,3) (88.7%, 99.7%), ce_loss 0.695, lat_loss 6.683
09/19 01:35:05 PM | Train: [112/180] Step 650/1249 Loss 0.444 Prec@(1,3) (88.7%, 99.7%), ce_loss 0.695, lat_loss 6.683
09/19 01:35:30 PM | Train: [112/180] Step 700/1249 Loss 0.444 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.695, lat_loss 6.683
09/19 01:35:55 PM | Train: [112/180] Step 750/1249 Loss 0.442 Prec@(1,3) (88.7%, 99.7%), ce_loss 0.695, lat_loss 6.683
09/19 01:36:20 PM | Train: [112/180] Step 800/1249 Loss 0.441 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.695, lat_loss 6.683
09/19 01:36:44 PM | Train: [112/180] Step 850/1249 Loss 0.444 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.695, lat_loss 6.683
09/19 01:37:09 PM | Train: [112/180] Step 900/1249 Loss 0.444 Prec@(1,3) (88.7%, 99.7%), ce_loss 0.695, lat_loss 6.683
09/19 01:37:34 PM | Train: [112/180] Step 950/1249 Loss 0.446 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.695, lat_loss 6.683
09/19 01:37:58 PM | Train: [112/180] Step 1000/1249 Loss 0.445 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.695, lat_loss 6.683
09/19 01:38:23 PM | Train: [112/180] Step 1050/1249 Loss 0.446 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.695, lat_loss 6.683
09/19 01:38:48 PM | Train: [112/180] Step 1100/1249 Loss 0.444 Prec@(1,3) (88.7%, 99.7%), ce_loss 0.695, lat_loss 6.683
09/19 01:39:12 PM | Train: [112/180] Step 1150/1249 Loss 0.444 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.694, lat_loss 6.683
09/19 01:39:37 PM | Train: [112/180] Step 1200/1249 Loss 0.443 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.694, lat_loss 6.683
09/19 01:40:01 PM | Train: [112/180] Step 1249/1249 Loss 0.442 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.694, lat_loss 6.683
09/19 01:40:01 PM | _w_step_train: [112/180] Final Prec@1 88.8025% Time 618.99
09/19 01:40:01 PM | Start to train theta for epoch 111
09/19 01:40:23 PM | Train: [112/180] Step 050/312 Loss 0.634 Prec@(1,3) (86.2%, 98.6%), ce_loss 0.694, lat_loss 6.683
09/19 01:40:43 PM | Train: [112/180] Step 100/312 Loss 0.652 Prec@(1,3) (84.9%, 98.7%), ce_loss 0.694, lat_loss 6.683
09/19 01:41:03 PM | Train: [112/180] Step 150/312 Loss 0.657 Prec@(1,3) (84.3%, 98.8%), ce_loss 0.694, lat_loss 6.683
09/19 01:41:23 PM | Train: [112/180] Step 200/312 Loss 0.655 Prec@(1,3) (84.4%, 98.9%), ce_loss 0.694, lat_loss 6.683
09/19 01:41:43 PM | Train: [112/180] Step 250/312 Loss 0.659 Prec@(1,3) (84.1%, 99.0%), ce_loss 0.694, lat_loss 6.683
09/19 01:42:03 PM | Train: [112/180] Step 300/312 Loss 0.649 Prec@(1,3) (84.3%, 99.0%), ce_loss 0.694, lat_loss 6.683
09/19 01:42:08 PM | Train: [112/180] Step 312/312 Loss 0.645 Prec@(1,3) (84.4%, 99.0%), ce_loss 0.694, lat_loss 6.683
09/19 01:42:09 PM | _theta_step_train: [112/180] Final Prec@1 84.3900% Time 127.26
09/19 01:42:14 PM | Valid: [112/180] Step 050/312 Loss 0.755 Prec@(1,3) (81.4%, 97.8%), ce_loss 0.694, lat_loss 6.683
09/19 01:42:19 PM | Valid: [112/180] Step 100/312 Loss 0.742 Prec@(1,3) (81.7%, 98.3%), ce_loss 0.694, lat_loss 6.683
09/19 01:42:23 PM | Valid: [112/180] Step 150/312 Loss 0.809 Prec@(1,3) (81.3%, 97.8%), ce_loss 0.694, lat_loss 6.683
09/19 01:42:28 PM | Valid: [112/180] Step 200/312 Loss 0.792 Prec@(1,3) (81.4%, 98.1%), ce_loss 0.694, lat_loss 6.683
09/19 01:42:33 PM | Valid: [112/180] Step 250/312 Loss 0.809 Prec@(1,3) (81.1%, 97.9%), ce_loss 0.694, lat_loss 6.683
09/19 01:42:37 PM | Valid: [112/180] Step 300/312 Loss 0.779 Prec@(1,3) (81.6%, 98.1%), ce_loss 0.694, lat_loss 6.683
09/19 01:42:38 PM | Valid: [112/180] Step 312/312 Loss 0.775 Prec@(1,3) (81.6%, 98.2%), ce_loss 0.694, lat_loss 6.683
09/19 01:42:38 PM | val: [112/180] Final Prec@1 81.5700% Time 29.73
09/19 01:42:38 PM | Start to train weights for epoch 112
09/19 01:43:04 PM | Train: [113/180] Step 050/1249 Loss 0.404 Prec@(1,3) (89.8%, 99.8%), ce_loss 0.694, lat_loss 6.683
09/19 01:43:28 PM | Train: [113/180] Step 100/1249 Loss 0.414 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.694, lat_loss 6.683
09/19 01:43:51 PM | Train: [113/180] Step 150/1249 Loss 0.407 Prec@(1,3) (89.7%, 99.6%), ce_loss 0.693, lat_loss 6.683
09/19 01:44:12 PM | Train: [113/180] Step 200/1249 Loss 0.403 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.693, lat_loss 6.683
09/19 01:44:34 PM | Train: [113/180] Step 250/1249 Loss 0.421 Prec@(1,3) (89.4%, 99.6%), ce_loss 0.693, lat_loss 6.683
09/19 01:44:55 PM | Train: [113/180] Step 300/1249 Loss 0.430 Prec@(1,3) (89.2%, 99.6%), ce_loss 0.693, lat_loss 6.683
09/19 01:45:17 PM | Train: [113/180] Step 350/1249 Loss 0.432 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.693, lat_loss 6.683
09/19 01:45:39 PM | Train: [113/180] Step 400/1249 Loss 0.430 Prec@(1,3) (89.2%, 99.6%), ce_loss 0.693, lat_loss 6.683
09/19 01:46:02 PM | Train: [113/180] Step 450/1249 Loss 0.436 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.693, lat_loss 6.683
09/19 01:46:24 PM | Train: [113/180] Step 500/1249 Loss 0.432 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.693, lat_loss 6.683
09/19 01:46:46 PM | Train: [113/180] Step 550/1249 Loss 0.436 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.693, lat_loss 6.683
09/19 01:47:08 PM | Train: [113/180] Step 600/1249 Loss 0.435 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.693, lat_loss 6.683
09/19 01:47:30 PM | Train: [113/180] Step 650/1249 Loss 0.435 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.693, lat_loss 6.683
09/19 01:47:54 PM | Train: [113/180] Step 700/1249 Loss 0.440 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.693, lat_loss 6.683
09/19 01:48:16 PM | Train: [113/180] Step 750/1249 Loss 0.441 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.692, lat_loss 6.683
09/19 01:48:39 PM | Train: [113/180] Step 800/1249 Loss 0.438 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.692, lat_loss 6.683
09/19 01:49:00 PM | Train: [113/180] Step 850/1249 Loss 0.439 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.692, lat_loss 6.683
09/19 01:49:23 PM | Train: [113/180] Step 900/1249 Loss 0.443 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.692, lat_loss 6.683
09/19 01:49:46 PM | Train: [113/180] Step 950/1249 Loss 0.442 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.692, lat_loss 6.683
09/19 01:50:10 PM | Train: [113/180] Step 1000/1249 Loss 0.444 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.692, lat_loss 6.683
09/19 01:50:34 PM | Train: [113/180] Step 1050/1249 Loss 0.443 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.692, lat_loss 6.683
09/19 01:50:57 PM | Train: [113/180] Step 1100/1249 Loss 0.443 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.692, lat_loss 6.683
09/19 01:51:21 PM | Train: [113/180] Step 1150/1249 Loss 0.448 Prec@(1,3) (88.5%, 99.6%), ce_loss 0.692, lat_loss 6.683
09/19 01:51:45 PM | Train: [113/180] Step 1200/1249 Loss 0.447 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.692, lat_loss 6.683
09/19 01:52:09 PM | Train: [113/180] Step 1249/1249 Loss 0.446 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.692, lat_loss 6.683
09/19 01:52:09 PM | _w_step_train: [113/180] Final Prec@1 88.6000% Time 570.73
09/19 01:52:09 PM | Start to train theta for epoch 112
09/19 01:52:30 PM | Train: [113/180] Step 050/312 Loss 0.653 Prec@(1,3) (84.0%, 99.1%), ce_loss 0.692, lat_loss 6.683
09/19 01:52:50 PM | Train: [113/180] Step 100/312 Loss 0.634 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.691, lat_loss 6.683
09/19 01:53:10 PM | Train: [113/180] Step 150/312 Loss 0.630 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.691, lat_loss 6.683
09/19 01:53:31 PM | Train: [113/180] Step 200/312 Loss 0.609 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.691, lat_loss 6.683
09/19 01:53:51 PM | Train: [113/180] Step 250/312 Loss 0.618 Prec@(1,3) (84.9%, 99.2%), ce_loss 0.691, lat_loss 6.683
09/19 01:54:12 PM | Train: [113/180] Step 300/312 Loss 0.624 Prec@(1,3) (84.9%, 99.2%), ce_loss 0.691, lat_loss 6.683
09/19 01:54:17 PM | Train: [113/180] Step 312/312 Loss 0.630 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.691, lat_loss 6.683
09/19 01:54:17 PM | _theta_step_train: [113/180] Final Prec@1 84.8200% Time 127.58
09/19 01:54:22 PM | Valid: [113/180] Step 050/312 Loss 0.616 Prec@(1,3) (84.1%, 99.4%), ce_loss 0.691, lat_loss 6.683
09/19 01:54:27 PM | Valid: [113/180] Step 100/312 Loss 0.635 Prec@(1,3) (84.2%, 99.2%), ce_loss 0.691, lat_loss 6.683
09/19 01:54:31 PM | Valid: [113/180] Step 150/312 Loss 0.625 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.691, lat_loss 6.683
09/19 01:54:36 PM | Valid: [113/180] Step 200/312 Loss 0.625 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.691, lat_loss 6.683
09/19 01:54:41 PM | Valid: [113/180] Step 250/312 Loss 0.654 Prec@(1,3) (84.3%, 99.0%), ce_loss 0.691, lat_loss 6.683
09/19 01:54:45 PM | Valid: [113/180] Step 300/312 Loss 0.651 Prec@(1,3) (84.2%, 99.1%), ce_loss 0.691, lat_loss 6.683
09/19 01:54:47 PM | Valid: [113/180] Step 312/312 Loss 0.647 Prec@(1,3) (84.3%, 99.1%), ce_loss 0.691, lat_loss 6.683
09/19 01:54:47 PM | val: [113/180] Final Prec@1 84.2900% Time 29.98
09/19 01:54:47 PM | Best top1 acc by now. Save model
09/19 01:54:47 PM | Start to train weights for epoch 113
09/19 01:55:13 PM | Train: [114/180] Step 050/1249 Loss 0.392 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.691, lat_loss 6.683
09/19 01:55:37 PM | Train: [114/180] Step 100/1249 Loss 0.457 Prec@(1,3) (88.0%, 99.6%), ce_loss 0.691, lat_loss 6.683
09/19 01:56:01 PM | Train: [114/180] Step 150/1249 Loss 0.434 Prec@(1,3) (88.6%, 99.5%), ce_loss 0.691, lat_loss 6.683
09/19 01:56:25 PM | Train: [114/180] Step 200/1249 Loss 0.429 Prec@(1,3) (88.9%, 99.5%), ce_loss 0.691, lat_loss 6.683
09/19 01:56:48 PM | Train: [114/180] Step 250/1249 Loss 0.428 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.690, lat_loss 6.683
09/19 01:57:11 PM | Train: [114/180] Step 300/1249 Loss 0.428 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.690, lat_loss 6.683
09/19 01:57:34 PM | Train: [114/180] Step 350/1249 Loss 0.437 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.690, lat_loss 6.683
09/19 01:57:57 PM | Train: [114/180] Step 400/1249 Loss 0.437 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.690, lat_loss 6.683
09/19 01:58:22 PM | Train: [114/180] Step 450/1249 Loss 0.431 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.690, lat_loss 6.683
09/19 01:58:47 PM | Train: [114/180] Step 500/1249 Loss 0.434 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.690, lat_loss 6.683
09/19 01:59:12 PM | Train: [114/180] Step 550/1249 Loss 0.432 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.690, lat_loss 6.683
09/19 01:59:37 PM | Train: [114/180] Step 600/1249 Loss 0.433 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.690, lat_loss 6.683
09/19 02:00:02 PM | Train: [114/180] Step 650/1249 Loss 0.432 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.690, lat_loss 6.683
09/19 02:00:27 PM | Train: [114/180] Step 700/1249 Loss 0.443 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.690, lat_loss 6.683
09/19 02:00:52 PM | Train: [114/180] Step 750/1249 Loss 0.444 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.690, lat_loss 6.683
09/19 02:01:17 PM | Train: [114/180] Step 800/1249 Loss 0.440 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.690, lat_loss 6.683
09/19 02:01:42 PM | Train: [114/180] Step 850/1249 Loss 0.437 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.689, lat_loss 6.683
09/19 02:02:07 PM | Train: [114/180] Step 900/1249 Loss 0.434 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.689, lat_loss 6.683
09/19 02:02:32 PM | Train: [114/180] Step 950/1249 Loss 0.436 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.689, lat_loss 6.683
09/19 02:02:57 PM | Train: [114/180] Step 1000/1249 Loss 0.437 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.689, lat_loss 6.683
09/19 02:03:22 PM | Train: [114/180] Step 1050/1249 Loss 0.438 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.689, lat_loss 6.683
09/19 02:03:47 PM | Train: [114/180] Step 1100/1249 Loss 0.441 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.689, lat_loss 6.683
09/19 02:04:12 PM | Train: [114/180] Step 1150/1249 Loss 0.444 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.689, lat_loss 6.683
09/19 02:04:37 PM | Train: [114/180] Step 1200/1249 Loss 0.442 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.689, lat_loss 6.683
09/19 02:05:02 PM | Train: [114/180] Step 1249/1249 Loss 0.440 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.689, lat_loss 6.683
09/19 02:05:02 PM | _w_step_train: [114/180] Final Prec@1 88.8100% Time 614.87
09/19 02:05:02 PM | Start to train theta for epoch 113
09/19 02:05:23 PM | Train: [114/180] Step 050/312 Loss 0.635 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.689, lat_loss 6.683
09/19 02:05:43 PM | Train: [114/180] Step 100/312 Loss 0.628 Prec@(1,3) (85.0%, 99.1%), ce_loss 0.689, lat_loss 6.683
09/19 02:06:04 PM | Train: [114/180] Step 150/312 Loss 0.623 Prec@(1,3) (84.8%, 99.3%), ce_loss 0.689, lat_loss 6.683
09/19 02:06:25 PM | Train: [114/180] Step 200/312 Loss 0.615 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.689, lat_loss 6.683
09/19 02:06:46 PM | Train: [114/180] Step 250/312 Loss 0.629 Prec@(1,3) (84.5%, 99.3%), ce_loss 0.688, lat_loss 6.683
09/19 02:07:06 PM | Train: [114/180] Step 300/312 Loss 0.637 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.688, lat_loss 6.683
09/19 02:07:11 PM | Train: [114/180] Step 312/312 Loss 0.630 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.688, lat_loss 6.683
09/19 02:07:12 PM | _theta_step_train: [114/180] Final Prec@1 84.4200% Time 129.83
09/19 02:07:17 PM | Valid: [114/180] Step 050/312 Loss 0.630 Prec@(1,3) (83.7%, 99.0%), ce_loss 0.688, lat_loss 6.683
09/19 02:07:22 PM | Valid: [114/180] Step 100/312 Loss 0.690 Prec@(1,3) (83.4%, 98.5%), ce_loss 0.688, lat_loss 6.683
09/19 02:07:26 PM | Valid: [114/180] Step 150/312 Loss 0.663 Prec@(1,3) (83.9%, 98.7%), ce_loss 0.688, lat_loss 6.683
09/19 02:07:31 PM | Valid: [114/180] Step 200/312 Loss 0.661 Prec@(1,3) (83.8%, 98.8%), ce_loss 0.688, lat_loss 6.683
09/19 02:07:35 PM | Valid: [114/180] Step 250/312 Loss 0.651 Prec@(1,3) (83.8%, 98.9%), ce_loss 0.688, lat_loss 6.683
09/19 02:07:40 PM | Valid: [114/180] Step 300/312 Loss 0.675 Prec@(1,3) (83.4%, 98.8%), ce_loss 0.688, lat_loss 6.683
09/19 02:07:41 PM | Valid: [114/180] Step 312/312 Loss 0.672 Prec@(1,3) (83.5%, 98.8%), ce_loss 0.688, lat_loss 6.683
09/19 02:07:41 PM | val: [114/180] Final Prec@1 83.4500% Time 29.63
09/19 02:07:41 PM | Start to train weights for epoch 114
09/19 02:08:07 PM | Train: [115/180] Step 050/1249 Loss 0.406 Prec@(1,3) (88.6%, 99.8%), ce_loss 0.688, lat_loss 6.683
09/19 02:08:31 PM | Train: [115/180] Step 100/1249 Loss 0.414 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.688, lat_loss 6.683
09/19 02:08:55 PM | Train: [115/180] Step 150/1249 Loss 0.416 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.688, lat_loss 6.683
09/19 02:09:19 PM | Train: [115/180] Step 200/1249 Loss 0.401 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.688, lat_loss 6.683
09/19 02:09:43 PM | Train: [115/180] Step 250/1249 Loss 0.423 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.688, lat_loss 6.683
09/19 02:10:07 PM | Train: [115/180] Step 300/1249 Loss 0.427 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.688, lat_loss 6.683
09/19 02:10:30 PM | Train: [115/180] Step 350/1249 Loss 0.432 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.688, lat_loss 6.683
09/19 02:10:54 PM | Train: [115/180] Step 400/1249 Loss 0.422 Prec@(1,3) (89.3%, 99.6%), ce_loss 0.687, lat_loss 6.683
09/19 02:11:18 PM | Train: [115/180] Step 450/1249 Loss 0.433 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.687, lat_loss 6.683
09/19 02:11:41 PM | Train: [115/180] Step 500/1249 Loss 0.429 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.687, lat_loss 6.683
09/19 02:12:04 PM | Train: [115/180] Step 550/1249 Loss 0.429 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.687, lat_loss 6.683
09/19 02:12:27 PM | Train: [115/180] Step 600/1249 Loss 0.425 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.687, lat_loss 6.683
09/19 02:12:51 PM | Train: [115/180] Step 650/1249 Loss 0.425 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.687, lat_loss 6.683
09/19 02:13:14 PM | Train: [115/180] Step 700/1249 Loss 0.423 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.687, lat_loss 6.683
09/19 02:13:38 PM | Train: [115/180] Step 750/1249 Loss 0.420 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.687, lat_loss 6.683
09/19 02:14:02 PM | Train: [115/180] Step 800/1249 Loss 0.424 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.687, lat_loss 6.683
09/19 02:14:22 PM | Train: [115/180] Step 850/1249 Loss 0.425 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.687, lat_loss 6.683
09/19 02:14:45 PM | Train: [115/180] Step 900/1249 Loss 0.424 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.687, lat_loss 6.683
09/19 02:15:07 PM | Train: [115/180] Step 950/1249 Loss 0.424 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.686, lat_loss 6.683
09/19 02:15:29 PM | Train: [115/180] Step 1000/1249 Loss 0.426 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.686, lat_loss 6.683
09/19 02:15:51 PM | Train: [115/180] Step 1050/1249 Loss 0.432 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.686, lat_loss 6.683
09/19 02:16:14 PM | Train: [115/180] Step 1100/1249 Loss 0.434 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.686, lat_loss 6.683
09/19 02:16:38 PM | Train: [115/180] Step 1150/1249 Loss 0.433 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.686, lat_loss 6.683
09/19 02:17:02 PM | Train: [115/180] Step 1200/1249 Loss 0.437 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.686, lat_loss 6.683
09/19 02:17:26 PM | Train: [115/180] Step 1249/1249 Loss 0.439 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.686, lat_loss 6.683
09/19 02:17:27 PM | _w_step_train: [115/180] Final Prec@1 88.7850% Time 585.34
09/19 02:17:27 PM | Start to train theta for epoch 114
09/19 02:17:47 PM | Train: [115/180] Step 050/312 Loss 0.556 Prec@(1,3) (85.8%, 99.6%), ce_loss 0.686, lat_loss 6.683
09/19 02:18:05 PM | Train: [115/180] Step 100/312 Loss 0.629 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.686, lat_loss 6.683
09/19 02:18:24 PM | Train: [115/180] Step 150/312 Loss 0.645 Prec@(1,3) (84.4%, 99.1%), ce_loss 0.686, lat_loss 6.683
09/19 02:18:42 PM | Train: [115/180] Step 200/312 Loss 0.642 Prec@(1,3) (84.5%, 99.1%), ce_loss 0.686, lat_loss 6.683
09/19 02:19:01 PM | Train: [115/180] Step 250/312 Loss 0.642 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.686, lat_loss 6.683
09/19 02:19:20 PM | Train: [115/180] Step 300/312 Loss 0.640 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.686, lat_loss 6.683
09/19 02:19:25 PM | Train: [115/180] Step 312/312 Loss 0.640 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.686, lat_loss 6.683
09/19 02:19:25 PM | _theta_step_train: [115/180] Final Prec@1 84.6200% Time 118.83
09/19 02:19:31 PM | Valid: [115/180] Step 050/312 Loss 0.633 Prec@(1,3) (84.4%, 99.3%), ce_loss 0.686, lat_loss 6.683
09/19 02:19:35 PM | Valid: [115/180] Step 100/312 Loss 0.635 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.686, lat_loss 6.683
09/19 02:19:40 PM | Valid: [115/180] Step 150/312 Loss 0.654 Prec@(1,3) (84.0%, 99.2%), ce_loss 0.686, lat_loss 6.683
09/19 02:19:44 PM | Valid: [115/180] Step 200/312 Loss 0.671 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.685, lat_loss 6.683
09/19 02:19:49 PM | Valid: [115/180] Step 250/312 Loss 0.674 Prec@(1,3) (83.6%, 98.9%), ce_loss 0.685, lat_loss 6.683
09/19 02:19:54 PM | Valid: [115/180] Step 300/312 Loss 0.655 Prec@(1,3) (84.0%, 99.0%), ce_loss 0.685, lat_loss 6.683
09/19 02:19:55 PM | Valid: [115/180] Step 312/312 Loss 0.653 Prec@(1,3) (84.0%, 99.1%), ce_loss 0.685, lat_loss 6.683
09/19 02:19:55 PM | val: [115/180] Final Prec@1 83.9700% Time 29.47
09/19 02:19:55 PM | Start to train weights for epoch 115
09/19 02:20:20 PM | Train: [116/180] Step 050/1249 Loss 0.409 Prec@(1,3) (89.5%, 99.9%), ce_loss 0.685, lat_loss 6.683
09/19 02:20:45 PM | Train: [116/180] Step 100/1249 Loss 0.398 Prec@(1,3) (89.6%, 99.8%), ce_loss 0.685, lat_loss 6.683
09/19 02:21:09 PM | Train: [116/180] Step 150/1249 Loss 0.407 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.685, lat_loss 6.683
09/19 02:21:31 PM | Train: [116/180] Step 200/1249 Loss 0.419 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.685, lat_loss 6.683
09/19 02:21:56 PM | Train: [116/180] Step 250/1249 Loss 0.432 Prec@(1,3) (88.9%, 99.7%), ce_loss 0.685, lat_loss 6.683
09/19 02:22:20 PM | Train: [116/180] Step 300/1249 Loss 0.430 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.685, lat_loss 6.683
09/19 02:22:43 PM | Train: [116/180] Step 350/1249 Loss 0.430 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.685, lat_loss 6.683
09/19 02:23:08 PM | Train: [116/180] Step 400/1249 Loss 0.428 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.685, lat_loss 6.683
09/19 02:23:32 PM | Train: [116/180] Step 450/1249 Loss 0.429 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.685, lat_loss 6.683
09/19 02:23:57 PM | Train: [116/180] Step 500/1249 Loss 0.425 Prec@(1,3) (89.2%, 99.6%), ce_loss 0.684, lat_loss 6.683
09/19 02:24:20 PM | Train: [116/180] Step 550/1249 Loss 0.426 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.684, lat_loss 6.683
09/19 02:24:44 PM | Train: [116/180] Step 600/1249 Loss 0.432 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.684, lat_loss 6.683
09/19 02:25:08 PM | Train: [116/180] Step 650/1249 Loss 0.433 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.684, lat_loss 6.683
09/19 02:25:33 PM | Train: [116/180] Step 700/1249 Loss 0.430 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.684, lat_loss 6.683
09/19 02:25:57 PM | Train: [116/180] Step 750/1249 Loss 0.433 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.684, lat_loss 6.683
09/19 02:26:19 PM | Train: [116/180] Step 800/1249 Loss 0.431 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.684, lat_loss 6.683
09/19 02:26:42 PM | Train: [116/180] Step 850/1249 Loss 0.435 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.684, lat_loss 6.683
09/19 02:27:07 PM | Train: [116/180] Step 900/1249 Loss 0.434 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.684, lat_loss 6.683
09/19 02:27:31 PM | Train: [116/180] Step 950/1249 Loss 0.433 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.684, lat_loss 6.683
09/19 02:27:54 PM | Train: [116/180] Step 1000/1249 Loss 0.435 Prec@(1,3) (88.9%, 99.7%), ce_loss 0.684, lat_loss 6.683
09/19 02:28:17 PM | Train: [116/180] Step 1050/1249 Loss 0.437 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.684, lat_loss 6.683
09/19 02:28:42 PM | Train: [116/180] Step 1100/1249 Loss 0.436 Prec@(1,3) (88.9%, 99.7%), ce_loss 0.683, lat_loss 6.683
09/19 02:29:04 PM | Train: [116/180] Step 1150/1249 Loss 0.434 Prec@(1,3) (88.9%, 99.7%), ce_loss 0.683, lat_loss 6.683
09/19 02:29:28 PM | Train: [116/180] Step 1200/1249 Loss 0.435 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.683, lat_loss 6.683
09/19 02:29:52 PM | Train: [116/180] Step 1249/1249 Loss 0.432 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.683, lat_loss 6.683
09/19 02:29:52 PM | _w_step_train: [116/180] Final Prec@1 88.9525% Time 597.12
09/19 02:29:52 PM | Start to train theta for epoch 115
09/19 02:30:13 PM | Train: [116/180] Step 050/312 Loss 0.663 Prec@(1,3) (83.6%, 99.1%), ce_loss 0.683, lat_loss 6.683
09/19 02:30:31 PM | Train: [116/180] Step 100/312 Loss 0.647 Prec@(1,3) (84.4%, 99.1%), ce_loss 0.683, lat_loss 6.683
09/19 02:30:51 PM | Train: [116/180] Step 150/312 Loss 0.634 Prec@(1,3) (84.5%, 99.1%), ce_loss 0.683, lat_loss 6.683
09/19 02:31:11 PM | Train: [116/180] Step 200/312 Loss 0.639 Prec@(1,3) (84.3%, 99.1%), ce_loss 0.683, lat_loss 6.683
09/19 02:31:32 PM | Train: [116/180] Step 250/312 Loss 0.637 Prec@(1,3) (84.5%, 99.1%), ce_loss 0.683, lat_loss 6.683
09/19 02:31:52 PM | Train: [116/180] Step 300/312 Loss 0.632 Prec@(1,3) (84.5%, 99.1%), ce_loss 0.683, lat_loss 6.683
09/19 02:31:57 PM | Train: [116/180] Step 312/312 Loss 0.629 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.683, lat_loss 6.683
09/19 02:31:57 PM | _theta_step_train: [116/180] Final Prec@1 84.5800% Time 125.26
09/19 02:32:03 PM | Valid: [116/180] Step 050/312 Loss 0.638 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.683, lat_loss 6.683
09/19 02:32:07 PM | Valid: [116/180] Step 100/312 Loss 0.642 Prec@(1,3) (84.2%, 99.1%), ce_loss 0.683, lat_loss 6.683
09/19 02:32:12 PM | Valid: [116/180] Step 150/312 Loss 0.681 Prec@(1,3) (83.6%, 98.6%), ce_loss 0.683, lat_loss 6.683
09/19 02:32:17 PM | Valid: [116/180] Step 200/312 Loss 0.672 Prec@(1,3) (83.9%, 98.6%), ce_loss 0.683, lat_loss 6.683
09/19 02:32:21 PM | Valid: [116/180] Step 250/312 Loss 0.688 Prec@(1,3) (83.4%, 98.4%), ce_loss 0.683, lat_loss 6.683
09/19 02:32:26 PM | Valid: [116/180] Step 300/312 Loss 0.672 Prec@(1,3) (83.5%, 98.6%), ce_loss 0.683, lat_loss 6.683
09/19 02:32:27 PM | Valid: [116/180] Step 312/312 Loss 0.668 Prec@(1,3) (83.5%, 98.7%), ce_loss 0.683, lat_loss 6.683
09/19 02:32:27 PM | val: [116/180] Final Prec@1 83.5400% Time 29.69
09/19 02:32:27 PM | Start to train weights for epoch 116
09/19 02:32:51 PM | Train: [117/180] Step 050/1249 Loss 0.385 Prec@(1,3) (90.1%, 99.9%), ce_loss 0.683, lat_loss 6.683
09/19 02:33:14 PM | Train: [117/180] Step 100/1249 Loss 0.383 Prec@(1,3) (90.0%, 99.9%), ce_loss 0.682, lat_loss 6.683
09/19 02:33:39 PM | Train: [117/180] Step 150/1249 Loss 0.406 Prec@(1,3) (89.6%, 99.8%), ce_loss 0.682, lat_loss 6.683
09/19 02:34:03 PM | Train: [117/180] Step 200/1249 Loss 0.405 Prec@(1,3) (89.5%, 99.8%), ce_loss 0.682, lat_loss 6.683
09/19 02:34:28 PM | Train: [117/180] Step 250/1249 Loss 0.399 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.682, lat_loss 6.683
09/19 02:34:51 PM | Train: [117/180] Step 300/1249 Loss 0.402 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.682, lat_loss 6.683
09/19 02:35:15 PM | Train: [117/180] Step 350/1249 Loss 0.411 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.682, lat_loss 6.683
09/19 02:35:40 PM | Train: [117/180] Step 400/1249 Loss 0.423 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.682, lat_loss 6.683
09/19 02:36:04 PM | Train: [117/180] Step 450/1249 Loss 0.427 Prec@(1,3) (89.1%, 99.6%), ce_loss 0.682, lat_loss 6.683
09/19 02:36:28 PM | Train: [117/180] Step 500/1249 Loss 0.431 Prec@(1,3) (89.0%, 99.6%), ce_loss 0.682, lat_loss 6.683
09/19 02:36:51 PM | Train: [117/180] Step 550/1249 Loss 0.433 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.682, lat_loss 6.683
09/19 02:37:15 PM | Train: [117/180] Step 600/1249 Loss 0.431 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.682, lat_loss 6.683
09/19 02:37:40 PM | Train: [117/180] Step 650/1249 Loss 0.430 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.682, lat_loss 6.683
09/19 02:38:04 PM | Train: [117/180] Step 700/1249 Loss 0.433 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.681, lat_loss 6.683
09/19 02:38:28 PM | Train: [117/180] Step 750/1249 Loss 0.428 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.681, lat_loss 6.683
09/19 02:38:53 PM | Train: [117/180] Step 800/1249 Loss 0.427 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.681, lat_loss 6.683
09/19 02:39:18 PM | Train: [117/180] Step 850/1249 Loss 0.430 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.681, lat_loss 6.683
09/19 02:39:42 PM | Train: [117/180] Step 900/1249 Loss 0.429 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.681, lat_loss 6.683
09/19 02:40:07 PM | Train: [117/180] Step 950/1249 Loss 0.427 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.681, lat_loss 6.683
09/19 02:40:31 PM | Train: [117/180] Step 1000/1249 Loss 0.431 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.681, lat_loss 6.683
09/19 02:40:55 PM | Train: [117/180] Step 1050/1249 Loss 0.433 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.681, lat_loss 6.683
09/19 02:41:19 PM | Train: [117/180] Step 1100/1249 Loss 0.432 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.681, lat_loss 6.683
09/19 02:41:44 PM | Train: [117/180] Step 1150/1249 Loss 0.430 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.681, lat_loss 6.683
09/19 02:42:08 PM | Train: [117/180] Step 1200/1249 Loss 0.429 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.681, lat_loss 6.683
09/19 02:42:33 PM | Train: [117/180] Step 1249/1249 Loss 0.427 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.680, lat_loss 6.684
09/19 02:42:33 PM | _w_step_train: [117/180] Final Prec@1 89.1175% Time 605.68
09/19 02:42:33 PM | Start to train theta for epoch 116
09/19 02:42:53 PM | Train: [117/180] Step 050/312 Loss 0.633 Prec@(1,3) (84.1%, 99.3%), ce_loss 0.680, lat_loss 6.684
09/19 02:43:12 PM | Train: [117/180] Step 100/312 Loss 0.629 Prec@(1,3) (84.5%, 99.1%), ce_loss 0.680, lat_loss 6.684
09/19 02:43:31 PM | Train: [117/180] Step 150/312 Loss 0.631 Prec@(1,3) (84.5%, 99.1%), ce_loss 0.680, lat_loss 6.684
09/19 02:43:50 PM | Train: [117/180] Step 200/312 Loss 0.637 Prec@(1,3) (84.3%, 99.1%), ce_loss 0.680, lat_loss 6.684
09/19 02:44:08 PM | Train: [117/180] Step 250/312 Loss 0.640 Prec@(1,3) (84.1%, 99.2%), ce_loss 0.680, lat_loss 6.684
09/19 02:44:28 PM | Train: [117/180] Step 300/312 Loss 0.633 Prec@(1,3) (84.1%, 99.2%), ce_loss 0.680, lat_loss 6.684
09/19 02:44:33 PM | Train: [117/180] Step 312/312 Loss 0.635 Prec@(1,3) (84.1%, 99.2%), ce_loss 0.680, lat_loss 6.684
09/19 02:44:33 PM | _theta_step_train: [117/180] Final Prec@1 84.1100% Time 120.65
09/19 02:44:39 PM | Valid: [117/180] Step 050/312 Loss 0.667 Prec@(1,3) (83.6%, 98.8%), ce_loss 0.680, lat_loss 6.684
09/19 02:44:43 PM | Valid: [117/180] Step 100/312 Loss 0.673 Prec@(1,3) (83.7%, 98.7%), ce_loss 0.680, lat_loss 6.684
09/19 02:44:48 PM | Valid: [117/180] Step 150/312 Loss 0.712 Prec@(1,3) (83.3%, 98.4%), ce_loss 0.680, lat_loss 6.684
09/19 02:44:52 PM | Valid: [117/180] Step 200/312 Loss 0.708 Prec@(1,3) (83.5%, 98.4%), ce_loss 0.680, lat_loss 6.684
09/19 02:44:57 PM | Valid: [117/180] Step 250/312 Loss 0.700 Prec@(1,3) (83.3%, 98.6%), ce_loss 0.680, lat_loss 6.684
09/19 02:45:02 PM | Valid: [117/180] Step 300/312 Loss 0.679 Prec@(1,3) (83.6%, 98.8%), ce_loss 0.680, lat_loss 6.684
09/19 02:45:03 PM | Valid: [117/180] Step 312/312 Loss 0.676 Prec@(1,3) (83.7%, 98.8%), ce_loss 0.680, lat_loss 6.684
09/19 02:45:03 PM | val: [117/180] Final Prec@1 83.6500% Time 29.38
09/19 02:45:03 PM | Start to train weights for epoch 117
09/19 02:45:29 PM | Train: [118/180] Step 050/1249 Loss 0.495 Prec@(1,3) (86.6%, 99.4%), ce_loss 0.680, lat_loss 6.684
09/19 02:45:53 PM | Train: [118/180] Step 100/1249 Loss 0.451 Prec@(1,3) (88.1%, 99.5%), ce_loss 0.680, lat_loss 6.684
09/19 02:46:18 PM | Train: [118/180] Step 150/1249 Loss 0.443 Prec@(1,3) (88.4%, 99.6%), ce_loss 0.680, lat_loss 6.684
09/19 02:46:43 PM | Train: [118/180] Step 200/1249 Loss 0.438 Prec@(1,3) (88.5%, 99.6%), ce_loss 0.680, lat_loss 6.684
09/19 02:47:08 PM | Train: [118/180] Step 250/1249 Loss 0.427 Prec@(1,3) (88.9%, 99.7%), ce_loss 0.679, lat_loss 6.684
09/19 02:47:33 PM | Train: [118/180] Step 300/1249 Loss 0.445 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.679, lat_loss 6.684
09/19 02:47:58 PM | Train: [118/180] Step 350/1249 Loss 0.445 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.679, lat_loss 6.684
09/19 02:48:23 PM | Train: [118/180] Step 400/1249 Loss 0.450 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.679, lat_loss 6.684
09/19 02:48:48 PM | Train: [118/180] Step 450/1249 Loss 0.448 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.679, lat_loss 6.684
09/19 02:49:08 PM | Train: [118/180] Step 500/1249 Loss 0.445 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.679, lat_loss 6.684
09/19 02:49:29 PM | Train: [118/180] Step 550/1249 Loss 0.444 Prec@(1,3) (88.6%, 99.6%), ce_loss 0.679, lat_loss 6.684
09/19 02:49:51 PM | Train: [118/180] Step 600/1249 Loss 0.442 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.679, lat_loss 6.684
09/19 02:50:16 PM | Train: [118/180] Step 650/1249 Loss 0.443 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.679, lat_loss 6.684
09/19 02:50:41 PM | Train: [118/180] Step 700/1249 Loss 0.445 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.679, lat_loss 6.684
09/19 02:51:06 PM | Train: [118/180] Step 750/1249 Loss 0.443 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.679, lat_loss 6.684
09/19 02:51:31 PM | Train: [118/180] Step 800/1249 Loss 0.442 Prec@(1,3) (88.7%, 99.6%), ce_loss 0.679, lat_loss 6.684
09/19 02:51:56 PM | Train: [118/180] Step 850/1249 Loss 0.441 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.679, lat_loss 6.684
09/19 02:52:19 PM | Train: [118/180] Step 900/1249 Loss 0.443 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.678, lat_loss 6.684
09/19 02:52:40 PM | Train: [118/180] Step 950/1249 Loss 0.441 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.678, lat_loss 6.684
09/19 02:53:06 PM | Train: [118/180] Step 1000/1249 Loss 0.439 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.678, lat_loss 6.684
09/19 02:53:31 PM | Train: [118/180] Step 1050/1249 Loss 0.440 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.678, lat_loss 6.684
09/19 02:53:55 PM | Train: [118/180] Step 1100/1249 Loss 0.441 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.678, lat_loss 6.684
09/19 02:54:21 PM | Train: [118/180] Step 1150/1249 Loss 0.439 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.678, lat_loss 6.684
09/19 02:54:46 PM | Train: [118/180] Step 1200/1249 Loss 0.438 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.678, lat_loss 6.684
09/19 02:55:10 PM | Train: [118/180] Step 1249/1249 Loss 0.438 Prec@(1,3) (88.9%, 99.6%), ce_loss 0.678, lat_loss 6.684
09/19 02:55:10 PM | _w_step_train: [118/180] Final Prec@1 88.9400% Time 607.20
09/19 02:55:10 PM | Start to train theta for epoch 117
09/19 02:55:31 PM | Train: [118/180] Step 050/312 Loss 0.633 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.678, lat_loss 6.684
09/19 02:55:52 PM | Train: [118/180] Step 100/312 Loss 0.626 Prec@(1,3) (84.9%, 99.2%), ce_loss 0.678, lat_loss 6.684
09/19 02:56:13 PM | Train: [118/180] Step 150/312 Loss 0.645 Prec@(1,3) (84.4%, 99.1%), ce_loss 0.678, lat_loss 6.684
09/19 02:56:33 PM | Train: [118/180] Step 200/312 Loss 0.651 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.678, lat_loss 6.684
09/19 02:56:54 PM | Train: [118/180] Step 250/312 Loss 0.645 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.678, lat_loss 6.684
09/19 02:57:14 PM | Train: [118/180] Step 300/312 Loss 0.645 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.678, lat_loss 6.684
09/19 02:57:19 PM | Train: [118/180] Step 312/312 Loss 0.650 Prec@(1,3) (84.3%, 99.1%), ce_loss 0.678, lat_loss 6.684
09/19 02:57:20 PM | _theta_step_train: [118/180] Final Prec@1 84.2700% Time 130.01
09/19 02:57:25 PM | Valid: [118/180] Step 050/312 Loss 0.611 Prec@(1,3) (85.0%, 99.5%), ce_loss 0.678, lat_loss 6.684
09/19 02:57:29 PM | Valid: [118/180] Step 100/312 Loss 0.706 Prec@(1,3) (83.5%, 98.8%), ce_loss 0.678, lat_loss 6.684
09/19 02:57:33 PM | Valid: [118/180] Step 150/312 Loss 0.733 Prec@(1,3) (82.9%, 98.4%), ce_loss 0.677, lat_loss 6.684
09/19 02:57:37 PM | Valid: [118/180] Step 200/312 Loss 0.702 Prec@(1,3) (83.3%, 98.6%), ce_loss 0.677, lat_loss 6.684
09/19 02:57:42 PM | Valid: [118/180] Step 250/312 Loss 0.685 Prec@(1,3) (83.6%, 98.8%), ce_loss 0.677, lat_loss 6.684
09/19 02:57:46 PM | Valid: [118/180] Step 300/312 Loss 0.672 Prec@(1,3) (83.7%, 98.9%), ce_loss 0.677, lat_loss 6.684
09/19 02:57:47 PM | Valid: [118/180] Step 312/312 Loss 0.672 Prec@(1,3) (83.7%, 98.9%), ce_loss 0.677, lat_loss 6.684
09/19 02:57:47 PM | val: [118/180] Final Prec@1 83.6600% Time 26.98
09/19 02:57:47 PM | Start to train weights for epoch 118
09/19 02:58:11 PM | Train: [119/180] Step 050/1249 Loss 0.470 Prec@(1,3) (88.1%, 99.8%), ce_loss 0.677, lat_loss 6.684
09/19 02:58:34 PM | Train: [119/180] Step 100/1249 Loss 0.451 Prec@(1,3) (88.7%, 99.7%), ce_loss 0.677, lat_loss 6.684
09/19 02:58:58 PM | Train: [119/180] Step 150/1249 Loss 0.443 Prec@(1,3) (88.7%, 99.7%), ce_loss 0.677, lat_loss 6.684
09/19 02:59:23 PM | Train: [119/180] Step 200/1249 Loss 0.430 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.677, lat_loss 6.684
09/19 02:59:48 PM | Train: [119/180] Step 250/1249 Loss 0.419 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.677, lat_loss 6.684
09/19 03:00:10 PM | Train: [119/180] Step 300/1249 Loss 0.415 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.677, lat_loss 6.684
09/19 03:00:32 PM | Train: [119/180] Step 350/1249 Loss 0.410 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.677, lat_loss 6.684
09/19 03:00:55 PM | Train: [119/180] Step 400/1249 Loss 0.410 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.677, lat_loss 6.684
09/19 03:01:20 PM | Train: [119/180] Step 450/1249 Loss 0.410 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.677, lat_loss 6.684
09/19 03:01:45 PM | Train: [119/180] Step 500/1249 Loss 0.409 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.676, lat_loss 6.684
09/19 03:02:09 PM | Train: [119/180] Step 550/1249 Loss 0.414 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.676, lat_loss 6.684
09/19 03:02:34 PM | Train: [119/180] Step 600/1249 Loss 0.416 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.676, lat_loss 6.684
09/19 03:02:59 PM | Train: [119/180] Step 650/1249 Loss 0.420 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.676, lat_loss 6.684
09/19 03:03:24 PM | Train: [119/180] Step 700/1249 Loss 0.423 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.676, lat_loss 6.684
09/19 03:03:49 PM | Train: [119/180] Step 750/1249 Loss 0.428 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.676, lat_loss 6.684
09/19 03:04:14 PM | Train: [119/180] Step 800/1249 Loss 0.429 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.676, lat_loss 6.684
09/19 03:04:39 PM | Train: [119/180] Step 850/1249 Loss 0.430 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.676, lat_loss 6.684
09/19 03:05:04 PM | Train: [119/180] Step 900/1249 Loss 0.428 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.676, lat_loss 6.684
09/19 03:05:28 PM | Train: [119/180] Step 950/1249 Loss 0.429 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.676, lat_loss 6.684
09/19 03:05:53 PM | Train: [119/180] Step 1000/1249 Loss 0.428 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.676, lat_loss 6.684
09/19 03:06:19 PM | Train: [119/180] Step 1050/1249 Loss 0.428 Prec@(1,3) (89.0%, 99.7%), ce_loss 0.676, lat_loss 6.684
09/19 03:06:43 PM | Train: [119/180] Step 1100/1249 Loss 0.427 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.675, lat_loss 6.684
09/19 03:07:08 PM | Train: [119/180] Step 1150/1249 Loss 0.425 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.675, lat_loss 6.684
09/19 03:07:33 PM | Train: [119/180] Step 1200/1249 Loss 0.425 Prec@(1,3) (89.1%, 99.7%), ce_loss 0.675, lat_loss 6.684
09/19 03:07:58 PM | Train: [119/180] Step 1249/1249 Loss 0.425 Prec@(1,3) (89.2%, 99.7%), ce_loss 0.675, lat_loss 6.684
09/19 03:07:58 PM | _w_step_train: [119/180] Final Prec@1 89.1600% Time 610.59
09/19 03:07:58 PM | Start to train theta for epoch 118
09/19 03:08:19 PM | Train: [119/180] Step 050/312 Loss 0.708 Prec@(1,3) (83.6%, 99.0%), ce_loss 0.675, lat_loss 6.684
09/19 03:08:38 PM | Train: [119/180] Step 100/312 Loss 0.681 Prec@(1,3) (84.0%, 99.0%), ce_loss 0.675, lat_loss 6.684
09/19 03:08:58 PM | Train: [119/180] Step 150/312 Loss 0.672 Prec@(1,3) (83.9%, 99.0%), ce_loss 0.675, lat_loss 6.684
09/19 03:09:13 PM | Train: [119/180] Step 200/312 Loss 0.661 Prec@(1,3) (84.4%, 99.1%), ce_loss 0.675, lat_loss 6.684
09/19 03:09:33 PM | Train: [119/180] Step 250/312 Loss 0.662 Prec@(1,3) (84.3%, 99.1%), ce_loss 0.675, lat_loss 6.684
09/19 03:09:53 PM | Train: [119/180] Step 300/312 Loss 0.659 Prec@(1,3) (84.3%, 99.1%), ce_loss 0.675, lat_loss 6.684
09/19 03:09:57 PM | Train: [119/180] Step 312/312 Loss 0.653 Prec@(1,3) (84.4%, 99.1%), ce_loss 0.675, lat_loss 6.684
09/19 03:09:57 PM | _theta_step_train: [119/180] Final Prec@1 84.3700% Time 119.37
09/19 03:10:03 PM | Valid: [119/180] Step 050/312 Loss 0.758 Prec@(1,3) (81.4%, 97.9%), ce_loss 0.675, lat_loss 6.684
09/19 03:10:07 PM | Valid: [119/180] Step 100/312 Loss 0.712 Prec@(1,3) (82.5%, 98.3%), ce_loss 0.675, lat_loss 6.684
09/19 03:10:12 PM | Valid: [119/180] Step 150/312 Loss 0.681 Prec@(1,3) (83.6%, 98.6%), ce_loss 0.675, lat_loss 6.684
09/19 03:10:17 PM | Valid: [119/180] Step 200/312 Loss 0.663 Prec@(1,3) (84.0%, 98.8%), ce_loss 0.675, lat_loss 6.684
09/19 03:10:21 PM | Valid: [119/180] Step 250/312 Loss 0.671 Prec@(1,3) (83.9%, 98.8%), ce_loss 0.675, lat_loss 6.684
09/19 03:10:26 PM | Valid: [119/180] Step 300/312 Loss 0.676 Prec@(1,3) (83.6%, 98.8%), ce_loss 0.675, lat_loss 6.684
09/19 03:10:27 PM | Valid: [119/180] Step 312/312 Loss 0.669 Prec@(1,3) (83.8%, 98.8%), ce_loss 0.675, lat_loss 6.684
09/19 03:10:27 PM | val: [119/180] Final Prec@1 83.7500% Time 29.84
09/19 03:10:27 PM | Start to train weights for epoch 119
09/19 03:10:49 PM | Train: [120/180] Step 050/1249 Loss 0.390 Prec@(1,3) (90.8%, 99.9%), ce_loss 0.675, lat_loss 6.684
09/19 03:11:13 PM | Train: [120/180] Step 100/1249 Loss 0.380 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.675, lat_loss 6.684
09/19 03:11:38 PM | Train: [120/180] Step 150/1249 Loss 0.407 Prec@(1,3) (90.2%, 99.6%), ce_loss 0.674, lat_loss 6.684
09/19 03:12:03 PM | Train: [120/180] Step 200/1249 Loss 0.412 Prec@(1,3) (90.0%, 99.6%), ce_loss 0.674, lat_loss 6.684
09/19 03:12:28 PM | Train: [120/180] Step 250/1249 Loss 0.409 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.674, lat_loss 6.684
09/19 03:12:53 PM | Train: [120/180] Step 300/1249 Loss 0.402 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.674, lat_loss 6.684
09/19 03:13:17 PM | Train: [120/180] Step 350/1249 Loss 0.404 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.674, lat_loss 6.684
09/19 03:13:42 PM | Train: [120/180] Step 400/1249 Loss 0.404 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.674, lat_loss 6.684
09/19 03:14:02 PM | Train: [120/180] Step 450/1249 Loss 0.409 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.674, lat_loss 6.684
09/19 03:14:26 PM | Train: [120/180] Step 500/1249 Loss 0.407 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.674, lat_loss 6.684
09/19 03:14:50 PM | Train: [120/180] Step 550/1249 Loss 0.409 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.674, lat_loss 6.684
09/19 03:15:12 PM | Train: [120/180] Step 600/1249 Loss 0.415 Prec@(1,3) (89.3%, 99.6%), ce_loss 0.674, lat_loss 6.684
09/19 03:15:35 PM | Train: [120/180] Step 650/1249 Loss 0.414 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.674, lat_loss 6.684
09/19 03:15:59 PM | Train: [120/180] Step 700/1249 Loss 0.415 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.674, lat_loss 6.684
09/19 03:16:22 PM | Train: [120/180] Step 750/1249 Loss 0.414 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.673, lat_loss 6.684
09/19 03:16:47 PM | Train: [120/180] Step 800/1249 Loss 0.414 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.673, lat_loss 6.684
09/19 03:17:12 PM | Train: [120/180] Step 850/1249 Loss 0.414 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.673, lat_loss 6.684
09/19 03:17:37 PM | Train: [120/180] Step 900/1249 Loss 0.413 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.673, lat_loss 6.684
09/19 03:18:02 PM | Train: [120/180] Step 950/1249 Loss 0.412 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.673, lat_loss 6.684
09/19 03:18:25 PM | Train: [120/180] Step 1000/1249 Loss 0.414 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.673, lat_loss 6.684
09/19 03:18:49 PM | Train: [120/180] Step 1050/1249 Loss 0.417 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.673, lat_loss 6.684
09/19 03:19:14 PM | Train: [120/180] Step 1100/1249 Loss 0.415 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.673, lat_loss 6.684
09/19 03:19:39 PM | Train: [120/180] Step 1150/1249 Loss 0.413 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.673, lat_loss 6.684
09/19 03:20:04 PM | Train: [120/180] Step 1200/1249 Loss 0.414 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.673, lat_loss 6.684
09/19 03:20:28 PM | Train: [120/180] Step 1249/1249 Loss 0.413 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.673, lat_loss 6.684
09/19 03:20:28 PM | _w_step_train: [120/180] Final Prec@1 89.3700% Time 601.11
09/19 03:20:28 PM | Start to train theta for epoch 119
09/19 03:20:50 PM | Train: [120/180] Step 050/312 Loss 0.657 Prec@(1,3) (83.8%, 99.3%), ce_loss 0.673, lat_loss 6.684
09/19 03:21:10 PM | Train: [120/180] Step 100/312 Loss 0.631 Prec@(1,3) (84.6%, 99.2%), ce_loss 0.673, lat_loss 6.684
09/19 03:21:30 PM | Train: [120/180] Step 150/312 Loss 0.635 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.672, lat_loss 6.684
09/19 03:21:51 PM | Train: [120/180] Step 200/312 Loss 0.645 Prec@(1,3) (84.4%, 99.1%), ce_loss 0.672, lat_loss 6.684
09/19 03:22:11 PM | Train: [120/180] Step 250/312 Loss 0.631 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.672, lat_loss 6.684
09/19 03:22:31 PM | Train: [120/180] Step 300/312 Loss 0.625 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.672, lat_loss 6.684
09/19 03:22:36 PM | Train: [120/180] Step 312/312 Loss 0.632 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.672, lat_loss 6.684
09/19 03:22:36 PM | _theta_step_train: [120/180] Final Prec@1 84.6500% Time 127.74
09/19 03:22:41 PM | Valid: [120/180] Step 050/312 Loss 0.575 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.672, lat_loss 6.684
09/19 03:22:45 PM | Valid: [120/180] Step 100/312 Loss 0.609 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.672, lat_loss 6.684
09/19 03:22:50 PM | Valid: [120/180] Step 150/312 Loss 0.667 Prec@(1,3) (84.6%, 98.8%), ce_loss 0.672, lat_loss 6.684
09/19 03:22:54 PM | Valid: [120/180] Step 200/312 Loss 0.675 Prec@(1,3) (84.5%, 98.7%), ce_loss 0.672, lat_loss 6.684
09/19 03:22:58 PM | Valid: [120/180] Step 250/312 Loss 0.700 Prec@(1,3) (84.2%, 98.5%), ce_loss 0.672, lat_loss 6.684
09/19 03:23:02 PM | Valid: [120/180] Step 300/312 Loss 0.685 Prec@(1,3) (84.2%, 98.6%), ce_loss 0.672, lat_loss 6.684
09/19 03:23:03 PM | Valid: [120/180] Step 312/312 Loss 0.680 Prec@(1,3) (84.3%, 98.7%), ce_loss 0.672, lat_loss 6.684
09/19 03:23:03 PM | val: [120/180] Final Prec@1 84.3000% Time 27.16
09/19 03:23:03 PM | Best top1 acc by now. Save model
09/19 03:23:04 PM | Start to train weights for epoch 120
09/19 03:23:28 PM | Train: [121/180] Step 050/1249 Loss 0.434 Prec@(1,3) (88.8%, 99.6%), ce_loss 0.672, lat_loss 6.684
09/19 03:23:48 PM | Train: [121/180] Step 100/1249 Loss 0.434 Prec@(1,3) (89.0%, 99.5%), ce_loss 0.672, lat_loss 6.684
09/19 03:24:12 PM | Train: [121/180] Step 150/1249 Loss 0.419 Prec@(1,3) (89.5%, 99.6%), ce_loss 0.672, lat_loss 6.684
09/19 03:24:35 PM | Train: [121/180] Step 200/1249 Loss 0.419 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.672, lat_loss 6.684
09/19 03:24:59 PM | Train: [121/180] Step 250/1249 Loss 0.412 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.672, lat_loss 6.684
09/19 03:25:21 PM | Train: [121/180] Step 300/1249 Loss 0.412 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.672, lat_loss 6.684
09/19 03:25:45 PM | Train: [121/180] Step 350/1249 Loss 0.409 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.672, lat_loss 6.684
09/19 03:26:10 PM | Train: [121/180] Step 400/1249 Loss 0.411 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.671, lat_loss 6.684
09/19 03:26:35 PM | Train: [121/180] Step 450/1249 Loss 0.414 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.671, lat_loss 6.684
09/19 03:26:59 PM | Train: [121/180] Step 500/1249 Loss 0.416 Prec@(1,3) (89.5%, 99.7%), ce_loss 0.671, lat_loss 6.684
09/19 03:27:24 PM | Train: [121/180] Step 550/1249 Loss 0.413 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.671, lat_loss 6.684
09/19 03:27:50 PM | Train: [121/180] Step 600/1249 Loss 0.409 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.671, lat_loss 6.684
09/19 03:28:15 PM | Train: [121/180] Step 650/1249 Loss 0.410 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.671, lat_loss 6.684
09/19 03:28:40 PM | Train: [121/180] Step 700/1249 Loss 0.406 Prec@(1,3) (89.7%, 99.7%), ce_loss 0.671, lat_loss 6.684
09/19 03:29:05 PM | Train: [121/180] Step 750/1249 Loss 0.411 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.671, lat_loss 6.684
09/19 03:29:29 PM | Train: [121/180] Step 800/1249 Loss 0.411 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.671, lat_loss 6.684
09/19 03:29:53 PM | Train: [121/180] Step 850/1249 Loss 0.418 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.671, lat_loss 6.684
09/19 03:30:18 PM | Train: [121/180] Step 900/1249 Loss 0.415 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.671, lat_loss 6.684
09/19 03:30:39 PM | Train: [121/180] Step 950/1249 Loss 0.412 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.671, lat_loss 6.684
09/19 03:31:02 PM | Train: [121/180] Step 1000/1249 Loss 0.417 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.670, lat_loss 6.684
09/19 03:31:25 PM | Train: [121/180] Step 1050/1249 Loss 0.418 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.670, lat_loss 6.684
09/19 03:31:49 PM | Train: [121/180] Step 1100/1249 Loss 0.418 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.670, lat_loss 6.684
09/19 03:32:11 PM | Train: [121/180] Step 1150/1249 Loss 0.420 Prec@(1,3) (89.4%, 99.7%), ce_loss 0.670, lat_loss 6.684
09/19 03:32:35 PM | Train: [121/180] Step 1200/1249 Loss 0.421 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.670, lat_loss 6.684
09/19 03:33:00 PM | Train: [121/180] Step 1249/1249 Loss 0.420 Prec@(1,3) (89.3%, 99.7%), ce_loss 0.670, lat_loss 6.684
09/19 03:33:00 PM | _w_step_train: [121/180] Final Prec@1 89.3450% Time 596.16
09/19 03:33:00 PM | Start to train theta for epoch 120
09/19 03:33:20 PM | Train: [121/180] Step 050/312 Loss 0.694 Prec@(1,3) (84.2%, 99.1%), ce_loss 0.670, lat_loss 6.684
09/19 03:33:39 PM | Train: [121/180] Step 100/312 Loss 0.658 Prec@(1,3) (84.0%, 99.1%), ce_loss 0.670, lat_loss 6.684
09/19 03:33:58 PM | Train: [121/180] Step 150/312 Loss 0.640 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.670, lat_loss 6.684
09/19 03:34:17 PM | Train: [121/180] Step 200/312 Loss 0.643 Prec@(1,3) (84.5%, 99.1%), ce_loss 0.670, lat_loss 6.684
09/19 03:34:33 PM | Train: [121/180] Step 250/312 Loss 0.644 Prec@(1,3) (84.4%, 99.1%), ce_loss 0.670, lat_loss 6.684
09/19 03:34:49 PM | Train: [121/180] Step 300/312 Loss 0.638 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.670, lat_loss 6.684
09/19 03:34:54 PM | Train: [121/180] Step 312/312 Loss 0.632 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.670, lat_loss 6.684
09/19 03:34:54 PM | _theta_step_train: [121/180] Final Prec@1 84.6600% Time 114.19
09/19 03:34:59 PM | Valid: [121/180] Step 050/312 Loss 0.566 Prec@(1,3) (85.4%, 99.5%), ce_loss 0.670, lat_loss 6.684
09/19 03:35:04 PM | Valid: [121/180] Step 100/312 Loss 0.595 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.670, lat_loss 6.684
09/19 03:35:09 PM | Valid: [121/180] Step 150/312 Loss 0.608 Prec@(1,3) (85.1%, 99.2%), ce_loss 0.670, lat_loss 6.684
09/19 03:35:13 PM | Valid: [121/180] Step 200/312 Loss 0.613 Prec@(1,3) (84.9%, 99.2%), ce_loss 0.670, lat_loss 6.684
09/19 03:35:18 PM | Valid: [121/180] Step 250/312 Loss 0.660 Prec@(1,3) (84.2%, 98.9%), ce_loss 0.670, lat_loss 6.684
09/19 03:35:23 PM | Valid: [121/180] Step 300/312 Loss 0.658 Prec@(1,3) (84.1%, 98.9%), ce_loss 0.670, lat_loss 6.684
09/19 03:35:24 PM | Valid: [121/180] Step 312/312 Loss 0.656 Prec@(1,3) (84.1%, 98.9%), ce_loss 0.670, lat_loss 6.684
09/19 03:35:24 PM | val: [121/180] Final Prec@1 84.1000% Time 29.89
09/19 03:35:24 PM | Start to train weights for epoch 121
09/19 03:35:50 PM | Train: [122/180] Step 050/1249 Loss 0.381 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.669, lat_loss 6.684
09/19 03:36:15 PM | Train: [122/180] Step 100/1249 Loss 0.361 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.669, lat_loss 6.684
09/19 03:36:40 PM | Train: [122/180] Step 150/1249 Loss 0.378 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.669, lat_loss 6.684
09/19 03:37:03 PM | Train: [122/180] Step 200/1249 Loss 0.395 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.669, lat_loss 6.684
09/19 03:37:26 PM | Train: [122/180] Step 250/1249 Loss 0.408 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.669, lat_loss 6.684
09/19 03:37:49 PM | Train: [122/180] Step 300/1249 Loss 0.408 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.669, lat_loss 6.684
09/19 03:38:13 PM | Train: [122/180] Step 350/1249 Loss 0.403 Prec@(1,3) (89.9%, 99.6%), ce_loss 0.669, lat_loss 6.684
09/19 03:38:36 PM | Train: [122/180] Step 400/1249 Loss 0.400 Prec@(1,3) (90.0%, 99.6%), ce_loss 0.669, lat_loss 6.684
09/19 03:38:59 PM | Train: [122/180] Step 450/1249 Loss 0.400 Prec@(1,3) (90.1%, 99.6%), ce_loss 0.669, lat_loss 6.684
09/19 03:39:22 PM | Train: [122/180] Step 500/1249 Loss 0.404 Prec@(1,3) (90.0%, 99.6%), ce_loss 0.669, lat_loss 6.684
09/19 03:39:45 PM | Train: [122/180] Step 550/1249 Loss 0.404 Prec@(1,3) (90.0%, 99.6%), ce_loss 0.669, lat_loss 6.684
09/19 03:40:07 PM | Train: [122/180] Step 600/1249 Loss 0.400 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.669, lat_loss 6.684
09/19 03:40:30 PM | Train: [122/180] Step 650/1249 Loss 0.398 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.668, lat_loss 6.684
09/19 03:40:52 PM | Train: [122/180] Step 700/1249 Loss 0.397 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.668, lat_loss 6.684
09/19 03:41:14 PM | Train: [122/180] Step 750/1249 Loss 0.395 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.668, lat_loss 6.684
09/19 03:41:36 PM | Train: [122/180] Step 800/1249 Loss 0.395 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.668, lat_loss 6.684
09/19 03:41:59 PM | Train: [122/180] Step 850/1249 Loss 0.394 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.668, lat_loss 6.684
09/19 03:42:20 PM | Train: [122/180] Step 900/1249 Loss 0.399 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.668, lat_loss 6.684
09/19 03:42:42 PM | Train: [122/180] Step 950/1249 Loss 0.401 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.668, lat_loss 6.684
09/19 03:43:04 PM | Train: [122/180] Step 1000/1249 Loss 0.403 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.668, lat_loss 6.684
09/19 03:43:27 PM | Train: [122/180] Step 1050/1249 Loss 0.404 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.668, lat_loss 6.684
09/19 03:43:48 PM | Train: [122/180] Step 1100/1249 Loss 0.404 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.668, lat_loss 6.684
09/19 03:44:11 PM | Train: [122/180] Step 1150/1249 Loss 0.405 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.668, lat_loss 6.684
09/19 03:44:34 PM | Train: [122/180] Step 1200/1249 Loss 0.405 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.668, lat_loss 6.684
09/19 03:44:58 PM | Train: [122/180] Step 1249/1249 Loss 0.406 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.667, lat_loss 6.684
09/19 03:44:58 PM | _w_step_train: [122/180] Final Prec@1 89.7925% Time 574.36
09/19 03:44:58 PM | Start to train theta for epoch 121
09/19 03:45:19 PM | Train: [122/180] Step 050/312 Loss 0.661 Prec@(1,3) (83.0%, 99.4%), ce_loss 0.667, lat_loss 6.684
09/19 03:45:39 PM | Train: [122/180] Step 100/312 Loss 0.653 Prec@(1,3) (83.7%, 99.2%), ce_loss 0.667, lat_loss 6.684
09/19 03:45:59 PM | Train: [122/180] Step 150/312 Loss 0.663 Prec@(1,3) (83.5%, 99.2%), ce_loss 0.667, lat_loss 6.684
09/19 03:46:19 PM | Train: [122/180] Step 200/312 Loss 0.639 Prec@(1,3) (84.3%, 99.2%), ce_loss 0.667, lat_loss 6.684
09/19 03:46:40 PM | Train: [122/180] Step 250/312 Loss 0.630 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.667, lat_loss 6.684
09/19 03:47:00 PM | Train: [122/180] Step 300/312 Loss 0.634 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.667, lat_loss 6.684
09/19 03:47:05 PM | Train: [122/180] Step 312/312 Loss 0.634 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.667, lat_loss 6.684
09/19 03:47:05 PM | _theta_step_train: [122/180] Final Prec@1 84.6100% Time 126.95
09/19 03:47:10 PM | Valid: [122/180] Step 050/312 Loss 0.644 Prec@(1,3) (84.1%, 98.7%), ce_loss 0.667, lat_loss 6.684
09/19 03:47:15 PM | Valid: [122/180] Step 100/312 Loss 0.645 Prec@(1,3) (84.3%, 98.9%), ce_loss 0.667, lat_loss 6.684
09/19 03:47:20 PM | Valid: [122/180] Step 150/312 Loss 0.680 Prec@(1,3) (83.7%, 98.8%), ce_loss 0.667, lat_loss 6.684
09/19 03:47:24 PM | Valid: [122/180] Step 200/312 Loss 0.736 Prec@(1,3) (82.8%, 98.5%), ce_loss 0.667, lat_loss 6.684
09/19 03:47:29 PM | Valid: [122/180] Step 250/312 Loss 0.734 Prec@(1,3) (82.9%, 98.5%), ce_loss 0.667, lat_loss 6.684
09/19 03:47:34 PM | Valid: [122/180] Step 300/312 Loss 0.705 Prec@(1,3) (83.3%, 98.7%), ce_loss 0.667, lat_loss 6.684
09/19 03:47:35 PM | Valid: [122/180] Step 312/312 Loss 0.708 Prec@(1,3) (83.1%, 98.7%), ce_loss 0.667, lat_loss 6.684
09/19 03:47:35 PM | val: [122/180] Final Prec@1 83.0700% Time 29.68
09/19 03:47:35 PM | Start to train weights for epoch 122
09/19 03:47:52 PM | Train: [123/180] Step 050/1249 Loss 0.393 Prec@(1,3) (89.5%, 99.9%), ce_loss 0.667, lat_loss 6.684
09/19 03:48:08 PM | Train: [123/180] Step 100/1249 Loss 0.404 Prec@(1,3) (89.2%, 99.8%), ce_loss 0.667, lat_loss 6.684
09/19 03:48:25 PM | Train: [123/180] Step 150/1249 Loss 0.417 Prec@(1,3) (89.1%, 99.8%), ce_loss 0.667, lat_loss 6.684
09/19 03:48:41 PM | Train: [123/180] Step 200/1249 Loss 0.407 Prec@(1,3) (89.6%, 99.8%), ce_loss 0.667, lat_loss 6.684
09/19 03:48:57 PM | Train: [123/180] Step 250/1249 Loss 0.397 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.667, lat_loss 6.684
09/19 03:49:13 PM | Train: [123/180] Step 300/1249 Loss 0.396 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.666, lat_loss 6.684
09/19 03:49:29 PM | Train: [123/180] Step 350/1249 Loss 0.390 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.666, lat_loss 6.684
09/19 03:49:45 PM | Train: [123/180] Step 400/1249 Loss 0.390 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.666, lat_loss 6.684
09/19 03:50:01 PM | Train: [123/180] Step 450/1249 Loss 0.389 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.666, lat_loss 6.684
09/19 03:50:17 PM | Train: [123/180] Step 500/1249 Loss 0.388 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.666, lat_loss 6.684
09/19 03:50:33 PM | Train: [123/180] Step 550/1249 Loss 0.390 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.666, lat_loss 6.684
09/19 03:50:49 PM | Train: [123/180] Step 600/1249 Loss 0.391 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.666, lat_loss 6.684
09/19 03:51:05 PM | Train: [123/180] Step 650/1249 Loss 0.396 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.666, lat_loss 6.684
09/19 03:51:21 PM | Train: [123/180] Step 700/1249 Loss 0.398 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.666, lat_loss 6.684
09/19 03:51:37 PM | Train: [123/180] Step 750/1249 Loss 0.400 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.666, lat_loss 6.684
09/19 03:51:53 PM | Train: [123/180] Step 800/1249 Loss 0.400 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.666, lat_loss 6.684
09/19 03:52:09 PM | Train: [123/180] Step 850/1249 Loss 0.399 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.666, lat_loss 6.684
09/19 03:52:25 PM | Train: [123/180] Step 900/1249 Loss 0.402 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.666, lat_loss 6.684
09/19 03:52:40 PM | Train: [123/180] Step 950/1249 Loss 0.408 Prec@(1,3) (89.6%, 99.6%), ce_loss 0.665, lat_loss 6.684
09/19 03:52:56 PM | Train: [123/180] Step 1000/1249 Loss 0.409 Prec@(1,3) (89.7%, 99.6%), ce_loss 0.665, lat_loss 6.684
09/19 03:53:12 PM | Train: [123/180] Step 1050/1249 Loss 0.408 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.665, lat_loss 6.684
09/19 03:53:28 PM | Train: [123/180] Step 1100/1249 Loss 0.407 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.665, lat_loss 6.684
09/19 03:53:44 PM | Train: [123/180] Step 1150/1249 Loss 0.408 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.665, lat_loss 6.684
09/19 03:54:09 PM | Train: [123/180] Step 1200/1249 Loss 0.408 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.665, lat_loss 6.684
09/19 03:54:33 PM | Train: [123/180] Step 1249/1249 Loss 0.408 Prec@(1,3) (89.6%, 99.7%), ce_loss 0.665, lat_loss 6.684
09/19 03:54:33 PM | _w_step_train: [123/180] Final Prec@1 89.5750% Time 418.49
09/19 03:54:33 PM | Start to train theta for epoch 122
09/19 03:54:54 PM | Train: [123/180] Step 050/312 Loss 0.715 Prec@(1,3) (83.0%, 98.9%), ce_loss 0.665, lat_loss 6.684
09/19 03:55:15 PM | Train: [123/180] Step 100/312 Loss 0.631 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.665, lat_loss 6.684
09/19 03:55:35 PM | Train: [123/180] Step 150/312 Loss 0.620 Prec@(1,3) (85.0%, 99.2%), ce_loss 0.665, lat_loss 6.684
09/19 03:55:55 PM | Train: [123/180] Step 200/312 Loss 0.609 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.665, lat_loss 6.684
09/19 03:56:15 PM | Train: [123/180] Step 250/312 Loss 0.607 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.665, lat_loss 6.684
09/19 03:56:34 PM | Train: [123/180] Step 300/312 Loss 0.607 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.665, lat_loss 6.684
09/19 03:56:36 PM | Train: [123/180] Step 312/312 Loss 0.608 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.665, lat_loss 6.684
09/19 03:56:36 PM | _theta_step_train: [123/180] Final Prec@1 85.2400% Time 123.05
09/19 03:56:42 PM | Valid: [123/180] Step 050/312 Loss 0.687 Prec@(1,3) (84.6%, 98.4%), ce_loss 0.665, lat_loss 6.684
09/19 03:56:46 PM | Valid: [123/180] Step 100/312 Loss 0.726 Prec@(1,3) (84.6%, 98.3%), ce_loss 0.665, lat_loss 6.684
09/19 03:56:51 PM | Valid: [123/180] Step 150/312 Loss 0.724 Prec@(1,3) (84.1%, 98.3%), ce_loss 0.665, lat_loss 6.684
09/19 03:56:55 PM | Valid: [123/180] Step 200/312 Loss 0.699 Prec@(1,3) (84.2%, 98.5%), ce_loss 0.665, lat_loss 6.684
09/19 03:57:00 PM | Valid: [123/180] Step 250/312 Loss 0.679 Prec@(1,3) (84.2%, 98.7%), ce_loss 0.664, lat_loss 6.684
09/19 03:57:05 PM | Valid: [123/180] Step 300/312 Loss 0.655 Prec@(1,3) (84.6%, 98.9%), ce_loss 0.664, lat_loss 6.684
09/19 03:57:06 PM | Valid: [123/180] Step 312/312 Loss 0.653 Prec@(1,3) (84.6%, 98.9%), ce_loss 0.664, lat_loss 6.684
09/19 03:57:06 PM | val: [123/180] Final Prec@1 84.6000% Time 29.80
09/19 03:57:06 PM | Best top1 acc by now. Save model
09/19 03:57:06 PM | Start to train weights for epoch 123
09/19 03:57:31 PM | Train: [124/180] Step 050/1249 Loss 0.344 Prec@(1,3) (91.2%, 99.9%), ce_loss 0.664, lat_loss 6.684
09/19 03:57:54 PM | Train: [124/180] Step 100/1249 Loss 0.352 Prec@(1,3) (90.8%, 99.9%), ce_loss 0.664, lat_loss 6.684
09/19 03:58:16 PM | Train: [124/180] Step 150/1249 Loss 0.357 Prec@(1,3) (90.7%, 99.9%), ce_loss 0.664, lat_loss 6.684
09/19 03:58:41 PM | Train: [124/180] Step 200/1249 Loss 0.363 Prec@(1,3) (90.7%, 99.9%), ce_loss 0.664, lat_loss 6.684
09/19 03:59:04 PM | Train: [124/180] Step 250/1249 Loss 0.378 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.664, lat_loss 6.684
09/19 03:59:28 PM | Train: [124/180] Step 300/1249 Loss 0.374 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.664, lat_loss 6.684
09/19 03:59:51 PM | Train: [124/180] Step 350/1249 Loss 0.375 Prec@(1,3) (90.2%, 99.8%), ce_loss 0.664, lat_loss 6.684
09/19 04:00:16 PM | Train: [124/180] Step 400/1249 Loss 0.375 Prec@(1,3) (90.2%, 99.8%), ce_loss 0.664, lat_loss 6.684
09/19 04:00:39 PM | Train: [124/180] Step 450/1249 Loss 0.379 Prec@(1,3) (90.2%, 99.8%), ce_loss 0.664, lat_loss 6.684
09/19 04:01:02 PM | Train: [124/180] Step 500/1249 Loss 0.383 Prec@(1,3) (90.1%, 99.8%), ce_loss 0.664, lat_loss 6.684
09/19 04:01:26 PM | Train: [124/180] Step 550/1249 Loss 0.383 Prec@(1,3) (90.1%, 99.8%), ce_loss 0.663, lat_loss 6.685
09/19 04:01:49 PM | Train: [124/180] Step 600/1249 Loss 0.381 Prec@(1,3) (90.2%, 99.8%), ce_loss 0.663, lat_loss 6.685
09/19 04:02:12 PM | Train: [124/180] Step 650/1249 Loss 0.380 Prec@(1,3) (90.2%, 99.8%), ce_loss 0.663, lat_loss 6.685
09/19 04:02:35 PM | Train: [124/180] Step 700/1249 Loss 0.379 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.663, lat_loss 6.685
09/19 04:02:59 PM | Train: [124/180] Step 750/1249 Loss 0.382 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.663, lat_loss 6.685
09/19 04:03:22 PM | Train: [124/180] Step 800/1249 Loss 0.382 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.663, lat_loss 6.685
09/19 04:03:45 PM | Train: [124/180] Step 850/1249 Loss 0.380 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.663, lat_loss 6.685
09/19 04:04:09 PM | Train: [124/180] Step 900/1249 Loss 0.381 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.663, lat_loss 6.685
09/19 04:04:32 PM | Train: [124/180] Step 950/1249 Loss 0.384 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.663, lat_loss 6.685
09/19 04:04:55 PM | Train: [124/180] Step 1000/1249 Loss 0.385 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.663, lat_loss 6.685
09/19 04:05:19 PM | Train: [124/180] Step 1050/1249 Loss 0.385 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.663, lat_loss 6.685
09/19 04:05:43 PM | Train: [124/180] Step 1100/1249 Loss 0.385 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.663, lat_loss 6.685
09/19 04:06:08 PM | Train: [124/180] Step 1150/1249 Loss 0.385 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.662, lat_loss 6.685
09/19 04:06:33 PM | Train: [124/180] Step 1200/1249 Loss 0.385 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.662, lat_loss 6.685
09/19 04:06:57 PM | Train: [124/180] Step 1249/1249 Loss 0.384 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.662, lat_loss 6.685
09/19 04:06:57 PM | _w_step_train: [124/180] Final Prec@1 90.0900% Time 590.59
09/19 04:06:57 PM | Start to train theta for epoch 123
09/19 04:07:18 PM | Train: [124/180] Step 050/312 Loss 0.644 Prec@(1,3) (84.9%, 99.4%), ce_loss 0.662, lat_loss 6.685
09/19 04:07:35 PM | Train: [124/180] Step 100/312 Loss 0.613 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.662, lat_loss 6.685
09/19 04:07:52 PM | Train: [124/180] Step 150/312 Loss 0.639 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.662, lat_loss 6.685
09/19 04:08:08 PM | Train: [124/180] Step 200/312 Loss 0.626 Prec@(1,3) (85.0%, 99.2%), ce_loss 0.662, lat_loss 6.685
09/19 04:08:24 PM | Train: [124/180] Step 250/312 Loss 0.615 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.662, lat_loss 6.685
09/19 04:08:41 PM | Train: [124/180] Step 300/312 Loss 0.610 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.662, lat_loss 6.685
09/19 04:08:46 PM | Train: [124/180] Step 312/312 Loss 0.605 Prec@(1,3) (85.5%, 99.2%), ce_loss 0.662, lat_loss 6.685
09/19 04:08:46 PM | _theta_step_train: [124/180] Final Prec@1 85.5100% Time 108.92
09/19 04:08:51 PM | Valid: [124/180] Step 050/312 Loss 0.630 Prec@(1,3) (84.5%, 99.0%), ce_loss 0.662, lat_loss 6.685
09/19 04:08:56 PM | Valid: [124/180] Step 100/312 Loss 0.730 Prec@(1,3) (83.3%, 98.2%), ce_loss 0.662, lat_loss 6.685
09/19 04:09:01 PM | Valid: [124/180] Step 150/312 Loss 0.752 Prec@(1,3) (83.2%, 98.2%), ce_loss 0.662, lat_loss 6.685
09/19 04:09:05 PM | Valid: [124/180] Step 200/312 Loss 0.741 Prec@(1,3) (83.4%, 98.3%), ce_loss 0.662, lat_loss 6.685
09/19 04:09:10 PM | Valid: [124/180] Step 250/312 Loss 0.747 Prec@(1,3) (82.9%, 98.3%), ce_loss 0.662, lat_loss 6.685
09/19 04:09:15 PM | Valid: [124/180] Step 300/312 Loss 0.745 Prec@(1,3) (83.0%, 98.4%), ce_loss 0.662, lat_loss 6.685
09/19 04:09:16 PM | Valid: [124/180] Step 312/312 Loss 0.738 Prec@(1,3) (83.1%, 98.5%), ce_loss 0.662, lat_loss 6.685
09/19 04:09:16 PM | val: [124/180] Final Prec@1 83.1300% Time 29.89
09/19 04:09:16 PM | Start to train weights for epoch 124
09/19 04:09:38 PM | Train: [125/180] Step 050/1249 Loss 0.381 Prec@(1,3) (90.0%, 99.6%), ce_loss 0.662, lat_loss 6.685
09/19 04:09:58 PM | Train: [125/180] Step 100/1249 Loss 0.382 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.662, lat_loss 6.685
09/19 04:10:18 PM | Train: [125/180] Step 150/1249 Loss 0.363 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.662, lat_loss 6.685
09/19 04:10:39 PM | Train: [125/180] Step 200/1249 Loss 0.365 Prec@(1,3) (90.4%, 99.8%), ce_loss 0.662, lat_loss 6.685
09/19 04:10:59 PM | Train: [125/180] Step 250/1249 Loss 0.376 Prec@(1,3) (90.1%, 99.8%), ce_loss 0.661, lat_loss 6.685
09/19 04:11:19 PM | Train: [125/180] Step 300/1249 Loss 0.379 Prec@(1,3) (90.1%, 99.8%), ce_loss 0.661, lat_loss 6.685
09/19 04:11:39 PM | Train: [125/180] Step 350/1249 Loss 0.379 Prec@(1,3) (90.0%, 99.8%), ce_loss 0.661, lat_loss 6.685
09/19 04:11:59 PM | Train: [125/180] Step 400/1249 Loss 0.377 Prec@(1,3) (90.2%, 99.8%), ce_loss 0.661, lat_loss 6.685
09/19 04:12:17 PM | Train: [125/180] Step 450/1249 Loss 0.385 Prec@(1,3) (90.1%, 99.8%), ce_loss 0.661, lat_loss 6.685
09/19 04:12:35 PM | Train: [125/180] Step 500/1249 Loss 0.388 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.661, lat_loss 6.685
09/19 04:12:53 PM | Train: [125/180] Step 550/1249 Loss 0.386 Prec@(1,3) (90.0%, 99.7%), ce_loss 0.661, lat_loss 6.685
09/19 04:13:13 PM | Train: [125/180] Step 600/1249 Loss 0.393 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.661, lat_loss 6.685
09/19 04:13:33 PM | Train: [125/180] Step 650/1249 Loss 0.393 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.661, lat_loss 6.685
09/19 04:13:53 PM | Train: [125/180] Step 700/1249 Loss 0.394 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.661, lat_loss 6.685
09/19 04:14:13 PM | Train: [125/180] Step 750/1249 Loss 0.393 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.661, lat_loss 6.685
09/19 04:14:33 PM | Train: [125/180] Step 800/1249 Loss 0.395 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.661, lat_loss 6.685
09/19 04:14:54 PM | Train: [125/180] Step 850/1249 Loss 0.394 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.661, lat_loss 6.685
09/19 04:15:15 PM | Train: [125/180] Step 900/1249 Loss 0.396 Prec@(1,3) (89.8%, 99.7%), ce_loss 0.660, lat_loss 6.685
09/19 04:15:38 PM | Train: [125/180] Step 950/1249 Loss 0.395 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.660, lat_loss 6.685
09/19 04:16:01 PM | Train: [125/180] Step 1000/1249 Loss 0.395 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.660, lat_loss 6.685
09/19 04:16:22 PM | Train: [125/180] Step 1050/1249 Loss 0.395 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.660, lat_loss 6.685
09/19 04:16:46 PM | Train: [125/180] Step 1100/1249 Loss 0.396 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.660, lat_loss 6.685
09/19 04:17:10 PM | Train: [125/180] Step 1150/1249 Loss 0.395 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.660, lat_loss 6.685
09/19 04:17:34 PM | Train: [125/180] Step 1200/1249 Loss 0.394 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.660, lat_loss 6.685
09/19 04:17:58 PM | Train: [125/180] Step 1249/1249 Loss 0.393 Prec@(1,3) (89.9%, 99.7%), ce_loss 0.660, lat_loss 6.685
09/19 04:17:58 PM | _w_step_train: [125/180] Final Prec@1 89.9225% Time 521.99
09/19 04:17:58 PM | Start to train theta for epoch 124
09/19 04:18:17 PM | Train: [125/180] Step 050/312 Loss 0.585 Prec@(1,3) (86.0%, 98.9%), ce_loss 0.660, lat_loss 6.685
09/19 04:18:38 PM | Train: [125/180] Step 100/312 Loss 0.629 Prec@(1,3) (85.1%, 98.8%), ce_loss 0.660, lat_loss 6.685
09/19 04:18:58 PM | Train: [125/180] Step 150/312 Loss 0.633 Prec@(1,3) (84.9%, 99.0%), ce_loss 0.660, lat_loss 6.685
09/19 04:19:18 PM | Train: [125/180] Step 200/312 Loss 0.622 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.660, lat_loss 6.685
09/19 04:19:38 PM | Train: [125/180] Step 250/312 Loss 0.613 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.660, lat_loss 6.685
09/19 04:19:58 PM | Train: [125/180] Step 300/312 Loss 0.622 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.660, lat_loss 6.685
09/19 04:20:03 PM | Train: [125/180] Step 312/312 Loss 0.624 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.660, lat_loss 6.685
09/19 04:20:03 PM | _theta_step_train: [125/180] Final Prec@1 85.0700% Time 125.29
09/19 04:20:08 PM | Valid: [125/180] Step 050/312 Loss 0.826 Prec@(1,3) (81.1%, 97.2%), ce_loss 0.660, lat_loss 6.685
09/19 04:20:13 PM | Valid: [125/180] Step 100/312 Loss 0.841 Prec@(1,3) (80.1%, 97.3%), ce_loss 0.660, lat_loss 6.685
09/19 04:20:18 PM | Valid: [125/180] Step 150/312 Loss 0.780 Prec@(1,3) (81.6%, 97.8%), ce_loss 0.660, lat_loss 6.685
09/19 04:20:23 PM | Valid: [125/180] Step 200/312 Loss 0.744 Prec@(1,3) (82.4%, 98.1%), ce_loss 0.659, lat_loss 6.685
09/19 04:20:27 PM | Valid: [125/180] Step 250/312 Loss 0.747 Prec@(1,3) (82.6%, 98.2%), ce_loss 0.659, lat_loss 6.685
09/19 04:20:32 PM | Valid: [125/180] Step 300/312 Loss 0.725 Prec@(1,3) (83.0%, 98.3%), ce_loss 0.659, lat_loss 6.685
09/19 04:20:33 PM | Valid: [125/180] Step 312/312 Loss 0.718 Prec@(1,3) (83.0%, 98.4%), ce_loss 0.659, lat_loss 6.685
09/19 04:20:33 PM | val: [125/180] Final Prec@1 83.0400% Time 29.87
09/19 04:20:33 PM | Start to train weights for epoch 125
09/19 04:20:55 PM | Train: [126/180] Step 050/1249 Loss 0.374 Prec@(1,3) (90.6%, 99.6%), ce_loss 0.659, lat_loss 6.685
09/19 04:21:15 PM | Train: [126/180] Step 100/1249 Loss 0.346 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.659, lat_loss 6.685
09/19 04:21:39 PM | Train: [126/180] Step 150/1249 Loss 0.378 Prec@(1,3) (90.8%, 99.6%), ce_loss 0.659, lat_loss 6.685
09/19 04:22:03 PM | Train: [126/180] Step 200/1249 Loss 0.384 Prec@(1,3) (90.5%, 99.6%), ce_loss 0.659, lat_loss 6.685
09/19 04:22:28 PM | Train: [126/180] Step 250/1249 Loss 0.401 Prec@(1,3) (90.1%, 99.5%), ce_loss 0.659, lat_loss 6.685
09/19 04:22:53 PM | Train: [126/180] Step 300/1249 Loss 0.406 Prec@(1,3) (90.0%, 99.5%), ce_loss 0.659, lat_loss 6.685
09/19 04:23:16 PM | Train: [126/180] Step 350/1249 Loss 0.406 Prec@(1,3) (89.8%, 99.5%), ce_loss 0.659, lat_loss 6.685
09/19 04:23:39 PM | Train: [126/180] Step 400/1249 Loss 0.403 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.659, lat_loss 6.685
09/19 04:24:02 PM | Train: [126/180] Step 450/1249 Loss 0.407 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.659, lat_loss 6.685
09/19 04:24:24 PM | Train: [126/180] Step 500/1249 Loss 0.403 Prec@(1,3) (89.9%, 99.6%), ce_loss 0.659, lat_loss 6.685
09/19 04:24:49 PM | Train: [126/180] Step 550/1249 Loss 0.403 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.659, lat_loss 6.685
09/19 04:25:13 PM | Train: [126/180] Step 600/1249 Loss 0.407 Prec@(1,3) (89.7%, 99.6%), ce_loss 0.658, lat_loss 6.685
09/19 04:25:38 PM | Train: [126/180] Step 650/1249 Loss 0.404 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.658, lat_loss 6.685
09/19 04:26:02 PM | Train: [126/180] Step 700/1249 Loss 0.404 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.658, lat_loss 6.685
09/19 04:26:25 PM | Train: [126/180] Step 750/1249 Loss 0.398 Prec@(1,3) (90.0%, 99.6%), ce_loss 0.658, lat_loss 6.685
09/19 04:26:49 PM | Train: [126/180] Step 800/1249 Loss 0.399 Prec@(1,3) (89.9%, 99.6%), ce_loss 0.658, lat_loss 6.685
09/19 04:27:13 PM | Train: [126/180] Step 850/1249 Loss 0.399 Prec@(1,3) (89.9%, 99.6%), ce_loss 0.658, lat_loss 6.685
09/19 04:27:37 PM | Train: [126/180] Step 900/1249 Loss 0.402 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.658, lat_loss 6.685
09/19 04:28:00 PM | Train: [126/180] Step 950/1249 Loss 0.400 Prec@(1,3) (89.9%, 99.6%), ce_loss 0.658, lat_loss 6.685
09/19 04:28:24 PM | Train: [126/180] Step 1000/1249 Loss 0.399 Prec@(1,3) (89.9%, 99.6%), ce_loss 0.658, lat_loss 6.685
09/19 04:28:48 PM | Train: [126/180] Step 1050/1249 Loss 0.398 Prec@(1,3) (89.9%, 99.6%), ce_loss 0.658, lat_loss 6.685
09/19 04:29:12 PM | Train: [126/180] Step 1100/1249 Loss 0.402 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.658, lat_loss 6.685
09/19 04:29:36 PM | Train: [126/180] Step 1150/1249 Loss 0.401 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.658, lat_loss 6.685
09/19 04:29:59 PM | Train: [126/180] Step 1200/1249 Loss 0.403 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.658, lat_loss 6.685
09/19 04:30:23 PM | Train: [126/180] Step 1249/1249 Loss 0.404 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.657, lat_loss 6.685
09/19 04:30:23 PM | _w_step_train: [126/180] Final Prec@1 89.7775% Time 590.12
09/19 04:30:23 PM | Start to train theta for epoch 125
09/19 04:30:42 PM | Train: [126/180] Step 050/312 Loss 0.583 Prec@(1,3) (85.8%, 99.1%), ce_loss 0.657, lat_loss 6.685
09/19 04:30:59 PM | Train: [126/180] Step 100/312 Loss 0.623 Prec@(1,3) (85.5%, 99.1%), ce_loss 0.657, lat_loss 6.685
09/19 04:31:16 PM | Train: [126/180] Step 150/312 Loss 0.619 Prec@(1,3) (85.5%, 99.1%), ce_loss 0.657, lat_loss 6.685
09/19 04:31:36 PM | Train: [126/180] Step 200/312 Loss 0.607 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.657, lat_loss 6.685
09/19 04:31:55 PM | Train: [126/180] Step 250/312 Loss 0.607 Prec@(1,3) (85.6%, 99.1%), ce_loss 0.657, lat_loss 6.685
09/19 04:32:15 PM | Train: [126/180] Step 300/312 Loss 0.606 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.657, lat_loss 6.685
09/19 04:32:20 PM | Train: [126/180] Step 312/312 Loss 0.609 Prec@(1,3) (85.5%, 99.1%), ce_loss 0.657, lat_loss 6.685
09/19 04:32:20 PM | _theta_step_train: [126/180] Final Prec@1 85.5200% Time 117.27
09/19 04:32:26 PM | Valid: [126/180] Step 050/312 Loss 0.610 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.657, lat_loss 6.685
09/19 04:32:30 PM | Valid: [126/180] Step 100/312 Loss 0.689 Prec@(1,3) (83.8%, 98.9%), ce_loss 0.657, lat_loss 6.685
09/19 04:32:35 PM | Valid: [126/180] Step 150/312 Loss 0.690 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.657, lat_loss 6.685
09/19 04:32:39 PM | Valid: [126/180] Step 200/312 Loss 0.670 Prec@(1,3) (84.0%, 99.1%), ce_loss 0.657, lat_loss 6.685
09/19 04:32:44 PM | Valid: [126/180] Step 250/312 Loss 0.679 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.657, lat_loss 6.685
09/19 04:32:49 PM | Valid: [126/180] Step 300/312 Loss 0.664 Prec@(1,3) (84.1%, 99.1%), ce_loss 0.657, lat_loss 6.685
09/19 04:32:50 PM | Valid: [126/180] Step 312/312 Loss 0.675 Prec@(1,3) (83.8%, 99.1%), ce_loss 0.657, lat_loss 6.685
09/19 04:32:50 PM | val: [126/180] Final Prec@1 83.8400% Time 29.61
09/19 04:32:50 PM | Start to train weights for epoch 126
09/19 04:33:15 PM | Train: [127/180] Step 050/1249 Loss 0.348 Prec@(1,3) (91.4%, 99.9%), ce_loss 0.657, lat_loss 6.685
09/19 04:33:37 PM | Train: [127/180] Step 100/1249 Loss 0.365 Prec@(1,3) (91.0%, 99.6%), ce_loss 0.657, lat_loss 6.685
09/19 04:34:00 PM | Train: [127/180] Step 150/1249 Loss 0.358 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.657, lat_loss 6.685
09/19 04:34:23 PM | Train: [127/180] Step 200/1249 Loss 0.364 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.657, lat_loss 6.685
09/19 04:34:48 PM | Train: [127/180] Step 250/1249 Loss 0.364 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.657, lat_loss 6.685
09/19 04:35:12 PM | Train: [127/180] Step 300/1249 Loss 0.363 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.656, lat_loss 6.685
09/19 04:35:36 PM | Train: [127/180] Step 350/1249 Loss 0.377 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.656, lat_loss 6.685
09/19 04:36:01 PM | Train: [127/180] Step 400/1249 Loss 0.376 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.656, lat_loss 6.685
09/19 04:36:24 PM | Train: [127/180] Step 450/1249 Loss 0.375 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.656, lat_loss 6.685
09/19 04:36:46 PM | Train: [127/180] Step 500/1249 Loss 0.370 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.656, lat_loss 6.685
09/19 04:37:10 PM | Train: [127/180] Step 550/1249 Loss 0.382 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.656, lat_loss 6.685
09/19 04:37:33 PM | Train: [127/180] Step 600/1249 Loss 0.378 Prec@(1,3) (90.5%, 99.8%), ce_loss 0.656, lat_loss 6.685
09/19 04:37:57 PM | Train: [127/180] Step 650/1249 Loss 0.374 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.656, lat_loss 6.685
09/19 04:38:21 PM | Train: [127/180] Step 700/1249 Loss 0.375 Prec@(1,3) (90.5%, 99.8%), ce_loss 0.656, lat_loss 6.685
09/19 04:38:45 PM | Train: [127/180] Step 750/1249 Loss 0.376 Prec@(1,3) (90.5%, 99.8%), ce_loss 0.656, lat_loss 6.685
09/19 04:39:10 PM | Train: [127/180] Step 800/1249 Loss 0.377 Prec@(1,3) (90.5%, 99.8%), ce_loss 0.656, lat_loss 6.685
09/19 04:39:34 PM | Train: [127/180] Step 850/1249 Loss 0.382 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.656, lat_loss 6.685
09/19 04:39:59 PM | Train: [127/180] Step 900/1249 Loss 0.386 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.656, lat_loss 6.685
09/19 04:40:24 PM | Train: [127/180] Step 950/1249 Loss 0.387 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.655, lat_loss 6.685
09/19 04:40:48 PM | Train: [127/180] Step 1000/1249 Loss 0.391 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.655, lat_loss 6.685
09/19 04:41:13 PM | Train: [127/180] Step 1050/1249 Loss 0.393 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.655, lat_loss 6.685
09/19 04:41:37 PM | Train: [127/180] Step 1100/1249 Loss 0.393 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.655, lat_loss 6.685
09/19 04:42:02 PM | Train: [127/180] Step 1150/1249 Loss 0.394 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.655, lat_loss 6.685
09/19 04:42:27 PM | Train: [127/180] Step 1200/1249 Loss 0.394 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.655, lat_loss 6.685
09/19 04:42:51 PM | Train: [127/180] Step 1249/1249 Loss 0.394 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.655, lat_loss 6.685
09/19 04:42:51 PM | _w_step_train: [127/180] Final Prec@1 90.1050% Time 601.35
09/19 04:42:51 PM | Start to train theta for epoch 126
09/19 04:43:13 PM | Train: [127/180] Step 050/312 Loss 0.645 Prec@(1,3) (83.9%, 99.0%), ce_loss 0.655, lat_loss 6.685
09/19 04:43:33 PM | Train: [127/180] Step 100/312 Loss 0.596 Prec@(1,3) (85.0%, 99.2%), ce_loss 0.655, lat_loss 6.685
09/19 04:43:54 PM | Train: [127/180] Step 150/312 Loss 0.605 Prec@(1,3) (85.0%, 99.2%), ce_loss 0.655, lat_loss 6.685
09/19 04:44:14 PM | Train: [127/180] Step 200/312 Loss 0.592 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.655, lat_loss 6.685
09/19 04:44:35 PM | Train: [127/180] Step 250/312 Loss 0.619 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.655, lat_loss 6.685
09/19 04:44:56 PM | Train: [127/180] Step 300/312 Loss 0.617 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.655, lat_loss 6.685
09/19 04:45:01 PM | Train: [127/180] Step 312/312 Loss 0.620 Prec@(1,3) (85.1%, 99.2%), ce_loss 0.655, lat_loss 6.685
09/19 04:45:01 PM | _theta_step_train: [127/180] Final Prec@1 85.0900% Time 129.30
09/19 04:45:06 PM | Valid: [127/180] Step 050/312 Loss 0.621 Prec@(1,3) (83.9%, 99.3%), ce_loss 0.655, lat_loss 6.685
09/19 04:45:10 PM | Valid: [127/180] Step 100/312 Loss 0.627 Prec@(1,3) (84.1%, 99.1%), ce_loss 0.655, lat_loss 6.685
09/19 04:45:14 PM | Valid: [127/180] Step 150/312 Loss 0.640 Prec@(1,3) (84.0%, 99.0%), ce_loss 0.655, lat_loss 6.685
09/19 04:45:19 PM | Valid: [127/180] Step 200/312 Loss 0.623 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.655, lat_loss 6.685
09/19 04:45:23 PM | Valid: [127/180] Step 250/312 Loss 0.654 Prec@(1,3) (83.8%, 99.1%), ce_loss 0.655, lat_loss 6.685
09/19 04:45:27 PM | Valid: [127/180] Step 300/312 Loss 0.645 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.655, lat_loss 6.685
09/19 04:45:28 PM | Valid: [127/180] Step 312/312 Loss 0.645 Prec@(1,3) (83.8%, 99.0%), ce_loss 0.655, lat_loss 6.685
09/19 04:45:28 PM | val: [127/180] Final Prec@1 83.8400% Time 27.33
09/19 04:45:28 PM | Start to train weights for epoch 127
09/19 04:45:53 PM | Train: [128/180] Step 050/1249 Loss 0.364 Prec@(1,3) (91.1%, 99.5%), ce_loss 0.654, lat_loss 6.685
09/19 04:46:17 PM | Train: [128/180] Step 100/1249 Loss 0.397 Prec@(1,3) (90.3%, 99.4%), ce_loss 0.654, lat_loss 6.685
09/19 04:46:39 PM | Train: [128/180] Step 150/1249 Loss 0.385 Prec@(1,3) (90.4%, 99.5%), ce_loss 0.654, lat_loss 6.685
09/19 04:47:01 PM | Train: [128/180] Step 200/1249 Loss 0.373 Prec@(1,3) (90.7%, 99.6%), ce_loss 0.654, lat_loss 6.685
09/19 04:47:25 PM | Train: [128/180] Step 250/1249 Loss 0.373 Prec@(1,3) (90.7%, 99.6%), ce_loss 0.654, lat_loss 6.685
09/19 04:47:47 PM | Train: [128/180] Step 300/1249 Loss 0.372 Prec@(1,3) (90.7%, 99.6%), ce_loss 0.654, lat_loss 6.685
09/19 04:48:09 PM | Train: [128/180] Step 350/1249 Loss 0.372 Prec@(1,3) (90.7%, 99.6%), ce_loss 0.654, lat_loss 6.685
09/19 04:48:32 PM | Train: [128/180] Step 400/1249 Loss 0.372 Prec@(1,3) (90.6%, 99.6%), ce_loss 0.654, lat_loss 6.685
09/19 04:48:54 PM | Train: [128/180] Step 450/1249 Loss 0.371 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.654, lat_loss 6.685
09/19 04:49:17 PM | Train: [128/180] Step 500/1249 Loss 0.372 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.654, lat_loss 6.685
09/19 04:49:39 PM | Train: [128/180] Step 550/1249 Loss 0.376 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.654, lat_loss 6.685
09/19 04:50:03 PM | Train: [128/180] Step 600/1249 Loss 0.376 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.654, lat_loss 6.685
09/19 04:50:25 PM | Train: [128/180] Step 650/1249 Loss 0.374 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.653, lat_loss 6.685
09/19 04:50:49 PM | Train: [128/180] Step 700/1249 Loss 0.376 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.653, lat_loss 6.685
09/19 04:51:12 PM | Train: [128/180] Step 750/1249 Loss 0.375 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.653, lat_loss 6.685
09/19 04:51:35 PM | Train: [128/180] Step 800/1249 Loss 0.372 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.653, lat_loss 6.685
09/19 04:51:58 PM | Train: [128/180] Step 850/1249 Loss 0.372 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.653, lat_loss 6.685
09/19 04:52:21 PM | Train: [128/180] Step 900/1249 Loss 0.371 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.653, lat_loss 6.685
09/19 04:52:43 PM | Train: [128/180] Step 950/1249 Loss 0.371 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.653, lat_loss 6.685
09/19 04:53:05 PM | Train: [128/180] Step 1000/1249 Loss 0.372 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.653, lat_loss 6.685
09/19 04:53:28 PM | Train: [128/180] Step 1050/1249 Loss 0.372 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.653, lat_loss 6.685
09/19 04:53:50 PM | Train: [128/180] Step 1100/1249 Loss 0.371 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.653, lat_loss 6.685
09/19 04:54:12 PM | Train: [128/180] Step 1150/1249 Loss 0.371 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.653, lat_loss 6.685
09/19 04:54:34 PM | Train: [128/180] Step 1200/1249 Loss 0.373 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.653, lat_loss 6.685
09/19 04:54:56 PM | Train: [128/180] Step 1249/1249 Loss 0.374 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.653, lat_loss 6.685
09/19 04:54:57 PM | _w_step_train: [128/180] Final Prec@1 90.4425% Time 568.49
09/19 04:54:57 PM | Start to train theta for epoch 127
09/19 04:55:18 PM | Train: [128/180] Step 050/312 Loss 0.615 Prec@(1,3) (84.5%, 99.3%), ce_loss 0.652, lat_loss 6.685
09/19 04:55:38 PM | Train: [128/180] Step 100/312 Loss 0.604 Prec@(1,3) (85.0%, 99.4%), ce_loss 0.652, lat_loss 6.685
09/19 04:55:59 PM | Train: [128/180] Step 150/312 Loss 0.595 Prec@(1,3) (85.0%, 99.3%), ce_loss 0.652, lat_loss 6.685
09/19 04:56:19 PM | Train: [128/180] Step 200/312 Loss 0.600 Prec@(1,3) (84.9%, 99.4%), ce_loss 0.652, lat_loss 6.685
09/19 04:56:38 PM | Train: [128/180] Step 250/312 Loss 0.613 Prec@(1,3) (84.9%, 99.3%), ce_loss 0.652, lat_loss 6.685
09/19 04:56:58 PM | Train: [128/180] Step 300/312 Loss 0.613 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.652, lat_loss 6.685
09/19 04:57:03 PM | Train: [128/180] Step 312/312 Loss 0.617 Prec@(1,3) (85.1%, 99.2%), ce_loss 0.652, lat_loss 6.685
09/19 04:57:03 PM | _theta_step_train: [128/180] Final Prec@1 85.0800% Time 126.64
09/19 04:57:08 PM | Valid: [128/180] Step 050/312 Loss 0.619 Prec@(1,3) (84.4%, 99.2%), ce_loss 0.652, lat_loss 6.685
09/19 04:57:13 PM | Valid: [128/180] Step 100/312 Loss 0.633 Prec@(1,3) (84.4%, 99.0%), ce_loss 0.652, lat_loss 6.685
09/19 04:57:18 PM | Valid: [128/180] Step 150/312 Loss 0.692 Prec@(1,3) (83.5%, 98.4%), ce_loss 0.652, lat_loss 6.685
09/19 04:57:22 PM | Valid: [128/180] Step 200/312 Loss 0.671 Prec@(1,3) (83.8%, 98.6%), ce_loss 0.652, lat_loss 6.685
09/19 04:57:27 PM | Valid: [128/180] Step 250/312 Loss 0.696 Prec@(1,3) (83.4%, 98.5%), ce_loss 0.652, lat_loss 6.685
09/19 04:57:32 PM | Valid: [128/180] Step 300/312 Loss 0.676 Prec@(1,3) (83.6%, 98.6%), ce_loss 0.652, lat_loss 6.685
09/19 04:57:33 PM | Valid: [128/180] Step 312/312 Loss 0.671 Prec@(1,3) (83.8%, 98.7%), ce_loss 0.652, lat_loss 6.685
09/19 04:57:33 PM | val: [128/180] Final Prec@1 83.7600% Time 29.57
09/19 04:57:33 PM | Start to train weights for epoch 128
09/19 04:57:59 PM | Train: [129/180] Step 050/1249 Loss 0.362 Prec@(1,3) (91.0%, 99.9%), ce_loss 0.652, lat_loss 6.685
09/19 04:58:23 PM | Train: [129/180] Step 100/1249 Loss 0.363 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.652, lat_loss 6.685
09/19 04:58:47 PM | Train: [129/180] Step 150/1249 Loss 0.362 Prec@(1,3) (90.8%, 99.9%), ce_loss 0.652, lat_loss 6.685
09/19 04:59:11 PM | Train: [129/180] Step 200/1249 Loss 0.352 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.652, lat_loss 6.685
09/19 04:59:36 PM | Train: [129/180] Step 250/1249 Loss 0.365 Prec@(1,3) (90.9%, 99.8%), ce_loss 0.652, lat_loss 6.685
09/19 05:00:00 PM | Train: [129/180] Step 300/1249 Loss 0.364 Prec@(1,3) (90.9%, 99.8%), ce_loss 0.652, lat_loss 6.685
09/19 05:00:23 PM | Train: [129/180] Step 350/1249 Loss 0.361 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.651, lat_loss 6.685
09/19 05:00:47 PM | Train: [129/180] Step 400/1249 Loss 0.367 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.651, lat_loss 6.685
09/19 05:01:10 PM | Train: [129/180] Step 450/1249 Loss 0.369 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.651, lat_loss 6.685
09/19 05:01:35 PM | Train: [129/180] Step 500/1249 Loss 0.370 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.651, lat_loss 6.685
09/19 05:01:59 PM | Train: [129/180] Step 550/1249 Loss 0.377 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.651, lat_loss 6.685
09/19 05:02:22 PM | Train: [129/180] Step 600/1249 Loss 0.378 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.651, lat_loss 6.685
09/19 05:02:47 PM | Train: [129/180] Step 650/1249 Loss 0.379 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.651, lat_loss 6.685
09/19 05:03:10 PM | Train: [129/180] Step 700/1249 Loss 0.379 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.651, lat_loss 6.685
09/19 05:03:30 PM | Train: [129/180] Step 750/1249 Loss 0.378 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.651, lat_loss 6.685
09/19 05:03:54 PM | Train: [129/180] Step 800/1249 Loss 0.376 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.651, lat_loss 6.685
09/19 05:04:19 PM | Train: [129/180] Step 850/1249 Loss 0.379 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.651, lat_loss 6.685
09/19 05:04:44 PM | Train: [129/180] Step 900/1249 Loss 0.380 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.651, lat_loss 6.685
09/19 05:05:07 PM | Train: [129/180] Step 950/1249 Loss 0.380 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.651, lat_loss 6.685
09/19 05:05:30 PM | Train: [129/180] Step 1000/1249 Loss 0.378 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.650, lat_loss 6.685
09/19 05:05:53 PM | Train: [129/180] Step 1050/1249 Loss 0.376 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.650, lat_loss 6.685
09/19 05:06:17 PM | Train: [129/180] Step 1100/1249 Loss 0.377 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.650, lat_loss 6.685
09/19 05:06:41 PM | Train: [129/180] Step 1150/1249 Loss 0.375 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.650, lat_loss 6.685
09/19 05:07:06 PM | Train: [129/180] Step 1200/1249 Loss 0.375 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.650, lat_loss 6.685
09/19 05:07:31 PM | Train: [129/180] Step 1249/1249 Loss 0.376 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.650, lat_loss 6.685
09/19 05:07:31 PM | _w_step_train: [129/180] Final Prec@1 90.4875% Time 597.86
09/19 05:07:31 PM | Start to train theta for epoch 128
09/19 05:07:52 PM | Train: [129/180] Step 050/312 Loss 0.558 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.650, lat_loss 6.685
09/19 05:08:12 PM | Train: [129/180] Step 100/312 Loss 0.582 Prec@(1,3) (85.6%, 99.1%), ce_loss 0.650, lat_loss 6.685
09/19 05:08:28 PM | Train: [129/180] Step 150/312 Loss 0.618 Prec@(1,3) (85.1%, 99.0%), ce_loss 0.650, lat_loss 6.685
09/19 05:08:41 PM | Train: [129/180] Step 200/312 Loss 0.614 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.650, lat_loss 6.685
09/19 05:09:02 PM | Train: [129/180] Step 250/312 Loss 0.624 Prec@(1,3) (85.0%, 99.1%), ce_loss 0.650, lat_loss 6.685
09/19 05:09:23 PM | Train: [129/180] Step 300/312 Loss 0.630 Prec@(1,3) (84.9%, 99.0%), ce_loss 0.650, lat_loss 6.685
09/19 05:09:27 PM | Train: [129/180] Step 312/312 Loss 0.631 Prec@(1,3) (84.9%, 99.0%), ce_loss 0.650, lat_loss 6.685
09/19 05:09:28 PM | _theta_step_train: [129/180] Final Prec@1 84.9200% Time 116.92
09/19 05:09:33 PM | Valid: [129/180] Step 050/312 Loss 0.572 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.650, lat_loss 6.685
09/19 05:09:37 PM | Valid: [129/180] Step 100/312 Loss 0.662 Prec@(1,3) (84.5%, 98.4%), ce_loss 0.650, lat_loss 6.685
09/19 05:09:42 PM | Valid: [129/180] Step 150/312 Loss 0.643 Prec@(1,3) (84.9%, 98.5%), ce_loss 0.650, lat_loss 6.685
09/19 05:09:47 PM | Valid: [129/180] Step 200/312 Loss 0.654 Prec@(1,3) (84.9%, 98.6%), ce_loss 0.650, lat_loss 6.685
09/19 05:09:52 PM | Valid: [129/180] Step 250/312 Loss 0.672 Prec@(1,3) (84.4%, 98.4%), ce_loss 0.650, lat_loss 6.685
09/19 05:09:56 PM | Valid: [129/180] Step 300/312 Loss 0.655 Prec@(1,3) (84.6%, 98.6%), ce_loss 0.650, lat_loss 6.685
09/19 05:09:58 PM | Valid: [129/180] Step 312/312 Loss 0.657 Prec@(1,3) (84.5%, 98.6%), ce_loss 0.650, lat_loss 6.685
09/19 05:09:58 PM | val: [129/180] Final Prec@1 84.4700% Time 30.04
09/19 05:09:58 PM | Start to train weights for epoch 129
09/19 05:10:23 PM | Train: [130/180] Step 050/1249 Loss 0.387 Prec@(1,3) (90.0%, 99.5%), ce_loss 0.650, lat_loss 6.685
09/19 05:10:47 PM | Train: [130/180] Step 100/1249 Loss 0.415 Prec@(1,3) (89.8%, 99.4%), ce_loss 0.649, lat_loss 6.685
09/19 05:11:11 PM | Train: [130/180] Step 150/1249 Loss 0.416 Prec@(1,3) (89.4%, 99.4%), ce_loss 0.649, lat_loss 6.685
09/19 05:11:34 PM | Train: [130/180] Step 200/1249 Loss 0.408 Prec@(1,3) (89.7%, 99.5%), ce_loss 0.649, lat_loss 6.685
09/19 05:11:58 PM | Train: [130/180] Step 250/1249 Loss 0.392 Prec@(1,3) (90.1%, 99.6%), ce_loss 0.649, lat_loss 6.685
09/19 05:12:22 PM | Train: [130/180] Step 300/1249 Loss 0.403 Prec@(1,3) (89.8%, 99.6%), ce_loss 0.649, lat_loss 6.685
09/19 05:12:46 PM | Train: [130/180] Step 350/1249 Loss 0.399 Prec@(1,3) (89.9%, 99.6%), ce_loss 0.649, lat_loss 6.685
09/19 05:13:11 PM | Train: [130/180] Step 400/1249 Loss 0.394 Prec@(1,3) (90.0%, 99.6%), ce_loss 0.649, lat_loss 6.685
09/19 05:13:35 PM | Train: [130/180] Step 450/1249 Loss 0.393 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.649, lat_loss 6.685
09/19 05:14:00 PM | Train: [130/180] Step 500/1249 Loss 0.393 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.649, lat_loss 6.685
09/19 05:14:25 PM | Train: [130/180] Step 550/1249 Loss 0.392 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.649, lat_loss 6.685
09/19 05:14:49 PM | Train: [130/180] Step 600/1249 Loss 0.392 Prec@(1,3) (90.1%, 99.7%), ce_loss 0.649, lat_loss 6.685
09/19 05:15:14 PM | Train: [130/180] Step 650/1249 Loss 0.389 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.649, lat_loss 6.685
09/19 05:15:38 PM | Train: [130/180] Step 700/1249 Loss 0.387 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.649, lat_loss 6.685
09/19 05:16:01 PM | Train: [130/180] Step 750/1249 Loss 0.387 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.648, lat_loss 6.685
09/19 05:16:25 PM | Train: [130/180] Step 800/1249 Loss 0.386 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.648, lat_loss 6.685
09/19 05:16:48 PM | Train: [130/180] Step 850/1249 Loss 0.384 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.648, lat_loss 6.685
09/19 05:17:10 PM | Train: [130/180] Step 900/1249 Loss 0.384 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.648, lat_loss 6.685
09/19 05:17:32 PM | Train: [130/180] Step 950/1249 Loss 0.387 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.648, lat_loss 6.685
09/19 05:17:55 PM | Train: [130/180] Step 1000/1249 Loss 0.384 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.648, lat_loss 6.685
09/19 05:18:16 PM | Train: [130/180] Step 1050/1249 Loss 0.384 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.648, lat_loss 6.685
09/19 05:18:39 PM | Train: [130/180] Step 1100/1249 Loss 0.386 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.648, lat_loss 6.685
09/19 05:19:03 PM | Train: [130/180] Step 1150/1249 Loss 0.386 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.648, lat_loss 6.685
09/19 05:19:27 PM | Train: [130/180] Step 1200/1249 Loss 0.385 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.648, lat_loss 6.685
09/19 05:19:51 PM | Train: [130/180] Step 1249/1249 Loss 0.387 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.648, lat_loss 6.685
09/19 05:19:51 PM | _w_step_train: [130/180] Final Prec@1 90.2750% Time 593.70
09/19 05:19:51 PM | Start to train theta for epoch 129
09/19 05:20:11 PM | Train: [130/180] Step 050/312 Loss 0.588 Prec@(1,3) (85.4%, 99.0%), ce_loss 0.648, lat_loss 6.685
09/19 05:20:30 PM | Train: [130/180] Step 100/312 Loss 0.612 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.648, lat_loss 6.685
09/19 05:20:46 PM | Train: [130/180] Step 150/312 Loss 0.603 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.648, lat_loss 6.685
09/19 05:21:04 PM | Train: [130/180] Step 200/312 Loss 0.607 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.648, lat_loss 6.685
09/19 05:21:22 PM | Train: [130/180] Step 250/312 Loss 0.598 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.648, lat_loss 6.685
09/19 05:21:40 PM | Train: [130/180] Step 300/312 Loss 0.603 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.647, lat_loss 6.685
09/19 05:21:45 PM | Train: [130/180] Step 312/312 Loss 0.604 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.647, lat_loss 6.685
09/19 05:21:45 PM | _theta_step_train: [130/180] Final Prec@1 85.3800% Time 114.10
09/19 05:21:51 PM | Valid: [130/180] Step 050/312 Loss 0.791 Prec@(1,3) (81.1%, 97.2%), ce_loss 0.647, lat_loss 6.685
09/19 05:21:56 PM | Valid: [130/180] Step 100/312 Loss 0.765 Prec@(1,3) (81.9%, 97.6%), ce_loss 0.647, lat_loss 6.685
09/19 05:22:01 PM | Valid: [130/180] Step 150/312 Loss 0.796 Prec@(1,3) (81.6%, 97.4%), ce_loss 0.647, lat_loss 6.685
09/19 05:22:05 PM | Valid: [130/180] Step 200/312 Loss 0.772 Prec@(1,3) (81.9%, 97.7%), ce_loss 0.647, lat_loss 6.685
09/19 05:22:10 PM | Valid: [130/180] Step 250/312 Loss 0.757 Prec@(1,3) (82.4%, 98.0%), ce_loss 0.647, lat_loss 6.685
09/19 05:22:15 PM | Valid: [130/180] Step 300/312 Loss 0.755 Prec@(1,3) (82.3%, 97.9%), ce_loss 0.647, lat_loss 6.685
09/19 05:22:16 PM | Valid: [130/180] Step 312/312 Loss 0.751 Prec@(1,3) (82.4%, 98.0%), ce_loss 0.647, lat_loss 6.685
09/19 05:22:16 PM | val: [130/180] Final Prec@1 82.3600% Time 30.34
09/19 05:22:16 PM | Start to train weights for epoch 130
09/19 05:22:41 PM | Train: [131/180] Step 050/1249 Loss 0.344 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.647, lat_loss 6.685
09/19 05:23:05 PM | Train: [131/180] Step 100/1249 Loss 0.356 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.647, lat_loss 6.685
09/19 05:23:30 PM | Train: [131/180] Step 150/1249 Loss 0.338 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.647, lat_loss 6.685
09/19 05:23:52 PM | Train: [131/180] Step 200/1249 Loss 0.350 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.647, lat_loss 6.685
09/19 05:24:08 PM | Train: [131/180] Step 250/1249 Loss 0.354 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.647, lat_loss 6.685
09/19 05:24:26 PM | Train: [131/180] Step 300/1249 Loss 0.364 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.647, lat_loss 6.685
09/19 05:24:52 PM | Train: [131/180] Step 350/1249 Loss 0.367 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.647, lat_loss 6.685
09/19 05:25:17 PM | Train: [131/180] Step 400/1249 Loss 0.365 Prec@(1,3) (90.8%, 99.7%), ce_loss 0.647, lat_loss 6.685
09/19 05:25:42 PM | Train: [131/180] Step 450/1249 Loss 0.370 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.647, lat_loss 6.685
09/19 05:26:07 PM | Train: [131/180] Step 500/1249 Loss 0.367 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.647, lat_loss 6.685
09/19 05:26:32 PM | Train: [131/180] Step 550/1249 Loss 0.372 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.646, lat_loss 6.685
09/19 05:26:57 PM | Train: [131/180] Step 600/1249 Loss 0.374 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.646, lat_loss 6.685
09/19 05:27:21 PM | Train: [131/180] Step 650/1249 Loss 0.377 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.646, lat_loss 6.685
09/19 05:27:43 PM | Train: [131/180] Step 700/1249 Loss 0.377 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.646, lat_loss 6.685
09/19 05:28:08 PM | Train: [131/180] Step 750/1249 Loss 0.380 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.646, lat_loss 6.685
09/19 05:28:32 PM | Train: [131/180] Step 800/1249 Loss 0.379 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.646, lat_loss 6.685
09/19 05:28:57 PM | Train: [131/180] Step 850/1249 Loss 0.381 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.646, lat_loss 6.685
09/19 05:29:22 PM | Train: [131/180] Step 900/1249 Loss 0.382 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.646, lat_loss 6.685
09/19 05:29:45 PM | Train: [131/180] Step 950/1249 Loss 0.382 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.646, lat_loss 6.685
09/19 05:30:10 PM | Train: [131/180] Step 1000/1249 Loss 0.382 Prec@(1,3) (90.2%, 99.7%), ce_loss 0.646, lat_loss 6.685
09/19 05:30:34 PM | Train: [131/180] Step 1050/1249 Loss 0.379 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.646, lat_loss 6.685
09/19 05:30:56 PM | Train: [131/180] Step 1100/1249 Loss 0.376 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.646, lat_loss 6.685
09/19 05:31:21 PM | Train: [131/180] Step 1150/1249 Loss 0.377 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.646, lat_loss 6.685
09/19 05:31:45 PM | Train: [131/180] Step 1200/1249 Loss 0.375 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.646, lat_loss 6.685
09/19 05:32:09 PM | Train: [131/180] Step 1249/1249 Loss 0.375 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.645, lat_loss 6.685
09/19 05:32:09 PM | _w_step_train: [131/180] Final Prec@1 90.3575% Time 593.31
09/19 05:32:09 PM | Start to train theta for epoch 130
09/19 05:32:29 PM | Train: [131/180] Step 050/312 Loss 0.649 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.645, lat_loss 6.685
09/19 05:32:48 PM | Train: [131/180] Step 100/312 Loss 0.622 Prec@(1,3) (85.0%, 99.2%), ce_loss 0.645, lat_loss 6.685
09/19 05:33:05 PM | Train: [131/180] Step 150/312 Loss 0.626 Prec@(1,3) (85.0%, 99.2%), ce_loss 0.645, lat_loss 6.685
09/19 05:33:24 PM | Train: [131/180] Step 200/312 Loss 0.626 Prec@(1,3) (85.0%, 99.2%), ce_loss 0.645, lat_loss 6.685
09/19 05:33:45 PM | Train: [131/180] Step 250/312 Loss 0.637 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.645, lat_loss 6.685
09/19 05:34:05 PM | Train: [131/180] Step 300/312 Loss 0.633 Prec@(1,3) (85.0%, 99.1%), ce_loss 0.645, lat_loss 6.686
09/19 05:34:10 PM | Train: [131/180] Step 312/312 Loss 0.637 Prec@(1,3) (85.0%, 99.2%), ce_loss 0.645, lat_loss 6.686
09/19 05:34:10 PM | _theta_step_train: [131/180] Final Prec@1 84.9500% Time 121.08
09/19 05:34:15 PM | Valid: [131/180] Step 050/312 Loss 0.744 Prec@(1,3) (82.8%, 97.9%), ce_loss 0.645, lat_loss 6.686
09/19 05:34:20 PM | Valid: [131/180] Step 100/312 Loss 0.771 Prec@(1,3) (81.6%, 97.9%), ce_loss 0.645, lat_loss 6.686
09/19 05:34:25 PM | Valid: [131/180] Step 150/312 Loss 0.709 Prec@(1,3) (83.3%, 98.4%), ce_loss 0.645, lat_loss 6.686
09/19 05:34:29 PM | Valid: [131/180] Step 200/312 Loss 0.706 Prec@(1,3) (83.8%, 98.4%), ce_loss 0.645, lat_loss 6.686
09/19 05:34:34 PM | Valid: [131/180] Step 250/312 Loss 0.700 Prec@(1,3) (83.8%, 98.5%), ce_loss 0.645, lat_loss 6.686
09/19 05:34:39 PM | Valid: [131/180] Step 300/312 Loss 0.690 Prec@(1,3) (83.9%, 98.6%), ce_loss 0.645, lat_loss 6.686
09/19 05:34:40 PM | Valid: [131/180] Step 312/312 Loss 0.689 Prec@(1,3) (83.9%, 98.7%), ce_loss 0.645, lat_loss 6.686
09/19 05:34:40 PM | val: [131/180] Final Prec@1 83.8600% Time 29.49
09/19 05:34:40 PM | Start to train weights for epoch 131
09/19 05:35:04 PM | Train: [132/180] Step 050/1249 Loss 0.333 Prec@(1,3) (91.4%, 99.6%), ce_loss 0.645, lat_loss 6.686
09/19 05:35:27 PM | Train: [132/180] Step 100/1249 Loss 0.363 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.645, lat_loss 6.686
09/19 05:35:50 PM | Train: [132/180] Step 150/1249 Loss 0.354 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.645, lat_loss 6.686
09/19 05:36:13 PM | Train: [132/180] Step 200/1249 Loss 0.357 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.645, lat_loss 6.686
09/19 05:36:36 PM | Train: [132/180] Step 250/1249 Loss 0.355 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.645, lat_loss 6.686
09/19 05:36:58 PM | Train: [132/180] Step 300/1249 Loss 0.367 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.645, lat_loss 6.686
09/19 05:37:20 PM | Train: [132/180] Step 350/1249 Loss 0.356 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.644, lat_loss 6.686
09/19 05:37:40 PM | Train: [132/180] Step 400/1249 Loss 0.358 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.644, lat_loss 6.686
09/19 05:38:01 PM | Train: [132/180] Step 450/1249 Loss 0.359 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.644, lat_loss 6.686
09/19 05:38:23 PM | Train: [132/180] Step 500/1249 Loss 0.361 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.644, lat_loss 6.686
09/19 05:38:47 PM | Train: [132/180] Step 550/1249 Loss 0.363 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.644, lat_loss 6.686
09/19 05:39:10 PM | Train: [132/180] Step 600/1249 Loss 0.371 Prec@(1,3) (90.6%, 99.7%), ce_loss 0.644, lat_loss 6.686
09/19 05:39:33 PM | Train: [132/180] Step 650/1249 Loss 0.366 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.644, lat_loss 6.686
09/19 05:39:58 PM | Train: [132/180] Step 700/1249 Loss 0.370 Prec@(1,3) (90.5%, 99.7%), ce_loss 0.644, lat_loss 6.686
09/19 05:40:21 PM | Train: [132/180] Step 750/1249 Loss 0.369 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.644, lat_loss 6.686
09/19 05:40:45 PM | Train: [132/180] Step 800/1249 Loss 0.368 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.644, lat_loss 6.686
09/19 05:41:09 PM | Train: [132/180] Step 850/1249 Loss 0.367 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.644, lat_loss 6.686
09/19 05:41:32 PM | Train: [132/180] Step 900/1249 Loss 0.366 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.644, lat_loss 6.686
09/19 05:41:56 PM | Train: [132/180] Step 950/1249 Loss 0.364 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.644, lat_loss 6.686
09/19 05:42:21 PM | Train: [132/180] Step 1000/1249 Loss 0.366 Prec@(1,3) (90.7%, 99.8%), ce_loss 0.643, lat_loss 6.686
09/19 05:42:45 PM | Train: [132/180] Step 1050/1249 Loss 0.367 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.643, lat_loss 6.686
09/19 05:43:09 PM | Train: [132/180] Step 1100/1249 Loss 0.369 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.643, lat_loss 6.686
09/19 05:43:33 PM | Train: [132/180] Step 1150/1249 Loss 0.371 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.643, lat_loss 6.686
09/19 05:43:57 PM | Train: [132/180] Step 1200/1249 Loss 0.371 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.643, lat_loss 6.686
09/19 05:44:21 PM | Train: [132/180] Step 1249/1249 Loss 0.371 Prec@(1,3) (90.5%, 99.8%), ce_loss 0.643, lat_loss 6.686
09/19 05:44:21 PM | _w_step_train: [132/180] Final Prec@1 90.5200% Time 581.40
09/19 05:44:21 PM | Start to train theta for epoch 131
09/19 05:44:41 PM | Train: [132/180] Step 050/312 Loss 0.586 Prec@(1,3) (86.0%, 99.4%), ce_loss 0.643, lat_loss 6.686
09/19 05:45:01 PM | Train: [132/180] Step 100/312 Loss 0.579 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.643, lat_loss 6.686
09/19 05:45:19 PM | Train: [132/180] Step 150/312 Loss 0.576 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.643, lat_loss 6.686
09/19 05:45:38 PM | Train: [132/180] Step 200/312 Loss 0.585 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.643, lat_loss 6.686
09/19 05:45:56 PM | Train: [132/180] Step 250/312 Loss 0.598 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.643, lat_loss 6.686
09/19 05:46:16 PM | Train: [132/180] Step 300/312 Loss 0.606 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.643, lat_loss 6.686
09/19 05:46:21 PM | Train: [132/180] Step 312/312 Loss 0.605 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.643, lat_loss 6.686
09/19 05:46:21 PM | _theta_step_train: [132/180] Final Prec@1 85.4200% Time 119.83
09/19 05:46:26 PM | Valid: [132/180] Step 050/312 Loss 0.709 Prec@(1,3) (85.1%, 98.8%), ce_loss 0.643, lat_loss 6.686
09/19 05:46:31 PM | Valid: [132/180] Step 100/312 Loss 0.676 Prec@(1,3) (85.2%, 98.9%), ce_loss 0.643, lat_loss 6.686
09/19 05:46:36 PM | Valid: [132/180] Step 150/312 Loss 0.677 Prec@(1,3) (85.0%, 98.9%), ce_loss 0.643, lat_loss 6.686
09/19 05:46:41 PM | Valid: [132/180] Step 200/312 Loss 0.658 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.643, lat_loss 6.686
09/19 05:46:45 PM | Valid: [132/180] Step 250/312 Loss 0.653 Prec@(1,3) (85.2%, 99.0%), ce_loss 0.643, lat_loss 6.686
09/19 05:46:50 PM | Valid: [132/180] Step 300/312 Loss 0.653 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.643, lat_loss 6.686
09/19 05:46:51 PM | Valid: [132/180] Step 312/312 Loss 0.685 Prec@(1,3) (84.4%, 98.8%), ce_loss 0.643, lat_loss 6.686
09/19 05:46:51 PM | val: [132/180] Final Prec@1 84.3600% Time 30.29
09/19 05:46:51 PM | Start to train weights for epoch 132
09/19 05:47:15 PM | Train: [133/180] Step 050/1249 Loss 0.358 Prec@(1,3) (90.4%, 99.7%), ce_loss 0.643, lat_loss 6.686
09/19 05:47:37 PM | Train: [133/180] Step 100/1249 Loss 0.366 Prec@(1,3) (90.7%, 99.6%), ce_loss 0.643, lat_loss 6.686
09/19 05:48:01 PM | Train: [133/180] Step 150/1249 Loss 0.376 Prec@(1,3) (90.5%, 99.6%), ce_loss 0.642, lat_loss 6.686
09/19 05:48:24 PM | Train: [133/180] Step 200/1249 Loss 0.374 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.642, lat_loss 6.686
09/19 05:48:48 PM | Train: [133/180] Step 250/1249 Loss 0.369 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.642, lat_loss 6.686
09/19 05:49:12 PM | Train: [133/180] Step 300/1249 Loss 0.376 Prec@(1,3) (90.7%, 99.6%), ce_loss 0.642, lat_loss 6.686
09/19 05:49:36 PM | Train: [133/180] Step 350/1249 Loss 0.370 Prec@(1,3) (90.8%, 99.7%), ce_loss 0.642, lat_loss 6.686
09/19 05:49:59 PM | Train: [133/180] Step 400/1249 Loss 0.364 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.642, lat_loss 6.686
09/19 05:50:23 PM | Train: [133/180] Step 450/1249 Loss 0.357 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.642, lat_loss 6.686
09/19 05:50:45 PM | Train: [133/180] Step 500/1249 Loss 0.355 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.642, lat_loss 6.686
09/19 05:51:05 PM | Train: [133/180] Step 550/1249 Loss 0.356 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.642, lat_loss 6.686
09/19 05:51:26 PM | Train: [133/180] Step 600/1249 Loss 0.361 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.642, lat_loss 6.686
09/19 05:51:47 PM | Train: [133/180] Step 650/1249 Loss 0.361 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.642, lat_loss 6.686
09/19 05:52:08 PM | Train: [133/180] Step 700/1249 Loss 0.358 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.642, lat_loss 6.686
09/19 05:52:29 PM | Train: [133/180] Step 750/1249 Loss 0.357 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.642, lat_loss 6.686
09/19 05:52:49 PM | Train: [133/180] Step 800/1249 Loss 0.356 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.641, lat_loss 6.686
09/19 05:53:11 PM | Train: [133/180] Step 850/1249 Loss 0.353 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.641, lat_loss 6.686
09/19 05:53:31 PM | Train: [133/180] Step 900/1249 Loss 0.354 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.641, lat_loss 6.686
09/19 05:53:52 PM | Train: [133/180] Step 950/1249 Loss 0.356 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.641, lat_loss 6.686
09/19 05:54:13 PM | Train: [133/180] Step 1000/1249 Loss 0.354 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.641, lat_loss 6.686
09/19 05:54:34 PM | Train: [133/180] Step 1050/1249 Loss 0.354 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.641, lat_loss 6.686
09/19 05:54:54 PM | Train: [133/180] Step 1100/1249 Loss 0.354 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.641, lat_loss 6.686
09/19 05:55:15 PM | Train: [133/180] Step 1150/1249 Loss 0.356 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.641, lat_loss 6.686
09/19 05:55:37 PM | Train: [133/180] Step 1200/1249 Loss 0.356 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.641, lat_loss 6.686
09/19 05:56:01 PM | Train: [133/180] Step 1249/1249 Loss 0.356 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.641, lat_loss 6.686
09/19 05:56:01 PM | _w_step_train: [133/180] Final Prec@1 91.0625% Time 549.92
09/19 05:56:01 PM | Start to train theta for epoch 132
09/19 05:56:22 PM | Train: [133/180] Step 050/312 Loss 0.591 Prec@(1,3) (85.1%, 99.5%), ce_loss 0.641, lat_loss 6.686
09/19 05:56:42 PM | Train: [133/180] Step 100/312 Loss 0.623 Prec@(1,3) (85.0%, 99.2%), ce_loss 0.641, lat_loss 6.686
09/19 05:57:03 PM | Train: [133/180] Step 150/312 Loss 0.619 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.641, lat_loss 6.686
09/19 05:57:24 PM | Train: [133/180] Step 200/312 Loss 0.632 Prec@(1,3) (85.1%, 99.2%), ce_loss 0.641, lat_loss 6.686
09/19 05:57:45 PM | Train: [133/180] Step 250/312 Loss 0.618 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.641, lat_loss 6.686
09/19 05:58:06 PM | Train: [133/180] Step 300/312 Loss 0.628 Prec@(1,3) (85.1%, 99.2%), ce_loss 0.641, lat_loss 6.686
09/19 05:58:11 PM | Train: [133/180] Step 312/312 Loss 0.623 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.641, lat_loss 6.686
09/19 05:58:11 PM | _theta_step_train: [133/180] Final Prec@1 85.1600% Time 129.36
09/19 05:58:16 PM | Valid: [133/180] Step 050/312 Loss 0.774 Prec@(1,3) (82.4%, 97.3%), ce_loss 0.641, lat_loss 6.686
09/19 05:58:20 PM | Valid: [133/180] Step 100/312 Loss 0.692 Prec@(1,3) (83.8%, 98.1%), ce_loss 0.640, lat_loss 6.686
09/19 05:58:25 PM | Valid: [133/180] Step 150/312 Loss 0.687 Prec@(1,3) (84.0%, 98.2%), ce_loss 0.640, lat_loss 6.686
09/19 05:58:30 PM | Valid: [133/180] Step 200/312 Loss 0.727 Prec@(1,3) (83.1%, 98.1%), ce_loss 0.640, lat_loss 6.686
09/19 05:58:34 PM | Valid: [133/180] Step 250/312 Loss 0.717 Prec@(1,3) (83.2%, 98.2%), ce_loss 0.640, lat_loss 6.686
09/19 05:58:39 PM | Valid: [133/180] Step 300/312 Loss 0.722 Prec@(1,3) (83.1%, 98.1%), ce_loss 0.640, lat_loss 6.686
09/19 05:58:40 PM | Valid: [133/180] Step 312/312 Loss 0.719 Prec@(1,3) (83.0%, 98.1%), ce_loss 0.640, lat_loss 6.686
09/19 05:58:40 PM | val: [133/180] Final Prec@1 83.0300% Time 29.55
09/19 05:58:40 PM | Start to train weights for epoch 133
09/19 05:58:57 PM | Train: [134/180] Step 050/1249 Loss 0.339 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.640, lat_loss 6.686
09/19 05:59:13 PM | Train: [134/180] Step 100/1249 Loss 0.356 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.640, lat_loss 6.686
09/19 05:59:29 PM | Train: [134/180] Step 150/1249 Loss 0.356 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.640, lat_loss 6.686
09/19 05:59:45 PM | Train: [134/180] Step 200/1249 Loss 0.362 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.640, lat_loss 6.686
09/19 06:00:01 PM | Train: [134/180] Step 250/1249 Loss 0.351 Prec@(1,3) (91.2%, 99.9%), ce_loss 0.640, lat_loss 6.686
09/19 06:00:17 PM | Train: [134/180] Step 300/1249 Loss 0.353 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.640, lat_loss 6.686
09/19 06:00:34 PM | Train: [134/180] Step 350/1249 Loss 0.350 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.640, lat_loss 6.686
09/19 06:00:50 PM | Train: [134/180] Step 400/1249 Loss 0.350 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.640, lat_loss 6.686
09/19 06:01:06 PM | Train: [134/180] Step 450/1249 Loss 0.353 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.640, lat_loss 6.686
09/19 06:01:22 PM | Train: [134/180] Step 500/1249 Loss 0.352 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.640, lat_loss 6.686
09/19 06:01:38 PM | Train: [134/180] Step 550/1249 Loss 0.355 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.640, lat_loss 6.686
09/19 06:01:54 PM | Train: [134/180] Step 600/1249 Loss 0.353 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.639, lat_loss 6.686
09/19 06:02:10 PM | Train: [134/180] Step 650/1249 Loss 0.351 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.639, lat_loss 6.686
09/19 06:02:26 PM | Train: [134/180] Step 700/1249 Loss 0.356 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.639, lat_loss 6.686
09/19 06:02:42 PM | Train: [134/180] Step 750/1249 Loss 0.353 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.639, lat_loss 6.686
09/19 06:02:58 PM | Train: [134/180] Step 800/1249 Loss 0.353 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.639, lat_loss 6.686
09/19 06:03:14 PM | Train: [134/180] Step 850/1249 Loss 0.351 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.639, lat_loss 6.686
09/19 06:03:30 PM | Train: [134/180] Step 900/1249 Loss 0.351 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.639, lat_loss 6.686
09/19 06:03:46 PM | Train: [134/180] Step 950/1249 Loss 0.351 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.639, lat_loss 6.686
09/19 06:04:02 PM | Train: [134/180] Step 1000/1249 Loss 0.353 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.639, lat_loss 6.686
09/19 06:04:18 PM | Train: [134/180] Step 1050/1249 Loss 0.351 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.639, lat_loss 6.686
09/19 06:04:34 PM | Train: [134/180] Step 1100/1249 Loss 0.352 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.639, lat_loss 6.686
09/19 06:04:50 PM | Train: [134/180] Step 1150/1249 Loss 0.353 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.639, lat_loss 6.686
09/19 06:05:07 PM | Train: [134/180] Step 1200/1249 Loss 0.355 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.639, lat_loss 6.686
09/19 06:05:22 PM | Train: [134/180] Step 1249/1249 Loss 0.356 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.638, lat_loss 6.686
09/19 06:05:22 PM | _w_step_train: [134/180] Final Prec@1 91.0200% Time 402.13
09/19 06:05:22 PM | Start to train theta for epoch 133
09/19 06:05:43 PM | Train: [134/180] Step 050/312 Loss 0.591 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.638, lat_loss 6.686
09/19 06:06:04 PM | Train: [134/180] Step 100/312 Loss 0.604 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.638, lat_loss 6.686
09/19 06:06:25 PM | Train: [134/180] Step 150/312 Loss 0.592 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.638, lat_loss 6.686
09/19 06:06:46 PM | Train: [134/180] Step 200/312 Loss 0.577 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.638, lat_loss 6.686
09/19 06:07:07 PM | Train: [134/180] Step 250/312 Loss 0.578 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.638, lat_loss 6.686
09/19 06:07:27 PM | Train: [134/180] Step 300/312 Loss 0.580 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.638, lat_loss 6.686
09/19 06:07:32 PM | Train: [134/180] Step 312/312 Loss 0.578 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.638, lat_loss 6.686
09/19 06:07:32 PM | _theta_step_train: [134/180] Final Prec@1 86.0500% Time 129.83
09/19 06:07:37 PM | Valid: [134/180] Step 050/312 Loss 0.654 Prec@(1,3) (84.6%, 98.6%), ce_loss 0.638, lat_loss 6.686
09/19 06:07:41 PM | Valid: [134/180] Step 100/312 Loss 0.677 Prec@(1,3) (84.7%, 98.6%), ce_loss 0.638, lat_loss 6.686
09/19 06:07:45 PM | Valid: [134/180] Step 150/312 Loss 0.700 Prec@(1,3) (84.4%, 98.6%), ce_loss 0.638, lat_loss 6.686
09/19 06:07:50 PM | Valid: [134/180] Step 200/312 Loss 0.668 Prec@(1,3) (84.9%, 98.8%), ce_loss 0.638, lat_loss 6.686
09/19 06:07:54 PM | Valid: [134/180] Step 250/312 Loss 0.673 Prec@(1,3) (84.6%, 98.9%), ce_loss 0.638, lat_loss 6.686
09/19 06:07:58 PM | Valid: [134/180] Step 300/312 Loss 0.657 Prec@(1,3) (84.9%, 99.0%), ce_loss 0.638, lat_loss 6.686
09/19 06:07:59 PM | Valid: [134/180] Step 312/312 Loss 0.658 Prec@(1,3) (84.8%, 99.0%), ce_loss 0.638, lat_loss 6.686
09/19 06:07:59 PM | val: [134/180] Final Prec@1 84.8100% Time 27.05
09/19 06:08:00 PM | Best top1 acc by now. Save model
09/19 06:08:00 PM | Start to train weights for epoch 134
09/19 06:08:17 PM | Train: [135/180] Step 050/1249 Loss 0.307 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.638, lat_loss 6.686
09/19 06:08:33 PM | Train: [135/180] Step 100/1249 Loss 0.327 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.638, lat_loss 6.686
09/19 06:08:49 PM | Train: [135/180] Step 150/1249 Loss 0.330 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.638, lat_loss 6.686
09/19 06:09:05 PM | Train: [135/180] Step 200/1249 Loss 0.332 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.638, lat_loss 6.686
09/19 06:09:21 PM | Train: [135/180] Step 250/1249 Loss 0.325 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.638, lat_loss 6.686
09/19 06:09:37 PM | Train: [135/180] Step 300/1249 Loss 0.326 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.638, lat_loss 6.686
09/19 06:09:53 PM | Train: [135/180] Step 350/1249 Loss 0.324 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.637, lat_loss 6.686
09/19 06:10:09 PM | Train: [135/180] Step 400/1249 Loss 0.323 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.637, lat_loss 6.686
09/19 06:10:25 PM | Train: [135/180] Step 450/1249 Loss 0.322 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.637, lat_loss 6.686
09/19 06:10:41 PM | Train: [135/180] Step 500/1249 Loss 0.324 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.637, lat_loss 6.686
09/19 06:10:57 PM | Train: [135/180] Step 550/1249 Loss 0.328 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.637, lat_loss 6.686
09/19 06:11:13 PM | Train: [135/180] Step 600/1249 Loss 0.329 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.637, lat_loss 6.686
09/19 06:11:29 PM | Train: [135/180] Step 650/1249 Loss 0.331 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.637, lat_loss 6.686
09/19 06:11:45 PM | Train: [135/180] Step 700/1249 Loss 0.328 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.637, lat_loss 6.686
09/19 06:12:01 PM | Train: [135/180] Step 750/1249 Loss 0.331 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.637, lat_loss 6.686
09/19 06:12:17 PM | Train: [135/180] Step 800/1249 Loss 0.332 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.637, lat_loss 6.686
09/19 06:12:33 PM | Train: [135/180] Step 850/1249 Loss 0.333 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.637, lat_loss 6.686
09/19 06:12:49 PM | Train: [135/180] Step 900/1249 Loss 0.338 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.637, lat_loss 6.686
09/19 06:13:05 PM | Train: [135/180] Step 950/1249 Loss 0.338 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.637, lat_loss 6.686
09/19 06:13:21 PM | Train: [135/180] Step 1000/1249 Loss 0.339 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.636, lat_loss 6.686
09/19 06:13:37 PM | Train: [135/180] Step 1050/1249 Loss 0.339 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.636, lat_loss 6.686
09/19 06:13:53 PM | Train: [135/180] Step 1100/1249 Loss 0.341 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.636, lat_loss 6.686
09/19 06:14:09 PM | Train: [135/180] Step 1150/1249 Loss 0.343 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.636, lat_loss 6.686
09/19 06:14:25 PM | Train: [135/180] Step 1200/1249 Loss 0.347 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.636, lat_loss 6.686
09/19 06:14:41 PM | Train: [135/180] Step 1249/1249 Loss 0.348 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.636, lat_loss 6.686
09/19 06:14:41 PM | _w_step_train: [135/180] Final Prec@1 91.0900% Time 400.99
09/19 06:14:41 PM | Start to train theta for epoch 134
09/19 06:15:02 PM | Train: [135/180] Step 050/312 Loss 0.678 Prec@(1,3) (84.2%, 98.7%), ce_loss 0.636, lat_loss 6.686
09/19 06:15:22 PM | Train: [135/180] Step 100/312 Loss 0.650 Prec@(1,3) (84.9%, 98.9%), ce_loss 0.636, lat_loss 6.686
09/19 06:15:42 PM | Train: [135/180] Step 150/312 Loss 0.633 Prec@(1,3) (85.1%, 99.0%), ce_loss 0.636, lat_loss 6.686
09/19 06:16:02 PM | Train: [135/180] Step 200/312 Loss 0.628 Prec@(1,3) (85.1%, 99.0%), ce_loss 0.636, lat_loss 6.686
09/19 06:16:22 PM | Train: [135/180] Step 250/312 Loss 0.613 Prec@(1,3) (85.5%, 99.0%), ce_loss 0.636, lat_loss 6.686
09/19 06:16:42 PM | Train: [135/180] Step 300/312 Loss 0.602 Prec@(1,3) (85.8%, 99.0%), ce_loss 0.636, lat_loss 6.686
09/19 06:16:48 PM | Train: [135/180] Step 312/312 Loss 0.601 Prec@(1,3) (85.8%, 99.1%), ce_loss 0.636, lat_loss 6.686
09/19 06:16:48 PM | _theta_step_train: [135/180] Final Prec@1 85.7700% Time 126.87
09/19 06:16:53 PM | Valid: [135/180] Step 050/312 Loss 0.579 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.636, lat_loss 6.686
09/19 06:16:58 PM | Valid: [135/180] Step 100/312 Loss 0.666 Prec@(1,3) (84.3%, 98.6%), ce_loss 0.636, lat_loss 6.686
09/19 06:17:02 PM | Valid: [135/180] Step 150/312 Loss 0.692 Prec@(1,3) (83.9%, 98.5%), ce_loss 0.636, lat_loss 6.686
09/19 06:17:07 PM | Valid: [135/180] Step 200/312 Loss 0.680 Prec@(1,3) (84.0%, 98.6%), ce_loss 0.636, lat_loss 6.686
09/19 06:17:12 PM | Valid: [135/180] Step 250/312 Loss 0.681 Prec@(1,3) (83.8%, 98.7%), ce_loss 0.636, lat_loss 6.686
09/19 06:17:16 PM | Valid: [135/180] Step 300/312 Loss 0.681 Prec@(1,3) (83.8%, 98.7%), ce_loss 0.636, lat_loss 6.686
09/19 06:17:17 PM | Valid: [135/180] Step 312/312 Loss 0.676 Prec@(1,3) (83.9%, 98.7%), ce_loss 0.636, lat_loss 6.686
09/19 06:17:17 PM | val: [135/180] Final Prec@1 83.8500% Time 29.53
09/19 06:17:17 PM | Start to train weights for epoch 135
09/19 06:17:43 PM | Train: [136/180] Step 050/1249 Loss 0.382 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.636, lat_loss 6.686
09/19 06:18:06 PM | Train: [136/180] Step 100/1249 Loss 0.367 Prec@(1,3) (90.5%, 99.8%), ce_loss 0.636, lat_loss 6.686
09/19 06:18:30 PM | Train: [136/180] Step 150/1249 Loss 0.341 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.635, lat_loss 6.686
09/19 06:18:54 PM | Train: [136/180] Step 200/1249 Loss 0.345 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.635, lat_loss 6.686
09/19 06:19:17 PM | Train: [136/180] Step 250/1249 Loss 0.347 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.635, lat_loss 6.686
09/19 06:19:41 PM | Train: [136/180] Step 300/1249 Loss 0.340 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.635, lat_loss 6.686
09/19 06:20:05 PM | Train: [136/180] Step 350/1249 Loss 0.340 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.635, lat_loss 6.686
09/19 06:20:30 PM | Train: [136/180] Step 400/1249 Loss 0.345 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.635, lat_loss 6.686
09/19 06:20:55 PM | Train: [136/180] Step 450/1249 Loss 0.343 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.635, lat_loss 6.686
09/19 06:21:20 PM | Train: [136/180] Step 500/1249 Loss 0.345 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.635, lat_loss 6.686
09/19 06:21:44 PM | Train: [136/180] Step 550/1249 Loss 0.343 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.635, lat_loss 6.686
09/19 06:22:07 PM | Train: [136/180] Step 600/1249 Loss 0.352 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.635, lat_loss 6.686
09/19 06:22:33 PM | Train: [136/180] Step 650/1249 Loss 0.359 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.635, lat_loss 6.686
09/19 06:22:57 PM | Train: [136/180] Step 700/1249 Loss 0.359 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.635, lat_loss 6.686
09/19 06:23:22 PM | Train: [136/180] Step 750/1249 Loss 0.361 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.635, lat_loss 6.686
09/19 06:23:47 PM | Train: [136/180] Step 800/1249 Loss 0.358 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.635, lat_loss 6.686
09/19 06:24:10 PM | Train: [136/180] Step 850/1249 Loss 0.359 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.634, lat_loss 6.686
09/19 06:24:34 PM | Train: [136/180] Step 900/1249 Loss 0.359 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.634, lat_loss 6.686
09/19 06:24:58 PM | Train: [136/180] Step 950/1249 Loss 0.357 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.634, lat_loss 6.686
09/19 06:25:23 PM | Train: [136/180] Step 1000/1249 Loss 0.355 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.634, lat_loss 6.686
09/19 06:25:47 PM | Train: [136/180] Step 1050/1249 Loss 0.355 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.634, lat_loss 6.686
09/19 06:26:11 PM | Train: [136/180] Step 1100/1249 Loss 0.355 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.634, lat_loss 6.686
09/19 06:26:34 PM | Train: [136/180] Step 1150/1249 Loss 0.357 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.634, lat_loss 6.686
09/19 06:26:59 PM | Train: [136/180] Step 1200/1249 Loss 0.358 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.634, lat_loss 6.686
09/19 06:27:23 PM | Train: [136/180] Step 1249/1249 Loss 0.359 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.634, lat_loss 6.686
09/19 06:27:23 PM | _w_step_train: [136/180] Final Prec@1 90.9900% Time 606.13
09/19 06:27:23 PM | Start to train theta for epoch 135
09/19 06:27:44 PM | Train: [136/180] Step 050/312 Loss 0.598 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.634, lat_loss 6.686
09/19 06:28:04 PM | Train: [136/180] Step 100/312 Loss 0.602 Prec@(1,3) (86.3%, 99.1%), ce_loss 0.634, lat_loss 6.686
09/19 06:28:23 PM | Train: [136/180] Step 150/312 Loss 0.595 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.634, lat_loss 6.686
09/19 06:28:41 PM | Train: [136/180] Step 200/312 Loss 0.612 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.634, lat_loss 6.686
09/19 06:29:01 PM | Train: [136/180] Step 250/312 Loss 0.609 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.634, lat_loss 6.686
09/19 06:29:22 PM | Train: [136/180] Step 300/312 Loss 0.595 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.634, lat_loss 6.686
09/19 06:29:26 PM | Train: [136/180] Step 312/312 Loss 0.595 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.634, lat_loss 6.686
09/19 06:29:26 PM | _theta_step_train: [136/180] Final Prec@1 86.0500% Time 122.73
09/19 06:29:31 PM | Valid: [136/180] Step 050/312 Loss 0.705 Prec@(1,3) (84.9%, 98.0%), ce_loss 0.634, lat_loss 6.686
09/19 06:29:36 PM | Valid: [136/180] Step 100/312 Loss 0.695 Prec@(1,3) (84.0%, 98.3%), ce_loss 0.634, lat_loss 6.686
09/19 06:29:41 PM | Valid: [136/180] Step 150/312 Loss 0.737 Prec@(1,3) (83.0%, 98.3%), ce_loss 0.634, lat_loss 6.686
09/19 06:29:45 PM | Valid: [136/180] Step 200/312 Loss 0.711 Prec@(1,3) (83.4%, 98.6%), ce_loss 0.634, lat_loss 6.686
09/19 06:29:50 PM | Valid: [136/180] Step 250/312 Loss 0.777 Prec@(1,3) (82.5%, 98.3%), ce_loss 0.634, lat_loss 6.686
09/19 06:29:55 PM | Valid: [136/180] Step 300/312 Loss 0.790 Prec@(1,3) (82.3%, 98.0%), ce_loss 0.634, lat_loss 6.686
09/19 06:29:56 PM | Valid: [136/180] Step 312/312 Loss 0.785 Prec@(1,3) (82.3%, 98.0%), ce_loss 0.634, lat_loss 6.686
09/19 06:29:56 PM | val: [136/180] Final Prec@1 82.3500% Time 29.97
09/19 06:29:56 PM | Start to train weights for epoch 136
09/19 06:30:21 PM | Train: [137/180] Step 050/1249 Loss 0.311 Prec@(1,3) (92.3%, 99.9%), ce_loss 0.633, lat_loss 6.686
09/19 06:30:45 PM | Train: [137/180] Step 100/1249 Loss 0.299 Prec@(1,3) (92.6%, 99.9%), ce_loss 0.633, lat_loss 6.686
09/19 06:31:08 PM | Train: [137/180] Step 150/1249 Loss 0.310 Prec@(1,3) (92.2%, 99.9%), ce_loss 0.633, lat_loss 6.686
09/19 06:31:33 PM | Train: [137/180] Step 200/1249 Loss 0.314 Prec@(1,3) (91.9%, 99.9%), ce_loss 0.633, lat_loss 6.686
09/19 06:31:58 PM | Train: [137/180] Step 250/1249 Loss 0.315 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.633, lat_loss 6.686
09/19 06:32:24 PM | Train: [137/180] Step 300/1249 Loss 0.317 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.633, lat_loss 6.686
09/19 06:32:49 PM | Train: [137/180] Step 350/1249 Loss 0.331 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.633, lat_loss 6.686
09/19 06:33:14 PM | Train: [137/180] Step 400/1249 Loss 0.335 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.633, lat_loss 6.686
09/19 06:33:40 PM | Train: [137/180] Step 450/1249 Loss 0.332 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.633, lat_loss 6.686
09/19 06:34:05 PM | Train: [137/180] Step 500/1249 Loss 0.332 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.633, lat_loss 6.686
09/19 06:34:30 PM | Train: [137/180] Step 550/1249 Loss 0.334 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.633, lat_loss 6.686
09/19 06:34:55 PM | Train: [137/180] Step 600/1249 Loss 0.334 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.633, lat_loss 6.686
09/19 06:35:17 PM | Train: [137/180] Step 650/1249 Loss 0.336 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.633, lat_loss 6.686
09/19 06:35:38 PM | Train: [137/180] Step 700/1249 Loss 0.338 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.632, lat_loss 6.686
09/19 06:36:02 PM | Train: [137/180] Step 750/1249 Loss 0.338 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.632, lat_loss 6.686
09/19 06:36:25 PM | Train: [137/180] Step 800/1249 Loss 0.339 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.632, lat_loss 6.686
09/19 06:36:46 PM | Train: [137/180] Step 850/1249 Loss 0.343 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.632, lat_loss 6.686
09/19 06:37:08 PM | Train: [137/180] Step 900/1249 Loss 0.344 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.632, lat_loss 6.686
09/19 06:37:30 PM | Train: [137/180] Step 950/1249 Loss 0.346 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.632, lat_loss 6.686
09/19 06:37:52 PM | Train: [137/180] Step 1000/1249 Loss 0.346 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.632, lat_loss 6.686
09/19 06:38:14 PM | Train: [137/180] Step 1050/1249 Loss 0.345 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.632, lat_loss 6.686
09/19 06:38:35 PM | Train: [137/180] Step 1100/1249 Loss 0.350 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.632, lat_loss 6.686
09/19 06:38:57 PM | Train: [137/180] Step 1150/1249 Loss 0.350 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.632, lat_loss 6.686
09/19 06:39:20 PM | Train: [137/180] Step 1200/1249 Loss 0.352 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.632, lat_loss 6.686
09/19 06:39:44 PM | Train: [137/180] Step 1249/1249 Loss 0.351 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.632, lat_loss 6.686
09/19 06:39:44 PM | _w_step_train: [137/180] Final Prec@1 90.9850% Time 587.90
09/19 06:39:44 PM | Start to train theta for epoch 136
09/19 06:40:05 PM | Train: [137/180] Step 050/312 Loss 0.605 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.632, lat_loss 6.686
09/19 06:40:23 PM | Train: [137/180] Step 100/312 Loss 0.597 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.632, lat_loss 6.686
09/19 06:40:42 PM | Train: [137/180] Step 150/312 Loss 0.577 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.632, lat_loss 6.686
09/19 06:41:01 PM | Train: [137/180] Step 200/312 Loss 0.585 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.632, lat_loss 6.686
09/19 06:41:20 PM | Train: [137/180] Step 250/312 Loss 0.600 Prec@(1,3) (85.5%, 99.2%), ce_loss 0.631, lat_loss 6.686
09/19 06:41:41 PM | Train: [137/180] Step 300/312 Loss 0.602 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.631, lat_loss 6.686
09/19 06:41:46 PM | Train: [137/180] Step 312/312 Loss 0.605 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.631, lat_loss 6.686
09/19 06:41:46 PM | _theta_step_train: [137/180] Final Prec@1 85.3700% Time 121.62
09/19 06:41:51 PM | Valid: [137/180] Step 050/312 Loss 0.729 Prec@(1,3) (83.6%, 98.3%), ce_loss 0.631, lat_loss 6.686
09/19 06:41:55 PM | Valid: [137/180] Step 100/312 Loss 0.712 Prec@(1,3) (83.5%, 98.5%), ce_loss 0.631, lat_loss 6.686
09/19 06:42:00 PM | Valid: [137/180] Step 150/312 Loss 0.676 Prec@(1,3) (84.2%, 98.8%), ce_loss 0.631, lat_loss 6.686
09/19 06:42:05 PM | Valid: [137/180] Step 200/312 Loss 0.663 Prec@(1,3) (84.6%, 98.9%), ce_loss 0.631, lat_loss 6.687
09/19 06:42:10 PM | Valid: [137/180] Step 250/312 Loss 0.652 Prec@(1,3) (84.9%, 99.0%), ce_loss 0.631, lat_loss 6.687
09/19 06:42:14 PM | Valid: [137/180] Step 300/312 Loss 0.691 Prec@(1,3) (84.5%, 98.8%), ce_loss 0.631, lat_loss 6.687
09/19 06:42:15 PM | Valid: [137/180] Step 312/312 Loss 0.689 Prec@(1,3) (84.5%, 98.8%), ce_loss 0.631, lat_loss 6.687
09/19 06:42:15 PM | val: [137/180] Final Prec@1 84.5300% Time 29.75
09/19 06:42:15 PM | Start to train weights for epoch 137
09/19 06:42:39 PM | Train: [138/180] Step 050/1249 Loss 0.310 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.631, lat_loss 6.687
09/19 06:43:01 PM | Train: [138/180] Step 100/1249 Loss 0.326 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.631, lat_loss 6.687
09/19 06:43:22 PM | Train: [138/180] Step 150/1249 Loss 0.346 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.631, lat_loss 6.687
09/19 06:43:43 PM | Train: [138/180] Step 200/1249 Loss 0.344 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.631, lat_loss 6.687
09/19 06:44:05 PM | Train: [138/180] Step 250/1249 Loss 0.348 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.631, lat_loss 6.687
09/19 06:44:25 PM | Train: [138/180] Step 300/1249 Loss 0.341 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.631, lat_loss 6.687
09/19 06:44:46 PM | Train: [138/180] Step 350/1249 Loss 0.345 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.631, lat_loss 6.687
09/19 06:45:06 PM | Train: [138/180] Step 400/1249 Loss 0.354 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.631, lat_loss 6.687
09/19 06:45:27 PM | Train: [138/180] Step 450/1249 Loss 0.350 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.631, lat_loss 6.687
09/19 06:45:50 PM | Train: [138/180] Step 500/1249 Loss 0.350 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.631, lat_loss 6.687
09/19 06:46:14 PM | Train: [138/180] Step 550/1249 Loss 0.352 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.630, lat_loss 6.687
09/19 06:46:37 PM | Train: [138/180] Step 600/1249 Loss 0.354 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.630, lat_loss 6.687
09/19 06:47:01 PM | Train: [138/180] Step 650/1249 Loss 0.353 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.630, lat_loss 6.687
09/19 06:47:22 PM | Train: [138/180] Step 700/1249 Loss 0.353 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.630, lat_loss 6.687
09/19 06:47:44 PM | Train: [138/180] Step 750/1249 Loss 0.352 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.630, lat_loss 6.687
09/19 06:48:04 PM | Train: [138/180] Step 800/1249 Loss 0.350 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.630, lat_loss 6.687
09/19 06:48:26 PM | Train: [138/180] Step 850/1249 Loss 0.351 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.630, lat_loss 6.687
09/19 06:48:49 PM | Train: [138/180] Step 900/1249 Loss 0.350 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.630, lat_loss 6.687
09/19 06:49:09 PM | Train: [138/180] Step 950/1249 Loss 0.348 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.630, lat_loss 6.687
09/19 06:49:32 PM | Train: [138/180] Step 1000/1249 Loss 0.349 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.630, lat_loss 6.687
09/19 06:49:52 PM | Train: [138/180] Step 1050/1249 Loss 0.350 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.630, lat_loss 6.687
09/19 06:50:16 PM | Train: [138/180] Step 1100/1249 Loss 0.352 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.630, lat_loss 6.687
09/19 06:50:37 PM | Train: [138/180] Step 1150/1249 Loss 0.350 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.630, lat_loss 6.687
09/19 06:50:54 PM | Train: [138/180] Step 1200/1249 Loss 0.352 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.630, lat_loss 6.687
09/19 06:51:09 PM | Train: [138/180] Step 1249/1249 Loss 0.351 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.629, lat_loss 6.687
09/19 06:51:09 PM | _w_step_train: [138/180] Final Prec@1 91.1000% Time 533.68
09/19 06:51:09 PM | Start to train theta for epoch 137
09/19 06:51:29 PM | Train: [138/180] Step 050/312 Loss 0.632 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.629, lat_loss 6.687
09/19 06:51:49 PM | Train: [138/180] Step 100/312 Loss 0.597 Prec@(1,3) (86.2%, 99.4%), ce_loss 0.629, lat_loss 6.687
09/19 06:52:07 PM | Train: [138/180] Step 150/312 Loss 0.596 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.629, lat_loss 6.687
09/19 06:52:26 PM | Train: [138/180] Step 200/312 Loss 0.588 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.629, lat_loss 6.687
09/19 06:52:44 PM | Train: [138/180] Step 250/312 Loss 0.582 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.629, lat_loss 6.687
09/19 06:53:02 PM | Train: [138/180] Step 300/312 Loss 0.580 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.629, lat_loss 6.687
09/19 06:53:07 PM | Train: [138/180] Step 312/312 Loss 0.578 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.629, lat_loss 6.687
09/19 06:53:07 PM | _theta_step_train: [138/180] Final Prec@1 86.2600% Time 117.74
09/19 06:53:13 PM | Valid: [138/180] Step 050/312 Loss 0.687 Prec@(1,3) (81.4%, 99.1%), ce_loss 0.629, lat_loss 6.687
09/19 06:53:17 PM | Valid: [138/180] Step 100/312 Loss 0.707 Prec@(1,3) (82.7%, 98.6%), ce_loss 0.629, lat_loss 6.687
09/19 06:53:22 PM | Valid: [138/180] Step 150/312 Loss 0.699 Prec@(1,3) (83.1%, 98.8%), ce_loss 0.629, lat_loss 6.687
09/19 06:53:27 PM | Valid: [138/180] Step 200/312 Loss 0.671 Prec@(1,3) (83.8%, 98.8%), ce_loss 0.629, lat_loss 6.687
09/19 06:53:31 PM | Valid: [138/180] Step 250/312 Loss 0.679 Prec@(1,3) (83.5%, 98.8%), ce_loss 0.629, lat_loss 6.687
09/19 06:53:36 PM | Valid: [138/180] Step 300/312 Loss 0.673 Prec@(1,3) (83.5%, 98.8%), ce_loss 0.629, lat_loss 6.687
09/19 06:53:37 PM | Valid: [138/180] Step 312/312 Loss 0.669 Prec@(1,3) (83.5%, 98.9%), ce_loss 0.629, lat_loss 6.687
09/19 06:53:37 PM | val: [138/180] Final Prec@1 83.5400% Time 30.26
09/19 06:53:37 PM | Start to train weights for epoch 138
09/19 06:54:02 PM | Train: [139/180] Step 050/1249 Loss 0.338 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.629, lat_loss 6.687
09/19 06:54:24 PM | Train: [139/180] Step 100/1249 Loss 0.330 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.629, lat_loss 6.687
09/19 06:54:46 PM | Train: [139/180] Step 150/1249 Loss 0.325 Prec@(1,3) (92.0%, 99.6%), ce_loss 0.629, lat_loss 6.687
09/19 06:55:08 PM | Train: [139/180] Step 200/1249 Loss 0.331 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.629, lat_loss 6.687
09/19 06:55:28 PM | Train: [139/180] Step 250/1249 Loss 0.325 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.629, lat_loss 6.687
09/19 06:55:51 PM | Train: [139/180] Step 300/1249 Loss 0.331 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.629, lat_loss 6.687
09/19 06:56:13 PM | Train: [139/180] Step 350/1249 Loss 0.343 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.629, lat_loss 6.687
09/19 06:56:36 PM | Train: [139/180] Step 400/1249 Loss 0.345 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.628, lat_loss 6.687
09/19 06:56:58 PM | Train: [139/180] Step 450/1249 Loss 0.342 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.628, lat_loss 6.687
09/19 06:57:21 PM | Train: [139/180] Step 500/1249 Loss 0.344 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.628, lat_loss 6.687
09/19 06:57:43 PM | Train: [139/180] Step 550/1249 Loss 0.346 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.628, lat_loss 6.687
09/19 06:58:06 PM | Train: [139/180] Step 600/1249 Loss 0.349 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.628, lat_loss 6.687
09/19 06:58:29 PM | Train: [139/180] Step 650/1249 Loss 0.347 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.628, lat_loss 6.687
09/19 06:58:52 PM | Train: [139/180] Step 700/1249 Loss 0.353 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.628, lat_loss 6.687
09/19 06:59:15 PM | Train: [139/180] Step 750/1249 Loss 0.357 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.628, lat_loss 6.687
09/19 06:59:35 PM | Train: [139/180] Step 800/1249 Loss 0.355 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.628, lat_loss 6.687
09/19 06:59:58 PM | Train: [139/180] Step 850/1249 Loss 0.355 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.628, lat_loss 6.687
09/19 07:00:20 PM | Train: [139/180] Step 900/1249 Loss 0.356 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.628, lat_loss 6.687
09/19 07:00:41 PM | Train: [139/180] Step 950/1249 Loss 0.354 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.628, lat_loss 6.687
09/19 07:01:05 PM | Train: [139/180] Step 1000/1249 Loss 0.358 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.628, lat_loss 6.687
09/19 07:01:28 PM | Train: [139/180] Step 1050/1249 Loss 0.356 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.628, lat_loss 6.687
09/19 07:01:53 PM | Train: [139/180] Step 1100/1249 Loss 0.356 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.627, lat_loss 6.687
09/19 07:02:16 PM | Train: [139/180] Step 1150/1249 Loss 0.356 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.627, lat_loss 6.687
09/19 07:02:38 PM | Train: [139/180] Step 1200/1249 Loss 0.354 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.627, lat_loss 6.687
09/19 07:03:02 PM | Train: [139/180] Step 1249/1249 Loss 0.356 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.627, lat_loss 6.687
09/19 07:03:02 PM | _w_step_train: [139/180] Final Prec@1 91.1425% Time 565.25
09/19 07:03:02 PM | Start to train theta for epoch 138
09/19 07:03:24 PM | Train: [139/180] Step 050/312 Loss 0.612 Prec@(1,3) (85.7%, 98.7%), ce_loss 0.627, lat_loss 6.687
09/19 07:03:43 PM | Train: [139/180] Step 100/312 Loss 0.618 Prec@(1,3) (85.5%, 99.1%), ce_loss 0.627, lat_loss 6.687
09/19 07:04:02 PM | Train: [139/180] Step 150/312 Loss 0.622 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.627, lat_loss 6.687
09/19 07:04:22 PM | Train: [139/180] Step 200/312 Loss 0.617 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.627, lat_loss 6.687
09/19 07:04:41 PM | Train: [139/180] Step 250/312 Loss 0.611 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.627, lat_loss 6.687
09/19 07:05:01 PM | Train: [139/180] Step 300/312 Loss 0.612 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.627, lat_loss 6.687
09/19 07:05:06 PM | Train: [139/180] Step 312/312 Loss 0.620 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.627, lat_loss 6.687
09/19 07:05:06 PM | _theta_step_train: [139/180] Final Prec@1 85.7800% Time 123.26
09/19 07:05:11 PM | Valid: [139/180] Step 050/312 Loss 0.676 Prec@(1,3) (83.5%, 98.8%), ce_loss 0.627, lat_loss 6.687
09/19 07:05:16 PM | Valid: [139/180] Step 100/312 Loss 0.765 Prec@(1,3) (81.9%, 97.8%), ce_loss 0.627, lat_loss 6.687
09/19 07:05:20 PM | Valid: [139/180] Step 150/312 Loss 0.726 Prec@(1,3) (82.8%, 98.2%), ce_loss 0.627, lat_loss 6.687
09/19 07:05:25 PM | Valid: [139/180] Step 200/312 Loss 0.769 Prec@(1,3) (81.8%, 97.9%), ce_loss 0.627, lat_loss 6.687
09/19 07:05:30 PM | Valid: [139/180] Step 250/312 Loss 0.757 Prec@(1,3) (81.7%, 98.2%), ce_loss 0.627, lat_loss 6.687
09/19 07:05:34 PM | Valid: [139/180] Step 300/312 Loss 0.723 Prec@(1,3) (82.4%, 98.4%), ce_loss 0.627, lat_loss 6.687
09/19 07:05:36 PM | Valid: [139/180] Step 312/312 Loss 0.717 Prec@(1,3) (82.5%, 98.5%), ce_loss 0.627, lat_loss 6.687
09/19 07:05:36 PM | val: [139/180] Final Prec@1 82.5200% Time 29.93
09/19 07:05:36 PM | Start to train weights for epoch 139
09/19 07:06:02 PM | Train: [140/180] Step 050/1249 Loss 0.335 Prec@(1,3) (91.1%, 99.9%), ce_loss 0.627, lat_loss 6.687
09/19 07:06:27 PM | Train: [140/180] Step 100/1249 Loss 0.315 Prec@(1,3) (91.7%, 99.9%), ce_loss 0.627, lat_loss 6.687
09/19 07:06:50 PM | Train: [140/180] Step 150/1249 Loss 0.332 Prec@(1,3) (91.4%, 99.9%), ce_loss 0.627, lat_loss 6.687
09/19 07:07:15 PM | Train: [140/180] Step 200/1249 Loss 0.345 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.627, lat_loss 6.687
09/19 07:07:39 PM | Train: [140/180] Step 250/1249 Loss 0.357 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.627, lat_loss 6.687
09/19 07:08:02 PM | Train: [140/180] Step 300/1249 Loss 0.355 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.627, lat_loss 6.687
09/19 07:08:27 PM | Train: [140/180] Step 350/1249 Loss 0.355 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.626, lat_loss 6.687
09/19 07:08:52 PM | Train: [140/180] Step 400/1249 Loss 0.353 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.626, lat_loss 6.687
09/19 07:09:16 PM | Train: [140/180] Step 450/1249 Loss 0.353 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.626, lat_loss 6.687
09/19 07:09:40 PM | Train: [140/180] Step 500/1249 Loss 0.361 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.626, lat_loss 6.687
09/19 07:10:05 PM | Train: [140/180] Step 550/1249 Loss 0.362 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.626, lat_loss 6.687
09/19 07:10:29 PM | Train: [140/180] Step 600/1249 Loss 0.361 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.626, lat_loss 6.687
09/19 07:10:52 PM | Train: [140/180] Step 650/1249 Loss 0.363 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.626, lat_loss 6.687
09/19 07:11:16 PM | Train: [140/180] Step 700/1249 Loss 0.362 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.626, lat_loss 6.687
09/19 07:11:41 PM | Train: [140/180] Step 750/1249 Loss 0.360 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.626, lat_loss 6.687
09/19 07:12:05 PM | Train: [140/180] Step 800/1249 Loss 0.357 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.626, lat_loss 6.687
09/19 07:12:28 PM | Train: [140/180] Step 850/1249 Loss 0.357 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.626, lat_loss 6.687
09/19 07:12:52 PM | Train: [140/180] Step 900/1249 Loss 0.358 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.626, lat_loss 6.687
09/19 07:13:17 PM | Train: [140/180] Step 950/1249 Loss 0.358 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.626, lat_loss 6.687
09/19 07:13:40 PM | Train: [140/180] Step 1000/1249 Loss 0.359 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.626, lat_loss 6.687
09/19 07:14:04 PM | Train: [140/180] Step 1050/1249 Loss 0.359 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.625, lat_loss 6.687
09/19 07:14:27 PM | Train: [140/180] Step 1100/1249 Loss 0.359 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.625, lat_loss 6.687
09/19 07:14:52 PM | Train: [140/180] Step 1150/1249 Loss 0.357 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.625, lat_loss 6.687
09/19 07:15:16 PM | Train: [140/180] Step 1200/1249 Loss 0.357 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.625, lat_loss 6.687
09/19 07:15:40 PM | Train: [140/180] Step 1249/1249 Loss 0.357 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.625, lat_loss 6.687
09/19 07:15:40 PM | _w_step_train: [140/180] Final Prec@1 90.9525% Time 604.57
09/19 07:15:40 PM | Start to train theta for epoch 139
09/19 07:16:01 PM | Train: [140/180] Step 050/312 Loss 0.550 Prec@(1,3) (87.4%, 99.3%), ce_loss 0.625, lat_loss 6.687
09/19 07:16:19 PM | Train: [140/180] Step 100/312 Loss 0.634 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.625, lat_loss 6.687
09/19 07:16:37 PM | Train: [140/180] Step 150/312 Loss 0.640 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.625, lat_loss 6.687
09/19 07:16:56 PM | Train: [140/180] Step 200/312 Loss 0.604 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.625, lat_loss 6.687
09/19 07:17:15 PM | Train: [140/180] Step 250/312 Loss 0.600 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.625, lat_loss 6.687
09/19 07:17:35 PM | Train: [140/180] Step 300/312 Loss 0.591 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.625, lat_loss 6.687
09/19 07:17:40 PM | Train: [140/180] Step 312/312 Loss 0.595 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.625, lat_loss 6.687
09/19 07:17:41 PM | _theta_step_train: [140/180] Final Prec@1 85.9100% Time 120.41
09/19 07:17:46 PM | Valid: [140/180] Step 050/312 Loss 0.614 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.625, lat_loss 6.687
09/19 07:17:51 PM | Valid: [140/180] Step 100/312 Loss 0.647 Prec@(1,3) (84.8%, 99.0%), ce_loss 0.625, lat_loss 6.687
09/19 07:17:55 PM | Valid: [140/180] Step 150/312 Loss 0.660 Prec@(1,3) (84.4%, 98.9%), ce_loss 0.625, lat_loss 6.687
09/19 07:18:00 PM | Valid: [140/180] Step 200/312 Loss 0.693 Prec@(1,3) (83.6%, 98.6%), ce_loss 0.625, lat_loss 6.687
09/19 07:18:05 PM | Valid: [140/180] Step 250/312 Loss 0.692 Prec@(1,3) (83.8%, 98.6%), ce_loss 0.625, lat_loss 6.687
09/19 07:18:09 PM | Valid: [140/180] Step 300/312 Loss 0.667 Prec@(1,3) (84.3%, 98.8%), ce_loss 0.625, lat_loss 6.687
09/19 07:18:10 PM | Valid: [140/180] Step 312/312 Loss 0.663 Prec@(1,3) (84.3%, 98.9%), ce_loss 0.625, lat_loss 6.687
09/19 07:18:10 PM | val: [140/180] Final Prec@1 84.2900% Time 29.75
09/19 07:18:10 PM | Start to train weights for epoch 140
09/19 07:18:28 PM | Train: [141/180] Step 050/1249 Loss 0.326 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.625, lat_loss 6.687
09/19 07:18:44 PM | Train: [141/180] Step 100/1249 Loss 0.315 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.625, lat_loss 6.687
09/19 07:18:59 PM | Train: [141/180] Step 150/1249 Loss 0.323 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.625, lat_loss 6.687
09/19 07:19:15 PM | Train: [141/180] Step 200/1249 Loss 0.324 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.625, lat_loss 6.687
09/19 07:19:31 PM | Train: [141/180] Step 250/1249 Loss 0.338 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.624, lat_loss 6.687
09/19 07:19:47 PM | Train: [141/180] Step 300/1249 Loss 0.345 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.624, lat_loss 6.687
09/19 07:20:03 PM | Train: [141/180] Step 350/1249 Loss 0.341 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.624, lat_loss 6.687
09/19 07:20:19 PM | Train: [141/180] Step 400/1249 Loss 0.339 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.624, lat_loss 6.687
09/19 07:20:35 PM | Train: [141/180] Step 450/1249 Loss 0.339 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.624, lat_loss 6.687
09/19 07:20:51 PM | Train: [141/180] Step 500/1249 Loss 0.334 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.624, lat_loss 6.687
09/19 07:21:07 PM | Train: [141/180] Step 550/1249 Loss 0.334 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.624, lat_loss 6.687
09/19 07:21:23 PM | Train: [141/180] Step 600/1249 Loss 0.332 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.624, lat_loss 6.687
09/19 07:21:39 PM | Train: [141/180] Step 650/1249 Loss 0.333 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.624, lat_loss 6.687
09/19 07:21:55 PM | Train: [141/180] Step 700/1249 Loss 0.330 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.624, lat_loss 6.687
09/19 07:22:11 PM | Train: [141/180] Step 750/1249 Loss 0.333 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.624, lat_loss 6.687
09/19 07:22:29 PM | Train: [141/180] Step 800/1249 Loss 0.333 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.624, lat_loss 6.687
09/19 07:22:53 PM | Train: [141/180] Step 850/1249 Loss 0.333 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.624, lat_loss 6.687
09/19 07:23:17 PM | Train: [141/180] Step 900/1249 Loss 0.335 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.623, lat_loss 6.687
09/19 07:23:41 PM | Train: [141/180] Step 950/1249 Loss 0.336 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.623, lat_loss 6.687
09/19 07:24:05 PM | Train: [141/180] Step 1000/1249 Loss 0.335 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.623, lat_loss 6.687
09/19 07:24:30 PM | Train: [141/180] Step 1050/1249 Loss 0.335 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.623, lat_loss 6.687
09/19 07:24:55 PM | Train: [141/180] Step 1100/1249 Loss 0.338 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.623, lat_loss 6.687
09/19 07:25:19 PM | Train: [141/180] Step 1150/1249 Loss 0.338 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.623, lat_loss 6.687
09/19 07:25:41 PM | Train: [141/180] Step 1200/1249 Loss 0.340 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.623, lat_loss 6.687
09/19 07:26:04 PM | Train: [141/180] Step 1249/1249 Loss 0.341 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.623, lat_loss 6.687
09/19 07:26:04 PM | _w_step_train: [141/180] Final Prec@1 91.3550% Time 473.38
09/19 07:26:04 PM | Start to train theta for epoch 140
09/19 07:26:24 PM | Train: [141/180] Step 050/312 Loss 0.577 Prec@(1,3) (86.7%, 99.2%), ce_loss 0.623, lat_loss 6.687
09/19 07:26:44 PM | Train: [141/180] Step 100/312 Loss 0.586 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.623, lat_loss 6.687
09/19 07:26:59 PM | Train: [141/180] Step 150/312 Loss 0.581 Prec@(1,3) (86.3%, 99.4%), ce_loss 0.623, lat_loss 6.687
09/19 07:27:12 PM | Train: [141/180] Step 200/312 Loss 0.603 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.623, lat_loss 6.687
09/19 07:27:33 PM | Train: [141/180] Step 250/312 Loss 0.604 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.623, lat_loss 6.687
09/19 07:27:53 PM | Train: [141/180] Step 300/312 Loss 0.617 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.623, lat_loss 6.687
09/19 07:27:58 PM | Train: [141/180] Step 312/312 Loss 0.616 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.623, lat_loss 6.687
09/19 07:27:59 PM | _theta_step_train: [141/180] Final Prec@1 85.7000% Time 114.85
09/19 07:28:04 PM | Valid: [141/180] Step 050/312 Loss 0.614 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.623, lat_loss 6.687
09/19 07:28:09 PM | Valid: [141/180] Step 100/312 Loss 0.653 Prec@(1,3) (83.6%, 99.0%), ce_loss 0.623, lat_loss 6.687
09/19 07:28:13 PM | Valid: [141/180] Step 150/312 Loss 0.704 Prec@(1,3) (82.9%, 98.8%), ce_loss 0.623, lat_loss 6.687
09/19 07:28:18 PM | Valid: [141/180] Step 200/312 Loss 0.703 Prec@(1,3) (82.9%, 98.8%), ce_loss 0.623, lat_loss 6.687
09/19 07:28:23 PM | Valid: [141/180] Step 250/312 Loss 0.718 Prec@(1,3) (82.7%, 98.7%), ce_loss 0.623, lat_loss 6.687
09/19 07:28:27 PM | Valid: [141/180] Step 300/312 Loss 0.724 Prec@(1,3) (82.7%, 98.6%), ce_loss 0.623, lat_loss 6.687
09/19 07:28:28 PM | Valid: [141/180] Step 312/312 Loss 0.714 Prec@(1,3) (82.8%, 98.6%), ce_loss 0.623, lat_loss 6.687
09/19 07:28:28 PM | val: [141/180] Final Prec@1 82.8500% Time 29.67
09/19 07:28:28 PM | Start to train weights for epoch 141
09/19 07:28:54 PM | Train: [142/180] Step 050/1249 Loss 0.333 Prec@(1,3) (90.6%, 100.0%), ce_loss 0.623, lat_loss 6.687
09/19 07:29:15 PM | Train: [142/180] Step 100/1249 Loss 0.326 Prec@(1,3) (91.0%, 99.9%), ce_loss 0.623, lat_loss 6.687
09/19 07:29:39 PM | Train: [142/180] Step 150/1249 Loss 0.334 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.622, lat_loss 6.687
09/19 07:30:02 PM | Train: [142/180] Step 200/1249 Loss 0.345 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.622, lat_loss 6.687
09/19 07:30:24 PM | Train: [142/180] Step 250/1249 Loss 0.336 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.622, lat_loss 6.687
09/19 07:30:46 PM | Train: [142/180] Step 300/1249 Loss 0.336 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.622, lat_loss 6.687
09/19 07:31:07 PM | Train: [142/180] Step 350/1249 Loss 0.328 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.622, lat_loss 6.687
09/19 07:31:30 PM | Train: [142/180] Step 400/1249 Loss 0.328 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.622, lat_loss 6.687
09/19 07:31:51 PM | Train: [142/180] Step 450/1249 Loss 0.326 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.622, lat_loss 6.687
09/19 07:32:13 PM | Train: [142/180] Step 500/1249 Loss 0.333 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.622, lat_loss 6.687
09/19 07:32:37 PM | Train: [142/180] Step 550/1249 Loss 0.338 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.622, lat_loss 6.687
09/19 07:33:00 PM | Train: [142/180] Step 600/1249 Loss 0.339 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.622, lat_loss 6.687
09/19 07:33:24 PM | Train: [142/180] Step 650/1249 Loss 0.339 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.622, lat_loss 6.687
09/19 07:33:46 PM | Train: [142/180] Step 700/1249 Loss 0.343 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.622, lat_loss 6.687
09/19 07:34:08 PM | Train: [142/180] Step 750/1249 Loss 0.346 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.622, lat_loss 6.687
09/19 07:34:30 PM | Train: [142/180] Step 800/1249 Loss 0.349 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.622, lat_loss 6.687
09/19 07:34:52 PM | Train: [142/180] Step 850/1249 Loss 0.349 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.622, lat_loss 6.687
09/19 07:35:15 PM | Train: [142/180] Step 900/1249 Loss 0.350 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.621, lat_loss 6.687
09/19 07:35:37 PM | Train: [142/180] Step 950/1249 Loss 0.349 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.621, lat_loss 6.687
09/19 07:36:01 PM | Train: [142/180] Step 1000/1249 Loss 0.346 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.621, lat_loss 6.687
09/19 07:36:26 PM | Train: [142/180] Step 1050/1249 Loss 0.347 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.621, lat_loss 6.687
09/19 07:36:51 PM | Train: [142/180] Step 1100/1249 Loss 0.347 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.621, lat_loss 6.687
09/19 07:37:15 PM | Train: [142/180] Step 1150/1249 Loss 0.350 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.621, lat_loss 6.687
09/19 07:37:40 PM | Train: [142/180] Step 1200/1249 Loss 0.349 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.621, lat_loss 6.687
09/19 07:38:05 PM | Train: [142/180] Step 1249/1249 Loss 0.349 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.621, lat_loss 6.687
09/19 07:38:05 PM | _w_step_train: [142/180] Final Prec@1 91.0625% Time 576.27
09/19 07:38:05 PM | Start to train theta for epoch 141
09/19 07:38:18 PM | Train: [142/180] Step 050/312 Loss 0.562 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.621, lat_loss 6.687
09/19 07:38:30 PM | Train: [142/180] Step 100/312 Loss 0.563 Prec@(1,3) (86.4%, 99.3%), ce_loss 0.621, lat_loss 6.687
09/19 07:38:42 PM | Train: [142/180] Step 150/312 Loss 0.573 Prec@(1,3) (86.4%, 99.3%), ce_loss 0.621, lat_loss 6.687
09/19 07:38:54 PM | Train: [142/180] Step 200/312 Loss 0.587 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.621, lat_loss 6.687
09/19 07:39:07 PM | Train: [142/180] Step 250/312 Loss 0.596 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.621, lat_loss 6.687
09/19 07:39:19 PM | Train: [142/180] Step 300/312 Loss 0.595 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.621, lat_loss 6.687
09/19 07:39:22 PM | Train: [142/180] Step 312/312 Loss 0.596 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.621, lat_loss 6.687
09/19 07:39:22 PM | _theta_step_train: [142/180] Final Prec@1 85.8600% Time 77.04
09/19 07:39:27 PM | Valid: [142/180] Step 050/312 Loss 0.560 Prec@(1,3) (86.2%, 99.5%), ce_loss 0.621, lat_loss 6.687
09/19 07:39:32 PM | Valid: [142/180] Step 100/312 Loss 0.712 Prec@(1,3) (83.7%, 98.5%), ce_loss 0.621, lat_loss 6.687
09/19 07:39:36 PM | Valid: [142/180] Step 150/312 Loss 0.710 Prec@(1,3) (83.9%, 98.4%), ce_loss 0.621, lat_loss 6.687
09/19 07:39:41 PM | Valid: [142/180] Step 200/312 Loss 0.686 Prec@(1,3) (84.1%, 98.6%), ce_loss 0.621, lat_loss 6.687
09/19 07:39:46 PM | Valid: [142/180] Step 250/312 Loss 0.681 Prec@(1,3) (84.1%, 98.8%), ce_loss 0.621, lat_loss 6.687
09/19 07:39:51 PM | Valid: [142/180] Step 300/312 Loss 0.694 Prec@(1,3) (83.4%, 98.6%), ce_loss 0.621, lat_loss 6.687
09/19 07:39:52 PM | Valid: [142/180] Step 312/312 Loss 0.689 Prec@(1,3) (83.5%, 98.6%), ce_loss 0.621, lat_loss 6.687
09/19 07:39:52 PM | val: [142/180] Final Prec@1 83.5400% Time 30.38
09/19 07:39:52 PM | Start to train weights for epoch 142
09/19 07:40:17 PM | Train: [143/180] Step 050/1249 Loss 0.288 Prec@(1,3) (92.9%, 99.9%), ce_loss 0.621, lat_loss 6.687
09/19 07:40:40 PM | Train: [143/180] Step 100/1249 Loss 0.320 Prec@(1,3) (92.2%, 99.7%), ce_loss 0.620, lat_loss 6.687
09/19 07:41:02 PM | Train: [143/180] Step 150/1249 Loss 0.313 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.620, lat_loss 6.687
09/19 07:41:22 PM | Train: [143/180] Step 200/1249 Loss 0.320 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.620, lat_loss 6.687
09/19 07:41:42 PM | Train: [143/180] Step 250/1249 Loss 0.326 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.620, lat_loss 6.687
09/19 07:42:02 PM | Train: [143/180] Step 300/1249 Loss 0.323 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.620, lat_loss 6.687
09/19 07:42:22 PM | Train: [143/180] Step 350/1249 Loss 0.333 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.620, lat_loss 6.687
09/19 07:42:45 PM | Train: [143/180] Step 400/1249 Loss 0.335 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.620, lat_loss 6.687
09/19 07:43:09 PM | Train: [143/180] Step 450/1249 Loss 0.339 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.620, lat_loss 6.687
09/19 07:43:33 PM | Train: [143/180] Step 500/1249 Loss 0.339 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.620, lat_loss 6.687
09/19 07:43:56 PM | Train: [143/180] Step 550/1249 Loss 0.339 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.620, lat_loss 6.687
09/19 07:44:19 PM | Train: [143/180] Step 600/1249 Loss 0.339 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.620, lat_loss 6.687
09/19 07:44:43 PM | Train: [143/180] Step 650/1249 Loss 0.339 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.620, lat_loss 6.687
09/19 07:45:06 PM | Train: [143/180] Step 700/1249 Loss 0.344 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.620, lat_loss 6.687
09/19 07:45:29 PM | Train: [143/180] Step 750/1249 Loss 0.343 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.620, lat_loss 6.687
09/19 07:45:52 PM | Train: [143/180] Step 800/1249 Loss 0.341 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.619, lat_loss 6.687
09/19 07:46:16 PM | Train: [143/180] Step 850/1249 Loss 0.342 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.619, lat_loss 6.687
09/19 07:46:40 PM | Train: [143/180] Step 900/1249 Loss 0.344 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.619, lat_loss 6.687
09/19 07:47:03 PM | Train: [143/180] Step 950/1249 Loss 0.346 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.619, lat_loss 6.687
09/19 07:47:27 PM | Train: [143/180] Step 1000/1249 Loss 0.346 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.619, lat_loss 6.687
09/19 07:47:52 PM | Train: [143/180] Step 1050/1249 Loss 0.346 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.619, lat_loss 6.687
09/19 07:48:16 PM | Train: [143/180] Step 1100/1249 Loss 0.346 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.619, lat_loss 6.687
09/19 07:48:41 PM | Train: [143/180] Step 1150/1249 Loss 0.345 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.619, lat_loss 6.687
09/19 07:49:04 PM | Train: [143/180] Step 1200/1249 Loss 0.345 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.619, lat_loss 6.687
09/19 07:49:26 PM | Train: [143/180] Step 1249/1249 Loss 0.344 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.619, lat_loss 6.687
09/19 07:49:26 PM | _w_step_train: [143/180] Final Prec@1 91.1975% Time 573.42
09/19 07:49:26 PM | Start to train theta for epoch 142
09/19 07:49:47 PM | Train: [143/180] Step 050/312 Loss 0.569 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.619, lat_loss 6.687
09/19 07:50:07 PM | Train: [143/180] Step 100/312 Loss 0.591 Prec@(1,3) (85.7%, 99.5%), ce_loss 0.619, lat_loss 6.687
09/19 07:50:27 PM | Train: [143/180] Step 150/312 Loss 0.599 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.619, lat_loss 6.687
09/19 07:50:47 PM | Train: [143/180] Step 200/312 Loss 0.594 Prec@(1,3) (85.4%, 99.3%), ce_loss 0.619, lat_loss 6.687
09/19 07:51:06 PM | Train: [143/180] Step 250/312 Loss 0.603 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.619, lat_loss 6.687
09/19 07:51:25 PM | Train: [143/180] Step 300/312 Loss 0.602 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.619, lat_loss 6.687
09/19 07:51:29 PM | Train: [143/180] Step 312/312 Loss 0.601 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.619, lat_loss 6.687
09/19 07:51:29 PM | _theta_step_train: [143/180] Final Prec@1 85.5100% Time 123.81
09/19 07:51:35 PM | Valid: [143/180] Step 050/312 Loss 0.545 Prec@(1,3) (86.9%, 99.8%), ce_loss 0.619, lat_loss 6.687
09/19 07:51:39 PM | Valid: [143/180] Step 100/312 Loss 0.678 Prec@(1,3) (83.9%, 98.6%), ce_loss 0.619, lat_loss 6.687
09/19 07:51:44 PM | Valid: [143/180] Step 150/312 Loss 0.709 Prec@(1,3) (83.3%, 98.4%), ce_loss 0.619, lat_loss 6.687
09/19 07:51:49 PM | Valid: [143/180] Step 200/312 Loss 0.724 Prec@(1,3) (83.0%, 98.4%), ce_loss 0.619, lat_loss 6.687
09/19 07:51:53 PM | Valid: [143/180] Step 250/312 Loss 0.796 Prec@(1,3) (82.1%, 97.9%), ce_loss 0.619, lat_loss 6.687
09/19 07:51:58 PM | Valid: [143/180] Step 300/312 Loss 0.779 Prec@(1,3) (82.4%, 98.1%), ce_loss 0.619, lat_loss 6.687
09/19 07:51:59 PM | Valid: [143/180] Step 312/312 Loss 0.770 Prec@(1,3) (82.6%, 98.1%), ce_loss 0.619, lat_loss 6.687
09/19 07:51:59 PM | val: [143/180] Final Prec@1 82.5600% Time 29.81
09/19 07:51:59 PM | Start to train weights for epoch 143
09/19 07:52:17 PM | Train: [144/180] Step 050/1249 Loss 0.299 Prec@(1,3) (92.1%, 99.6%), ce_loss 0.619, lat_loss 6.687
09/19 07:52:32 PM | Train: [144/180] Step 100/1249 Loss 0.336 Prec@(1,3) (91.1%, 99.6%), ce_loss 0.618, lat_loss 6.687
09/19 07:52:49 PM | Train: [144/180] Step 150/1249 Loss 0.352 Prec@(1,3) (91.1%, 99.6%), ce_loss 0.618, lat_loss 6.687
09/19 07:53:05 PM | Train: [144/180] Step 200/1249 Loss 0.354 Prec@(1,3) (91.1%, 99.6%), ce_loss 0.618, lat_loss 6.687
09/19 07:53:21 PM | Train: [144/180] Step 250/1249 Loss 0.357 Prec@(1,3) (91.0%, 99.6%), ce_loss 0.618, lat_loss 6.687
09/19 07:53:36 PM | Train: [144/180] Step 300/1249 Loss 0.362 Prec@(1,3) (90.9%, 99.6%), ce_loss 0.618, lat_loss 6.687
09/19 07:53:52 PM | Train: [144/180] Step 350/1249 Loss 0.367 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.618, lat_loss 6.687
09/19 07:54:08 PM | Train: [144/180] Step 400/1249 Loss 0.370 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.618, lat_loss 6.687
09/19 07:54:24 PM | Train: [144/180] Step 450/1249 Loss 0.365 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.618, lat_loss 6.687
09/19 07:54:41 PM | Train: [144/180] Step 500/1249 Loss 0.374 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.618, lat_loss 6.688
09/19 07:54:56 PM | Train: [144/180] Step 550/1249 Loss 0.369 Prec@(1,3) (90.8%, 99.7%), ce_loss 0.618, lat_loss 6.688
09/19 07:55:12 PM | Train: [144/180] Step 600/1249 Loss 0.365 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.618, lat_loss 6.688
09/19 07:55:28 PM | Train: [144/180] Step 650/1249 Loss 0.364 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.618, lat_loss 6.688
09/19 07:55:44 PM | Train: [144/180] Step 700/1249 Loss 0.363 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.618, lat_loss 6.688
09/19 07:56:00 PM | Train: [144/180] Step 750/1249 Loss 0.363 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.618, lat_loss 6.688
09/19 07:56:16 PM | Train: [144/180] Step 800/1249 Loss 0.364 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.618, lat_loss 6.688
09/19 07:56:32 PM | Train: [144/180] Step 850/1249 Loss 0.363 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.617, lat_loss 6.688
09/19 07:56:48 PM | Train: [144/180] Step 900/1249 Loss 0.363 Prec@(1,3) (90.8%, 99.7%), ce_loss 0.617, lat_loss 6.688
09/19 07:57:04 PM | Train: [144/180] Step 950/1249 Loss 0.363 Prec@(1,3) (90.8%, 99.7%), ce_loss 0.617, lat_loss 6.688
09/19 07:57:20 PM | Train: [144/180] Step 1000/1249 Loss 0.362 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.617, lat_loss 6.688
09/19 07:57:36 PM | Train: [144/180] Step 1050/1249 Loss 0.360 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.617, lat_loss 6.688
09/19 07:57:53 PM | Train: [144/180] Step 1100/1249 Loss 0.358 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.617, lat_loss 6.688
09/19 07:58:18 PM | Train: [144/180] Step 1150/1249 Loss 0.359 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.617, lat_loss 6.688
09/19 07:58:41 PM | Train: [144/180] Step 1200/1249 Loss 0.356 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.617, lat_loss 6.688
09/19 07:59:05 PM | Train: [144/180] Step 1249/1249 Loss 0.354 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.617, lat_loss 6.688
09/19 07:59:05 PM | _w_step_train: [144/180] Final Prec@1 91.0775% Time 425.93
09/19 07:59:05 PM | Start to train theta for epoch 143
09/19 07:59:27 PM | Train: [144/180] Step 050/312 Loss 0.577 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.617, lat_loss 6.688
09/19 07:59:47 PM | Train: [144/180] Step 100/312 Loss 0.588 Prec@(1,3) (85.2%, 99.4%), ce_loss 0.617, lat_loss 6.688
09/19 08:00:07 PM | Train: [144/180] Step 150/312 Loss 0.597 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.617, lat_loss 6.688
09/19 08:00:20 PM | Train: [144/180] Step 200/312 Loss 0.596 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.617, lat_loss 6.688
09/19 08:00:32 PM | Train: [144/180] Step 250/312 Loss 0.617 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.617, lat_loss 6.688
09/19 08:00:43 PM | Train: [144/180] Step 300/312 Loss 0.625 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.617, lat_loss 6.688
09/19 08:00:46 PM | Train: [144/180] Step 312/312 Loss 0.625 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.617, lat_loss 6.688
09/19 08:00:46 PM | _theta_step_train: [144/180] Final Prec@1 85.2600% Time 100.54
09/19 08:00:51 PM | Valid: [144/180] Step 050/312 Loss 0.670 Prec@(1,3) (83.5%, 99.6%), ce_loss 0.617, lat_loss 6.688
09/19 08:00:56 PM | Valid: [144/180] Step 100/312 Loss 0.797 Prec@(1,3) (82.2%, 98.2%), ce_loss 0.617, lat_loss 6.688
09/19 08:01:00 PM | Valid: [144/180] Step 150/312 Loss 0.771 Prec@(1,3) (83.1%, 98.3%), ce_loss 0.617, lat_loss 6.688
09/19 08:01:05 PM | Valid: [144/180] Step 200/312 Loss 0.779 Prec@(1,3) (83.0%, 98.2%), ce_loss 0.617, lat_loss 6.688
09/19 08:01:10 PM | Valid: [144/180] Step 250/312 Loss 0.772 Prec@(1,3) (83.1%, 98.3%), ce_loss 0.617, lat_loss 6.688
09/19 08:01:14 PM | Valid: [144/180] Step 300/312 Loss 0.755 Prec@(1,3) (83.3%, 98.4%), ce_loss 0.617, lat_loss 6.688
09/19 08:01:15 PM | Valid: [144/180] Step 312/312 Loss 0.756 Prec@(1,3) (83.2%, 98.3%), ce_loss 0.617, lat_loss 6.688
09/19 08:01:15 PM | val: [144/180] Final Prec@1 83.1700% Time 29.61
09/19 08:01:15 PM | Start to train weights for epoch 144
09/19 08:01:41 PM | Train: [145/180] Step 050/1249 Loss 0.353 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.617, lat_loss 6.688
09/19 08:02:06 PM | Train: [145/180] Step 100/1249 Loss 0.342 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.617, lat_loss 6.688
09/19 08:02:30 PM | Train: [145/180] Step 150/1249 Loss 0.332 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.616, lat_loss 6.688
09/19 08:02:55 PM | Train: [145/180] Step 200/1249 Loss 0.336 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.616, lat_loss 6.688
09/19 08:03:20 PM | Train: [145/180] Step 250/1249 Loss 0.350 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.616, lat_loss 6.688
09/19 08:03:44 PM | Train: [145/180] Step 300/1249 Loss 0.344 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.616, lat_loss 6.688
09/19 08:04:09 PM | Train: [145/180] Step 350/1249 Loss 0.336 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.616, lat_loss 6.688
09/19 08:04:32 PM | Train: [145/180] Step 400/1249 Loss 0.351 Prec@(1,3) (91.0%, 99.8%), ce_loss 0.616, lat_loss 6.688
09/19 08:04:56 PM | Train: [145/180] Step 450/1249 Loss 0.347 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.616, lat_loss 6.688
09/19 08:05:22 PM | Train: [145/180] Step 500/1249 Loss 0.344 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.616, lat_loss 6.688
09/19 08:05:46 PM | Train: [145/180] Step 550/1249 Loss 0.346 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.616, lat_loss 6.688
09/19 08:06:11 PM | Train: [145/180] Step 600/1249 Loss 0.341 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.616, lat_loss 6.688
09/19 08:06:35 PM | Train: [145/180] Step 650/1249 Loss 0.342 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.616, lat_loss 6.688
09/19 08:07:01 PM | Train: [145/180] Step 700/1249 Loss 0.340 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.616, lat_loss 6.688
09/19 08:07:25 PM | Train: [145/180] Step 750/1249 Loss 0.337 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.616, lat_loss 6.688
09/19 08:07:50 PM | Train: [145/180] Step 800/1249 Loss 0.339 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.616, lat_loss 6.688
09/19 08:08:15 PM | Train: [145/180] Step 850/1249 Loss 0.339 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.616, lat_loss 6.688
09/19 08:08:39 PM | Train: [145/180] Step 900/1249 Loss 0.339 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.615, lat_loss 6.688
09/19 08:09:04 PM | Train: [145/180] Step 950/1249 Loss 0.337 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.615, lat_loss 6.688
09/19 08:09:29 PM | Train: [145/180] Step 1000/1249 Loss 0.338 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.615, lat_loss 6.688
09/19 08:09:53 PM | Train: [145/180] Step 1050/1249 Loss 0.338 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.615, lat_loss 6.688
09/19 08:10:16 PM | Train: [145/180] Step 1100/1249 Loss 0.338 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.615, lat_loss 6.688
09/19 08:10:38 PM | Train: [145/180] Step 1150/1249 Loss 0.338 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.615, lat_loss 6.688
09/19 08:11:01 PM | Train: [145/180] Step 1200/1249 Loss 0.337 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.615, lat_loss 6.688
09/19 08:11:25 PM | Train: [145/180] Step 1249/1249 Loss 0.336 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.615, lat_loss 6.688
09/19 08:11:26 PM | _w_step_train: [145/180] Final Prec@1 91.4400% Time 610.12
09/19 08:11:26 PM | Start to train theta for epoch 144
09/19 08:11:47 PM | Train: [145/180] Step 050/312 Loss 0.626 Prec@(1,3) (85.4%, 99.3%), ce_loss 0.615, lat_loss 6.688
09/19 08:12:06 PM | Train: [145/180] Step 100/312 Loss 0.611 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.615, lat_loss 6.688
09/19 08:12:26 PM | Train: [145/180] Step 150/312 Loss 0.599 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.615, lat_loss 6.688
09/19 08:12:45 PM | Train: [145/180] Step 200/312 Loss 0.595 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.615, lat_loss 6.688
09/19 08:13:04 PM | Train: [145/180] Step 250/312 Loss 0.594 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.615, lat_loss 6.688
09/19 08:13:22 PM | Train: [145/180] Step 300/312 Loss 0.598 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.615, lat_loss 6.688
09/19 08:13:27 PM | Train: [145/180] Step 312/312 Loss 0.593 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.615, lat_loss 6.688
09/19 08:13:27 PM | _theta_step_train: [145/180] Final Prec@1 85.8500% Time 121.30
09/19 08:13:32 PM | Valid: [145/180] Step 050/312 Loss 0.712 Prec@(1,3) (83.2%, 98.5%), ce_loss 0.615, lat_loss 6.688
09/19 08:13:36 PM | Valid: [145/180] Step 100/312 Loss 0.712 Prec@(1,3) (83.4%, 98.4%), ce_loss 0.615, lat_loss 6.688
09/19 08:13:40 PM | Valid: [145/180] Step 150/312 Loss 0.782 Prec@(1,3) (81.9%, 98.1%), ce_loss 0.615, lat_loss 6.688
09/19 08:13:45 PM | Valid: [145/180] Step 200/312 Loss 0.728 Prec@(1,3) (83.1%, 98.4%), ce_loss 0.615, lat_loss 6.688
09/19 08:13:49 PM | Valid: [145/180] Step 250/312 Loss 0.714 Prec@(1,3) (83.3%, 98.6%), ce_loss 0.615, lat_loss 6.688
09/19 08:13:53 PM | Valid: [145/180] Step 300/312 Loss 0.748 Prec@(1,3) (82.7%, 98.3%), ce_loss 0.615, lat_loss 6.688
09/19 08:13:54 PM | Valid: [145/180] Step 312/312 Loss 0.739 Prec@(1,3) (82.8%, 98.4%), ce_loss 0.615, lat_loss 6.688
09/19 08:13:54 PM | val: [145/180] Final Prec@1 82.7700% Time 27.30
09/19 08:13:54 PM | Start to train weights for epoch 145
09/19 08:14:19 PM | Train: [146/180] Step 050/1249 Loss 0.363 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.615, lat_loss 6.688
09/19 08:14:42 PM | Train: [146/180] Step 100/1249 Loss 0.328 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.615, lat_loss 6.688
09/19 08:15:04 PM | Train: [146/180] Step 150/1249 Loss 0.337 Prec@(1,3) (91.2%, 99.9%), ce_loss 0.614, lat_loss 6.688
09/19 08:15:26 PM | Train: [146/180] Step 200/1249 Loss 0.328 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.614, lat_loss 6.688
09/19 08:15:48 PM | Train: [146/180] Step 250/1249 Loss 0.344 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.614, lat_loss 6.688
09/19 08:16:06 PM | Train: [146/180] Step 300/1249 Loss 0.346 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.614, lat_loss 6.688
09/19 08:16:22 PM | Train: [146/180] Step 350/1249 Loss 0.351 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.614, lat_loss 6.688
09/19 08:16:38 PM | Train: [146/180] Step 400/1249 Loss 0.347 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.614, lat_loss 6.688
09/19 08:16:54 PM | Train: [146/180] Step 450/1249 Loss 0.344 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.614, lat_loss 6.688
09/19 08:17:10 PM | Train: [146/180] Step 500/1249 Loss 0.348 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.614, lat_loss 6.688
09/19 08:17:25 PM | Train: [146/180] Step 550/1249 Loss 0.344 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.614, lat_loss 6.688
09/19 08:17:41 PM | Train: [146/180] Step 600/1249 Loss 0.349 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.614, lat_loss 6.688
09/19 08:17:57 PM | Train: [146/180] Step 650/1249 Loss 0.344 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.614, lat_loss 6.688
09/19 08:18:13 PM | Train: [146/180] Step 700/1249 Loss 0.344 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.614, lat_loss 6.688
09/19 08:18:32 PM | Train: [146/180] Step 750/1249 Loss 0.344 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.614, lat_loss 6.688
09/19 08:18:56 PM | Train: [146/180] Step 800/1249 Loss 0.340 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.614, lat_loss 6.688
09/19 08:19:20 PM | Train: [146/180] Step 850/1249 Loss 0.337 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.614, lat_loss 6.688
09/19 08:19:43 PM | Train: [146/180] Step 900/1249 Loss 0.339 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.613, lat_loss 6.688
09/19 08:20:05 PM | Train: [146/180] Step 950/1249 Loss 0.340 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.613, lat_loss 6.688
09/19 08:20:26 PM | Train: [146/180] Step 1000/1249 Loss 0.339 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.613, lat_loss 6.688
09/19 08:20:49 PM | Train: [146/180] Step 1050/1249 Loss 0.338 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.613, lat_loss 6.688
09/19 08:21:13 PM | Train: [146/180] Step 1100/1249 Loss 0.341 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.613, lat_loss 6.688
09/19 08:21:37 PM | Train: [146/180] Step 1150/1249 Loss 0.341 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.613, lat_loss 6.688
09/19 08:22:02 PM | Train: [146/180] Step 1200/1249 Loss 0.342 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.613, lat_loss 6.688
09/19 08:22:26 PM | Train: [146/180] Step 1249/1249 Loss 0.342 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.613, lat_loss 6.688
09/19 08:22:26 PM | _w_step_train: [146/180] Final Prec@1 91.2300% Time 512.30
09/19 08:22:26 PM | Start to train theta for epoch 145
09/19 08:22:48 PM | Train: [146/180] Step 050/312 Loss 0.577 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.613, lat_loss 6.688
09/19 08:23:08 PM | Train: [146/180] Step 100/312 Loss 0.620 Prec@(1,3) (85.6%, 99.0%), ce_loss 0.613, lat_loss 6.688
09/19 08:23:28 PM | Train: [146/180] Step 150/312 Loss 0.609 Prec@(1,3) (85.8%, 99.1%), ce_loss 0.613, lat_loss 6.688
09/19 08:23:48 PM | Train: [146/180] Step 200/312 Loss 0.610 Prec@(1,3) (85.8%, 99.1%), ce_loss 0.613, lat_loss 6.688
09/19 08:24:09 PM | Train: [146/180] Step 250/312 Loss 0.612 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.613, lat_loss 6.688
09/19 08:24:29 PM | Train: [146/180] Step 300/312 Loss 0.619 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.613, lat_loss 6.688
09/19 08:24:34 PM | Train: [146/180] Step 312/312 Loss 0.627 Prec@(1,3) (85.5%, 99.2%), ce_loss 0.613, lat_loss 6.688
09/19 08:24:34 PM | _theta_step_train: [146/180] Final Prec@1 85.4600% Time 127.25
09/19 08:24:39 PM | Valid: [146/180] Step 050/312 Loss 0.753 Prec@(1,3) (82.2%, 98.5%), ce_loss 0.613, lat_loss 6.688
09/19 08:24:44 PM | Valid: [146/180] Step 100/312 Loss 0.741 Prec@(1,3) (82.4%, 98.8%), ce_loss 0.613, lat_loss 6.688
09/19 08:24:48 PM | Valid: [146/180] Step 150/312 Loss 0.720 Prec@(1,3) (82.9%, 98.9%), ce_loss 0.613, lat_loss 6.688
09/19 08:24:53 PM | Valid: [146/180] Step 200/312 Loss 0.715 Prec@(1,3) (83.1%, 98.8%), ce_loss 0.613, lat_loss 6.688
09/19 08:24:57 PM | Valid: [146/180] Step 250/312 Loss 0.715 Prec@(1,3) (83.0%, 98.9%), ce_loss 0.613, lat_loss 6.688
09/19 08:25:02 PM | Valid: [146/180] Step 300/312 Loss 0.765 Prec@(1,3) (82.2%, 98.3%), ce_loss 0.613, lat_loss 6.688
09/19 08:25:03 PM | Valid: [146/180] Step 312/312 Loss 0.759 Prec@(1,3) (82.3%, 98.4%), ce_loss 0.613, lat_loss 6.688
09/19 08:25:03 PM | val: [146/180] Final Prec@1 82.3300% Time 29.48
09/19 08:25:03 PM | Start to train weights for epoch 146
09/19 08:25:29 PM | Train: [147/180] Step 050/1249 Loss 0.328 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.613, lat_loss 6.688
09/19 08:25:54 PM | Train: [147/180] Step 100/1249 Loss 0.321 Prec@(1,3) (92.1%, 99.9%), ce_loss 0.613, lat_loss 6.688
09/19 08:26:18 PM | Train: [147/180] Step 150/1249 Loss 0.349 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.613, lat_loss 6.688
09/19 08:26:43 PM | Train: [147/180] Step 200/1249 Loss 0.377 Prec@(1,3) (90.6%, 99.8%), ce_loss 0.613, lat_loss 6.688
09/19 08:27:08 PM | Train: [147/180] Step 250/1249 Loss 0.368 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.612, lat_loss 6.688
09/19 08:27:33 PM | Train: [147/180] Step 300/1249 Loss 0.358 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.612, lat_loss 6.688
09/19 08:27:58 PM | Train: [147/180] Step 350/1249 Loss 0.353 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.612, lat_loss 6.688
09/19 08:28:23 PM | Train: [147/180] Step 400/1249 Loss 0.347 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.612, lat_loss 6.688
09/19 08:28:47 PM | Train: [147/180] Step 450/1249 Loss 0.341 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.612, lat_loss 6.688
09/19 08:29:12 PM | Train: [147/180] Step 500/1249 Loss 0.345 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.612, lat_loss 6.688
09/19 08:29:36 PM | Train: [147/180] Step 550/1249 Loss 0.349 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.612, lat_loss 6.688
09/19 08:30:01 PM | Train: [147/180] Step 600/1249 Loss 0.349 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.612, lat_loss 6.688
09/19 08:30:26 PM | Train: [147/180] Step 650/1249 Loss 0.347 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.612, lat_loss 6.688
09/19 08:30:50 PM | Train: [147/180] Step 700/1249 Loss 0.346 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.612, lat_loss 6.688
09/19 08:31:14 PM | Train: [147/180] Step 750/1249 Loss 0.345 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.612, lat_loss 6.688
09/19 08:31:39 PM | Train: [147/180] Step 800/1249 Loss 0.341 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.612, lat_loss 6.688
09/19 08:32:04 PM | Train: [147/180] Step 850/1249 Loss 0.340 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.612, lat_loss 6.688
09/19 08:32:28 PM | Train: [147/180] Step 900/1249 Loss 0.345 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.612, lat_loss 6.688
09/19 08:32:53 PM | Train: [147/180] Step 950/1249 Loss 0.345 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.612, lat_loss 6.688
09/19 08:33:17 PM | Train: [147/180] Step 1000/1249 Loss 0.344 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.611, lat_loss 6.688
09/19 08:33:42 PM | Train: [147/180] Step 1050/1249 Loss 0.344 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.611, lat_loss 6.688
09/19 08:34:07 PM | Train: [147/180] Step 1100/1249 Loss 0.346 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.611, lat_loss 6.688
09/19 08:34:31 PM | Train: [147/180] Step 1150/1249 Loss 0.346 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.611, lat_loss 6.688
09/19 08:34:56 PM | Train: [147/180] Step 1200/1249 Loss 0.350 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.611, lat_loss 6.688
09/19 08:35:20 PM | Train: [147/180] Step 1249/1249 Loss 0.348 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.611, lat_loss 6.688
09/19 08:35:20 PM | _w_step_train: [147/180] Final Prec@1 91.2250% Time 617.27
09/19 08:35:20 PM | Start to train theta for epoch 146
09/19 08:35:34 PM | Train: [147/180] Step 050/312 Loss 0.622 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.611, lat_loss 6.688
09/19 08:35:46 PM | Train: [147/180] Step 100/312 Loss 0.650 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.611, lat_loss 6.688
09/19 08:35:58 PM | Train: [147/180] Step 150/312 Loss 0.631 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.611, lat_loss 6.688
09/19 08:36:11 PM | Train: [147/180] Step 200/312 Loss 0.623 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.611, lat_loss 6.688
09/19 08:36:23 PM | Train: [147/180] Step 250/312 Loss 0.627 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.611, lat_loss 6.688
09/19 08:36:35 PM | Train: [147/180] Step 300/312 Loss 0.635 Prec@(1,3) (84.9%, 99.1%), ce_loss 0.611, lat_loss 6.688
09/19 08:36:39 PM | Train: [147/180] Step 312/312 Loss 0.631 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.611, lat_loss 6.688
09/19 08:36:39 PM | _theta_step_train: [147/180] Final Prec@1 85.0600% Time 78.65
09/19 08:36:44 PM | Valid: [147/180] Step 050/312 Loss 0.664 Prec@(1,3) (83.8%, 99.4%), ce_loss 0.611, lat_loss 6.688
09/19 08:36:49 PM | Valid: [147/180] Step 100/312 Loss 0.669 Prec@(1,3) (83.7%, 99.1%), ce_loss 0.611, lat_loss 6.688
09/19 08:36:53 PM | Valid: [147/180] Step 150/312 Loss 0.757 Prec@(1,3) (82.0%, 98.3%), ce_loss 0.611, lat_loss 6.688
09/19 08:36:58 PM | Valid: [147/180] Step 200/312 Loss 0.744 Prec@(1,3) (82.4%, 98.4%), ce_loss 0.611, lat_loss 6.688
09/19 08:37:03 PM | Valid: [147/180] Step 250/312 Loss 0.741 Prec@(1,3) (82.3%, 98.4%), ce_loss 0.611, lat_loss 6.688
09/19 08:37:08 PM | Valid: [147/180] Step 300/312 Loss 0.731 Prec@(1,3) (82.5%, 98.5%), ce_loss 0.611, lat_loss 6.688
09/19 08:37:09 PM | Valid: [147/180] Step 312/312 Loss 0.726 Prec@(1,3) (82.6%, 98.5%), ce_loss 0.611, lat_loss 6.688
09/19 08:37:09 PM | val: [147/180] Final Prec@1 82.5600% Time 30.14
09/19 08:37:09 PM | Start to train weights for epoch 147
09/19 08:37:35 PM | Train: [148/180] Step 050/1249 Loss 0.329 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.611, lat_loss 6.688
09/19 08:38:00 PM | Train: [148/180] Step 100/1249 Loss 0.322 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.611, lat_loss 6.688
09/19 08:38:25 PM | Train: [148/180] Step 150/1249 Loss 0.318 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.611, lat_loss 6.688
09/19 08:38:50 PM | Train: [148/180] Step 200/1249 Loss 0.325 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.611, lat_loss 6.688
09/19 08:39:14 PM | Train: [148/180] Step 250/1249 Loss 0.332 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.611, lat_loss 6.688
09/19 08:39:39 PM | Train: [148/180] Step 300/1249 Loss 0.335 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.610, lat_loss 6.688
09/19 08:40:04 PM | Train: [148/180] Step 350/1249 Loss 0.330 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.610, lat_loss 6.688
09/19 08:40:28 PM | Train: [148/180] Step 400/1249 Loss 0.338 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.610, lat_loss 6.688
09/19 08:40:53 PM | Train: [148/180] Step 450/1249 Loss 0.342 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.610, lat_loss 6.688
09/19 08:41:18 PM | Train: [148/180] Step 500/1249 Loss 0.340 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.610, lat_loss 6.688
09/19 08:41:42 PM | Train: [148/180] Step 550/1249 Loss 0.343 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.610, lat_loss 6.688
09/19 08:42:07 PM | Train: [148/180] Step 600/1249 Loss 0.345 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.610, lat_loss 6.688
09/19 08:42:31 PM | Train: [148/180] Step 650/1249 Loss 0.345 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.610, lat_loss 6.688
09/19 08:42:56 PM | Train: [148/180] Step 700/1249 Loss 0.339 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.610, lat_loss 6.688
09/19 08:43:21 PM | Train: [148/180] Step 750/1249 Loss 0.346 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.610, lat_loss 6.688
09/19 08:43:45 PM | Train: [148/180] Step 800/1249 Loss 0.347 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.610, lat_loss 6.688
09/19 08:44:10 PM | Train: [148/180] Step 850/1249 Loss 0.347 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.610, lat_loss 6.688
09/19 08:44:35 PM | Train: [148/180] Step 900/1249 Loss 0.346 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.610, lat_loss 6.688
09/19 08:45:00 PM | Train: [148/180] Step 950/1249 Loss 0.344 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.610, lat_loss 6.688
09/19 08:45:24 PM | Train: [148/180] Step 1000/1249 Loss 0.343 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.610, lat_loss 6.688
09/19 08:45:49 PM | Train: [148/180] Step 1050/1249 Loss 0.343 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.610, lat_loss 6.688
09/19 08:46:13 PM | Train: [148/180] Step 1100/1249 Loss 0.346 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.609, lat_loss 6.688
09/19 08:46:38 PM | Train: [148/180] Step 1150/1249 Loss 0.345 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.609, lat_loss 6.688
09/19 08:47:03 PM | Train: [148/180] Step 1200/1249 Loss 0.344 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.609, lat_loss 6.688
09/19 08:47:27 PM | Train: [148/180] Step 1249/1249 Loss 0.343 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.609, lat_loss 6.688
09/19 08:47:27 PM | _w_step_train: [148/180] Final Prec@1 91.3250% Time 617.62
09/19 08:47:27 PM | Start to train theta for epoch 147
09/19 08:47:48 PM | Train: [148/180] Step 050/312 Loss 0.604 Prec@(1,3) (85.5%, 99.6%), ce_loss 0.609, lat_loss 6.688
09/19 08:48:09 PM | Train: [148/180] Step 100/312 Loss 0.586 Prec@(1,3) (86.0%, 99.5%), ce_loss 0.609, lat_loss 6.688
09/19 08:48:29 PM | Train: [148/180] Step 150/312 Loss 0.620 Prec@(1,3) (85.4%, 99.4%), ce_loss 0.609, lat_loss 6.688
09/19 08:48:50 PM | Train: [148/180] Step 200/312 Loss 0.602 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.609, lat_loss 6.688
09/19 08:49:10 PM | Train: [148/180] Step 250/312 Loss 0.607 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.609, lat_loss 6.688
09/19 08:49:31 PM | Train: [148/180] Step 300/312 Loss 0.609 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.609, lat_loss 6.688
09/19 08:49:36 PM | Train: [148/180] Step 312/312 Loss 0.605 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.609, lat_loss 6.688
09/19 08:49:36 PM | _theta_step_train: [148/180] Final Prec@1 85.7900% Time 129.33
09/19 08:49:42 PM | Valid: [148/180] Step 050/312 Loss 0.722 Prec@(1,3) (83.0%, 98.2%), ce_loss 0.609, lat_loss 6.688
09/19 08:49:46 PM | Valid: [148/180] Step 100/312 Loss 0.814 Prec@(1,3) (82.4%, 97.4%), ce_loss 0.609, lat_loss 6.688
09/19 08:49:51 PM | Valid: [148/180] Step 150/312 Loss 0.802 Prec@(1,3) (82.4%, 97.6%), ce_loss 0.609, lat_loss 6.688
09/19 08:49:55 PM | Valid: [148/180] Step 200/312 Loss 0.812 Prec@(1,3) (81.7%, 97.7%), ce_loss 0.609, lat_loss 6.688
09/19 08:50:00 PM | Valid: [148/180] Step 250/312 Loss 0.792 Prec@(1,3) (81.8%, 97.9%), ce_loss 0.609, lat_loss 6.688
09/19 08:50:05 PM | Valid: [148/180] Step 300/312 Loss 0.757 Prec@(1,3) (82.5%, 98.1%), ce_loss 0.609, lat_loss 6.688
09/19 08:50:06 PM | Valid: [148/180] Step 312/312 Loss 0.747 Prec@(1,3) (82.7%, 98.2%), ce_loss 0.609, lat_loss 6.688
09/19 08:50:06 PM | val: [148/180] Final Prec@1 82.6900% Time 29.62
09/19 08:50:06 PM | Start to train weights for epoch 148
09/19 08:50:32 PM | Train: [149/180] Step 050/1249 Loss 0.366 Prec@(1,3) (91.3%, 99.9%), ce_loss 0.609, lat_loss 6.688
09/19 08:50:57 PM | Train: [149/180] Step 100/1249 Loss 0.361 Prec@(1,3) (91.1%, 99.8%), ce_loss 0.609, lat_loss 6.688
09/19 08:51:22 PM | Train: [149/180] Step 150/1249 Loss 0.344 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.609, lat_loss 6.688
09/19 08:51:47 PM | Train: [149/180] Step 200/1249 Loss 0.343 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.609, lat_loss 6.688
09/19 08:52:11 PM | Train: [149/180] Step 250/1249 Loss 0.347 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.609, lat_loss 6.688
09/19 08:52:35 PM | Train: [149/180] Step 300/1249 Loss 0.338 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.609, lat_loss 6.688
09/19 08:52:59 PM | Train: [149/180] Step 350/1249 Loss 0.337 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.609, lat_loss 6.688
09/19 08:53:24 PM | Train: [149/180] Step 400/1249 Loss 0.361 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.609, lat_loss 6.688
09/19 08:53:48 PM | Train: [149/180] Step 450/1249 Loss 0.363 Prec@(1,3) (91.0%, 99.6%), ce_loss 0.608, lat_loss 6.688
09/19 08:54:12 PM | Train: [149/180] Step 500/1249 Loss 0.359 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.608, lat_loss 6.688
09/19 08:54:36 PM | Train: [149/180] Step 550/1249 Loss 0.352 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.608, lat_loss 6.688
09/19 08:55:01 PM | Train: [149/180] Step 600/1249 Loss 0.355 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.608, lat_loss 6.688
09/19 08:55:26 PM | Train: [149/180] Step 650/1249 Loss 0.351 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.608, lat_loss 6.688
09/19 08:55:51 PM | Train: [149/180] Step 700/1249 Loss 0.352 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.608, lat_loss 6.688
09/19 08:56:15 PM | Train: [149/180] Step 750/1249 Loss 0.350 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.608, lat_loss 6.688
09/19 08:56:40 PM | Train: [149/180] Step 800/1249 Loss 0.346 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.608, lat_loss 6.688
09/19 08:57:04 PM | Train: [149/180] Step 850/1249 Loss 0.343 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.608, lat_loss 6.688
09/19 08:57:29 PM | Train: [149/180] Step 900/1249 Loss 0.344 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.608, lat_loss 6.688
09/19 08:57:53 PM | Train: [149/180] Step 950/1249 Loss 0.341 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.608, lat_loss 6.688
09/19 08:58:17 PM | Train: [149/180] Step 1000/1249 Loss 0.342 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.608, lat_loss 6.688
09/19 08:58:42 PM | Train: [149/180] Step 1050/1249 Loss 0.343 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.608, lat_loss 6.688
09/19 08:59:06 PM | Train: [149/180] Step 1100/1249 Loss 0.344 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.608, lat_loss 6.688
09/19 08:59:31 PM | Train: [149/180] Step 1150/1249 Loss 0.344 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.608, lat_loss 6.688
09/19 08:59:55 PM | Train: [149/180] Step 1200/1249 Loss 0.344 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.607, lat_loss 6.688
09/19 09:00:20 PM | Train: [149/180] Step 1249/1249 Loss 0.342 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.607, lat_loss 6.688
09/19 09:00:20 PM | _w_step_train: [149/180] Final Prec@1 91.4225% Time 613.81
09/19 09:00:20 PM | Start to train theta for epoch 148
09/19 09:00:41 PM | Train: [149/180] Step 050/312 Loss 0.574 Prec@(1,3) (85.7%, 99.4%), ce_loss 0.607, lat_loss 6.688
09/19 09:01:00 PM | Train: [149/180] Step 100/312 Loss 0.571 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.607, lat_loss 6.688
09/19 09:01:20 PM | Train: [149/180] Step 150/312 Loss 0.562 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.607, lat_loss 6.688
09/19 09:01:40 PM | Train: [149/180] Step 200/312 Loss 0.573 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.607, lat_loss 6.688
09/19 09:02:00 PM | Train: [149/180] Step 250/312 Loss 0.568 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.607, lat_loss 6.688
09/19 09:02:20 PM | Train: [149/180] Step 300/312 Loss 0.594 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.607, lat_loss 6.688
09/19 09:02:25 PM | Train: [149/180] Step 312/312 Loss 0.592 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.607, lat_loss 6.688
09/19 09:02:25 PM | _theta_step_train: [149/180] Final Prec@1 85.7800% Time 125.36
09/19 09:02:30 PM | Valid: [149/180] Step 050/312 Loss 0.732 Prec@(1,3) (81.6%, 99.0%), ce_loss 0.607, lat_loss 6.688
09/19 09:02:35 PM | Valid: [149/180] Step 100/312 Loss 0.663 Prec@(1,3) (84.3%, 99.1%), ce_loss 0.607, lat_loss 6.688
09/19 09:02:40 PM | Valid: [149/180] Step 150/312 Loss 0.683 Prec@(1,3) (84.2%, 98.9%), ce_loss 0.607, lat_loss 6.688
09/19 09:02:44 PM | Valid: [149/180] Step 200/312 Loss 0.726 Prec@(1,3) (83.3%, 98.5%), ce_loss 0.607, lat_loss 6.688
09/19 09:02:49 PM | Valid: [149/180] Step 250/312 Loss 0.732 Prec@(1,3) (82.6%, 98.7%), ce_loss 0.607, lat_loss 6.688
09/19 09:02:54 PM | Valid: [149/180] Step 300/312 Loss 0.730 Prec@(1,3) (82.4%, 98.7%), ce_loss 0.607, lat_loss 6.688
09/19 09:02:55 PM | Valid: [149/180] Step 312/312 Loss 0.722 Prec@(1,3) (82.6%, 98.7%), ce_loss 0.607, lat_loss 6.688
09/19 09:02:55 PM | val: [149/180] Final Prec@1 82.6000% Time 29.79
09/19 09:02:55 PM | Start to train weights for epoch 149
09/19 09:03:20 PM | Train: [150/180] Step 050/1249 Loss 0.323 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.607, lat_loss 6.688
09/19 09:03:45 PM | Train: [150/180] Step 100/1249 Loss 0.315 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.607, lat_loss 6.688
09/19 09:04:10 PM | Train: [150/180] Step 150/1249 Loss 0.328 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.607, lat_loss 6.688
09/19 09:04:35 PM | Train: [150/180] Step 200/1249 Loss 0.331 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.607, lat_loss 6.688
09/19 09:05:00 PM | Train: [150/180] Step 250/1249 Loss 0.336 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.607, lat_loss 6.688
09/19 09:05:24 PM | Train: [150/180] Step 300/1249 Loss 0.339 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.607, lat_loss 6.688
09/19 09:05:49 PM | Train: [150/180] Step 350/1249 Loss 0.332 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.607, lat_loss 6.688
09/19 09:06:14 PM | Train: [150/180] Step 400/1249 Loss 0.330 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.607, lat_loss 6.688
09/19 09:06:39 PM | Train: [150/180] Step 450/1249 Loss 0.327 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.607, lat_loss 6.688
09/19 09:07:03 PM | Train: [150/180] Step 500/1249 Loss 0.325 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.606, lat_loss 6.688
09/19 09:07:27 PM | Train: [150/180] Step 550/1249 Loss 0.326 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.606, lat_loss 6.688
09/19 09:07:50 PM | Train: [150/180] Step 600/1249 Loss 0.323 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.606, lat_loss 6.688
09/19 09:08:13 PM | Train: [150/180] Step 650/1249 Loss 0.328 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.606, lat_loss 6.688
09/19 09:08:34 PM | Train: [150/180] Step 700/1249 Loss 0.325 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.606, lat_loss 6.688
09/19 09:08:56 PM | Train: [150/180] Step 750/1249 Loss 0.329 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.606, lat_loss 6.688
09/19 09:09:20 PM | Train: [150/180] Step 800/1249 Loss 0.328 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.606, lat_loss 6.688
09/19 09:09:44 PM | Train: [150/180] Step 850/1249 Loss 0.327 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.606, lat_loss 6.688
09/19 09:10:07 PM | Train: [150/180] Step 900/1249 Loss 0.329 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.606, lat_loss 6.688
09/19 09:10:30 PM | Train: [150/180] Step 950/1249 Loss 0.332 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.606, lat_loss 6.688
09/19 09:10:55 PM | Train: [150/180] Step 1000/1249 Loss 0.334 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.606, lat_loss 6.688
09/19 09:11:19 PM | Train: [150/180] Step 1050/1249 Loss 0.335 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.606, lat_loss 6.688
09/19 09:11:42 PM | Train: [150/180] Step 1100/1249 Loss 0.333 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.606, lat_loss 6.688
09/19 09:12:06 PM | Train: [150/180] Step 1150/1249 Loss 0.333 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.606, lat_loss 6.688
09/19 09:12:29 PM | Train: [150/180] Step 1200/1249 Loss 0.331 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.606, lat_loss 6.688
09/19 09:12:54 PM | Train: [150/180] Step 1249/1249 Loss 0.332 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.605, lat_loss 6.688
09/19 09:12:54 PM | _w_step_train: [150/180] Final Prec@1 91.6450% Time 598.83
09/19 09:12:54 PM | Start to train theta for epoch 149
09/19 09:13:07 PM | Train: [150/180] Step 050/312 Loss 0.526 Prec@(1,3) (88.2%, 99.3%), ce_loss 0.605, lat_loss 6.688
09/19 09:13:19 PM | Train: [150/180] Step 100/312 Loss 0.601 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.605, lat_loss 6.688
09/19 09:13:31 PM | Train: [150/180] Step 150/312 Loss 0.607 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.605, lat_loss 6.688
09/19 09:13:47 PM | Train: [150/180] Step 200/312 Loss 0.614 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.605, lat_loss 6.688
09/19 09:14:08 PM | Train: [150/180] Step 250/312 Loss 0.605 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.605, lat_loss 6.688
09/19 09:14:28 PM | Train: [150/180] Step 300/312 Loss 0.600 Prec@(1,3) (86.1%, 99.3%), ce_loss 0.605, lat_loss 6.688
09/19 09:14:33 PM | Train: [150/180] Step 312/312 Loss 0.605 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.605, lat_loss 6.688
09/19 09:14:33 PM | _theta_step_train: [150/180] Final Prec@1 85.9500% Time 99.45
09/19 09:14:39 PM | Valid: [150/180] Step 050/312 Loss 0.884 Prec@(1,3) (80.4%, 97.9%), ce_loss 0.605, lat_loss 6.688
09/19 09:14:44 PM | Valid: [150/180] Step 100/312 Loss 0.859 Prec@(1,3) (79.9%, 97.7%), ce_loss 0.605, lat_loss 6.688
09/19 09:14:48 PM | Valid: [150/180] Step 150/312 Loss 0.889 Prec@(1,3) (79.0%, 97.3%), ce_loss 0.605, lat_loss 6.688
09/19 09:14:53 PM | Valid: [150/180] Step 200/312 Loss 0.842 Prec@(1,3) (80.1%, 97.5%), ce_loss 0.605, lat_loss 6.688
09/19 09:14:58 PM | Valid: [150/180] Step 250/312 Loss 0.820 Prec@(1,3) (80.4%, 97.7%), ce_loss 0.605, lat_loss 6.688
09/19 09:15:02 PM | Valid: [150/180] Step 300/312 Loss 0.797 Prec@(1,3) (80.9%, 97.9%), ce_loss 0.605, lat_loss 6.688
09/19 09:15:03 PM | Valid: [150/180] Step 312/312 Loss 0.791 Prec@(1,3) (81.0%, 98.0%), ce_loss 0.605, lat_loss 6.688
09/19 09:15:03 PM | val: [150/180] Final Prec@1 81.0300% Time 30.20
09/19 09:15:03 PM | Start to train weights for epoch 150
09/19 09:15:25 PM | Train: [151/180] Step 050/1249 Loss 0.320 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.605, lat_loss 6.688
09/19 09:15:46 PM | Train: [151/180] Step 100/1249 Loss 0.312 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.605, lat_loss 6.688
09/19 09:16:07 PM | Train: [151/180] Step 150/1249 Loss 0.323 Prec@(1,3) (91.9%, 99.9%), ce_loss 0.605, lat_loss 6.688
09/19 09:16:28 PM | Train: [151/180] Step 200/1249 Loss 0.320 Prec@(1,3) (92.0%, 99.9%), ce_loss 0.605, lat_loss 6.688
09/19 09:16:49 PM | Train: [151/180] Step 250/1249 Loss 0.315 Prec@(1,3) (92.0%, 99.9%), ce_loss 0.605, lat_loss 6.688
09/19 09:17:10 PM | Train: [151/180] Step 300/1249 Loss 0.315 Prec@(1,3) (92.0%, 99.9%), ce_loss 0.605, lat_loss 6.688
09/19 09:17:32 PM | Train: [151/180] Step 350/1249 Loss 0.317 Prec@(1,3) (92.0%, 99.9%), ce_loss 0.605, lat_loss 6.688
09/19 09:17:53 PM | Train: [151/180] Step 400/1249 Loss 0.320 Prec@(1,3) (91.8%, 99.9%), ce_loss 0.605, lat_loss 6.688
09/19 09:18:14 PM | Train: [151/180] Step 450/1249 Loss 0.319 Prec@(1,3) (91.8%, 99.9%), ce_loss 0.605, lat_loss 6.688
09/19 09:18:35 PM | Train: [151/180] Step 500/1249 Loss 0.321 Prec@(1,3) (91.8%, 99.9%), ce_loss 0.605, lat_loss 6.688
09/19 09:18:57 PM | Train: [151/180] Step 550/1249 Loss 0.321 Prec@(1,3) (91.8%, 99.9%), ce_loss 0.605, lat_loss 6.688
09/19 09:19:17 PM | Train: [151/180] Step 600/1249 Loss 0.325 Prec@(1,3) (91.7%, 99.9%), ce_loss 0.605, lat_loss 6.688
09/19 09:19:39 PM | Train: [151/180] Step 650/1249 Loss 0.327 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.604, lat_loss 6.688
09/19 09:19:59 PM | Train: [151/180] Step 700/1249 Loss 0.333 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.604, lat_loss 6.688
09/19 09:20:20 PM | Train: [151/180] Step 750/1249 Loss 0.332 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.604, lat_loss 6.688
09/19 09:20:41 PM | Train: [151/180] Step 800/1249 Loss 0.333 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.604, lat_loss 6.688
09/19 09:21:02 PM | Train: [151/180] Step 850/1249 Loss 0.333 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.604, lat_loss 6.688
09/19 09:21:23 PM | Train: [151/180] Step 900/1249 Loss 0.333 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.604, lat_loss 6.688
09/19 09:21:44 PM | Train: [151/180] Step 950/1249 Loss 0.335 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.604, lat_loss 6.688
09/19 09:22:07 PM | Train: [151/180] Step 1000/1249 Loss 0.336 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.604, lat_loss 6.688
09/19 09:22:28 PM | Train: [151/180] Step 1050/1249 Loss 0.335 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.604, lat_loss 6.688
09/19 09:22:51 PM | Train: [151/180] Step 1100/1249 Loss 0.339 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.604, lat_loss 6.688
09/19 09:23:12 PM | Train: [151/180] Step 1150/1249 Loss 0.338 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.604, lat_loss 6.688
09/19 09:23:34 PM | Train: [151/180] Step 1200/1249 Loss 0.336 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.604, lat_loss 6.688
09/19 09:23:58 PM | Train: [151/180] Step 1249/1249 Loss 0.339 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.604, lat_loss 6.688
09/19 09:23:58 PM | _w_step_train: [151/180] Final Prec@1 91.4325% Time 534.68
09/19 09:23:58 PM | Start to train theta for epoch 150
09/19 09:24:19 PM | Train: [151/180] Step 050/312 Loss 0.578 Prec@(1,3) (86.8%, 99.5%), ce_loss 0.604, lat_loss 6.688
09/19 09:24:38 PM | Train: [151/180] Step 100/312 Loss 0.609 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.604, lat_loss 6.688
09/19 09:24:59 PM | Train: [151/180] Step 150/312 Loss 0.611 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.604, lat_loss 6.688
09/19 09:25:19 PM | Train: [151/180] Step 200/312 Loss 0.612 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.604, lat_loss 6.688
09/19 09:25:39 PM | Train: [151/180] Step 250/312 Loss 0.624 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.604, lat_loss 6.688
09/19 09:25:59 PM | Train: [151/180] Step 300/312 Loss 0.615 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.604, lat_loss 6.688
09/19 09:26:04 PM | Train: [151/180] Step 312/312 Loss 0.614 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.604, lat_loss 6.688
09/19 09:26:04 PM | _theta_step_train: [151/180] Final Prec@1 85.7400% Time 125.81
09/19 09:26:09 PM | Valid: [151/180] Step 050/312 Loss 0.957 Prec@(1,3) (74.7%, 97.7%), ce_loss 0.604, lat_loss 6.688
09/19 09:26:14 PM | Valid: [151/180] Step 100/312 Loss 0.909 Prec@(1,3) (77.4%, 97.6%), ce_loss 0.604, lat_loss 6.688
09/19 09:26:18 PM | Valid: [151/180] Step 150/312 Loss 0.838 Prec@(1,3) (79.3%, 98.0%), ce_loss 0.604, lat_loss 6.688
09/19 09:26:23 PM | Valid: [151/180] Step 200/312 Loss 0.810 Prec@(1,3) (80.3%, 98.2%), ce_loss 0.604, lat_loss 6.688
09/19 09:26:27 PM | Valid: [151/180] Step 250/312 Loss 0.783 Prec@(1,3) (80.8%, 98.3%), ce_loss 0.604, lat_loss 6.688
09/19 09:26:32 PM | Valid: [151/180] Step 300/312 Loss 0.819 Prec@(1,3) (80.1%, 97.9%), ce_loss 0.604, lat_loss 6.688
09/19 09:26:33 PM | Valid: [151/180] Step 312/312 Loss 0.810 Prec@(1,3) (80.3%, 98.0%), ce_loss 0.604, lat_loss 6.688
09/19 09:26:33 PM | val: [151/180] Final Prec@1 80.2700% Time 29.29
09/19 09:26:33 PM | Start to train weights for epoch 151
09/19 09:26:57 PM | Train: [152/180] Step 050/1249 Loss 0.324 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.603, lat_loss 6.688
09/19 09:27:20 PM | Train: [152/180] Step 100/1249 Loss 0.322 Prec@(1,3) (92.1%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:27:41 PM | Train: [152/180] Step 150/1249 Loss 0.344 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:28:05 PM | Train: [152/180] Step 200/1249 Loss 0.346 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:28:30 PM | Train: [152/180] Step 250/1249 Loss 0.353 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:28:54 PM | Train: [152/180] Step 300/1249 Loss 0.354 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:29:19 PM | Train: [152/180] Step 350/1249 Loss 0.353 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:29:43 PM | Train: [152/180] Step 400/1249 Loss 0.350 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:30:08 PM | Train: [152/180] Step 450/1249 Loss 0.344 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:30:33 PM | Train: [152/180] Step 500/1249 Loss 0.344 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:30:58 PM | Train: [152/180] Step 550/1249 Loss 0.347 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:31:23 PM | Train: [152/180] Step 600/1249 Loss 0.354 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:31:48 PM | Train: [152/180] Step 650/1249 Loss 0.350 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:32:13 PM | Train: [152/180] Step 700/1249 Loss 0.359 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:32:38 PM | Train: [152/180] Step 750/1249 Loss 0.358 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:33:02 PM | Train: [152/180] Step 800/1249 Loss 0.355 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:33:27 PM | Train: [152/180] Step 850/1249 Loss 0.357 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.603, lat_loss 6.688
09/19 09:33:52 PM | Train: [152/180] Step 900/1249 Loss 0.359 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.602, lat_loss 6.688
09/19 09:34:17 PM | Train: [152/180] Step 950/1249 Loss 0.358 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.602, lat_loss 6.688
09/19 09:34:42 PM | Train: [152/180] Step 1000/1249 Loss 0.360 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.602, lat_loss 6.688
09/19 09:35:07 PM | Train: [152/180] Step 1050/1249 Loss 0.360 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.602, lat_loss 6.688
09/19 09:35:32 PM | Train: [152/180] Step 1100/1249 Loss 0.359 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.602, lat_loss 6.688
09/19 09:35:57 PM | Train: [152/180] Step 1150/1249 Loss 0.359 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.602, lat_loss 6.688
09/19 09:36:21 PM | Train: [152/180] Step 1200/1249 Loss 0.357 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.602, lat_loss 6.688
09/19 09:36:46 PM | Train: [152/180] Step 1249/1249 Loss 0.355 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.602, lat_loss 6.688
09/19 09:36:46 PM | _w_step_train: [152/180] Final Prec@1 91.1300% Time 612.51
09/19 09:36:46 PM | Start to train theta for epoch 151
09/19 09:37:07 PM | Train: [152/180] Step 050/312 Loss 0.645 Prec@(1,3) (84.4%, 98.8%), ce_loss 0.602, lat_loss 6.688
09/19 09:37:28 PM | Train: [152/180] Step 100/312 Loss 0.619 Prec@(1,3) (85.2%, 98.9%), ce_loss 0.602, lat_loss 6.688
09/19 09:37:48 PM | Train: [152/180] Step 150/312 Loss 0.618 Prec@(1,3) (85.3%, 98.9%), ce_loss 0.602, lat_loss 6.688
09/19 09:38:09 PM | Train: [152/180] Step 200/312 Loss 0.615 Prec@(1,3) (85.3%, 98.9%), ce_loss 0.602, lat_loss 6.688
09/19 09:38:30 PM | Train: [152/180] Step 250/312 Loss 0.601 Prec@(1,3) (85.6%, 99.0%), ce_loss 0.602, lat_loss 6.688
09/19 09:38:50 PM | Train: [152/180] Step 300/312 Loss 0.615 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.602, lat_loss 6.688
09/19 09:38:55 PM | Train: [152/180] Step 312/312 Loss 0.614 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.602, lat_loss 6.688
09/19 09:38:55 PM | _theta_step_train: [152/180] Final Prec@1 85.3400% Time 129.71
09/19 09:39:01 PM | Valid: [152/180] Step 050/312 Loss 0.692 Prec@(1,3) (82.9%, 98.8%), ce_loss 0.602, lat_loss 6.688
09/19 09:39:05 PM | Valid: [152/180] Step 100/312 Loss 0.767 Prec@(1,3) (81.6%, 98.3%), ce_loss 0.602, lat_loss 6.689
09/19 09:39:10 PM | Valid: [152/180] Step 150/312 Loss 0.786 Prec@(1,3) (81.4%, 98.2%), ce_loss 0.602, lat_loss 6.689
09/19 09:39:14 PM | Valid: [152/180] Step 200/312 Loss 0.779 Prec@(1,3) (81.8%, 98.2%), ce_loss 0.602, lat_loss 6.689
09/19 09:39:19 PM | Valid: [152/180] Step 250/312 Loss 0.807 Prec@(1,3) (81.4%, 98.0%), ce_loss 0.602, lat_loss 6.689
09/19 09:39:24 PM | Valid: [152/180] Step 300/312 Loss 0.802 Prec@(1,3) (81.5%, 98.1%), ce_loss 0.602, lat_loss 6.689
09/19 09:39:25 PM | Valid: [152/180] Step 312/312 Loss 0.802 Prec@(1,3) (81.4%, 98.1%), ce_loss 0.602, lat_loss 6.689
09/19 09:39:25 PM | val: [152/180] Final Prec@1 81.4300% Time 29.57
09/19 09:39:25 PM | Start to train weights for epoch 152
09/19 09:39:42 PM | Train: [153/180] Step 050/1249 Loss 0.383 Prec@(1,3) (90.4%, 99.5%), ce_loss 0.602, lat_loss 6.689
09/19 09:39:58 PM | Train: [153/180] Step 100/1249 Loss 0.351 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.602, lat_loss 6.689
09/19 09:40:14 PM | Train: [153/180] Step 150/1249 Loss 0.345 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.602, lat_loss 6.689
09/19 09:40:30 PM | Train: [153/180] Step 200/1249 Loss 0.344 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.602, lat_loss 6.689
09/19 09:40:46 PM | Train: [153/180] Step 250/1249 Loss 0.357 Prec@(1,3) (91.0%, 99.7%), ce_loss 0.602, lat_loss 6.689
09/19 09:41:02 PM | Train: [153/180] Step 300/1249 Loss 0.356 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:41:18 PM | Train: [153/180] Step 350/1249 Loss 0.352 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:41:34 PM | Train: [153/180] Step 400/1249 Loss 0.355 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:41:50 PM | Train: [153/180] Step 450/1249 Loss 0.353 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:42:06 PM | Train: [153/180] Step 500/1249 Loss 0.352 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:42:22 PM | Train: [153/180] Step 550/1249 Loss 0.347 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:42:38 PM | Train: [153/180] Step 600/1249 Loss 0.347 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:42:54 PM | Train: [153/180] Step 650/1249 Loss 0.343 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:43:10 PM | Train: [153/180] Step 700/1249 Loss 0.343 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:43:26 PM | Train: [153/180] Step 750/1249 Loss 0.344 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:43:42 PM | Train: [153/180] Step 800/1249 Loss 0.346 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:43:58 PM | Train: [153/180] Step 850/1249 Loss 0.347 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:44:14 PM | Train: [153/180] Step 900/1249 Loss 0.346 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:44:30 PM | Train: [153/180] Step 950/1249 Loss 0.350 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:44:46 PM | Train: [153/180] Step 1000/1249 Loss 0.352 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:45:02 PM | Train: [153/180] Step 1050/1249 Loss 0.350 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:45:18 PM | Train: [153/180] Step 1100/1249 Loss 0.352 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.601, lat_loss 6.689
09/19 09:45:33 PM | Train: [153/180] Step 1150/1249 Loss 0.355 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.600, lat_loss 6.689
09/19 09:45:49 PM | Train: [153/180] Step 1200/1249 Loss 0.356 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.600, lat_loss 6.689
09/19 09:46:05 PM | Train: [153/180] Step 1249/1249 Loss 0.355 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.600, lat_loss 6.689
09/19 09:46:05 PM | _w_step_train: [153/180] Final Prec@1 91.1000% Time 399.65
09/19 09:46:05 PM | Start to train theta for epoch 152
09/19 09:46:26 PM | Train: [153/180] Step 050/312 Loss 0.588 Prec@(1,3) (86.0%, 98.9%), ce_loss 0.600, lat_loss 6.689
09/19 09:46:46 PM | Train: [153/180] Step 100/312 Loss 0.635 Prec@(1,3) (85.3%, 98.9%), ce_loss 0.600, lat_loss 6.689
09/19 09:47:06 PM | Train: [153/180] Step 150/312 Loss 0.630 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.600, lat_loss 6.689
09/19 09:47:26 PM | Train: [153/180] Step 200/312 Loss 0.632 Prec@(1,3) (85.4%, 99.0%), ce_loss 0.600, lat_loss 6.689
09/19 09:47:47 PM | Train: [153/180] Step 250/312 Loss 0.627 Prec@(1,3) (85.5%, 99.0%), ce_loss 0.600, lat_loss 6.689
09/19 09:48:07 PM | Train: [153/180] Step 300/312 Loss 0.627 Prec@(1,3) (85.4%, 99.0%), ce_loss 0.600, lat_loss 6.689
09/19 09:48:12 PM | Train: [153/180] Step 312/312 Loss 0.630 Prec@(1,3) (85.4%, 99.0%), ce_loss 0.600, lat_loss 6.689
09/19 09:48:12 PM | _theta_step_train: [153/180] Final Prec@1 85.3500% Time 127.44
09/19 09:48:18 PM | Valid: [153/180] Step 050/312 Loss 0.929 Prec@(1,3) (79.8%, 96.4%), ce_loss 0.600, lat_loss 6.689
09/19 09:48:23 PM | Valid: [153/180] Step 100/312 Loss 0.987 Prec@(1,3) (79.3%, 96.3%), ce_loss 0.600, lat_loss 6.689
09/19 09:48:27 PM | Valid: [153/180] Step 150/312 Loss 0.923 Prec@(1,3) (79.2%, 97.0%), ce_loss 0.600, lat_loss 6.689
09/19 09:48:32 PM | Valid: [153/180] Step 200/312 Loss 0.866 Prec@(1,3) (80.3%, 97.5%), ce_loss 0.600, lat_loss 6.689
09/19 09:48:36 PM | Valid: [153/180] Step 250/312 Loss 0.840 Prec@(1,3) (80.6%, 97.8%), ce_loss 0.600, lat_loss 6.689
09/19 09:48:41 PM | Valid: [153/180] Step 300/312 Loss 0.830 Prec@(1,3) (80.8%, 97.8%), ce_loss 0.600, lat_loss 6.689
09/19 09:48:42 PM | Valid: [153/180] Step 312/312 Loss 0.834 Prec@(1,3) (80.8%, 97.8%), ce_loss 0.600, lat_loss 6.689
09/19 09:48:42 PM | val: [153/180] Final Prec@1 80.7500% Time 30.01
09/19 09:48:42 PM | Start to train weights for epoch 153
09/19 09:49:08 PM | Train: [154/180] Step 050/1249 Loss 0.310 Prec@(1,3) (91.5%, 99.9%), ce_loss 0.600, lat_loss 6.689
09/19 09:49:33 PM | Train: [154/180] Step 100/1249 Loss 0.358 Prec@(1,3) (90.9%, 99.8%), ce_loss 0.600, lat_loss 6.689
09/19 09:49:57 PM | Train: [154/180] Step 150/1249 Loss 0.357 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.600, lat_loss 6.689
09/19 09:50:22 PM | Train: [154/180] Step 200/1249 Loss 0.335 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.600, lat_loss 6.689
09/19 09:50:47 PM | Train: [154/180] Step 250/1249 Loss 0.333 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.600, lat_loss 6.689
09/19 09:51:11 PM | Train: [154/180] Step 300/1249 Loss 0.340 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.600, lat_loss 6.689
09/19 09:51:36 PM | Train: [154/180] Step 350/1249 Loss 0.334 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.600, lat_loss 6.689
09/19 09:52:00 PM | Train: [154/180] Step 400/1249 Loss 0.337 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.600, lat_loss 6.689
09/19 09:52:25 PM | Train: [154/180] Step 450/1249 Loss 0.339 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.600, lat_loss 6.689
09/19 09:52:50 PM | Train: [154/180] Step 500/1249 Loss 0.341 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.600, lat_loss 6.689
09/19 09:53:14 PM | Train: [154/180] Step 550/1249 Loss 0.341 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.600, lat_loss 6.689
09/19 09:53:37 PM | Train: [154/180] Step 600/1249 Loss 0.349 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.599, lat_loss 6.689
09/19 09:54:02 PM | Train: [154/180] Step 650/1249 Loss 0.350 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.599, lat_loss 6.689
09/19 09:54:27 PM | Train: [154/180] Step 700/1249 Loss 0.346 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.599, lat_loss 6.689
09/19 09:54:51 PM | Train: [154/180] Step 750/1249 Loss 0.344 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.599, lat_loss 6.689
09/19 09:55:15 PM | Train: [154/180] Step 800/1249 Loss 0.342 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.599, lat_loss 6.689
09/19 09:55:40 PM | Train: [154/180] Step 850/1249 Loss 0.342 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.599, lat_loss 6.689
09/19 09:56:05 PM | Train: [154/180] Step 900/1249 Loss 0.349 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.599, lat_loss 6.689
09/19 09:56:29 PM | Train: [154/180] Step 950/1249 Loss 0.346 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.599, lat_loss 6.689
09/19 09:56:53 PM | Train: [154/180] Step 1000/1249 Loss 0.346 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.599, lat_loss 6.689
09/19 09:57:16 PM | Train: [154/180] Step 1050/1249 Loss 0.348 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.599, lat_loss 6.689
09/19 09:57:39 PM | Train: [154/180] Step 1100/1249 Loss 0.346 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.599, lat_loss 6.689
09/19 09:58:04 PM | Train: [154/180] Step 1150/1249 Loss 0.349 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.599, lat_loss 6.689
09/19 09:58:27 PM | Train: [154/180] Step 1200/1249 Loss 0.348 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.599, lat_loss 6.689
09/19 09:58:49 PM | Train: [154/180] Step 1249/1249 Loss 0.349 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.599, lat_loss 6.689
09/19 09:58:49 PM | _w_step_train: [154/180] Final Prec@1 91.3850% Time 606.69
09/19 09:58:49 PM | Start to train theta for epoch 153
09/19 09:59:08 PM | Train: [154/180] Step 050/312 Loss 0.684 Prec@(1,3) (85.0%, 99.0%), ce_loss 0.599, lat_loss 6.689
09/19 09:59:29 PM | Train: [154/180] Step 100/312 Loss 0.601 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.599, lat_loss 6.689
09/19 09:59:49 PM | Train: [154/180] Step 150/312 Loss 0.614 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.599, lat_loss 6.689
09/19 10:00:09 PM | Train: [154/180] Step 200/312 Loss 0.609 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.599, lat_loss 6.689
09/19 10:00:29 PM | Train: [154/180] Step 250/312 Loss 0.606 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.599, lat_loss 6.689
09/19 10:00:50 PM | Train: [154/180] Step 300/312 Loss 0.609 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.599, lat_loss 6.689
09/19 10:00:55 PM | Train: [154/180] Step 312/312 Loss 0.614 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.599, lat_loss 6.689
09/19 10:00:55 PM | _theta_step_train: [154/180] Final Prec@1 85.3400% Time 126.32
09/19 10:01:00 PM | Valid: [154/180] Step 050/312 Loss 0.969 Prec@(1,3) (77.0%, 96.0%), ce_loss 0.599, lat_loss 6.689
09/19 10:01:05 PM | Valid: [154/180] Step 100/312 Loss 0.974 Prec@(1,3) (76.1%, 95.9%), ce_loss 0.599, lat_loss 6.689
09/19 10:01:10 PM | Valid: [154/180] Step 150/312 Loss 0.897 Prec@(1,3) (78.4%, 96.8%), ce_loss 0.599, lat_loss 6.689
09/19 10:01:14 PM | Valid: [154/180] Step 200/312 Loss 0.847 Prec@(1,3) (79.9%, 97.1%), ce_loss 0.599, lat_loss 6.689
09/19 10:01:19 PM | Valid: [154/180] Step 250/312 Loss 0.815 Prec@(1,3) (80.4%, 97.5%), ce_loss 0.599, lat_loss 6.689
09/19 10:01:23 PM | Valid: [154/180] Step 300/312 Loss 0.792 Prec@(1,3) (80.7%, 97.7%), ce_loss 0.599, lat_loss 6.689
09/19 10:01:24 PM | Valid: [154/180] Step 312/312 Loss 0.781 Prec@(1,3) (80.9%, 97.8%), ce_loss 0.599, lat_loss 6.689
09/19 10:01:25 PM | val: [154/180] Final Prec@1 80.8900% Time 29.24
09/19 10:01:25 PM | Start to train weights for epoch 154
09/19 10:01:51 PM | Train: [155/180] Step 050/1249 Loss 0.324 Prec@(1,3) (92.6%, 99.9%), ce_loss 0.598, lat_loss 6.689
09/19 10:02:16 PM | Train: [155/180] Step 100/1249 Loss 0.344 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.598, lat_loss 6.689
09/19 10:02:41 PM | Train: [155/180] Step 150/1249 Loss 0.326 Prec@(1,3) (92.3%, 99.7%), ce_loss 0.598, lat_loss 6.689
09/19 10:03:06 PM | Train: [155/180] Step 200/1249 Loss 0.341 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.598, lat_loss 6.689
09/19 10:03:31 PM | Train: [155/180] Step 250/1249 Loss 0.347 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.598, lat_loss 6.689
09/19 10:03:55 PM | Train: [155/180] Step 300/1249 Loss 0.341 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.598, lat_loss 6.689
09/19 10:04:21 PM | Train: [155/180] Step 350/1249 Loss 0.339 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.598, lat_loss 6.689
09/19 10:04:46 PM | Train: [155/180] Step 400/1249 Loss 0.334 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.598, lat_loss 6.689
09/19 10:05:10 PM | Train: [155/180] Step 450/1249 Loss 0.343 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.598, lat_loss 6.689
09/19 10:05:35 PM | Train: [155/180] Step 500/1249 Loss 0.337 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.598, lat_loss 6.689
09/19 10:06:00 PM | Train: [155/180] Step 550/1249 Loss 0.341 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.598, lat_loss 6.689
09/19 10:06:25 PM | Train: [155/180] Step 600/1249 Loss 0.338 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.598, lat_loss 6.689
09/19 10:06:50 PM | Train: [155/180] Step 650/1249 Loss 0.341 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.598, lat_loss 6.689
09/19 10:07:15 PM | Train: [155/180] Step 700/1249 Loss 0.341 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.598, lat_loss 6.689
09/19 10:07:40 PM | Train: [155/180] Step 750/1249 Loss 0.339 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.598, lat_loss 6.689
09/19 10:08:05 PM | Train: [155/180] Step 800/1249 Loss 0.340 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.598, lat_loss 6.689
09/19 10:08:30 PM | Train: [155/180] Step 850/1249 Loss 0.337 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:08:54 PM | Train: [155/180] Step 900/1249 Loss 0.337 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:09:19 PM | Train: [155/180] Step 950/1249 Loss 0.338 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:09:43 PM | Train: [155/180] Step 1000/1249 Loss 0.338 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:10:07 PM | Train: [155/180] Step 1050/1249 Loss 0.339 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:10:31 PM | Train: [155/180] Step 1100/1249 Loss 0.337 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:10:55 PM | Train: [155/180] Step 1150/1249 Loss 0.337 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:11:19 PM | Train: [155/180] Step 1200/1249 Loss 0.339 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.597, lat_loss 6.689
09/19 10:11:43 PM | Train: [155/180] Step 1249/1249 Loss 0.336 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:11:43 PM | _w_step_train: [155/180] Final Prec@1 91.5325% Time 618.38
09/19 10:11:43 PM | Start to train theta for epoch 154
09/19 10:12:02 PM | Train: [155/180] Step 050/312 Loss 0.631 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.597, lat_loss 6.689
09/19 10:12:19 PM | Train: [155/180] Step 100/312 Loss 0.641 Prec@(1,3) (84.7%, 99.0%), ce_loss 0.597, lat_loss 6.689
09/19 10:12:38 PM | Train: [155/180] Step 150/312 Loss 0.635 Prec@(1,3) (85.2%, 98.9%), ce_loss 0.597, lat_loss 6.689
09/19 10:12:57 PM | Train: [155/180] Step 200/312 Loss 0.608 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.597, lat_loss 6.689
09/19 10:13:17 PM | Train: [155/180] Step 250/312 Loss 0.597 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.597, lat_loss 6.689
09/19 10:13:37 PM | Train: [155/180] Step 300/312 Loss 0.605 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.597, lat_loss 6.689
09/19 10:13:42 PM | Train: [155/180] Step 312/312 Loss 0.607 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.597, lat_loss 6.689
09/19 10:13:42 PM | _theta_step_train: [155/180] Final Prec@1 85.7500% Time 118.87
09/19 10:13:48 PM | Valid: [155/180] Step 050/312 Loss 0.658 Prec@(1,3) (84.5%, 98.3%), ce_loss 0.597, lat_loss 6.689
09/19 10:13:52 PM | Valid: [155/180] Step 100/312 Loss 0.788 Prec@(1,3) (82.1%, 97.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:13:57 PM | Valid: [155/180] Step 150/312 Loss 0.875 Prec@(1,3) (80.2%, 97.2%), ce_loss 0.597, lat_loss 6.689
09/19 10:14:02 PM | Valid: [155/180] Step 200/312 Loss 0.936 Prec@(1,3) (79.2%, 96.7%), ce_loss 0.597, lat_loss 6.689
09/19 10:14:06 PM | Valid: [155/180] Step 250/312 Loss 0.929 Prec@(1,3) (79.1%, 96.6%), ce_loss 0.597, lat_loss 6.689
09/19 10:14:11 PM | Valid: [155/180] Step 300/312 Loss 0.927 Prec@(1,3) (79.3%, 96.7%), ce_loss 0.597, lat_loss 6.689
09/19 10:14:12 PM | Valid: [155/180] Step 312/312 Loss 0.923 Prec@(1,3) (79.3%, 96.7%), ce_loss 0.597, lat_loss 6.689
09/19 10:14:12 PM | val: [155/180] Final Prec@1 79.2800% Time 30.33
09/19 10:14:12 PM | Start to train weights for epoch 155
09/19 10:14:29 PM | Train: [156/180] Step 050/1249 Loss 0.372 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:14:45 PM | Train: [156/180] Step 100/1249 Loss 0.337 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:15:01 PM | Train: [156/180] Step 150/1249 Loss 0.324 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:15:17 PM | Train: [156/180] Step 200/1249 Loss 0.319 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:15:33 PM | Train: [156/180] Step 250/1249 Loss 0.322 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:15:49 PM | Train: [156/180] Step 300/1249 Loss 0.319 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:16:05 PM | Train: [156/180] Step 350/1249 Loss 0.319 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.597, lat_loss 6.689
09/19 10:16:20 PM | Train: [156/180] Step 400/1249 Loss 0.319 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.596, lat_loss 6.689
09/19 10:16:43 PM | Train: [156/180] Step 450/1249 Loss 0.322 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.596, lat_loss 6.689
09/19 10:17:08 PM | Train: [156/180] Step 500/1249 Loss 0.320 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.596, lat_loss 6.689
09/19 10:17:33 PM | Train: [156/180] Step 550/1249 Loss 0.327 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.596, lat_loss 6.689
09/19 10:17:54 PM | Train: [156/180] Step 600/1249 Loss 0.327 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.596, lat_loss 6.689
09/19 10:18:15 PM | Train: [156/180] Step 650/1249 Loss 0.330 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.596, lat_loss 6.689
09/19 10:18:37 PM | Train: [156/180] Step 700/1249 Loss 0.327 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.596, lat_loss 6.689
09/19 10:19:00 PM | Train: [156/180] Step 750/1249 Loss 0.327 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.596, lat_loss 6.689
09/19 10:19:25 PM | Train: [156/180] Step 800/1249 Loss 0.334 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.596, lat_loss 6.689
09/19 10:19:50 PM | Train: [156/180] Step 850/1249 Loss 0.337 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.596, lat_loss 6.689
09/19 10:20:14 PM | Train: [156/180] Step 900/1249 Loss 0.339 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.596, lat_loss 6.689
09/19 10:20:39 PM | Train: [156/180] Step 950/1249 Loss 0.339 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.596, lat_loss 6.689
09/19 10:21:04 PM | Train: [156/180] Step 1000/1249 Loss 0.340 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.596, lat_loss 6.689
09/19 10:21:29 PM | Train: [156/180] Step 1050/1249 Loss 0.340 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.596, lat_loss 6.689
09/19 10:21:53 PM | Train: [156/180] Step 1100/1249 Loss 0.342 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.596, lat_loss 6.689
09/19 10:22:18 PM | Train: [156/180] Step 1150/1249 Loss 0.343 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.596, lat_loss 6.689
09/19 10:22:42 PM | Train: [156/180] Step 1200/1249 Loss 0.344 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.596, lat_loss 6.689
09/19 10:23:06 PM | Train: [156/180] Step 1249/1249 Loss 0.344 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.595, lat_loss 6.689
09/19 10:23:06 PM | _w_step_train: [156/180] Final Prec@1 91.4250% Time 533.96
09/19 10:23:06 PM | Start to train theta for epoch 155
09/19 10:23:26 PM | Train: [156/180] Step 050/312 Loss 0.695 Prec@(1,3) (85.8%, 98.5%), ce_loss 0.595, lat_loss 6.689
09/19 10:23:47 PM | Train: [156/180] Step 100/312 Loss 0.644 Prec@(1,3) (85.8%, 98.8%), ce_loss 0.595, lat_loss 6.689
09/19 10:24:07 PM | Train: [156/180] Step 150/312 Loss 0.621 Prec@(1,3) (85.9%, 98.9%), ce_loss 0.595, lat_loss 6.689
09/19 10:24:27 PM | Train: [156/180] Step 200/312 Loss 0.611 Prec@(1,3) (85.9%, 98.9%), ce_loss 0.595, lat_loss 6.689
09/19 10:24:47 PM | Train: [156/180] Step 250/312 Loss 0.610 Prec@(1,3) (85.8%, 99.0%), ce_loss 0.595, lat_loss 6.689
09/19 10:25:08 PM | Train: [156/180] Step 300/312 Loss 0.623 Prec@(1,3) (85.6%, 99.0%), ce_loss 0.595, lat_loss 6.689
09/19 10:25:13 PM | Train: [156/180] Step 312/312 Loss 0.620 Prec@(1,3) (85.6%, 99.0%), ce_loss 0.595, lat_loss 6.689
09/19 10:25:13 PM | _theta_step_train: [156/180] Final Prec@1 85.6400% Time 126.85
09/19 10:25:18 PM | Valid: [156/180] Step 050/312 Loss 0.642 Prec@(1,3) (84.1%, 99.3%), ce_loss 0.595, lat_loss 6.689
09/19 10:25:23 PM | Valid: [156/180] Step 100/312 Loss 0.744 Prec@(1,3) (82.6%, 98.5%), ce_loss 0.595, lat_loss 6.689
09/19 10:25:27 PM | Valid: [156/180] Step 150/312 Loss 0.758 Prec@(1,3) (82.5%, 98.5%), ce_loss 0.595, lat_loss 6.689
09/19 10:25:31 PM | Valid: [156/180] Step 200/312 Loss 0.831 Prec@(1,3) (81.4%, 97.9%), ce_loss 0.595, lat_loss 6.689
09/19 10:25:35 PM | Valid: [156/180] Step 250/312 Loss 0.837 Prec@(1,3) (81.1%, 98.0%), ce_loss 0.595, lat_loss 6.689
09/19 10:25:40 PM | Valid: [156/180] Step 300/312 Loss 0.818 Prec@(1,3) (81.4%, 98.1%), ce_loss 0.595, lat_loss 6.689
09/19 10:25:41 PM | Valid: [156/180] Step 312/312 Loss 0.808 Prec@(1,3) (81.5%, 98.2%), ce_loss 0.595, lat_loss 6.689
09/19 10:25:41 PM | val: [156/180] Final Prec@1 81.4900% Time 27.85
09/19 10:25:41 PM | Start to train weights for epoch 156
09/19 10:26:07 PM | Train: [157/180] Step 050/1249 Loss 0.331 Prec@(1,3) (91.8%, 99.6%), ce_loss 0.595, lat_loss 6.689
09/19 10:26:32 PM | Train: [157/180] Step 100/1249 Loss 0.329 Prec@(1,3) (92.0%, 99.6%), ce_loss 0.595, lat_loss 6.689
09/19 10:26:57 PM | Train: [157/180] Step 150/1249 Loss 0.339 Prec@(1,3) (91.7%, 99.6%), ce_loss 0.595, lat_loss 6.689
09/19 10:27:22 PM | Train: [157/180] Step 200/1249 Loss 0.329 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.595, lat_loss 6.689
09/19 10:27:47 PM | Train: [157/180] Step 250/1249 Loss 0.355 Prec@(1,3) (91.1%, 99.6%), ce_loss 0.595, lat_loss 6.689
09/19 10:28:11 PM | Train: [157/180] Step 300/1249 Loss 0.348 Prec@(1,3) (91.3%, 99.6%), ce_loss 0.595, lat_loss 6.689
09/19 10:28:36 PM | Train: [157/180] Step 350/1249 Loss 0.350 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.595, lat_loss 6.689
09/19 10:29:00 PM | Train: [157/180] Step 400/1249 Loss 0.345 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.595, lat_loss 6.689
09/19 10:29:25 PM | Train: [157/180] Step 450/1249 Loss 0.341 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.595, lat_loss 6.689
09/19 10:29:50 PM | Train: [157/180] Step 500/1249 Loss 0.340 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.595, lat_loss 6.689
09/19 10:30:15 PM | Train: [157/180] Step 550/1249 Loss 0.342 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.595, lat_loss 6.689
09/19 10:30:40 PM | Train: [157/180] Step 600/1249 Loss 0.344 Prec@(1,3) (91.3%, 99.6%), ce_loss 0.595, lat_loss 6.689
09/19 10:31:05 PM | Train: [157/180] Step 650/1249 Loss 0.346 Prec@(1,3) (91.2%, 99.6%), ce_loss 0.595, lat_loss 6.689
09/19 10:31:30 PM | Train: [157/180] Step 700/1249 Loss 0.348 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.594, lat_loss 6.689
09/19 10:31:55 PM | Train: [157/180] Step 750/1249 Loss 0.350 Prec@(1,3) (91.3%, 99.6%), ce_loss 0.594, lat_loss 6.689
09/19 10:32:20 PM | Train: [157/180] Step 800/1249 Loss 0.351 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.594, lat_loss 6.689
09/19 10:32:44 PM | Train: [157/180] Step 850/1249 Loss 0.350 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.594, lat_loss 6.689
09/19 10:33:07 PM | Train: [157/180] Step 900/1249 Loss 0.348 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.594, lat_loss 6.689
09/19 10:33:30 PM | Train: [157/180] Step 950/1249 Loss 0.349 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.594, lat_loss 6.689
09/19 10:33:51 PM | Train: [157/180] Step 1000/1249 Loss 0.349 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.594, lat_loss 6.689
09/19 10:34:13 PM | Train: [157/180] Step 1050/1249 Loss 0.350 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.594, lat_loss 6.689
09/19 10:34:33 PM | Train: [157/180] Step 1100/1249 Loss 0.348 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.594, lat_loss 6.689
09/19 10:34:55 PM | Train: [157/180] Step 1150/1249 Loss 0.350 Prec@(1,3) (91.2%, 99.7%), ce_loss 0.594, lat_loss 6.689
09/19 10:35:17 PM | Train: [157/180] Step 1200/1249 Loss 0.348 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.594, lat_loss 6.689
09/19 10:35:41 PM | Train: [157/180] Step 1249/1249 Loss 0.346 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.594, lat_loss 6.689
09/19 10:35:41 PM | _w_step_train: [157/180] Final Prec@1 91.3425% Time 600.37
09/19 10:35:41 PM | Start to train theta for epoch 156
09/19 10:36:02 PM | Train: [157/180] Step 050/312 Loss 0.573 Prec@(1,3) (85.9%, 99.4%), ce_loss 0.594, lat_loss 6.689
09/19 10:36:19 PM | Train: [157/180] Step 100/312 Loss 0.596 Prec@(1,3) (85.8%, 99.4%), ce_loss 0.594, lat_loss 6.689
09/19 10:36:37 PM | Train: [157/180] Step 150/312 Loss 0.584 Prec@(1,3) (86.0%, 99.3%), ce_loss 0.594, lat_loss 6.689
09/19 10:36:54 PM | Train: [157/180] Step 200/312 Loss 0.588 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.594, lat_loss 6.689
09/19 10:37:13 PM | Train: [157/180] Step 250/312 Loss 0.592 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.594, lat_loss 6.689
09/19 10:37:32 PM | Train: [157/180] Step 300/312 Loss 0.607 Prec@(1,3) (85.3%, 99.3%), ce_loss 0.594, lat_loss 6.689
09/19 10:37:37 PM | Train: [157/180] Step 312/312 Loss 0.606 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.594, lat_loss 6.689
09/19 10:37:37 PM | _theta_step_train: [157/180] Final Prec@1 85.3300% Time 115.74
09/19 10:37:43 PM | Valid: [157/180] Step 050/312 Loss 0.666 Prec@(1,3) (83.4%, 98.7%), ce_loss 0.594, lat_loss 6.689
09/19 10:37:47 PM | Valid: [157/180] Step 100/312 Loss 0.733 Prec@(1,3) (82.1%, 98.0%), ce_loss 0.594, lat_loss 6.689
09/19 10:37:52 PM | Valid: [157/180] Step 150/312 Loss 0.754 Prec@(1,3) (81.8%, 97.8%), ce_loss 0.594, lat_loss 6.689
09/19 10:37:57 PM | Valid: [157/180] Step 200/312 Loss 0.765 Prec@(1,3) (82.0%, 97.8%), ce_loss 0.594, lat_loss 6.689
09/19 10:38:01 PM | Valid: [157/180] Step 250/312 Loss 0.784 Prec@(1,3) (81.5%, 97.7%), ce_loss 0.594, lat_loss 6.689
09/19 10:38:06 PM | Valid: [157/180] Step 300/312 Loss 0.801 Prec@(1,3) (81.6%, 97.6%), ce_loss 0.594, lat_loss 6.689
09/19 10:38:07 PM | Valid: [157/180] Step 312/312 Loss 0.806 Prec@(1,3) (81.4%, 97.6%), ce_loss 0.594, lat_loss 6.689
09/19 10:38:07 PM | val: [157/180] Final Prec@1 81.3600% Time 30.03
09/19 10:38:07 PM | Start to train weights for epoch 157
09/19 10:38:33 PM | Train: [158/180] Step 050/1249 Loss 0.353 Prec@(1,3) (91.6%, 99.6%), ce_loss 0.594, lat_loss 6.689
09/19 10:38:57 PM | Train: [158/180] Step 100/1249 Loss 0.335 Prec@(1,3) (91.7%, 99.6%), ce_loss 0.594, lat_loss 6.689
09/19 10:39:21 PM | Train: [158/180] Step 150/1249 Loss 0.320 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.594, lat_loss 6.689
09/19 10:39:46 PM | Train: [158/180] Step 200/1249 Loss 0.334 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.593, lat_loss 6.689
09/19 10:40:08 PM | Train: [158/180] Step 250/1249 Loss 0.327 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.593, lat_loss 6.689
09/19 10:40:31 PM | Train: [158/180] Step 300/1249 Loss 0.316 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.593, lat_loss 6.689
09/19 10:40:52 PM | Train: [158/180] Step 350/1249 Loss 0.313 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.593, lat_loss 6.689
09/19 10:41:14 PM | Train: [158/180] Step 400/1249 Loss 0.315 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.593, lat_loss 6.689
09/19 10:41:37 PM | Train: [158/180] Step 450/1249 Loss 0.327 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.593, lat_loss 6.689
09/19 10:42:01 PM | Train: [158/180] Step 500/1249 Loss 0.333 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.593, lat_loss 6.689
09/19 10:42:23 PM | Train: [158/180] Step 550/1249 Loss 0.331 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.593, lat_loss 6.689
09/19 10:42:46 PM | Train: [158/180] Step 600/1249 Loss 0.334 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.593, lat_loss 6.689
09/19 10:43:08 PM | Train: [158/180] Step 650/1249 Loss 0.338 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.593, lat_loss 6.689
09/19 10:43:31 PM | Train: [158/180] Step 700/1249 Loss 0.336 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.593, lat_loss 6.689
09/19 10:43:53 PM | Train: [158/180] Step 750/1249 Loss 0.341 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.593, lat_loss 6.689
09/19 10:44:15 PM | Train: [158/180] Step 800/1249 Loss 0.345 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.593, lat_loss 6.689
09/19 10:44:37 PM | Train: [158/180] Step 850/1249 Loss 0.343 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.593, lat_loss 6.689
09/19 10:44:59 PM | Train: [158/180] Step 900/1249 Loss 0.342 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.593, lat_loss 6.689
09/19 10:45:23 PM | Train: [158/180] Step 950/1249 Loss 0.345 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.593, lat_loss 6.689
09/19 10:45:46 PM | Train: [158/180] Step 1000/1249 Loss 0.342 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.593, lat_loss 6.689
09/19 10:46:09 PM | Train: [158/180] Step 1050/1249 Loss 0.340 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.592, lat_loss 6.689
09/19 10:46:31 PM | Train: [158/180] Step 1100/1249 Loss 0.342 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.592, lat_loss 6.689
09/19 10:46:52 PM | Train: [158/180] Step 1150/1249 Loss 0.342 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.592, lat_loss 6.689
09/19 10:47:15 PM | Train: [158/180] Step 1200/1249 Loss 0.340 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.592, lat_loss 6.689
09/19 10:47:39 PM | Train: [158/180] Step 1249/1249 Loss 0.339 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.592, lat_loss 6.689
09/19 10:47:39 PM | _w_step_train: [158/180] Final Prec@1 91.5050% Time 572.33
09/19 10:47:39 PM | Start to train theta for epoch 157
09/19 10:48:01 PM | Train: [158/180] Step 050/312 Loss 0.562 Prec@(1,3) (87.3%, 99.1%), ce_loss 0.592, lat_loss 6.689
09/19 10:48:21 PM | Train: [158/180] Step 100/312 Loss 0.555 Prec@(1,3) (87.3%, 99.2%), ce_loss 0.592, lat_loss 6.689
09/19 10:48:41 PM | Train: [158/180] Step 150/312 Loss 0.602 Prec@(1,3) (86.2%, 99.0%), ce_loss 0.592, lat_loss 6.689
09/19 10:49:00 PM | Train: [158/180] Step 200/312 Loss 0.593 Prec@(1,3) (86.2%, 99.1%), ce_loss 0.592, lat_loss 6.689
09/19 10:49:20 PM | Train: [158/180] Step 250/312 Loss 0.598 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.592, lat_loss 6.689
09/19 10:49:41 PM | Train: [158/180] Step 300/312 Loss 0.596 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.592, lat_loss 6.689
09/19 10:49:46 PM | Train: [158/180] Step 312/312 Loss 0.596 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.592, lat_loss 6.690
09/19 10:49:46 PM | _theta_step_train: [158/180] Final Prec@1 86.0500% Time 126.80
09/19 10:49:51 PM | Valid: [158/180] Step 050/312 Loss 0.927 Prec@(1,3) (81.1%, 97.1%), ce_loss 0.592, lat_loss 6.690
09/19 10:49:56 PM | Valid: [158/180] Step 100/312 Loss 0.884 Prec@(1,3) (80.7%, 97.6%), ce_loss 0.592, lat_loss 6.690
09/19 10:50:01 PM | Valid: [158/180] Step 150/312 Loss 0.911 Prec@(1,3) (79.9%, 97.6%), ce_loss 0.592, lat_loss 6.690
09/19 10:50:05 PM | Valid: [158/180] Step 200/312 Loss 0.866 Prec@(1,3) (81.0%, 97.7%), ce_loss 0.592, lat_loss 6.690
09/19 10:50:10 PM | Valid: [158/180] Step 250/312 Loss 0.876 Prec@(1,3) (80.8%, 97.7%), ce_loss 0.592, lat_loss 6.690
09/19 10:50:14 PM | Valid: [158/180] Step 300/312 Loss 0.867 Prec@(1,3) (81.1%, 97.6%), ce_loss 0.592, lat_loss 6.690
09/19 10:50:16 PM | Valid: [158/180] Step 312/312 Loss 0.863 Prec@(1,3) (81.1%, 97.7%), ce_loss 0.592, lat_loss 6.690
09/19 10:50:16 PM | val: [158/180] Final Prec@1 81.1100% Time 29.43
09/19 10:50:16 PM | Start to train weights for epoch 158
09/19 10:50:42 PM | Train: [159/180] Step 050/1249 Loss 0.317 Prec@(1,3) (92.2%, 99.6%), ce_loss 0.592, lat_loss 6.690
09/19 10:51:04 PM | Train: [159/180] Step 100/1249 Loss 0.354 Prec@(1,3) (91.3%, 99.6%), ce_loss 0.592, lat_loss 6.690
09/19 10:51:25 PM | Train: [159/180] Step 150/1249 Loss 0.338 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.592, lat_loss 6.690
09/19 10:51:49 PM | Train: [159/180] Step 200/1249 Loss 0.327 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.592, lat_loss 6.690
09/19 10:52:11 PM | Train: [159/180] Step 250/1249 Loss 0.315 Prec@(1,3) (92.1%, 99.7%), ce_loss 0.592, lat_loss 6.690
09/19 10:52:34 PM | Train: [159/180] Step 300/1249 Loss 0.319 Prec@(1,3) (92.1%, 99.7%), ce_loss 0.592, lat_loss 6.690
09/19 10:52:56 PM | Train: [159/180] Step 350/1249 Loss 0.331 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.592, lat_loss 6.690
09/19 10:53:18 PM | Train: [159/180] Step 400/1249 Loss 0.331 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.592, lat_loss 6.690
09/19 10:53:41 PM | Train: [159/180] Step 450/1249 Loss 0.323 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.592, lat_loss 6.690
09/19 10:54:06 PM | Train: [159/180] Step 500/1249 Loss 0.317 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.592, lat_loss 6.690
09/19 10:54:30 PM | Train: [159/180] Step 550/1249 Loss 0.322 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.591, lat_loss 6.690
09/19 10:54:55 PM | Train: [159/180] Step 600/1249 Loss 0.323 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.591, lat_loss 6.690
09/19 10:55:20 PM | Train: [159/180] Step 650/1249 Loss 0.329 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.591, lat_loss 6.690
09/19 10:55:45 PM | Train: [159/180] Step 700/1249 Loss 0.332 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.591, lat_loss 6.690
09/19 10:56:09 PM | Train: [159/180] Step 750/1249 Loss 0.338 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.591, lat_loss 6.690
09/19 10:56:34 PM | Train: [159/180] Step 800/1249 Loss 0.336 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.591, lat_loss 6.690
09/19 10:56:59 PM | Train: [159/180] Step 850/1249 Loss 0.340 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.591, lat_loss 6.690
09/19 10:57:24 PM | Train: [159/180] Step 900/1249 Loss 0.336 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.591, lat_loss 6.690
09/19 10:57:48 PM | Train: [159/180] Step 950/1249 Loss 0.337 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.591, lat_loss 6.690
09/19 10:58:10 PM | Train: [159/180] Step 1000/1249 Loss 0.335 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.591, lat_loss 6.690
09/19 10:58:25 PM | Train: [159/180] Step 1050/1249 Loss 0.332 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.591, lat_loss 6.690
09/19 10:58:41 PM | Train: [159/180] Step 1100/1249 Loss 0.336 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.591, lat_loss 6.690
09/19 10:58:58 PM | Train: [159/180] Step 1150/1249 Loss 0.336 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.591, lat_loss 6.690
09/19 10:59:14 PM | Train: [159/180] Step 1200/1249 Loss 0.336 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.591, lat_loss 6.690
09/19 10:59:30 PM | Train: [159/180] Step 1249/1249 Loss 0.336 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.591, lat_loss 6.690
09/19 10:59:30 PM | _w_step_train: [159/180] Final Prec@1 91.5800% Time 554.08
09/19 10:59:30 PM | Start to train theta for epoch 158
09/19 10:59:50 PM | Train: [159/180] Step 050/312 Loss 0.547 Prec@(1,3) (87.3%, 99.4%), ce_loss 0.591, lat_loss 6.690
09/19 11:00:09 PM | Train: [159/180] Step 100/312 Loss 0.550 Prec@(1,3) (86.9%, 99.4%), ce_loss 0.591, lat_loss 6.690
09/19 11:00:28 PM | Train: [159/180] Step 150/312 Loss 0.549 Prec@(1,3) (86.7%, 99.3%), ce_loss 0.591, lat_loss 6.690
09/19 11:00:48 PM | Train: [159/180] Step 200/312 Loss 0.548 Prec@(1,3) (86.7%, 99.4%), ce_loss 0.591, lat_loss 6.690
09/19 11:01:07 PM | Train: [159/180] Step 250/312 Loss 0.563 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.591, lat_loss 6.690
09/19 11:01:27 PM | Train: [159/180] Step 300/312 Loss 0.568 Prec@(1,3) (86.4%, 99.3%), ce_loss 0.590, lat_loss 6.690
09/19 11:01:32 PM | Train: [159/180] Step 312/312 Loss 0.574 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.590, lat_loss 6.690
09/19 11:01:32 PM | _theta_step_train: [159/180] Final Prec@1 86.3200% Time 121.88
09/19 11:01:37 PM | Valid: [159/180] Step 050/312 Loss 0.946 Prec@(1,3) (80.9%, 96.6%), ce_loss 0.591, lat_loss 6.690
09/19 11:01:41 PM | Valid: [159/180] Step 100/312 Loss 0.894 Prec@(1,3) (81.4%, 96.9%), ce_loss 0.591, lat_loss 6.690
09/19 11:01:46 PM | Valid: [159/180] Step 150/312 Loss 0.855 Prec@(1,3) (82.3%, 97.3%), ce_loss 0.591, lat_loss 6.690
09/19 11:01:51 PM | Valid: [159/180] Step 200/312 Loss 0.848 Prec@(1,3) (82.5%, 97.4%), ce_loss 0.591, lat_loss 6.690
09/19 11:01:55 PM | Valid: [159/180] Step 250/312 Loss 0.838 Prec@(1,3) (81.9%, 97.6%), ce_loss 0.591, lat_loss 6.690
09/19 11:02:00 PM | Valid: [159/180] Step 300/312 Loss 0.821 Prec@(1,3) (82.2%, 97.7%), ce_loss 0.591, lat_loss 6.690
09/19 11:02:01 PM | Valid: [159/180] Step 312/312 Loss 0.815 Prec@(1,3) (82.3%, 97.8%), ce_loss 0.591, lat_loss 6.690
09/19 11:02:01 PM | val: [159/180] Final Prec@1 82.2800% Time 29.59
09/19 11:02:01 PM | Start to train weights for epoch 159
09/19 11:02:26 PM | Train: [160/180] Step 050/1249 Loss 0.316 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.590, lat_loss 6.690
09/19 11:02:47 PM | Train: [160/180] Step 100/1249 Loss 0.310 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.590, lat_loss 6.690
09/19 11:03:10 PM | Train: [160/180] Step 150/1249 Loss 0.302 Prec@(1,3) (92.3%, 99.9%), ce_loss 0.590, lat_loss 6.690
09/19 11:03:31 PM | Train: [160/180] Step 200/1249 Loss 0.331 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.590, lat_loss 6.690
09/19 11:03:54 PM | Train: [160/180] Step 250/1249 Loss 0.338 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.590, lat_loss 6.690
09/19 11:04:16 PM | Train: [160/180] Step 300/1249 Loss 0.338 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.590, lat_loss 6.690
09/19 11:04:39 PM | Train: [160/180] Step 350/1249 Loss 0.340 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.590, lat_loss 6.690
09/19 11:05:02 PM | Train: [160/180] Step 400/1249 Loss 0.330 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.590, lat_loss 6.690
09/19 11:05:24 PM | Train: [160/180] Step 450/1249 Loss 0.333 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.590, lat_loss 6.690
09/19 11:05:46 PM | Train: [160/180] Step 500/1249 Loss 0.330 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.590, lat_loss 6.690
09/19 11:06:06 PM | Train: [160/180] Step 550/1249 Loss 0.329 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.590, lat_loss 6.690
09/19 11:06:28 PM | Train: [160/180] Step 600/1249 Loss 0.323 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.590, lat_loss 6.690
09/19 11:06:50 PM | Train: [160/180] Step 650/1249 Loss 0.326 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.590, lat_loss 6.690
09/19 11:07:14 PM | Train: [160/180] Step 700/1249 Loss 0.324 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.590, lat_loss 6.690
09/19 11:07:37 PM | Train: [160/180] Step 750/1249 Loss 0.322 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.590, lat_loss 6.690
09/19 11:08:00 PM | Train: [160/180] Step 800/1249 Loss 0.325 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.590, lat_loss 6.690
09/19 11:08:25 PM | Train: [160/180] Step 850/1249 Loss 0.325 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.589, lat_loss 6.690
09/19 11:08:50 PM | Train: [160/180] Step 900/1249 Loss 0.326 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.589, lat_loss 6.690
09/19 11:09:15 PM | Train: [160/180] Step 950/1249 Loss 0.329 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.589, lat_loss 6.690
09/19 11:09:40 PM | Train: [160/180] Step 1000/1249 Loss 0.328 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.589, lat_loss 6.690
09/19 11:10:05 PM | Train: [160/180] Step 1050/1249 Loss 0.325 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.589, lat_loss 6.690
09/19 11:10:30 PM | Train: [160/180] Step 1100/1249 Loss 0.323 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.589, lat_loss 6.690
09/19 11:10:55 PM | Train: [160/180] Step 1150/1249 Loss 0.322 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.589, lat_loss 6.690
09/19 11:11:16 PM | Train: [160/180] Step 1200/1249 Loss 0.321 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.589, lat_loss 6.690
09/19 11:11:31 PM | Train: [160/180] Step 1249/1249 Loss 0.319 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.589, lat_loss 6.690
09/19 11:11:31 PM | _w_step_train: [160/180] Final Prec@1 91.9675% Time 569.96
09/19 11:11:31 PM | Start to train theta for epoch 159
09/19 11:11:52 PM | Train: [160/180] Step 050/312 Loss 0.620 Prec@(1,3) (85.4%, 98.8%), ce_loss 0.589, lat_loss 6.690
09/19 11:12:12 PM | Train: [160/180] Step 100/312 Loss 0.594 Prec@(1,3) (85.6%, 99.1%), ce_loss 0.589, lat_loss 6.690
09/19 11:12:31 PM | Train: [160/180] Step 150/312 Loss 0.574 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.589, lat_loss 6.690
09/19 11:12:51 PM | Train: [160/180] Step 200/312 Loss 0.573 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.589, lat_loss 6.690
09/19 11:13:12 PM | Train: [160/180] Step 250/312 Loss 0.589 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.589, lat_loss 6.690
09/19 11:13:33 PM | Train: [160/180] Step 300/312 Loss 0.606 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.589, lat_loss 6.690
09/19 11:13:38 PM | Train: [160/180] Step 312/312 Loss 0.598 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.589, lat_loss 6.690
09/19 11:13:38 PM | _theta_step_train: [160/180] Final Prec@1 85.6400% Time 126.97
09/19 11:13:43 PM | Valid: [160/180] Step 050/312 Loss 0.849 Prec@(1,3) (78.7%, 97.5%), ce_loss 0.589, lat_loss 6.690
09/19 11:13:48 PM | Valid: [160/180] Step 100/312 Loss 0.842 Prec@(1,3) (80.0%, 97.5%), ce_loss 0.589, lat_loss 6.690
09/19 11:13:53 PM | Valid: [160/180] Step 150/312 Loss 0.814 Prec@(1,3) (81.0%, 97.8%), ce_loss 0.589, lat_loss 6.690
09/19 11:13:57 PM | Valid: [160/180] Step 200/312 Loss 0.811 Prec@(1,3) (81.5%, 97.8%), ce_loss 0.589, lat_loss 6.690
09/19 11:14:02 PM | Valid: [160/180] Step 250/312 Loss 0.797 Prec@(1,3) (81.5%, 98.0%), ce_loss 0.589, lat_loss 6.690
09/19 11:14:07 PM | Valid: [160/180] Step 300/312 Loss 0.777 Prec@(1,3) (81.8%, 98.0%), ce_loss 0.589, lat_loss 6.690
09/19 11:14:08 PM | Valid: [160/180] Step 312/312 Loss 0.767 Prec@(1,3) (81.9%, 98.0%), ce_loss 0.589, lat_loss 6.690
09/19 11:14:08 PM | val: [160/180] Final Prec@1 81.9400% Time 30.29
09/19 11:14:08 PM | Start to train weights for epoch 160
09/19 11:14:34 PM | Train: [161/180] Step 050/1249 Loss 0.358 Prec@(1,3) (91.3%, 99.9%), ce_loss 0.589, lat_loss 6.690
09/19 11:14:57 PM | Train: [161/180] Step 100/1249 Loss 0.344 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.589, lat_loss 6.690
09/19 11:15:22 PM | Train: [161/180] Step 150/1249 Loss 0.326 Prec@(1,3) (91.8%, 99.9%), ce_loss 0.589, lat_loss 6.690
09/19 11:15:47 PM | Train: [161/180] Step 200/1249 Loss 0.317 Prec@(1,3) (92.1%, 99.9%), ce_loss 0.589, lat_loss 6.690
09/19 11:16:12 PM | Train: [161/180] Step 250/1249 Loss 0.312 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.589, lat_loss 6.690
09/19 11:16:37 PM | Train: [161/180] Step 300/1249 Loss 0.318 Prec@(1,3) (92.0%, 99.9%), ce_loss 0.588, lat_loss 6.690
09/19 11:17:01 PM | Train: [161/180] Step 350/1249 Loss 0.314 Prec@(1,3) (92.1%, 99.9%), ce_loss 0.588, lat_loss 6.690
09/19 11:17:26 PM | Train: [161/180] Step 400/1249 Loss 0.318 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.588, lat_loss 6.690
09/19 11:17:47 PM | Train: [161/180] Step 450/1249 Loss 0.318 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.588, lat_loss 6.690
09/19 11:18:03 PM | Train: [161/180] Step 500/1249 Loss 0.321 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.588, lat_loss 6.690
09/19 11:18:19 PM | Train: [161/180] Step 550/1249 Loss 0.329 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.588, lat_loss 6.690
09/19 11:18:35 PM | Train: [161/180] Step 600/1249 Loss 0.327 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.588, lat_loss 6.690
09/19 11:18:51 PM | Train: [161/180] Step 650/1249 Loss 0.338 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.588, lat_loss 6.690
09/19 11:19:07 PM | Train: [161/180] Step 700/1249 Loss 0.343 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.588, lat_loss 6.690
09/19 11:19:23 PM | Train: [161/180] Step 750/1249 Loss 0.347 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.588, lat_loss 6.690
09/19 11:19:39 PM | Train: [161/180] Step 800/1249 Loss 0.348 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.588, lat_loss 6.690
09/19 11:19:55 PM | Train: [161/180] Step 850/1249 Loss 0.345 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.588, lat_loss 6.690
09/19 11:20:11 PM | Train: [161/180] Step 900/1249 Loss 0.349 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.588, lat_loss 6.690
09/19 11:20:27 PM | Train: [161/180] Step 950/1249 Loss 0.350 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.588, lat_loss 6.690
09/19 11:20:43 PM | Train: [161/180] Step 1000/1249 Loss 0.350 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.588, lat_loss 6.690
09/19 11:20:59 PM | Train: [161/180] Step 1050/1249 Loss 0.351 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.588, lat_loss 6.690
09/19 11:21:15 PM | Train: [161/180] Step 1100/1249 Loss 0.346 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.588, lat_loss 6.690
09/19 11:21:31 PM | Train: [161/180] Step 1150/1249 Loss 0.344 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.588, lat_loss 6.690
09/19 11:21:46 PM | Train: [161/180] Step 1200/1249 Loss 0.350 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.587, lat_loss 6.690
09/19 11:22:02 PM | Train: [161/180] Step 1249/1249 Loss 0.348 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.587, lat_loss 6.690
09/19 11:22:02 PM | _w_step_train: [161/180] Final Prec@1 91.4675% Time 473.61
09/19 11:22:02 PM | Start to train theta for epoch 160
09/19 11:22:23 PM | Train: [161/180] Step 050/312 Loss 0.631 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.587, lat_loss 6.690
09/19 11:22:44 PM | Train: [161/180] Step 100/312 Loss 0.652 Prec@(1,3) (85.1%, 98.9%), ce_loss 0.587, lat_loss 6.690
09/19 11:23:05 PM | Train: [161/180] Step 150/312 Loss 0.631 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.587, lat_loss 6.690
09/19 11:23:26 PM | Train: [161/180] Step 200/312 Loss 0.627 Prec@(1,3) (85.6%, 99.1%), ce_loss 0.587, lat_loss 6.690
09/19 11:23:46 PM | Train: [161/180] Step 250/312 Loss 0.621 Prec@(1,3) (85.8%, 99.1%), ce_loss 0.587, lat_loss 6.690
09/19 11:24:07 PM | Train: [161/180] Step 300/312 Loss 0.620 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.587, lat_loss 6.690
09/19 11:24:12 PM | Train: [161/180] Step 312/312 Loss 0.618 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.587, lat_loss 6.690
09/19 11:24:12 PM | _theta_step_train: [161/180] Final Prec@1 85.7000% Time 130.40
09/19 11:24:18 PM | Valid: [161/180] Step 050/312 Loss 0.726 Prec@(1,3) (82.1%, 98.3%), ce_loss 0.587, lat_loss 6.690
09/19 11:24:22 PM | Valid: [161/180] Step 100/312 Loss 0.911 Prec@(1,3) (80.3%, 97.1%), ce_loss 0.587, lat_loss 6.690
09/19 11:24:27 PM | Valid: [161/180] Step 150/312 Loss 0.924 Prec@(1,3) (80.8%, 97.2%), ce_loss 0.587, lat_loss 6.690
09/19 11:24:32 PM | Valid: [161/180] Step 200/312 Loss 0.852 Prec@(1,3) (81.9%, 97.7%), ce_loss 0.587, lat_loss 6.690
09/19 11:24:36 PM | Valid: [161/180] Step 250/312 Loss 0.871 Prec@(1,3) (81.6%, 97.4%), ce_loss 0.587, lat_loss 6.690
09/19 11:24:41 PM | Valid: [161/180] Step 300/312 Loss 0.839 Prec@(1,3) (81.9%, 97.6%), ce_loss 0.587, lat_loss 6.690
09/19 11:24:42 PM | Valid: [161/180] Step 312/312 Loss 0.835 Prec@(1,3) (81.9%, 97.7%), ce_loss 0.587, lat_loss 6.690
09/19 11:24:42 PM | val: [161/180] Final Prec@1 81.9100% Time 29.75
09/19 11:24:42 PM | Start to train weights for epoch 161
09/19 11:25:00 PM | Train: [162/180] Step 050/1249 Loss 0.419 Prec@(1,3) (89.4%, 99.6%), ce_loss 0.587, lat_loss 6.690
09/19 11:25:15 PM | Train: [162/180] Step 100/1249 Loss 0.417 Prec@(1,3) (89.2%, 99.6%), ce_loss 0.587, lat_loss 6.690
09/19 11:25:31 PM | Train: [162/180] Step 150/1249 Loss 0.374 Prec@(1,3) (90.3%, 99.6%), ce_loss 0.587, lat_loss 6.690
09/19 11:25:47 PM | Train: [162/180] Step 200/1249 Loss 0.357 Prec@(1,3) (90.8%, 99.7%), ce_loss 0.587, lat_loss 6.690
09/19 11:26:03 PM | Train: [162/180] Step 250/1249 Loss 0.348 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.587, lat_loss 6.690
09/19 11:26:19 PM | Train: [162/180] Step 300/1249 Loss 0.345 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.587, lat_loss 6.690
09/19 11:26:35 PM | Train: [162/180] Step 350/1249 Loss 0.332 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.587, lat_loss 6.690
09/19 11:26:51 PM | Train: [162/180] Step 400/1249 Loss 0.334 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.587, lat_loss 6.690
09/19 11:27:07 PM | Train: [162/180] Step 450/1249 Loss 0.337 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.587, lat_loss 6.690
09/19 11:27:23 PM | Train: [162/180] Step 500/1249 Loss 0.332 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.587, lat_loss 6.690
09/19 11:27:39 PM | Train: [162/180] Step 550/1249 Loss 0.335 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.587, lat_loss 6.690
09/19 11:27:55 PM | Train: [162/180] Step 600/1249 Loss 0.332 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.587, lat_loss 6.690
09/19 11:28:11 PM | Train: [162/180] Step 650/1249 Loss 0.330 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.587, lat_loss 6.690
09/19 11:28:27 PM | Train: [162/180] Step 700/1249 Loss 0.331 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.587, lat_loss 6.690
09/19 11:28:42 PM | Train: [162/180] Step 750/1249 Loss 0.333 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.586, lat_loss 6.690
09/19 11:28:58 PM | Train: [162/180] Step 800/1249 Loss 0.331 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.586, lat_loss 6.690
09/19 11:29:14 PM | Train: [162/180] Step 850/1249 Loss 0.327 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.586, lat_loss 6.690
09/19 11:29:30 PM | Train: [162/180] Step 900/1249 Loss 0.325 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.586, lat_loss 6.690
09/19 11:29:46 PM | Train: [162/180] Step 950/1249 Loss 0.325 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.586, lat_loss 6.690
09/19 11:30:02 PM | Train: [162/180] Step 1000/1249 Loss 0.325 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.586, lat_loss 6.690
09/19 11:30:18 PM | Train: [162/180] Step 1050/1249 Loss 0.325 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.586, lat_loss 6.690
09/19 11:30:34 PM | Train: [162/180] Step 1100/1249 Loss 0.325 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.586, lat_loss 6.690
09/19 11:30:50 PM | Train: [162/180] Step 1150/1249 Loss 0.325 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.586, lat_loss 6.690
09/19 11:31:06 PM | Train: [162/180] Step 1200/1249 Loss 0.324 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.586, lat_loss 6.690
09/19 11:31:21 PM | Train: [162/180] Step 1249/1249 Loss 0.326 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.586, lat_loss 6.690
09/19 11:31:21 PM | _w_step_train: [162/180] Final Prec@1 91.8175% Time 398.99
09/19 11:31:21 PM | Start to train theta for epoch 161
09/19 11:31:40 PM | Train: [162/180] Step 050/312 Loss 0.681 Prec@(1,3) (84.9%, 98.9%), ce_loss 0.586, lat_loss 6.690
09/19 11:31:58 PM | Train: [162/180] Step 100/312 Loss 0.662 Prec@(1,3) (84.7%, 99.0%), ce_loss 0.586, lat_loss 6.690
09/19 11:32:15 PM | Train: [162/180] Step 150/312 Loss 0.661 Prec@(1,3) (84.6%, 99.1%), ce_loss 0.586, lat_loss 6.690
09/19 11:32:32 PM | Train: [162/180] Step 200/312 Loss 0.635 Prec@(1,3) (85.1%, 99.2%), ce_loss 0.586, lat_loss 6.690
09/19 11:32:50 PM | Train: [162/180] Step 250/312 Loss 0.621 Prec@(1,3) (85.5%, 99.2%), ce_loss 0.586, lat_loss 6.690
09/19 11:33:09 PM | Train: [162/180] Step 300/312 Loss 0.608 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.586, lat_loss 6.690
09/19 11:33:14 PM | Train: [162/180] Step 312/312 Loss 0.606 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.586, lat_loss 6.690
09/19 11:33:15 PM | _theta_step_train: [162/180] Final Prec@1 85.8300% Time 113.46
09/19 11:33:20 PM | Valid: [162/180] Step 050/312 Loss 0.912 Prec@(1,3) (79.0%, 96.9%), ce_loss 0.586, lat_loss 6.690
09/19 11:33:24 PM | Valid: [162/180] Step 100/312 Loss 0.831 Prec@(1,3) (80.4%, 97.9%), ce_loss 0.586, lat_loss 6.690
09/19 11:33:28 PM | Valid: [162/180] Step 150/312 Loss 0.823 Prec@(1,3) (80.7%, 97.9%), ce_loss 0.586, lat_loss 6.690
09/19 11:33:32 PM | Valid: [162/180] Step 200/312 Loss 0.800 Prec@(1,3) (81.0%, 98.0%), ce_loss 0.586, lat_loss 6.690
09/19 11:33:37 PM | Valid: [162/180] Step 250/312 Loss 0.783 Prec@(1,3) (81.4%, 98.1%), ce_loss 0.586, lat_loss 6.690
09/19 11:33:41 PM | Valid: [162/180] Step 300/312 Loss 0.754 Prec@(1,3) (81.9%, 98.3%), ce_loss 0.586, lat_loss 6.690
09/19 11:33:42 PM | Valid: [162/180] Step 312/312 Loss 0.773 Prec@(1,3) (81.7%, 98.1%), ce_loss 0.586, lat_loss 6.690
09/19 11:33:42 PM | val: [162/180] Final Prec@1 81.7300% Time 27.13
09/19 11:33:42 PM | Start to train weights for epoch 162
09/19 11:34:06 PM | Train: [163/180] Step 050/1249 Loss 0.270 Prec@(1,3) (92.3%, 99.9%), ce_loss 0.586, lat_loss 6.690
09/19 11:34:29 PM | Train: [163/180] Step 100/1249 Loss 0.272 Prec@(1,3) (92.6%, 99.9%), ce_loss 0.586, lat_loss 6.690
09/19 11:34:51 PM | Train: [163/180] Step 150/1249 Loss 0.291 Prec@(1,3) (92.3%, 99.9%), ce_loss 0.586, lat_loss 6.690
09/19 11:35:12 PM | Train: [163/180] Step 200/1249 Loss 0.308 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:35:35 PM | Train: [163/180] Step 250/1249 Loss 0.317 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:35:58 PM | Train: [163/180] Step 300/1249 Loss 0.307 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:36:20 PM | Train: [163/180] Step 350/1249 Loss 0.317 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:36:42 PM | Train: [163/180] Step 400/1249 Loss 0.317 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:37:04 PM | Train: [163/180] Step 450/1249 Loss 0.318 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:37:25 PM | Train: [163/180] Step 500/1249 Loss 0.314 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:37:47 PM | Train: [163/180] Step 550/1249 Loss 0.315 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:38:10 PM | Train: [163/180] Step 600/1249 Loss 0.316 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:38:31 PM | Train: [163/180] Step 650/1249 Loss 0.313 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:38:53 PM | Train: [163/180] Step 700/1249 Loss 0.316 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:39:15 PM | Train: [163/180] Step 750/1249 Loss 0.312 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:39:37 PM | Train: [163/180] Step 800/1249 Loss 0.310 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:39:59 PM | Train: [163/180] Step 850/1249 Loss 0.309 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:40:21 PM | Train: [163/180] Step 900/1249 Loss 0.311 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:40:42 PM | Train: [163/180] Step 950/1249 Loss 0.311 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:41:05 PM | Train: [163/180] Step 1000/1249 Loss 0.313 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.585, lat_loss 6.690
09/19 11:41:27 PM | Train: [163/180] Step 1050/1249 Loss 0.316 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.584, lat_loss 6.690
09/19 11:41:48 PM | Train: [163/180] Step 1100/1249 Loss 0.317 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.584, lat_loss 6.690
09/19 11:42:10 PM | Train: [163/180] Step 1150/1249 Loss 0.314 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.584, lat_loss 6.690
09/19 11:42:32 PM | Train: [163/180] Step 1200/1249 Loss 0.315 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.584, lat_loss 6.690
09/19 11:42:56 PM | Train: [163/180] Step 1249/1249 Loss 0.316 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.584, lat_loss 6.690
09/19 11:42:57 PM | _w_step_train: [163/180] Final Prec@1 92.1200% Time 554.66
09/19 11:42:57 PM | Start to train theta for epoch 162
09/19 11:43:17 PM | Train: [163/180] Step 050/312 Loss 0.624 Prec@(1,3) (85.5%, 99.2%), ce_loss 0.584, lat_loss 6.690
09/19 11:43:37 PM | Train: [163/180] Step 100/312 Loss 0.658 Prec@(1,3) (84.5%, 99.2%), ce_loss 0.584, lat_loss 6.690
09/19 11:43:58 PM | Train: [163/180] Step 150/312 Loss 0.645 Prec@(1,3) (85.0%, 99.2%), ce_loss 0.584, lat_loss 6.690
09/19 11:44:19 PM | Train: [163/180] Step 200/312 Loss 0.629 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.584, lat_loss 6.690
09/19 11:44:40 PM | Train: [163/180] Step 250/312 Loss 0.617 Prec@(1,3) (85.5%, 99.2%), ce_loss 0.584, lat_loss 6.690
09/19 11:45:01 PM | Train: [163/180] Step 300/312 Loss 0.610 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.584, lat_loss 6.690
09/19 11:45:06 PM | Train: [163/180] Step 312/312 Loss 0.608 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.584, lat_loss 6.690
09/19 11:45:06 PM | _theta_step_train: [163/180] Final Prec@1 85.7100% Time 129.19
09/19 11:45:11 PM | Valid: [163/180] Step 050/312 Loss 0.781 Prec@(1,3) (81.7%, 98.6%), ce_loss 0.584, lat_loss 6.690
09/19 11:45:16 PM | Valid: [163/180] Step 100/312 Loss 0.867 Prec@(1,3) (80.0%, 98.0%), ce_loss 0.584, lat_loss 6.690
09/19 11:45:20 PM | Valid: [163/180] Step 150/312 Loss 0.798 Prec@(1,3) (81.7%, 98.3%), ce_loss 0.584, lat_loss 6.690
09/19 11:45:25 PM | Valid: [163/180] Step 200/312 Loss 0.833 Prec@(1,3) (81.7%, 98.1%), ce_loss 0.584, lat_loss 6.690
09/19 11:45:30 PM | Valid: [163/180] Step 250/312 Loss 0.848 Prec@(1,3) (81.5%, 97.9%), ce_loss 0.584, lat_loss 6.690
09/19 11:45:34 PM | Valid: [163/180] Step 300/312 Loss 0.806 Prec@(1,3) (82.3%, 98.1%), ce_loss 0.584, lat_loss 6.690
09/19 11:45:35 PM | Valid: [163/180] Step 312/312 Loss 0.796 Prec@(1,3) (82.3%, 98.1%), ce_loss 0.584, lat_loss 6.690
09/19 11:45:35 PM | val: [163/180] Final Prec@1 82.3300% Time 29.52
09/19 11:45:35 PM | Start to train weights for epoch 163
09/19 11:46:02 PM | Train: [164/180] Step 050/1249 Loss 0.346 Prec@(1,3) (91.1%, 99.6%), ce_loss 0.584, lat_loss 6.690
09/19 11:46:27 PM | Train: [164/180] Step 100/1249 Loss 0.331 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.584, lat_loss 6.690
09/19 11:46:52 PM | Train: [164/180] Step 150/1249 Loss 0.302 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.584, lat_loss 6.690
09/19 11:47:15 PM | Train: [164/180] Step 200/1249 Loss 0.308 Prec@(1,3) (92.4%, 99.7%), ce_loss 0.584, lat_loss 6.690
09/19 11:47:40 PM | Train: [164/180] Step 250/1249 Loss 0.308 Prec@(1,3) (92.4%, 99.7%), ce_loss 0.584, lat_loss 6.690
09/19 11:48:04 PM | Train: [164/180] Step 300/1249 Loss 0.314 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.584, lat_loss 6.690
09/19 11:48:28 PM | Train: [164/180] Step 350/1249 Loss 0.306 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.584, lat_loss 6.690
09/19 11:48:53 PM | Train: [164/180] Step 400/1249 Loss 0.307 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.584, lat_loss 6.690
09/19 11:49:17 PM | Train: [164/180] Step 450/1249 Loss 0.306 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.584, lat_loss 6.690
09/19 11:49:42 PM | Train: [164/180] Step 500/1249 Loss 0.311 Prec@(1,3) (92.3%, 99.7%), ce_loss 0.584, lat_loss 6.690
09/19 11:50:06 PM | Train: [164/180] Step 550/1249 Loss 0.311 Prec@(1,3) (92.2%, 99.7%), ce_loss 0.583, lat_loss 6.690
09/19 11:50:30 PM | Train: [164/180] Step 600/1249 Loss 0.310 Prec@(1,3) (92.3%, 99.7%), ce_loss 0.583, lat_loss 6.690
09/19 11:50:54 PM | Train: [164/180] Step 650/1249 Loss 0.308 Prec@(1,3) (92.3%, 99.7%), ce_loss 0.583, lat_loss 6.690
09/19 11:51:19 PM | Train: [164/180] Step 700/1249 Loss 0.312 Prec@(1,3) (92.2%, 99.7%), ce_loss 0.583, lat_loss 6.690
09/19 11:51:44 PM | Train: [164/180] Step 750/1249 Loss 0.315 Prec@(1,3) (92.1%, 99.7%), ce_loss 0.583, lat_loss 6.690
09/19 11:52:09 PM | Train: [164/180] Step 800/1249 Loss 0.315 Prec@(1,3) (92.1%, 99.7%), ce_loss 0.583, lat_loss 6.690
09/19 11:52:32 PM | Train: [164/180] Step 850/1249 Loss 0.320 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.583, lat_loss 6.690
09/19 11:52:55 PM | Train: [164/180] Step 900/1249 Loss 0.319 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.583, lat_loss 6.690
09/19 11:53:20 PM | Train: [164/180] Step 950/1249 Loss 0.320 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.583, lat_loss 6.690
09/19 11:53:45 PM | Train: [164/180] Step 1000/1249 Loss 0.325 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.583, lat_loss 6.690
09/19 11:54:10 PM | Train: [164/180] Step 1050/1249 Loss 0.327 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.583, lat_loss 6.690
09/19 11:54:35 PM | Train: [164/180] Step 1100/1249 Loss 0.327 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.583, lat_loss 6.690
09/19 11:54:59 PM | Train: [164/180] Step 1150/1249 Loss 0.331 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.583, lat_loss 6.691
09/19 11:55:24 PM | Train: [164/180] Step 1200/1249 Loss 0.329 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.583, lat_loss 6.691
09/19 11:55:48 PM | Train: [164/180] Step 1249/1249 Loss 0.330 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.583, lat_loss 6.691
09/19 11:55:48 PM | _w_step_train: [164/180] Final Prec@1 91.8725% Time 612.45
09/19 11:55:48 PM | Start to train theta for epoch 163
09/19 11:56:09 PM | Train: [164/180] Step 050/312 Loss 0.585 Prec@(1,3) (86.2%, 99.1%), ce_loss 0.583, lat_loss 6.691
09/19 11:56:30 PM | Train: [164/180] Step 100/312 Loss 0.589 Prec@(1,3) (86.6%, 98.9%), ce_loss 0.583, lat_loss 6.691
09/19 11:56:51 PM | Train: [164/180] Step 150/312 Loss 0.596 Prec@(1,3) (86.1%, 99.0%), ce_loss 0.583, lat_loss 6.691
09/19 11:57:10 PM | Train: [164/180] Step 200/312 Loss 0.617 Prec@(1,3) (85.8%, 99.0%), ce_loss 0.583, lat_loss 6.691
09/19 11:57:28 PM | Train: [164/180] Step 250/312 Loss 0.611 Prec@(1,3) (85.7%, 99.0%), ce_loss 0.583, lat_loss 6.691
09/19 11:57:46 PM | Train: [164/180] Step 300/312 Loss 0.601 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.583, lat_loss 6.691
09/19 11:57:51 PM | Train: [164/180] Step 312/312 Loss 0.605 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.583, lat_loss 6.691
09/19 11:57:51 PM | _theta_step_train: [164/180] Final Prec@1 85.9800% Time 123.67
09/19 11:57:57 PM | Valid: [164/180] Step 050/312 Loss 0.631 Prec@(1,3) (85.5%, 99.2%), ce_loss 0.583, lat_loss 6.691
09/19 11:58:01 PM | Valid: [164/180] Step 100/312 Loss 0.765 Prec@(1,3) (83.0%, 98.4%), ce_loss 0.583, lat_loss 6.691
09/19 11:58:06 PM | Valid: [164/180] Step 150/312 Loss 0.818 Prec@(1,3) (82.4%, 97.6%), ce_loss 0.583, lat_loss 6.691
09/19 11:58:11 PM | Valid: [164/180] Step 200/312 Loss 0.808 Prec@(1,3) (82.2%, 97.7%), ce_loss 0.583, lat_loss 6.691
09/19 11:58:15 PM | Valid: [164/180] Step 250/312 Loss 0.804 Prec@(1,3) (82.0%, 97.8%), ce_loss 0.583, lat_loss 6.691
09/19 11:58:20 PM | Valid: [164/180] Step 300/312 Loss 0.787 Prec@(1,3) (82.2%, 97.9%), ce_loss 0.583, lat_loss 6.691
09/19 11:58:21 PM | Valid: [164/180] Step 312/312 Loss 0.784 Prec@(1,3) (82.3%, 98.0%), ce_loss 0.583, lat_loss 6.691
09/19 11:58:21 PM | val: [164/180] Final Prec@1 82.2700% Time 29.85
09/19 11:58:21 PM | Start to train weights for epoch 164
09/19 11:58:48 PM | Train: [165/180] Step 050/1249 Loss 0.289 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.583, lat_loss 6.691
09/19 11:59:12 PM | Train: [165/180] Step 100/1249 Loss 0.294 Prec@(1,3) (93.2%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/19 11:59:37 PM | Train: [165/180] Step 150/1249 Loss 0.303 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:00:02 AM | Train: [165/180] Step 200/1249 Loss 0.313 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:00:25 AM | Train: [165/180] Step 250/1249 Loss 0.302 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:00:48 AM | Train: [165/180] Step 300/1249 Loss 0.312 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:01:10 AM | Train: [165/180] Step 350/1249 Loss 0.315 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:01:33 AM | Train: [165/180] Step 400/1249 Loss 0.315 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:01:56 AM | Train: [165/180] Step 450/1249 Loss 0.315 Prec@(1,3) (92.1%, 99.7%), ce_loss 0.582, lat_loss 6.691
09/20 12:02:20 AM | Train: [165/180] Step 500/1249 Loss 0.311 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:02:46 AM | Train: [165/180] Step 550/1249 Loss 0.313 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:03:10 AM | Train: [165/180] Step 600/1249 Loss 0.316 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:03:35 AM | Train: [165/180] Step 650/1249 Loss 0.316 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:03:57 AM | Train: [165/180] Step 700/1249 Loss 0.316 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:04:18 AM | Train: [165/180] Step 750/1249 Loss 0.318 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:04:39 AM | Train: [165/180] Step 800/1249 Loss 0.318 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:05:03 AM | Train: [165/180] Step 850/1249 Loss 0.316 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:05:27 AM | Train: [165/180] Step 900/1249 Loss 0.315 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:05:52 AM | Train: [165/180] Step 950/1249 Loss 0.316 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.582, lat_loss 6.691
09/20 12:06:17 AM | Train: [165/180] Step 1000/1249 Loss 0.320 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.581, lat_loss 6.691
09/20 12:06:41 AM | Train: [165/180] Step 1050/1249 Loss 0.323 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.581, lat_loss 6.691
09/20 12:07:05 AM | Train: [165/180] Step 1100/1249 Loss 0.321 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.581, lat_loss 6.691
09/20 12:07:26 AM | Train: [165/180] Step 1150/1249 Loss 0.321 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.581, lat_loss 6.691
09/20 12:07:50 AM | Train: [165/180] Step 1200/1249 Loss 0.320 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.581, lat_loss 6.691
09/20 12:08:14 AM | Train: [165/180] Step 1249/1249 Loss 0.320 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.581, lat_loss 6.691
09/20 12:08:14 AM | _w_step_train: [165/180] Final Prec@1 91.9575% Time 592.88
09/20 12:08:14 AM | Start to train theta for epoch 164
09/20 12:08:35 AM | Train: [165/180] Step 050/312 Loss 0.611 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.581, lat_loss 6.691
09/20 12:08:56 AM | Train: [165/180] Step 100/312 Loss 0.609 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.581, lat_loss 6.691
09/20 12:09:17 AM | Train: [165/180] Step 150/312 Loss 0.605 Prec@(1,3) (85.6%, 99.3%), ce_loss 0.581, lat_loss 6.691
09/20 12:09:37 AM | Train: [165/180] Step 200/312 Loss 0.597 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.581, lat_loss 6.691
09/20 12:09:57 AM | Train: [165/180] Step 250/312 Loss 0.588 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.581, lat_loss 6.691
09/20 12:10:18 AM | Train: [165/180] Step 300/312 Loss 0.596 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.581, lat_loss 6.691
09/20 12:10:23 AM | Train: [165/180] Step 312/312 Loss 0.599 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.581, lat_loss 6.691
09/20 12:10:23 AM | _theta_step_train: [165/180] Final Prec@1 86.0000% Time 128.54
09/20 12:10:28 AM | Valid: [165/180] Step 050/312 Loss 0.703 Prec@(1,3) (83.5%, 99.1%), ce_loss 0.581, lat_loss 6.691
09/20 12:10:32 AM | Valid: [165/180] Step 100/312 Loss 0.756 Prec@(1,3) (83.1%, 98.3%), ce_loss 0.581, lat_loss 6.691
09/20 12:10:36 AM | Valid: [165/180] Step 150/312 Loss 0.755 Prec@(1,3) (83.2%, 98.5%), ce_loss 0.581, lat_loss 6.691
09/20 12:10:40 AM | Valid: [165/180] Step 200/312 Loss 0.781 Prec@(1,3) (82.9%, 98.3%), ce_loss 0.581, lat_loss 6.691
09/20 12:10:45 AM | Valid: [165/180] Step 250/312 Loss 0.792 Prec@(1,3) (82.6%, 98.2%), ce_loss 0.581, lat_loss 6.691
09/20 12:10:50 AM | Valid: [165/180] Step 300/312 Loss 0.815 Prec@(1,3) (81.9%, 97.9%), ce_loss 0.581, lat_loss 6.691
09/20 12:10:51 AM | Valid: [165/180] Step 312/312 Loss 0.804 Prec@(1,3) (82.1%, 98.0%), ce_loss 0.581, lat_loss 6.691
09/20 12:10:51 AM | val: [165/180] Final Prec@1 82.0700% Time 28.22
09/20 12:10:51 AM | Start to train weights for epoch 165
09/20 12:11:15 AM | Train: [166/180] Step 050/1249 Loss 0.401 Prec@(1,3) (90.1%, 99.6%), ce_loss 0.581, lat_loss 6.691
09/20 12:11:39 AM | Train: [166/180] Step 100/1249 Loss 0.363 Prec@(1,3) (90.7%, 99.7%), ce_loss 0.581, lat_loss 6.691
09/20 12:12:02 AM | Train: [166/180] Step 150/1249 Loss 0.326 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.581, lat_loss 6.691
09/20 12:12:25 AM | Train: [166/180] Step 200/1249 Loss 0.315 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.581, lat_loss 6.691
09/20 12:12:48 AM | Train: [166/180] Step 250/1249 Loss 0.307 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.581, lat_loss 6.691
09/20 12:13:12 AM | Train: [166/180] Step 300/1249 Loss 0.312 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.581, lat_loss 6.691
09/20 12:13:36 AM | Train: [166/180] Step 350/1249 Loss 0.319 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.581, lat_loss 6.691
09/20 12:13:59 AM | Train: [166/180] Step 400/1249 Loss 0.320 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.581, lat_loss 6.691
09/20 12:14:22 AM | Train: [166/180] Step 450/1249 Loss 0.316 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.581, lat_loss 6.691
09/20 12:14:45 AM | Train: [166/180] Step 500/1249 Loss 0.319 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:15:07 AM | Train: [166/180] Step 550/1249 Loss 0.322 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:15:29 AM | Train: [166/180] Step 600/1249 Loss 0.325 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:15:53 AM | Train: [166/180] Step 650/1249 Loss 0.324 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.580, lat_loss 6.691
09/20 12:16:16 AM | Train: [166/180] Step 700/1249 Loss 0.321 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:16:37 AM | Train: [166/180] Step 750/1249 Loss 0.323 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:16:59 AM | Train: [166/180] Step 800/1249 Loss 0.323 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:17:22 AM | Train: [166/180] Step 850/1249 Loss 0.324 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:17:47 AM | Train: [166/180] Step 900/1249 Loss 0.324 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:18:12 AM | Train: [166/180] Step 950/1249 Loss 0.324 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:18:37 AM | Train: [166/180] Step 1000/1249 Loss 0.321 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:19:02 AM | Train: [166/180] Step 1050/1249 Loss 0.319 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:19:27 AM | Train: [166/180] Step 1100/1249 Loss 0.321 Prec@(1,3) (92.1%, 99.7%), ce_loss 0.580, lat_loss 6.691
09/20 12:19:53 AM | Train: [166/180] Step 1150/1249 Loss 0.322 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:20:17 AM | Train: [166/180] Step 1200/1249 Loss 0.322 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:20:42 AM | Train: [166/180] Step 1249/1249 Loss 0.321 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:20:42 AM | _w_step_train: [166/180] Final Prec@1 92.0925% Time 590.66
09/20 12:20:42 AM | Start to train theta for epoch 165
09/20 12:20:55 AM | Train: [166/180] Step 050/312 Loss 0.592 Prec@(1,3) (86.8%, 99.1%), ce_loss 0.580, lat_loss 6.691
09/20 12:21:07 AM | Train: [166/180] Step 100/312 Loss 0.600 Prec@(1,3) (86.4%, 99.2%), ce_loss 0.580, lat_loss 6.691
09/20 12:21:19 AM | Train: [166/180] Step 150/312 Loss 0.602 Prec@(1,3) (86.1%, 99.4%), ce_loss 0.580, lat_loss 6.691
09/20 12:21:31 AM | Train: [166/180] Step 200/312 Loss 0.597 Prec@(1,3) (86.3%, 99.3%), ce_loss 0.580, lat_loss 6.691
09/20 12:21:44 AM | Train: [166/180] Step 250/312 Loss 0.606 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.580, lat_loss 6.691
09/20 12:21:56 AM | Train: [166/180] Step 300/312 Loss 0.615 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.580, lat_loss 6.691
09/20 12:21:59 AM | Train: [166/180] Step 312/312 Loss 0.618 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.580, lat_loss 6.691
09/20 12:21:59 AM | _theta_step_train: [166/180] Final Prec@1 85.9700% Time 77.12
09/20 12:22:04 AM | Valid: [166/180] Step 050/312 Loss 0.916 Prec@(1,3) (80.0%, 97.1%), ce_loss 0.580, lat_loss 6.691
09/20 12:22:09 AM | Valid: [166/180] Step 100/312 Loss 0.843 Prec@(1,3) (82.1%, 97.6%), ce_loss 0.580, lat_loss 6.691
09/20 12:22:13 AM | Valid: [166/180] Step 150/312 Loss 0.916 Prec@(1,3) (81.3%, 97.2%), ce_loss 0.580, lat_loss 6.691
09/20 12:22:18 AM | Valid: [166/180] Step 200/312 Loss 0.942 Prec@(1,3) (80.7%, 96.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:22:22 AM | Valid: [166/180] Step 250/312 Loss 0.881 Prec@(1,3) (81.5%, 97.3%), ce_loss 0.580, lat_loss 6.691
09/20 12:22:27 AM | Valid: [166/180] Step 300/312 Loss 0.861 Prec@(1,3) (81.6%, 97.5%), ce_loss 0.580, lat_loss 6.691
09/20 12:22:28 AM | Valid: [166/180] Step 312/312 Loss 0.876 Prec@(1,3) (81.3%, 97.4%), ce_loss 0.580, lat_loss 6.691
09/20 12:22:28 AM | val: [166/180] Final Prec@1 81.3400% Time 29.46
09/20 12:22:28 AM | Start to train weights for epoch 166
09/20 12:22:54 AM | Train: [167/180] Step 050/1249 Loss 0.268 Prec@(1,3) (93.3%, 99.8%), ce_loss 0.580, lat_loss 6.691
09/20 12:23:18 AM | Train: [167/180] Step 100/1249 Loss 0.297 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:23:40 AM | Train: [167/180] Step 150/1249 Loss 0.306 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:24:02 AM | Train: [167/180] Step 200/1249 Loss 0.306 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:24:25 AM | Train: [167/180] Step 250/1249 Loss 0.297 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:24:47 AM | Train: [167/180] Step 300/1249 Loss 0.289 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:25:09 AM | Train: [167/180] Step 350/1249 Loss 0.282 Prec@(1,3) (92.9%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:25:31 AM | Train: [167/180] Step 400/1249 Loss 0.287 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:25:53 AM | Train: [167/180] Step 450/1249 Loss 0.299 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:26:16 AM | Train: [167/180] Step 500/1249 Loss 0.302 Prec@(1,3) (92.5%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:26:37 AM | Train: [167/180] Step 550/1249 Loss 0.301 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:27:00 AM | Train: [167/180] Step 600/1249 Loss 0.304 Prec@(1,3) (92.5%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:27:25 AM | Train: [167/180] Step 650/1249 Loss 0.305 Prec@(1,3) (92.5%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:27:50 AM | Train: [167/180] Step 700/1249 Loss 0.305 Prec@(1,3) (92.5%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:28:13 AM | Train: [167/180] Step 750/1249 Loss 0.303 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:28:37 AM | Train: [167/180] Step 800/1249 Loss 0.304 Prec@(1,3) (92.5%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:29:02 AM | Train: [167/180] Step 850/1249 Loss 0.312 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:29:27 AM | Train: [167/180] Step 900/1249 Loss 0.313 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:29:52 AM | Train: [167/180] Step 950/1249 Loss 0.315 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.579, lat_loss 6.691
09/20 12:30:17 AM | Train: [167/180] Step 1000/1249 Loss 0.319 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:30:42 AM | Train: [167/180] Step 1050/1249 Loss 0.316 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:31:07 AM | Train: [167/180] Step 1100/1249 Loss 0.315 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:31:31 AM | Train: [167/180] Step 1150/1249 Loss 0.316 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:31:56 AM | Train: [167/180] Step 1200/1249 Loss 0.316 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:32:21 AM | Train: [167/180] Step 1249/1249 Loss 0.314 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:32:21 AM | _w_step_train: [167/180] Final Prec@1 92.1925% Time 592.97
09/20 12:32:21 AM | Start to train theta for epoch 166
09/20 12:32:43 AM | Train: [167/180] Step 050/312 Loss 0.571 Prec@(1,3) (86.7%, 99.4%), ce_loss 0.578, lat_loss 6.691
09/20 12:33:03 AM | Train: [167/180] Step 100/312 Loss 0.590 Prec@(1,3) (86.6%, 99.1%), ce_loss 0.578, lat_loss 6.691
09/20 12:33:23 AM | Train: [167/180] Step 150/312 Loss 0.597 Prec@(1,3) (86.3%, 99.2%), ce_loss 0.578, lat_loss 6.691
09/20 12:33:42 AM | Train: [167/180] Step 200/312 Loss 0.597 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.578, lat_loss 6.691
09/20 12:34:02 AM | Train: [167/180] Step 250/312 Loss 0.600 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.578, lat_loss 6.691
09/20 12:34:23 AM | Train: [167/180] Step 300/312 Loss 0.610 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.578, lat_loss 6.691
09/20 12:34:28 AM | Train: [167/180] Step 312/312 Loss 0.615 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.578, lat_loss 6.691
09/20 12:34:28 AM | _theta_step_train: [167/180] Final Prec@1 85.7000% Time 126.50
09/20 12:34:33 AM | Valid: [167/180] Step 050/312 Loss 0.949 Prec@(1,3) (79.3%, 97.0%), ce_loss 0.578, lat_loss 6.691
09/20 12:34:38 AM | Valid: [167/180] Step 100/312 Loss 0.964 Prec@(1,3) (79.6%, 96.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:34:42 AM | Valid: [167/180] Step 150/312 Loss 0.922 Prec@(1,3) (80.4%, 97.1%), ce_loss 0.578, lat_loss 6.691
09/20 12:34:47 AM | Valid: [167/180] Step 200/312 Loss 0.909 Prec@(1,3) (80.7%, 97.1%), ce_loss 0.578, lat_loss 6.691
09/20 12:34:52 AM | Valid: [167/180] Step 250/312 Loss 0.855 Prec@(1,3) (81.5%, 97.6%), ce_loss 0.578, lat_loss 6.691
09/20 12:34:56 AM | Valid: [167/180] Step 300/312 Loss 0.836 Prec@(1,3) (81.5%, 97.7%), ce_loss 0.578, lat_loss 6.691
09/20 12:34:57 AM | Valid: [167/180] Step 312/312 Loss 0.829 Prec@(1,3) (81.5%, 97.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:34:57 AM | val: [167/180] Final Prec@1 81.5500% Time 29.60
09/20 12:34:57 AM | Start to train weights for epoch 167
09/20 12:35:22 AM | Train: [168/180] Step 050/1249 Loss 0.271 Prec@(1,3) (92.8%, 99.9%), ce_loss 0.578, lat_loss 6.691
09/20 12:35:46 AM | Train: [168/180] Step 100/1249 Loss 0.285 Prec@(1,3) (92.5%, 99.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:36:11 AM | Train: [168/180] Step 150/1249 Loss 0.295 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:36:36 AM | Train: [168/180] Step 200/1249 Loss 0.287 Prec@(1,3) (92.8%, 99.9%), ce_loss 0.578, lat_loss 6.691
09/20 12:37:00 AM | Train: [168/180] Step 250/1249 Loss 0.286 Prec@(1,3) (93.0%, 99.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:37:25 AM | Train: [168/180] Step 300/1249 Loss 0.285 Prec@(1,3) (93.0%, 99.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:37:49 AM | Train: [168/180] Step 350/1249 Loss 0.286 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:38:14 AM | Train: [168/180] Step 400/1249 Loss 0.285 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:38:39 AM | Train: [168/180] Step 450/1249 Loss 0.286 Prec@(1,3) (92.8%, 99.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:39:01 AM | Train: [168/180] Step 500/1249 Loss 0.290 Prec@(1,3) (92.7%, 99.8%), ce_loss 0.578, lat_loss 6.691
09/20 12:39:26 AM | Train: [168/180] Step 550/1249 Loss 0.294 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.577, lat_loss 6.691
09/20 12:39:52 AM | Train: [168/180] Step 600/1249 Loss 0.308 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.577, lat_loss 6.691
09/20 12:40:17 AM | Train: [168/180] Step 650/1249 Loss 0.313 Prec@(1,3) (92.2%, 99.7%), ce_loss 0.577, lat_loss 6.691
09/20 12:40:42 AM | Train: [168/180] Step 700/1249 Loss 0.311 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.577, lat_loss 6.691
09/20 12:41:07 AM | Train: [168/180] Step 750/1249 Loss 0.311 Prec@(1,3) (92.3%, 99.7%), ce_loss 0.577, lat_loss 6.691
09/20 12:41:32 AM | Train: [168/180] Step 800/1249 Loss 0.313 Prec@(1,3) (92.2%, 99.7%), ce_loss 0.577, lat_loss 6.691
09/20 12:41:57 AM | Train: [168/180] Step 850/1249 Loss 0.316 Prec@(1,3) (92.2%, 99.7%), ce_loss 0.577, lat_loss 6.691
09/20 12:42:22 AM | Train: [168/180] Step 900/1249 Loss 0.317 Prec@(1,3) (92.1%, 99.7%), ce_loss 0.577, lat_loss 6.691
09/20 12:42:48 AM | Train: [168/180] Step 950/1249 Loss 0.320 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.577, lat_loss 6.691
09/20 12:43:13 AM | Train: [168/180] Step 1000/1249 Loss 0.319 Prec@(1,3) (92.1%, 99.7%), ce_loss 0.577, lat_loss 6.691
09/20 12:43:38 AM | Train: [168/180] Step 1050/1249 Loss 0.319 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.577, lat_loss 6.691
09/20 12:44:03 AM | Train: [168/180] Step 1100/1249 Loss 0.316 Prec@(1,3) (92.1%, 99.7%), ce_loss 0.577, lat_loss 6.691
09/20 12:44:29 AM | Train: [168/180] Step 1150/1249 Loss 0.317 Prec@(1,3) (92.1%, 99.7%), ce_loss 0.577, lat_loss 6.691
09/20 12:44:54 AM | Train: [168/180] Step 1200/1249 Loss 0.320 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.577, lat_loss 6.691
09/20 12:45:18 AM | Train: [168/180] Step 1249/1249 Loss 0.323 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.577, lat_loss 6.691
09/20 12:45:18 AM | _w_step_train: [168/180] Final Prec@1 91.9300% Time 620.89
09/20 12:45:18 AM | Start to train theta for epoch 167
09/20 12:45:40 AM | Train: [168/180] Step 050/312 Loss 0.627 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.577, lat_loss 6.691
09/20 12:46:00 AM | Train: [168/180] Step 100/312 Loss 0.625 Prec@(1,3) (85.2%, 99.3%), ce_loss 0.577, lat_loss 6.691
09/20 12:46:20 AM | Train: [168/180] Step 150/312 Loss 0.624 Prec@(1,3) (85.1%, 99.3%), ce_loss 0.577, lat_loss 6.691
09/20 12:46:41 AM | Train: [168/180] Step 200/312 Loss 0.611 Prec@(1,3) (85.5%, 99.2%), ce_loss 0.577, lat_loss 6.691
09/20 12:47:01 AM | Train: [168/180] Step 250/312 Loss 0.625 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.577, lat_loss 6.691
09/20 12:47:21 AM | Train: [168/180] Step 300/312 Loss 0.630 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.577, lat_loss 6.691
09/20 12:47:26 AM | Train: [168/180] Step 312/312 Loss 0.630 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.577, lat_loss 6.691
09/20 12:47:26 AM | _theta_step_train: [168/180] Final Prec@1 85.3100% Time 128.01
09/20 12:47:32 AM | Valid: [168/180] Step 050/312 Loss 0.933 Prec@(1,3) (80.6%, 97.7%), ce_loss 0.577, lat_loss 6.691
09/20 12:47:36 AM | Valid: [168/180] Step 100/312 Loss 1.004 Prec@(1,3) (78.3%, 96.5%), ce_loss 0.577, lat_loss 6.691
09/20 12:47:41 AM | Valid: [168/180] Step 150/312 Loss 0.958 Prec@(1,3) (79.2%, 96.8%), ce_loss 0.577, lat_loss 6.691
09/20 12:47:45 AM | Valid: [168/180] Step 200/312 Loss 0.974 Prec@(1,3) (79.3%, 96.8%), ce_loss 0.577, lat_loss 6.691
09/20 12:47:50 AM | Valid: [168/180] Step 250/312 Loss 0.946 Prec@(1,3) (79.9%, 97.0%), ce_loss 0.577, lat_loss 6.691
09/20 12:47:55 AM | Valid: [168/180] Step 300/312 Loss 0.916 Prec@(1,3) (80.2%, 97.1%), ce_loss 0.577, lat_loss 6.691
09/20 12:47:56 AM | Valid: [168/180] Step 312/312 Loss 0.914 Prec@(1,3) (80.2%, 97.1%), ce_loss 0.577, lat_loss 6.691
09/20 12:47:56 AM | val: [168/180] Final Prec@1 80.1700% Time 29.58
09/20 12:47:56 AM | Start to train weights for epoch 168
09/20 12:48:22 AM | Train: [169/180] Step 050/1249 Loss 0.329 Prec@(1,3) (91.2%, 99.8%), ce_loss 0.577, lat_loss 6.691
09/20 12:48:47 AM | Train: [169/180] Step 100/1249 Loss 0.388 Prec@(1,3) (89.9%, 99.8%), ce_loss 0.577, lat_loss 6.691
09/20 12:49:11 AM | Train: [169/180] Step 150/1249 Loss 0.379 Prec@(1,3) (90.3%, 99.8%), ce_loss 0.577, lat_loss 6.691
09/20 12:49:34 AM | Train: [169/180] Step 200/1249 Loss 0.379 Prec@(1,3) (90.3%, 99.7%), ce_loss 0.577, lat_loss 6.691
09/20 12:49:59 AM | Train: [169/180] Step 250/1249 Loss 0.361 Prec@(1,3) (90.8%, 99.7%), ce_loss 0.576, lat_loss 6.691
09/20 12:50:23 AM | Train: [169/180] Step 300/1249 Loss 0.360 Prec@(1,3) (90.9%, 99.7%), ce_loss 0.576, lat_loss 6.691
09/20 12:50:48 AM | Train: [169/180] Step 350/1249 Loss 0.344 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.576, lat_loss 6.691
09/20 12:51:11 AM | Train: [169/180] Step 400/1249 Loss 0.337 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.576, lat_loss 6.691
09/20 12:51:27 AM | Train: [169/180] Step 450/1249 Loss 0.341 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.576, lat_loss 6.691
09/20 12:51:43 AM | Train: [169/180] Step 500/1249 Loss 0.339 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.576, lat_loss 6.691
09/20 12:51:59 AM | Train: [169/180] Step 550/1249 Loss 0.338 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.576, lat_loss 6.691
09/20 12:52:15 AM | Train: [169/180] Step 600/1249 Loss 0.334 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.576, lat_loss 6.691
09/20 12:52:30 AM | Train: [169/180] Step 650/1249 Loss 0.340 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.576, lat_loss 6.691
09/20 12:52:46 AM | Train: [169/180] Step 700/1249 Loss 0.341 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.576, lat_loss 6.691
09/20 12:53:03 AM | Train: [169/180] Step 750/1249 Loss 0.340 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.576, lat_loss 6.691
09/20 12:53:19 AM | Train: [169/180] Step 800/1249 Loss 0.336 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.576, lat_loss 6.691
09/20 12:53:35 AM | Train: [169/180] Step 850/1249 Loss 0.334 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.576, lat_loss 6.691
09/20 12:53:51 AM | Train: [169/180] Step 900/1249 Loss 0.330 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.576, lat_loss 6.691
09/20 12:54:07 AM | Train: [169/180] Step 950/1249 Loss 0.328 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.576, lat_loss 6.691
09/20 12:54:23 AM | Train: [169/180] Step 1000/1249 Loss 0.333 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.576, lat_loss 6.691
09/20 12:54:39 AM | Train: [169/180] Step 1050/1249 Loss 0.335 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.576, lat_loss 6.691
09/20 12:54:55 AM | Train: [169/180] Step 1100/1249 Loss 0.338 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.576, lat_loss 6.691
09/20 12:55:11 AM | Train: [169/180] Step 1150/1249 Loss 0.337 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.576, lat_loss 6.691
09/20 12:55:26 AM | Train: [169/180] Step 1200/1249 Loss 0.338 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.575, lat_loss 6.691
09/20 12:55:42 AM | Train: [169/180] Step 1249/1249 Loss 0.337 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.575, lat_loss 6.691
09/20 12:55:42 AM | _w_step_train: [169/180] Final Prec@1 91.6050% Time 466.17
09/20 12:55:42 AM | Start to train theta for epoch 168
09/20 12:56:03 AM | Train: [169/180] Step 050/312 Loss 0.592 Prec@(1,3) (85.8%, 99.1%), ce_loss 0.575, lat_loss 6.691
09/20 12:56:24 AM | Train: [169/180] Step 100/312 Loss 0.595 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.575, lat_loss 6.691
09/20 12:56:44 AM | Train: [169/180] Step 150/312 Loss 0.599 Prec@(1,3) (86.1%, 99.1%), ce_loss 0.575, lat_loss 6.691
09/20 12:57:05 AM | Train: [169/180] Step 200/312 Loss 0.613 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.575, lat_loss 6.691
09/20 12:57:25 AM | Train: [169/180] Step 250/312 Loss 0.606 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.575, lat_loss 6.691
09/20 12:57:46 AM | Train: [169/180] Step 300/312 Loss 0.613 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.575, lat_loss 6.691
09/20 12:57:51 AM | Train: [169/180] Step 312/312 Loss 0.617 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.575, lat_loss 6.691
09/20 12:57:51 AM | _theta_step_train: [169/180] Final Prec@1 85.6100% Time 128.98
09/20 12:57:56 AM | Valid: [169/180] Step 050/312 Loss 0.940 Prec@(1,3) (77.7%, 96.3%), ce_loss 0.575, lat_loss 6.691
09/20 12:58:01 AM | Valid: [169/180] Step 100/312 Loss 0.982 Prec@(1,3) (78.3%, 96.6%), ce_loss 0.575, lat_loss 6.691
09/20 12:58:06 AM | Valid: [169/180] Step 150/312 Loss 0.882 Prec@(1,3) (79.9%, 97.2%), ce_loss 0.575, lat_loss 6.691
09/20 12:58:11 AM | Valid: [169/180] Step 200/312 Loss 0.845 Prec@(1,3) (80.6%, 97.4%), ce_loss 0.575, lat_loss 6.691
09/20 12:58:15 AM | Valid: [169/180] Step 250/312 Loss 0.819 Prec@(1,3) (80.8%, 97.8%), ce_loss 0.575, lat_loss 6.691
09/20 12:58:20 AM | Valid: [169/180] Step 300/312 Loss 0.793 Prec@(1,3) (81.4%, 97.9%), ce_loss 0.575, lat_loss 6.691
09/20 12:58:21 AM | Valid: [169/180] Step 312/312 Loss 0.794 Prec@(1,3) (81.3%, 98.0%), ce_loss 0.575, lat_loss 6.691
09/20 12:58:21 AM | val: [169/180] Final Prec@1 81.3200% Time 30.18
09/20 12:58:21 AM | Start to train weights for epoch 169
09/20 12:58:47 AM | Train: [170/180] Step 050/1249 Loss 0.349 Prec@(1,3) (91.6%, 99.6%), ce_loss 0.575, lat_loss 6.691
09/20 12:59:12 AM | Train: [170/180] Step 100/1249 Loss 0.393 Prec@(1,3) (91.3%, 99.5%), ce_loss 0.575, lat_loss 6.691
09/20 12:59:37 AM | Train: [170/180] Step 150/1249 Loss 0.389 Prec@(1,3) (91.3%, 99.5%), ce_loss 0.575, lat_loss 6.691
09/20 01:00:02 AM | Train: [170/180] Step 200/1249 Loss 0.386 Prec@(1,3) (91.2%, 99.4%), ce_loss 0.575, lat_loss 6.691
09/20 01:00:27 AM | Train: [170/180] Step 250/1249 Loss 0.371 Prec@(1,3) (91.5%, 99.5%), ce_loss 0.575, lat_loss 6.691
09/20 01:00:52 AM | Train: [170/180] Step 300/1249 Loss 0.365 Prec@(1,3) (91.5%, 99.6%), ce_loss 0.575, lat_loss 6.691
09/20 01:01:17 AM | Train: [170/180] Step 350/1249 Loss 0.350 Prec@(1,3) (91.9%, 99.6%), ce_loss 0.575, lat_loss 6.691
09/20 01:01:42 AM | Train: [170/180] Step 400/1249 Loss 0.342 Prec@(1,3) (91.9%, 99.6%), ce_loss 0.575, lat_loss 6.691
09/20 01:02:07 AM | Train: [170/180] Step 450/1249 Loss 0.344 Prec@(1,3) (91.8%, 99.6%), ce_loss 0.575, lat_loss 6.691
09/20 01:02:32 AM | Train: [170/180] Step 500/1249 Loss 0.340 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.575, lat_loss 6.691
09/20 01:02:58 AM | Train: [170/180] Step 550/1249 Loss 0.333 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.575, lat_loss 6.691
09/20 01:03:23 AM | Train: [170/180] Step 600/1249 Loss 0.331 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.575, lat_loss 6.692
09/20 01:03:48 AM | Train: [170/180] Step 650/1249 Loss 0.332 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.575, lat_loss 6.692
09/20 01:04:13 AM | Train: [170/180] Step 700/1249 Loss 0.331 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.575, lat_loss 6.692
09/20 01:04:38 AM | Train: [170/180] Step 750/1249 Loss 0.327 Prec@(1,3) (92.1%, 99.7%), ce_loss 0.575, lat_loss 6.692
09/20 01:05:03 AM | Train: [170/180] Step 800/1249 Loss 0.325 Prec@(1,3) (92.2%, 99.7%), ce_loss 0.574, lat_loss 6.692
09/20 01:05:28 AM | Train: [170/180] Step 850/1249 Loss 0.325 Prec@(1,3) (92.1%, 99.7%), ce_loss 0.574, lat_loss 6.692
09/20 01:05:53 AM | Train: [170/180] Step 900/1249 Loss 0.321 Prec@(1,3) (92.2%, 99.7%), ce_loss 0.574, lat_loss 6.692
09/20 01:06:18 AM | Train: [170/180] Step 950/1249 Loss 0.320 Prec@(1,3) (92.2%, 99.7%), ce_loss 0.574, lat_loss 6.692
09/20 01:06:43 AM | Train: [170/180] Step 1000/1249 Loss 0.320 Prec@(1,3) (92.2%, 99.7%), ce_loss 0.574, lat_loss 6.692
09/20 01:07:08 AM | Train: [170/180] Step 1050/1249 Loss 0.320 Prec@(1,3) (92.2%, 99.7%), ce_loss 0.574, lat_loss 6.692
09/20 01:07:33 AM | Train: [170/180] Step 1100/1249 Loss 0.320 Prec@(1,3) (92.2%, 99.7%), ce_loss 0.574, lat_loss 6.692
09/20 01:07:58 AM | Train: [170/180] Step 1150/1249 Loss 0.320 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.574, lat_loss 6.692
09/20 01:08:23 AM | Train: [170/180] Step 1200/1249 Loss 0.320 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.574, lat_loss 6.692
09/20 01:08:48 AM | Train: [170/180] Step 1249/1249 Loss 0.318 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.574, lat_loss 6.692
09/20 01:08:48 AM | _w_step_train: [170/180] Final Prec@1 92.1800% Time 626.45
09/20 01:08:48 AM | Start to train theta for epoch 169
09/20 01:09:09 AM | Train: [170/180] Step 050/312 Loss 0.677 Prec@(1,3) (83.9%, 98.8%), ce_loss 0.574, lat_loss 6.692
09/20 01:09:30 AM | Train: [170/180] Step 100/312 Loss 0.635 Prec@(1,3) (84.8%, 99.0%), ce_loss 0.574, lat_loss 6.692
09/20 01:09:50 AM | Train: [170/180] Step 150/312 Loss 0.617 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.574, lat_loss 6.692
09/20 01:10:11 AM | Train: [170/180] Step 200/312 Loss 0.607 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.574, lat_loss 6.692
09/20 01:10:32 AM | Train: [170/180] Step 250/312 Loss 0.608 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.574, lat_loss 6.692
09/20 01:10:52 AM | Train: [170/180] Step 300/312 Loss 0.620 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.574, lat_loss 6.692
09/20 01:10:57 AM | Train: [170/180] Step 312/312 Loss 0.615 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.574, lat_loss 6.692
09/20 01:10:57 AM | _theta_step_train: [170/180] Final Prec@1 85.8000% Time 129.44
09/20 01:11:02 AM | Valid: [170/180] Step 050/312 Loss 0.821 Prec@(1,3) (81.1%, 98.0%), ce_loss 0.574, lat_loss 6.692
09/20 01:11:07 AM | Valid: [170/180] Step 100/312 Loss 0.861 Prec@(1,3) (80.0%, 97.7%), ce_loss 0.574, lat_loss 6.692
09/20 01:11:12 AM | Valid: [170/180] Step 150/312 Loss 0.777 Prec@(1,3) (82.0%, 98.2%), ce_loss 0.574, lat_loss 6.692
09/20 01:11:17 AM | Valid: [170/180] Step 200/312 Loss 0.851 Prec@(1,3) (80.8%, 97.8%), ce_loss 0.574, lat_loss 6.692
09/20 01:11:21 AM | Valid: [170/180] Step 250/312 Loss 0.824 Prec@(1,3) (81.1%, 98.0%), ce_loss 0.574, lat_loss 6.692
09/20 01:11:26 AM | Valid: [170/180] Step 300/312 Loss 0.846 Prec@(1,3) (80.9%, 97.7%), ce_loss 0.574, lat_loss 6.692
09/20 01:11:27 AM | Valid: [170/180] Step 312/312 Loss 0.838 Prec@(1,3) (81.0%, 97.8%), ce_loss 0.574, lat_loss 6.692
09/20 01:11:27 AM | val: [170/180] Final Prec@1 80.9900% Time 29.85
09/20 01:11:27 AM | Start to train weights for epoch 170
09/20 01:11:53 AM | Train: [171/180] Step 050/1249 Loss 0.308 Prec@(1,3) (92.2%, 99.6%), ce_loss 0.574, lat_loss 6.692
09/20 01:12:18 AM | Train: [171/180] Step 100/1249 Loss 0.312 Prec@(1,3) (92.2%, 99.7%), ce_loss 0.574, lat_loss 6.692
09/20 01:12:39 AM | Train: [171/180] Step 150/1249 Loss 0.309 Prec@(1,3) (92.3%, 99.7%), ce_loss 0.574, lat_loss 6.692
09/20 01:12:55 AM | Train: [171/180] Step 200/1249 Loss 0.295 Prec@(1,3) (92.6%, 99.7%), ce_loss 0.574, lat_loss 6.692
09/20 01:13:11 AM | Train: [171/180] Step 250/1249 Loss 0.296 Prec@(1,3) (92.7%, 99.8%), ce_loss 0.574, lat_loss 6.692
09/20 01:13:27 AM | Train: [171/180] Step 300/1249 Loss 0.304 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.574, lat_loss 6.692
09/20 01:13:43 AM | Train: [171/180] Step 350/1249 Loss 0.304 Prec@(1,3) (92.6%, 99.7%), ce_loss 0.574, lat_loss 6.692
09/20 01:13:59 AM | Train: [171/180] Step 400/1249 Loss 0.309 Prec@(1,3) (92.5%, 99.7%), ce_loss 0.573, lat_loss 6.692
09/20 01:14:15 AM | Train: [171/180] Step 450/1249 Loss 0.310 Prec@(1,3) (92.4%, 99.7%), ce_loss 0.573, lat_loss 6.692
09/20 01:14:31 AM | Train: [171/180] Step 500/1249 Loss 0.314 Prec@(1,3) (92.3%, 99.7%), ce_loss 0.573, lat_loss 6.692
09/20 01:14:47 AM | Train: [171/180] Step 550/1249 Loss 0.316 Prec@(1,3) (92.2%, 99.7%), ce_loss 0.573, lat_loss 6.692
09/20 01:15:03 AM | Train: [171/180] Step 600/1249 Loss 0.320 Prec@(1,3) (92.1%, 99.7%), ce_loss 0.573, lat_loss 6.692
09/20 01:15:18 AM | Train: [171/180] Step 650/1249 Loss 0.328 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.573, lat_loss 6.692
09/20 01:15:35 AM | Train: [171/180] Step 700/1249 Loss 0.324 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.573, lat_loss 6.692
09/20 01:15:51 AM | Train: [171/180] Step 750/1249 Loss 0.324 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.573, lat_loss 6.692
09/20 01:16:06 AM | Train: [171/180] Step 800/1249 Loss 0.325 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.573, lat_loss 6.692
09/20 01:16:22 AM | Train: [171/180] Step 850/1249 Loss 0.324 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.573, lat_loss 6.692
09/20 01:16:38 AM | Train: [171/180] Step 900/1249 Loss 0.323 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.573, lat_loss 6.692
09/20 01:16:54 AM | Train: [171/180] Step 950/1249 Loss 0.319 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.573, lat_loss 6.692
09/20 01:17:10 AM | Train: [171/180] Step 1000/1249 Loss 0.321 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.573, lat_loss 6.692
09/20 01:17:26 AM | Train: [171/180] Step 1050/1249 Loss 0.324 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.573, lat_loss 6.692
09/20 01:17:42 AM | Train: [171/180] Step 1100/1249 Loss 0.326 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.573, lat_loss 6.692
09/20 01:17:57 AM | Train: [171/180] Step 1150/1249 Loss 0.325 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.573, lat_loss 6.692
09/20 01:18:14 AM | Train: [171/180] Step 1200/1249 Loss 0.326 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.573, lat_loss 6.692
09/20 01:18:29 AM | Train: [171/180] Step 1249/1249 Loss 0.327 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.573, lat_loss 6.692
09/20 01:18:29 AM | _w_step_train: [171/180] Final Prec@1 91.9075% Time 422.38
09/20 01:18:29 AM | Start to train theta for epoch 170
09/20 01:18:42 AM | Train: [171/180] Step 050/312 Loss 0.588 Prec@(1,3) (86.3%, 99.1%), ce_loss 0.573, lat_loss 6.692
09/20 01:18:56 AM | Train: [171/180] Step 100/312 Loss 0.640 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.573, lat_loss 6.692
09/20 01:19:14 AM | Train: [171/180] Step 150/312 Loss 0.630 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.573, lat_loss 6.692
09/20 01:19:32 AM | Train: [171/180] Step 200/312 Loss 0.670 Prec@(1,3) (84.7%, 99.1%), ce_loss 0.573, lat_loss 6.692
09/20 01:19:48 AM | Train: [171/180] Step 250/312 Loss 0.661 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.573, lat_loss 6.692
09/20 01:20:06 AM | Train: [171/180] Step 300/312 Loss 0.657 Prec@(1,3) (84.7%, 99.2%), ce_loss 0.572, lat_loss 6.692
09/20 01:20:11 AM | Train: [171/180] Step 312/312 Loss 0.651 Prec@(1,3) (84.8%, 99.2%), ce_loss 0.572, lat_loss 6.692
09/20 01:20:11 AM | _theta_step_train: [171/180] Final Prec@1 84.8000% Time 101.69
09/20 01:20:17 AM | Valid: [171/180] Step 050/312 Loss 0.671 Prec@(1,3) (83.3%, 99.1%), ce_loss 0.572, lat_loss 6.692
09/20 01:20:21 AM | Valid: [171/180] Step 100/312 Loss 0.707 Prec@(1,3) (82.9%, 98.7%), ce_loss 0.572, lat_loss 6.692
09/20 01:20:26 AM | Valid: [171/180] Step 150/312 Loss 0.715 Prec@(1,3) (82.7%, 98.6%), ce_loss 0.572, lat_loss 6.692
09/20 01:20:31 AM | Valid: [171/180] Step 200/312 Loss 0.802 Prec@(1,3) (81.2%, 98.1%), ce_loss 0.573, lat_loss 6.692
09/20 01:20:35 AM | Valid: [171/180] Step 250/312 Loss 0.777 Prec@(1,3) (81.8%, 98.2%), ce_loss 0.572, lat_loss 6.692
09/20 01:20:40 AM | Valid: [171/180] Step 300/312 Loss 0.792 Prec@(1,3) (81.6%, 98.0%), ce_loss 0.573, lat_loss 6.692
09/20 01:20:41 AM | Valid: [171/180] Step 312/312 Loss 0.781 Prec@(1,3) (81.8%, 98.1%), ce_loss 0.573, lat_loss 6.692
09/20 01:20:41 AM | val: [171/180] Final Prec@1 81.8500% Time 29.95
09/20 01:20:41 AM | Start to train weights for epoch 171
09/20 01:21:06 AM | Train: [172/180] Step 050/1249 Loss 0.423 Prec@(1,3) (89.6%, 99.3%), ce_loss 0.572, lat_loss 6.692
09/20 01:21:30 AM | Train: [172/180] Step 100/1249 Loss 0.351 Prec@(1,3) (91.2%, 99.6%), ce_loss 0.572, lat_loss 6.692
09/20 01:21:55 AM | Train: [172/180] Step 150/1249 Loss 0.355 Prec@(1,3) (91.3%, 99.5%), ce_loss 0.572, lat_loss 6.692
09/20 01:22:20 AM | Train: [172/180] Step 200/1249 Loss 0.346 Prec@(1,3) (91.4%, 99.6%), ce_loss 0.572, lat_loss 6.692
09/20 01:22:45 AM | Train: [172/180] Step 250/1249 Loss 0.353 Prec@(1,3) (91.3%, 99.6%), ce_loss 0.572, lat_loss 6.692
09/20 01:23:10 AM | Train: [172/180] Step 300/1249 Loss 0.352 Prec@(1,3) (91.3%, 99.6%), ce_loss 0.572, lat_loss 6.692
09/20 01:23:36 AM | Train: [172/180] Step 350/1249 Loss 0.344 Prec@(1,3) (91.4%, 99.6%), ce_loss 0.572, lat_loss 6.692
09/20 01:24:00 AM | Train: [172/180] Step 400/1249 Loss 0.337 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.572, lat_loss 6.692
09/20 01:24:24 AM | Train: [172/180] Step 450/1249 Loss 0.334 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.572, lat_loss 6.692
09/20 01:24:48 AM | Train: [172/180] Step 500/1249 Loss 0.340 Prec@(1,3) (91.7%, 99.6%), ce_loss 0.572, lat_loss 6.692
09/20 01:25:12 AM | Train: [172/180] Step 550/1249 Loss 0.337 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.572, lat_loss 6.692
09/20 01:25:36 AM | Train: [172/180] Step 600/1249 Loss 0.331 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.572, lat_loss 6.692
09/20 01:25:59 AM | Train: [172/180] Step 650/1249 Loss 0.331 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.572, lat_loss 6.692
09/20 01:26:22 AM | Train: [172/180] Step 700/1249 Loss 0.327 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.572, lat_loss 6.692
09/20 01:26:45 AM | Train: [172/180] Step 750/1249 Loss 0.329 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.572, lat_loss 6.692
09/20 01:27:09 AM | Train: [172/180] Step 800/1249 Loss 0.332 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.572, lat_loss 6.692
09/20 01:27:33 AM | Train: [172/180] Step 850/1249 Loss 0.333 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.572, lat_loss 6.692
09/20 01:27:57 AM | Train: [172/180] Step 900/1249 Loss 0.331 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.572, lat_loss 6.692
09/20 01:28:21 AM | Train: [172/180] Step 950/1249 Loss 0.332 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.572, lat_loss 6.692
09/20 01:28:44 AM | Train: [172/180] Step 1000/1249 Loss 0.332 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.571, lat_loss 6.692
09/20 01:29:07 AM | Train: [172/180] Step 1050/1249 Loss 0.331 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.571, lat_loss 6.692
09/20 01:29:29 AM | Train: [172/180] Step 1100/1249 Loss 0.334 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.571, lat_loss 6.692
09/20 01:29:54 AM | Train: [172/180] Step 1150/1249 Loss 0.333 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.571, lat_loss 6.692
09/20 01:30:18 AM | Train: [172/180] Step 1200/1249 Loss 0.333 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.571, lat_loss 6.692
09/20 01:30:42 AM | Train: [172/180] Step 1249/1249 Loss 0.334 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.571, lat_loss 6.692
09/20 01:30:42 AM | _w_step_train: [172/180] Final Prec@1 91.6700% Time 601.15
09/20 01:30:42 AM | Start to train theta for epoch 171
09/20 01:31:03 AM | Train: [172/180] Step 050/312 Loss 0.594 Prec@(1,3) (86.2%, 99.3%), ce_loss 0.571, lat_loss 6.692
09/20 01:31:24 AM | Train: [172/180] Step 100/312 Loss 0.573 Prec@(1,3) (86.9%, 99.3%), ce_loss 0.571, lat_loss 6.692
09/20 01:31:45 AM | Train: [172/180] Step 150/312 Loss 0.572 Prec@(1,3) (86.7%, 99.3%), ce_loss 0.571, lat_loss 6.692
09/20 01:32:06 AM | Train: [172/180] Step 200/312 Loss 0.574 Prec@(1,3) (86.7%, 99.4%), ce_loss 0.571, lat_loss 6.692
09/20 01:32:27 AM | Train: [172/180] Step 250/312 Loss 0.569 Prec@(1,3) (86.8%, 99.4%), ce_loss 0.571, lat_loss 6.692
09/20 01:32:48 AM | Train: [172/180] Step 300/312 Loss 0.577 Prec@(1,3) (86.6%, 99.3%), ce_loss 0.571, lat_loss 6.692
09/20 01:32:53 AM | Train: [172/180] Step 312/312 Loss 0.583 Prec@(1,3) (86.5%, 99.3%), ce_loss 0.571, lat_loss 6.692
09/20 01:32:53 AM | _theta_step_train: [172/180] Final Prec@1 86.4700% Time 130.59
09/20 01:32:58 AM | Valid: [172/180] Step 050/312 Loss 0.607 Prec@(1,3) (85.8%, 99.3%), ce_loss 0.571, lat_loss 6.692
09/20 01:33:03 AM | Valid: [172/180] Step 100/312 Loss 0.720 Prec@(1,3) (84.3%, 98.1%), ce_loss 0.571, lat_loss 6.692
09/20 01:33:08 AM | Valid: [172/180] Step 150/312 Loss 0.868 Prec@(1,3) (81.3%, 96.9%), ce_loss 0.571, lat_loss 6.692
09/20 01:33:12 AM | Valid: [172/180] Step 200/312 Loss 0.874 Prec@(1,3) (81.4%, 96.9%), ce_loss 0.571, lat_loss 6.692
09/20 01:33:17 AM | Valid: [172/180] Step 250/312 Loss 0.845 Prec@(1,3) (81.9%, 97.2%), ce_loss 0.571, lat_loss 6.692
09/20 01:33:22 AM | Valid: [172/180] Step 300/312 Loss 0.824 Prec@(1,3) (82.4%, 97.4%), ce_loss 0.571, lat_loss 6.692
09/20 01:33:23 AM | Valid: [172/180] Step 312/312 Loss 0.815 Prec@(1,3) (82.5%, 97.5%), ce_loss 0.571, lat_loss 6.692
09/20 01:33:23 AM | val: [172/180] Final Prec@1 82.5500% Time 30.34
09/20 01:33:23 AM | Start to train weights for epoch 172
09/20 01:33:46 AM | Train: [173/180] Step 050/1249 Loss 0.305 Prec@(1,3) (92.6%, 99.8%), ce_loss 0.571, lat_loss 6.692
09/20 01:34:10 AM | Train: [173/180] Step 100/1249 Loss 0.344 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.571, lat_loss 6.692
09/20 01:34:35 AM | Train: [173/180] Step 150/1249 Loss 0.320 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.571, lat_loss 6.692
09/20 01:34:59 AM | Train: [173/180] Step 200/1249 Loss 0.332 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.571, lat_loss 6.692
09/20 01:35:24 AM | Train: [173/180] Step 250/1249 Loss 0.335 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.571, lat_loss 6.692
09/20 01:35:49 AM | Train: [173/180] Step 300/1249 Loss 0.328 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.571, lat_loss 6.692
09/20 01:36:14 AM | Train: [173/180] Step 350/1249 Loss 0.321 Prec@(1,3) (92.1%, 99.7%), ce_loss 0.571, lat_loss 6.692
09/20 01:36:36 AM | Train: [173/180] Step 400/1249 Loss 0.318 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.571, lat_loss 6.692
09/20 01:36:59 AM | Train: [173/180] Step 450/1249 Loss 0.319 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.571, lat_loss 6.692
09/20 01:37:22 AM | Train: [173/180] Step 500/1249 Loss 0.319 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.571, lat_loss 6.692
09/20 01:37:45 AM | Train: [173/180] Step 550/1249 Loss 0.323 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.571, lat_loss 6.692
09/20 01:38:09 AM | Train: [173/180] Step 600/1249 Loss 0.324 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.570, lat_loss 6.692
09/20 01:38:32 AM | Train: [173/180] Step 650/1249 Loss 0.324 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.570, lat_loss 6.692
09/20 01:38:54 AM | Train: [173/180] Step 700/1249 Loss 0.324 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.570, lat_loss 6.692
09/20 01:39:16 AM | Train: [173/180] Step 750/1249 Loss 0.324 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.570, lat_loss 6.692
09/20 01:39:37 AM | Train: [173/180] Step 800/1249 Loss 0.324 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.570, lat_loss 6.692
09/20 01:39:58 AM | Train: [173/180] Step 850/1249 Loss 0.323 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.570, lat_loss 6.692
09/20 01:40:20 AM | Train: [173/180] Step 900/1249 Loss 0.320 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.570, lat_loss 6.692
09/20 01:40:42 AM | Train: [173/180] Step 950/1249 Loss 0.319 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.570, lat_loss 6.692
09/20 01:41:05 AM | Train: [173/180] Step 1000/1249 Loss 0.316 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.570, lat_loss 6.692
09/20 01:41:26 AM | Train: [173/180] Step 1050/1249 Loss 0.316 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.570, lat_loss 6.692
09/20 01:41:49 AM | Train: [173/180] Step 1100/1249 Loss 0.318 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.570, lat_loss 6.692
09/20 01:42:11 AM | Train: [173/180] Step 1150/1249 Loss 0.321 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.570, lat_loss 6.692
09/20 01:42:34 AM | Train: [173/180] Step 1200/1249 Loss 0.325 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.570, lat_loss 6.692
09/20 01:42:58 AM | Train: [173/180] Step 1249/1249 Loss 0.326 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.570, lat_loss 6.692
09/20 01:42:58 AM | _w_step_train: [173/180] Final Prec@1 91.9875% Time 574.82
09/20 01:42:58 AM | Start to train theta for epoch 172
09/20 01:43:18 AM | Train: [173/180] Step 050/312 Loss 0.502 Prec@(1,3) (86.9%, 99.1%), ce_loss 0.570, lat_loss 6.692
09/20 01:43:36 AM | Train: [173/180] Step 100/312 Loss 0.546 Prec@(1,3) (86.8%, 99.1%), ce_loss 0.570, lat_loss 6.692
09/20 01:43:56 AM | Train: [173/180] Step 150/312 Loss 0.547 Prec@(1,3) (86.6%, 99.2%), ce_loss 0.570, lat_loss 6.692
09/20 01:44:17 AM | Train: [173/180] Step 200/312 Loss 0.555 Prec@(1,3) (86.6%, 99.1%), ce_loss 0.570, lat_loss 6.692
09/20 01:44:37 AM | Train: [173/180] Step 250/312 Loss 0.572 Prec@(1,3) (86.2%, 99.2%), ce_loss 0.570, lat_loss 6.692
09/20 01:44:58 AM | Train: [173/180] Step 300/312 Loss 0.577 Prec@(1,3) (86.1%, 99.2%), ce_loss 0.570, lat_loss 6.692
09/20 01:45:02 AM | Train: [173/180] Step 312/312 Loss 0.582 Prec@(1,3) (86.0%, 99.2%), ce_loss 0.570, lat_loss 6.692
09/20 01:45:03 AM | _theta_step_train: [173/180] Final Prec@1 85.9700% Time 124.41
09/20 01:45:08 AM | Valid: [173/180] Step 050/312 Loss 0.784 Prec@(1,3) (81.2%, 98.4%), ce_loss 0.570, lat_loss 6.692
09/20 01:45:12 AM | Valid: [173/180] Step 100/312 Loss 0.777 Prec@(1,3) (81.6%, 98.4%), ce_loss 0.570, lat_loss 6.692
09/20 01:45:17 AM | Valid: [173/180] Step 150/312 Loss 0.850 Prec@(1,3) (80.8%, 97.8%), ce_loss 0.570, lat_loss 6.692
09/20 01:45:22 AM | Valid: [173/180] Step 200/312 Loss 0.900 Prec@(1,3) (80.8%, 97.4%), ce_loss 0.570, lat_loss 6.692
09/20 01:45:26 AM | Valid: [173/180] Step 250/312 Loss 0.859 Prec@(1,3) (81.5%, 97.7%), ce_loss 0.570, lat_loss 6.692
09/20 01:45:31 AM | Valid: [173/180] Step 300/312 Loss 0.828 Prec@(1,3) (81.9%, 97.9%), ce_loss 0.570, lat_loss 6.692
09/20 01:45:32 AM | Valid: [173/180] Step 312/312 Loss 0.818 Prec@(1,3) (82.0%, 98.0%), ce_loss 0.570, lat_loss 6.692
09/20 01:45:32 AM | val: [173/180] Final Prec@1 82.0200% Time 29.54
09/20 01:45:32 AM | Start to train weights for epoch 173
09/20 01:45:58 AM | Train: [174/180] Step 050/1249 Loss 0.335 Prec@(1,3) (91.8%, 99.6%), ce_loss 0.570, lat_loss 6.692
09/20 01:46:21 AM | Train: [174/180] Step 100/1249 Loss 0.341 Prec@(1,3) (91.5%, 99.6%), ce_loss 0.570, lat_loss 6.692
09/20 01:46:43 AM | Train: [174/180] Step 150/1249 Loss 0.321 Prec@(1,3) (92.0%, 99.6%), ce_loss 0.570, lat_loss 6.692
09/20 01:47:06 AM | Train: [174/180] Step 200/1249 Loss 0.320 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.570, lat_loss 6.692
09/20 01:47:29 AM | Train: [174/180] Step 250/1249 Loss 0.319 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:47:51 AM | Train: [174/180] Step 300/1249 Loss 0.321 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:48:14 AM | Train: [174/180] Step 350/1249 Loss 0.318 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:48:36 AM | Train: [174/180] Step 400/1249 Loss 0.318 Prec@(1,3) (92.0%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:48:59 AM | Train: [174/180] Step 450/1249 Loss 0.327 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:49:21 AM | Train: [174/180] Step 500/1249 Loss 0.333 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:49:44 AM | Train: [174/180] Step 550/1249 Loss 0.330 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:50:07 AM | Train: [174/180] Step 600/1249 Loss 0.342 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:50:29 AM | Train: [174/180] Step 650/1249 Loss 0.338 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:50:52 AM | Train: [174/180] Step 700/1249 Loss 0.338 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:51:14 AM | Train: [174/180] Step 750/1249 Loss 0.343 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:51:37 AM | Train: [174/180] Step 800/1249 Loss 0.345 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:52:00 AM | Train: [174/180] Step 850/1249 Loss 0.341 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:52:22 AM | Train: [174/180] Step 900/1249 Loss 0.339 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:52:44 AM | Train: [174/180] Step 950/1249 Loss 0.339 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:53:06 AM | Train: [174/180] Step 1000/1249 Loss 0.340 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:53:29 AM | Train: [174/180] Step 1050/1249 Loss 0.341 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:53:52 AM | Train: [174/180] Step 1100/1249 Loss 0.343 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:54:15 AM | Train: [174/180] Step 1150/1249 Loss 0.343 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:54:39 AM | Train: [174/180] Step 1200/1249 Loss 0.344 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:55:03 AM | Train: [174/180] Step 1249/1249 Loss 0.344 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.569, lat_loss 6.692
09/20 01:55:03 AM | _w_step_train: [174/180] Final Prec@1 91.3525% Time 571.05
09/20 01:55:03 AM | Start to train theta for epoch 173
09/20 01:55:25 AM | Train: [174/180] Step 050/312 Loss 0.606 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.568, lat_loss 6.692
09/20 01:55:44 AM | Train: [174/180] Step 100/312 Loss 0.580 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.568, lat_loss 6.692
09/20 01:56:04 AM | Train: [174/180] Step 150/312 Loss 0.599 Prec@(1,3) (85.4%, 99.3%), ce_loss 0.568, lat_loss 6.692
09/20 01:56:24 AM | Train: [174/180] Step 200/312 Loss 0.613 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.568, lat_loss 6.692
09/20 01:56:44 AM | Train: [174/180] Step 250/312 Loss 0.618 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.568, lat_loss 6.692
09/20 01:57:04 AM | Train: [174/180] Step 300/312 Loss 0.610 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.568, lat_loss 6.692
09/20 01:57:09 AM | Train: [174/180] Step 312/312 Loss 0.609 Prec@(1,3) (85.8%, 99.1%), ce_loss 0.568, lat_loss 6.692
09/20 01:57:09 AM | _theta_step_train: [174/180] Final Prec@1 85.8000% Time 126.32
09/20 01:57:15 AM | Valid: [174/180] Step 050/312 Loss 0.694 Prec@(1,3) (84.7%, 98.9%), ce_loss 0.568, lat_loss 6.692
09/20 01:57:19 AM | Valid: [174/180] Step 100/312 Loss 0.837 Prec@(1,3) (82.1%, 98.0%), ce_loss 0.568, lat_loss 6.692
09/20 01:57:24 AM | Valid: [174/180] Step 150/312 Loss 0.841 Prec@(1,3) (81.5%, 97.9%), ce_loss 0.568, lat_loss 6.692
09/20 01:57:29 AM | Valid: [174/180] Step 200/312 Loss 0.874 Prec@(1,3) (81.4%, 97.7%), ce_loss 0.568, lat_loss 6.692
09/20 01:57:33 AM | Valid: [174/180] Step 250/312 Loss 0.871 Prec@(1,3) (81.6%, 97.6%), ce_loss 0.568, lat_loss 6.692
09/20 01:57:38 AM | Valid: [174/180] Step 300/312 Loss 0.861 Prec@(1,3) (81.7%, 97.6%), ce_loss 0.568, lat_loss 6.692
09/20 01:57:39 AM | Valid: [174/180] Step 312/312 Loss 0.873 Prec@(1,3) (81.5%, 97.6%), ce_loss 0.568, lat_loss 6.692
09/20 01:57:39 AM | val: [174/180] Final Prec@1 81.5300% Time 29.73
09/20 01:57:39 AM | Start to train weights for epoch 174
09/20 01:58:03 AM | Train: [175/180] Step 050/1249 Loss 0.325 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 01:58:26 AM | Train: [175/180] Step 100/1249 Loss 0.316 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 01:58:48 AM | Train: [175/180] Step 150/1249 Loss 0.310 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 01:59:13 AM | Train: [175/180] Step 200/1249 Loss 0.313 Prec@(1,3) (92.3%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 01:59:38 AM | Train: [175/180] Step 250/1249 Loss 0.318 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 02:00:03 AM | Train: [175/180] Step 300/1249 Loss 0.323 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 02:00:27 AM | Train: [175/180] Step 350/1249 Loss 0.329 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 02:00:53 AM | Train: [175/180] Step 400/1249 Loss 0.323 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 02:01:17 AM | Train: [175/180] Step 450/1249 Loss 0.328 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 02:01:43 AM | Train: [175/180] Step 500/1249 Loss 0.331 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 02:02:08 AM | Train: [175/180] Step 550/1249 Loss 0.329 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 02:02:33 AM | Train: [175/180] Step 600/1249 Loss 0.327 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 02:02:58 AM | Train: [175/180] Step 650/1249 Loss 0.325 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 02:03:23 AM | Train: [175/180] Step 700/1249 Loss 0.323 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 02:03:48 AM | Train: [175/180] Step 750/1249 Loss 0.322 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 02:04:13 AM | Train: [175/180] Step 800/1249 Loss 0.323 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 02:04:38 AM | Train: [175/180] Step 850/1249 Loss 0.322 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 02:05:03 AM | Train: [175/180] Step 900/1249 Loss 0.319 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.568, lat_loss 6.692
09/20 02:05:27 AM | Train: [175/180] Step 950/1249 Loss 0.318 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.567, lat_loss 6.692
09/20 02:05:50 AM | Train: [175/180] Step 1000/1249 Loss 0.320 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.567, lat_loss 6.692
09/20 02:06:14 AM | Train: [175/180] Step 1050/1249 Loss 0.320 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.567, lat_loss 6.692
09/20 02:06:37 AM | Train: [175/180] Step 1100/1249 Loss 0.317 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.567, lat_loss 6.692
09/20 02:07:01 AM | Train: [175/180] Step 1150/1249 Loss 0.318 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.567, lat_loss 6.692
09/20 02:07:24 AM | Train: [175/180] Step 1200/1249 Loss 0.321 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.567, lat_loss 6.692
09/20 02:07:49 AM | Train: [175/180] Step 1249/1249 Loss 0.322 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.567, lat_loss 6.692
09/20 02:07:49 AM | _w_step_train: [175/180] Final Prec@1 91.9200% Time 609.65
09/20 02:07:49 AM | Start to train theta for epoch 174
09/20 02:08:10 AM | Train: [175/180] Step 050/312 Loss 0.612 Prec@(1,3) (85.9%, 99.0%), ce_loss 0.567, lat_loss 6.692
09/20 02:08:28 AM | Train: [175/180] Step 100/312 Loss 0.628 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.567, lat_loss 6.692
09/20 02:08:47 AM | Train: [175/180] Step 150/312 Loss 0.628 Prec@(1,3) (85.2%, 99.1%), ce_loss 0.567, lat_loss 6.692
09/20 02:09:06 AM | Train: [175/180] Step 200/312 Loss 0.623 Prec@(1,3) (85.3%, 99.2%), ce_loss 0.567, lat_loss 6.692
09/20 02:09:27 AM | Train: [175/180] Step 250/312 Loss 0.625 Prec@(1,3) (85.2%, 99.2%), ce_loss 0.567, lat_loss 6.692
09/20 02:09:47 AM | Train: [175/180] Step 300/312 Loss 0.623 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.567, lat_loss 6.692
09/20 02:09:51 AM | Train: [175/180] Step 312/312 Loss 0.619 Prec@(1,3) (85.5%, 99.3%), ce_loss 0.567, lat_loss 6.692
09/20 02:09:51 AM | _theta_step_train: [175/180] Final Prec@1 85.4700% Time 122.52
09/20 02:09:57 AM | Valid: [175/180] Step 050/312 Loss 0.903 Prec@(1,3) (80.0%, 97.1%), ce_loss 0.567, lat_loss 6.692
09/20 02:10:01 AM | Valid: [175/180] Step 100/312 Loss 0.956 Prec@(1,3) (79.7%, 96.8%), ce_loss 0.567, lat_loss 6.692
09/20 02:10:06 AM | Valid: [175/180] Step 150/312 Loss 0.910 Prec@(1,3) (80.0%, 97.1%), ce_loss 0.567, lat_loss 6.692
09/20 02:10:11 AM | Valid: [175/180] Step 200/312 Loss 0.914 Prec@(1,3) (80.3%, 96.9%), ce_loss 0.567, lat_loss 6.692
09/20 02:10:15 AM | Valid: [175/180] Step 250/312 Loss 0.875 Prec@(1,3) (80.8%, 97.3%), ce_loss 0.567, lat_loss 6.692
09/20 02:10:20 AM | Valid: [175/180] Step 300/312 Loss 0.870 Prec@(1,3) (80.9%, 97.3%), ce_loss 0.567, lat_loss 6.692
09/20 02:10:21 AM | Valid: [175/180] Step 312/312 Loss 0.872 Prec@(1,3) (80.7%, 97.3%), ce_loss 0.567, lat_loss 6.692
09/20 02:10:21 AM | val: [175/180] Final Prec@1 80.6500% Time 29.89
09/20 02:10:21 AM | Start to train weights for epoch 175
09/20 02:10:47 AM | Train: [176/180] Step 050/1249 Loss 0.358 Prec@(1,3) (90.8%, 99.8%), ce_loss 0.567, lat_loss 6.692
09/20 02:11:12 AM | Train: [176/180] Step 100/1249 Loss 0.352 Prec@(1,3) (91.3%, 99.7%), ce_loss 0.567, lat_loss 6.692
09/20 02:11:37 AM | Train: [176/180] Step 150/1249 Loss 0.348 Prec@(1,3) (91.1%, 99.7%), ce_loss 0.567, lat_loss 6.692
09/20 02:12:02 AM | Train: [176/180] Step 200/1249 Loss 0.355 Prec@(1,3) (91.2%, 99.6%), ce_loss 0.567, lat_loss 6.692
09/20 02:12:27 AM | Train: [176/180] Step 250/1249 Loss 0.342 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.567, lat_loss 6.692
09/20 02:12:52 AM | Train: [176/180] Step 300/1249 Loss 0.349 Prec@(1,3) (91.4%, 99.6%), ce_loss 0.567, lat_loss 6.692
09/20 02:13:17 AM | Train: [176/180] Step 350/1249 Loss 0.341 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.567, lat_loss 6.692
09/20 02:13:42 AM | Train: [176/180] Step 400/1249 Loss 0.340 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.567, lat_loss 6.692
09/20 02:14:06 AM | Train: [176/180] Step 450/1249 Loss 0.346 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.567, lat_loss 6.692
09/20 02:14:29 AM | Train: [176/180] Step 500/1249 Loss 0.343 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.567, lat_loss 6.692
09/20 02:14:53 AM | Train: [176/180] Step 550/1249 Loss 0.340 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.567, lat_loss 6.692
09/20 02:15:15 AM | Train: [176/180] Step 600/1249 Loss 0.334 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.567, lat_loss 6.692
09/20 02:15:40 AM | Train: [176/180] Step 650/1249 Loss 0.331 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.567, lat_loss 6.692
09/20 02:16:05 AM | Train: [176/180] Step 700/1249 Loss 0.329 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.566, lat_loss 6.692
09/20 02:16:30 AM | Train: [176/180] Step 750/1249 Loss 0.328 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.566, lat_loss 6.692
09/20 02:16:54 AM | Train: [176/180] Step 800/1249 Loss 0.331 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.566, lat_loss 6.692
09/20 02:17:19 AM | Train: [176/180] Step 850/1249 Loss 0.334 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.566, lat_loss 6.692
09/20 02:17:44 AM | Train: [176/180] Step 900/1249 Loss 0.336 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.566, lat_loss 6.692
09/20 02:18:09 AM | Train: [176/180] Step 950/1249 Loss 0.334 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.566, lat_loss 6.692
09/20 02:18:33 AM | Train: [176/180] Step 1000/1249 Loss 0.340 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.566, lat_loss 6.692
09/20 02:18:56 AM | Train: [176/180] Step 1050/1249 Loss 0.343 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.566, lat_loss 6.692
09/20 02:19:20 AM | Train: [176/180] Step 1100/1249 Loss 0.344 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.566, lat_loss 6.692
09/20 02:19:44 AM | Train: [176/180] Step 1150/1249 Loss 0.342 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.566, lat_loss 6.692
09/20 02:20:08 AM | Train: [176/180] Step 1200/1249 Loss 0.339 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.566, lat_loss 6.692
09/20 02:20:32 AM | Train: [176/180] Step 1249/1249 Loss 0.337 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.566, lat_loss 6.692
09/20 02:20:32 AM | _w_step_train: [176/180] Final Prec@1 91.6575% Time 611.10
09/20 02:20:32 AM | Start to train theta for epoch 175
09/20 02:20:53 AM | Train: [176/180] Step 050/312 Loss 0.587 Prec@(1,3) (85.9%, 99.3%), ce_loss 0.566, lat_loss 6.692
09/20 02:21:10 AM | Train: [176/180] Step 100/312 Loss 0.625 Prec@(1,3) (85.4%, 99.1%), ce_loss 0.566, lat_loss 6.692
09/20 02:21:26 AM | Train: [176/180] Step 150/312 Loss 0.636 Prec@(1,3) (85.6%, 99.1%), ce_loss 0.566, lat_loss 6.692
09/20 02:21:43 AM | Train: [176/180] Step 200/312 Loss 0.623 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.566, lat_loss 6.692
09/20 02:22:03 AM | Train: [176/180] Step 250/312 Loss 0.614 Prec@(1,3) (85.9%, 99.2%), ce_loss 0.566, lat_loss 6.692
09/20 02:22:23 AM | Train: [176/180] Step 300/312 Loss 0.622 Prec@(1,3) (85.7%, 99.1%), ce_loss 0.566, lat_loss 6.692
09/20 02:22:28 AM | Train: [176/180] Step 312/312 Loss 0.619 Prec@(1,3) (85.8%, 99.2%), ce_loss 0.566, lat_loss 6.692
09/20 02:22:28 AM | _theta_step_train: [176/180] Final Prec@1 85.7500% Time 115.18
09/20 02:22:33 AM | Valid: [176/180] Step 050/312 Loss 0.845 Prec@(1,3) (80.3%, 97.4%), ce_loss 0.566, lat_loss 6.692
09/20 02:22:38 AM | Valid: [176/180] Step 100/312 Loss 0.856 Prec@(1,3) (80.4%, 97.7%), ce_loss 0.566, lat_loss 6.692
09/20 02:22:42 AM | Valid: [176/180] Step 150/312 Loss 0.870 Prec@(1,3) (80.3%, 97.7%), ce_loss 0.566, lat_loss 6.692
09/20 02:22:47 AM | Valid: [176/180] Step 200/312 Loss 0.890 Prec@(1,3) (80.0%, 97.4%), ce_loss 0.566, lat_loss 6.692
09/20 02:22:51 AM | Valid: [176/180] Step 250/312 Loss 0.869 Prec@(1,3) (80.3%, 97.4%), ce_loss 0.566, lat_loss 6.692
09/20 02:22:56 AM | Valid: [176/180] Step 300/312 Loss 0.872 Prec@(1,3) (80.5%, 97.4%), ce_loss 0.566, lat_loss 6.692
09/20 02:22:57 AM | Valid: [176/180] Step 312/312 Loss 0.868 Prec@(1,3) (80.5%, 97.4%), ce_loss 0.566, lat_loss 6.692
09/20 02:22:57 AM | val: [176/180] Final Prec@1 80.5200% Time 29.54
09/20 02:22:57 AM | Start to train weights for epoch 176
09/20 02:23:23 AM | Train: [177/180] Step 050/1249 Loss 0.350 Prec@(1,3) (90.1%, 99.8%), ce_loss 0.566, lat_loss 6.692
09/20 02:23:46 AM | Train: [177/180] Step 100/1249 Loss 0.344 Prec@(1,3) (90.9%, 99.9%), ce_loss 0.566, lat_loss 6.692
09/20 02:24:10 AM | Train: [177/180] Step 150/1249 Loss 0.321 Prec@(1,3) (91.5%, 99.9%), ce_loss 0.566, lat_loss 6.692
09/20 02:24:35 AM | Train: [177/180] Step 200/1249 Loss 0.320 Prec@(1,3) (91.6%, 99.9%), ce_loss 0.566, lat_loss 6.693
09/20 02:24:59 AM | Train: [177/180] Step 250/1249 Loss 0.313 Prec@(1,3) (91.9%, 99.9%), ce_loss 0.566, lat_loss 6.693
09/20 02:25:23 AM | Train: [177/180] Step 300/1249 Loss 0.313 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.566, lat_loss 6.693
09/20 02:25:46 AM | Train: [177/180] Step 350/1249 Loss 0.318 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.566, lat_loss 6.693
09/20 02:26:11 AM | Train: [177/180] Step 400/1249 Loss 0.337 Prec@(1,3) (91.3%, 99.8%), ce_loss 0.566, lat_loss 6.693
09/20 02:26:35 AM | Train: [177/180] Step 450/1249 Loss 0.335 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.565, lat_loss 6.693
09/20 02:27:00 AM | Train: [177/180] Step 500/1249 Loss 0.330 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.565, lat_loss 6.693
09/20 02:27:25 AM | Train: [177/180] Step 550/1249 Loss 0.332 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.565, lat_loss 6.693
09/20 02:27:50 AM | Train: [177/180] Step 600/1249 Loss 0.339 Prec@(1,3) (91.4%, 99.8%), ce_loss 0.565, lat_loss 6.693
09/20 02:28:14 AM | Train: [177/180] Step 650/1249 Loss 0.337 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.565, lat_loss 6.693
09/20 02:28:38 AM | Train: [177/180] Step 700/1249 Loss 0.339 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.565, lat_loss 6.693
09/20 02:29:03 AM | Train: [177/180] Step 750/1249 Loss 0.337 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.565, lat_loss 6.693
09/20 02:29:27 AM | Train: [177/180] Step 800/1249 Loss 0.340 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.565, lat_loss 6.693
09/20 02:29:52 AM | Train: [177/180] Step 850/1249 Loss 0.340 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.565, lat_loss 6.693
09/20 02:30:15 AM | Train: [177/180] Step 900/1249 Loss 0.343 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.565, lat_loss 6.693
09/20 02:30:39 AM | Train: [177/180] Step 950/1249 Loss 0.344 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.565, lat_loss 6.693
09/20 02:31:04 AM | Train: [177/180] Step 1000/1249 Loss 0.342 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.565, lat_loss 6.693
09/20 02:31:27 AM | Train: [177/180] Step 1050/1249 Loss 0.346 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.565, lat_loss 6.693
09/20 02:31:50 AM | Train: [177/180] Step 1100/1249 Loss 0.348 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.565, lat_loss 6.693
09/20 02:32:15 AM | Train: [177/180] Step 1150/1249 Loss 0.348 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.565, lat_loss 6.693
09/20 02:32:39 AM | Train: [177/180] Step 1200/1249 Loss 0.349 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.565, lat_loss 6.693
09/20 02:33:03 AM | Train: [177/180] Step 1249/1249 Loss 0.348 Prec@(1,3) (91.4%, 99.7%), ce_loss 0.565, lat_loss 6.693
09/20 02:33:03 AM | _w_step_train: [177/180] Final Prec@1 91.4150% Time 606.16
09/20 02:33:03 AM | Start to train theta for epoch 176
09/20 02:33:22 AM | Train: [177/180] Step 050/312 Loss 0.679 Prec@(1,3) (85.2%, 98.7%), ce_loss 0.565, lat_loss 6.693
09/20 02:33:41 AM | Train: [177/180] Step 100/312 Loss 0.642 Prec@(1,3) (85.6%, 98.9%), ce_loss 0.565, lat_loss 6.693
09/20 02:34:00 AM | Train: [177/180] Step 150/312 Loss 0.622 Prec@(1,3) (85.9%, 99.0%), ce_loss 0.565, lat_loss 6.693
09/20 02:34:19 AM | Train: [177/180] Step 200/312 Loss 0.653 Prec@(1,3) (85.4%, 99.0%), ce_loss 0.565, lat_loss 6.693
09/20 02:34:37 AM | Train: [177/180] Step 250/312 Loss 0.659 Prec@(1,3) (85.2%, 99.0%), ce_loss 0.565, lat_loss 6.693
09/20 02:34:56 AM | Train: [177/180] Step 300/312 Loss 0.655 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.565, lat_loss 6.693
09/20 02:35:01 AM | Train: [177/180] Step 312/312 Loss 0.653 Prec@(1,3) (85.1%, 99.1%), ce_loss 0.565, lat_loss 6.693
09/20 02:35:01 AM | _theta_step_train: [177/180] Final Prec@1 85.1300% Time 117.34
09/20 02:35:06 AM | Valid: [177/180] Step 050/312 Loss 0.907 Prec@(1,3) (80.5%, 97.4%), ce_loss 0.565, lat_loss 6.693
09/20 02:35:11 AM | Valid: [177/180] Step 100/312 Loss 0.927 Prec@(1,3) (80.0%, 97.2%), ce_loss 0.565, lat_loss 6.693
09/20 02:35:15 AM | Valid: [177/180] Step 150/312 Loss 0.883 Prec@(1,3) (81.0%, 97.2%), ce_loss 0.565, lat_loss 6.693
09/20 02:35:20 AM | Valid: [177/180] Step 200/312 Loss 0.859 Prec@(1,3) (81.4%, 97.5%), ce_loss 0.565, lat_loss 6.693
09/20 02:35:24 AM | Valid: [177/180] Step 250/312 Loss 0.829 Prec@(1,3) (81.9%, 97.7%), ce_loss 0.565, lat_loss 6.693
09/20 02:35:29 AM | Valid: [177/180] Step 300/312 Loss 0.890 Prec@(1,3) (81.2%, 97.3%), ce_loss 0.565, lat_loss 6.693
09/20 02:35:30 AM | Valid: [177/180] Step 312/312 Loss 0.877 Prec@(1,3) (81.4%, 97.4%), ce_loss 0.565, lat_loss 6.693
09/20 02:35:30 AM | val: [177/180] Final Prec@1 81.4000% Time 29.61
09/20 02:35:30 AM | Start to train weights for epoch 177
09/20 02:35:56 AM | Train: [178/180] Step 050/1249 Loss 0.296 Prec@(1,3) (92.8%, 99.9%), ce_loss 0.565, lat_loss 6.693
09/20 02:36:21 AM | Train: [178/180] Step 100/1249 Loss 0.308 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.565, lat_loss 6.693
09/20 02:36:46 AM | Train: [178/180] Step 150/1249 Loss 0.324 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.565, lat_loss 6.693
09/20 02:37:09 AM | Train: [178/180] Step 200/1249 Loss 0.327 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.565, lat_loss 6.693
09/20 02:37:33 AM | Train: [178/180] Step 250/1249 Loss 0.326 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.565, lat_loss 6.693
09/20 02:37:57 AM | Train: [178/180] Step 300/1249 Loss 0.327 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.564, lat_loss 6.693
09/20 02:38:18 AM | Train: [178/180] Step 350/1249 Loss 0.325 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.564, lat_loss 6.693
09/20 02:38:37 AM | Train: [178/180] Step 400/1249 Loss 0.324 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.564, lat_loss 6.693
09/20 02:38:53 AM | Train: [178/180] Step 450/1249 Loss 0.326 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.564, lat_loss 6.693
09/20 02:39:09 AM | Train: [178/180] Step 500/1249 Loss 0.325 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.564, lat_loss 6.693
09/20 02:39:25 AM | Train: [178/180] Step 550/1249 Loss 0.329 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.564, lat_loss 6.693
09/20 02:39:41 AM | Train: [178/180] Step 600/1249 Loss 0.330 Prec@(1,3) (91.5%, 99.8%), ce_loss 0.564, lat_loss 6.693
09/20 02:39:57 AM | Train: [178/180] Step 650/1249 Loss 0.332 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.564, lat_loss 6.693
09/20 02:40:13 AM | Train: [178/180] Step 700/1249 Loss 0.327 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.564, lat_loss 6.693
09/20 02:40:29 AM | Train: [178/180] Step 750/1249 Loss 0.323 Prec@(1,3) (91.7%, 99.8%), ce_loss 0.564, lat_loss 6.693
09/20 02:40:45 AM | Train: [178/180] Step 800/1249 Loss 0.328 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.564, lat_loss 6.693
09/20 02:41:02 AM | Train: [178/180] Step 850/1249 Loss 0.332 Prec@(1,3) (91.5%, 99.7%), ce_loss 0.564, lat_loss 6.693
09/20 02:41:27 AM | Train: [178/180] Step 900/1249 Loss 0.331 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.564, lat_loss 6.693
09/20 02:41:52 AM | Train: [178/180] Step 950/1249 Loss 0.329 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.564, lat_loss 6.693
09/20 02:42:17 AM | Train: [178/180] Step 1000/1249 Loss 0.329 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.564, lat_loss 6.693
09/20 02:42:41 AM | Train: [178/180] Step 1050/1249 Loss 0.331 Prec@(1,3) (91.7%, 99.7%), ce_loss 0.564, lat_loss 6.693
09/20 02:43:06 AM | Train: [178/180] Step 1100/1249 Loss 0.333 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.564, lat_loss 6.693
09/20 02:43:31 AM | Train: [178/180] Step 1150/1249 Loss 0.332 Prec@(1,3) (91.6%, 99.7%), ce_loss 0.564, lat_loss 6.693
09/20 02:43:56 AM | Train: [178/180] Step 1200/1249 Loss 0.332 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.564, lat_loss 6.693
09/20 02:44:21 AM | Train: [178/180] Step 1249/1249 Loss 0.330 Prec@(1,3) (91.6%, 99.8%), ce_loss 0.564, lat_loss 6.693
09/20 02:44:21 AM | _w_step_train: [178/180] Final Prec@1 91.6400% Time 530.48
09/20 02:44:21 AM | Start to train theta for epoch 177
09/20 02:44:42 AM | Train: [178/180] Step 050/312 Loss 0.560 Prec@(1,3) (86.5%, 99.6%), ce_loss 0.564, lat_loss 6.693
09/20 02:45:03 AM | Train: [178/180] Step 100/312 Loss 0.625 Prec@(1,3) (85.6%, 99.4%), ce_loss 0.564, lat_loss 6.693
09/20 02:45:24 AM | Train: [178/180] Step 150/312 Loss 0.635 Prec@(1,3) (85.3%, 99.1%), ce_loss 0.564, lat_loss 6.693
09/20 02:45:42 AM | Train: [178/180] Step 200/312 Loss 0.626 Prec@(1,3) (85.4%, 99.2%), ce_loss 0.563, lat_loss 6.693
09/20 02:45:59 AM | Train: [178/180] Step 250/312 Loss 0.617 Prec@(1,3) (85.7%, 99.3%), ce_loss 0.563, lat_loss 6.693
09/20 02:46:15 AM | Train: [178/180] Step 300/312 Loss 0.616 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.563, lat_loss 6.693
09/20 02:46:20 AM | Train: [178/180] Step 312/312 Loss 0.616 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.563, lat_loss 6.693
09/20 02:46:20 AM | _theta_step_train: [178/180] Final Prec@1 85.6500% Time 119.15
09/20 02:46:25 AM | Valid: [178/180] Step 050/312 Loss 0.814 Prec@(1,3) (82.1%, 97.9%), ce_loss 0.563, lat_loss 6.693
09/20 02:46:30 AM | Valid: [178/180] Step 100/312 Loss 0.788 Prec@(1,3) (82.6%, 98.0%), ce_loss 0.563, lat_loss 6.693
09/20 02:46:35 AM | Valid: [178/180] Step 150/312 Loss 0.788 Prec@(1,3) (82.8%, 97.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:46:39 AM | Valid: [178/180] Step 200/312 Loss 0.804 Prec@(1,3) (81.9%, 97.9%), ce_loss 0.563, lat_loss 6.693
09/20 02:46:44 AM | Valid: [178/180] Step 250/312 Loss 0.816 Prec@(1,3) (81.3%, 97.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:46:48 AM | Valid: [178/180] Step 300/312 Loss 0.791 Prec@(1,3) (81.6%, 98.0%), ce_loss 0.563, lat_loss 6.693
09/20 02:46:50 AM | Valid: [178/180] Step 312/312 Loss 0.780 Prec@(1,3) (81.8%, 98.1%), ce_loss 0.563, lat_loss 6.693
09/20 02:46:50 AM | val: [178/180] Final Prec@1 81.7700% Time 29.60
09/20 02:46:50 AM | Start to train weights for epoch 178
09/20 02:47:07 AM | Train: [179/180] Step 050/1249 Loss 0.300 Prec@(1,3) (92.4%, 99.9%), ce_loss 0.563, lat_loss 6.693
09/20 02:47:23 AM | Train: [179/180] Step 100/1249 Loss 0.331 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:47:38 AM | Train: [179/180] Step 150/1249 Loss 0.319 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:47:54 AM | Train: [179/180] Step 200/1249 Loss 0.310 Prec@(1,3) (92.4%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:48:10 AM | Train: [179/180] Step 250/1249 Loss 0.325 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:48:26 AM | Train: [179/180] Step 300/1249 Loss 0.329 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:48:42 AM | Train: [179/180] Step 350/1249 Loss 0.325 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:48:58 AM | Train: [179/180] Step 400/1249 Loss 0.321 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:49:13 AM | Train: [179/180] Step 450/1249 Loss 0.322 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:49:29 AM | Train: [179/180] Step 500/1249 Loss 0.322 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:49:45 AM | Train: [179/180] Step 550/1249 Loss 0.316 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:50:01 AM | Train: [179/180] Step 600/1249 Loss 0.318 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:50:17 AM | Train: [179/180] Step 650/1249 Loss 0.314 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:50:33 AM | Train: [179/180] Step 700/1249 Loss 0.311 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:50:48 AM | Train: [179/180] Step 750/1249 Loss 0.321 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:51:04 AM | Train: [179/180] Step 800/1249 Loss 0.321 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:51:20 AM | Train: [179/180] Step 850/1249 Loss 0.322 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:51:36 AM | Train: [179/180] Step 900/1249 Loss 0.321 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:51:52 AM | Train: [179/180] Step 950/1249 Loss 0.320 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.563, lat_loss 6.693
09/20 02:52:07 AM | Train: [179/180] Step 1000/1249 Loss 0.325 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.562, lat_loss 6.693
09/20 02:52:23 AM | Train: [179/180] Step 1050/1249 Loss 0.323 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.562, lat_loss 6.693
09/20 02:52:39 AM | Train: [179/180] Step 1100/1249 Loss 0.323 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.562, lat_loss 6.693
09/20 02:52:55 AM | Train: [179/180] Step 1150/1249 Loss 0.323 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.562, lat_loss 6.693
09/20 02:53:11 AM | Train: [179/180] Step 1200/1249 Loss 0.324 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.562, lat_loss 6.693
09/20 02:53:26 AM | Train: [179/180] Step 1249/1249 Loss 0.325 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.562, lat_loss 6.693
09/20 02:53:26 AM | _w_step_train: [179/180] Final Prec@1 91.9175% Time 396.76
09/20 02:53:26 AM | Start to train theta for epoch 178
09/20 02:53:48 AM | Train: [179/180] Step 050/312 Loss 0.636 Prec@(1,3) (85.9%, 98.7%), ce_loss 0.562, lat_loss 6.693
09/20 02:54:09 AM | Train: [179/180] Step 100/312 Loss 0.644 Prec@(1,3) (85.8%, 98.9%), ce_loss 0.562, lat_loss 6.693
09/20 02:54:30 AM | Train: [179/180] Step 150/312 Loss 0.634 Prec@(1,3) (85.8%, 99.0%), ce_loss 0.562, lat_loss 6.693
09/20 02:54:51 AM | Train: [179/180] Step 200/312 Loss 0.617 Prec@(1,3) (85.8%, 99.1%), ce_loss 0.562, lat_loss 6.693
09/20 02:55:12 AM | Train: [179/180] Step 250/312 Loss 0.607 Prec@(1,3) (86.0%, 99.1%), ce_loss 0.562, lat_loss 6.693
09/20 02:55:32 AM | Train: [179/180] Step 300/312 Loss 0.615 Prec@(1,3) (85.9%, 99.1%), ce_loss 0.562, lat_loss 6.693
09/20 02:55:37 AM | Train: [179/180] Step 312/312 Loss 0.619 Prec@(1,3) (85.9%, 99.1%), ce_loss 0.562, lat_loss 6.693
09/20 02:55:37 AM | _theta_step_train: [179/180] Final Prec@1 85.8500% Time 130.64
09/20 02:55:42 AM | Valid: [179/180] Step 050/312 Loss 0.665 Prec@(1,3) (83.6%, 99.1%), ce_loss 0.562, lat_loss 6.693
09/20 02:55:47 AM | Valid: [179/180] Step 100/312 Loss 0.887 Prec@(1,3) (80.2%, 97.6%), ce_loss 0.562, lat_loss 6.693
09/20 02:55:51 AM | Valid: [179/180] Step 150/312 Loss 0.847 Prec@(1,3) (81.2%, 97.6%), ce_loss 0.562, lat_loss 6.693
09/20 02:55:56 AM | Valid: [179/180] Step 200/312 Loss 0.806 Prec@(1,3) (81.7%, 97.9%), ce_loss 0.562, lat_loss 6.693
09/20 02:56:01 AM | Valid: [179/180] Step 250/312 Loss 0.825 Prec@(1,3) (81.4%, 97.6%), ce_loss 0.562, lat_loss 6.693
09/20 02:56:05 AM | Valid: [179/180] Step 300/312 Loss 0.800 Prec@(1,3) (81.9%, 97.8%), ce_loss 0.562, lat_loss 6.693
09/20 02:56:06 AM | Valid: [179/180] Step 312/312 Loss 0.796 Prec@(1,3) (81.8%, 97.8%), ce_loss 0.562, lat_loss 6.693
09/20 02:56:06 AM | val: [179/180] Final Prec@1 81.8300% Time 29.35
09/20 02:56:06 AM | Start to train weights for epoch 179
09/20 02:56:32 AM | Train: [180/180] Step 050/1249 Loss 0.262 Prec@(1,3) (93.8%, 99.9%), ce_loss 0.562, lat_loss 6.693
09/20 02:56:57 AM | Train: [180/180] Step 100/1249 Loss 0.278 Prec@(1,3) (92.9%, 99.9%), ce_loss 0.562, lat_loss 6.693
09/20 02:57:22 AM | Train: [180/180] Step 150/1249 Loss 0.327 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.562, lat_loss 6.693
09/20 02:57:47 AM | Train: [180/180] Step 200/1249 Loss 0.329 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.562, lat_loss 6.693
09/20 02:58:11 AM | Train: [180/180] Step 250/1249 Loss 0.325 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.562, lat_loss 6.693
09/20 02:58:36 AM | Train: [180/180] Step 300/1249 Loss 0.320 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.562, lat_loss 6.693
09/20 02:59:01 AM | Train: [180/180] Step 350/1249 Loss 0.313 Prec@(1,3) (92.2%, 99.8%), ce_loss 0.562, lat_loss 6.693
09/20 02:59:26 AM | Train: [180/180] Step 400/1249 Loss 0.313 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.562, lat_loss 6.693
09/20 02:59:49 AM | Train: [180/180] Step 450/1249 Loss 0.319 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.562, lat_loss 6.693
09/20 03:00:13 AM | Train: [180/180] Step 500/1249 Loss 0.315 Prec@(1,3) (92.1%, 99.8%), ce_loss 0.562, lat_loss 6.693
09/20 03:00:35 AM | Train: [180/180] Step 550/1249 Loss 0.329 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.562, lat_loss 6.693
09/20 03:00:58 AM | Train: [180/180] Step 600/1249 Loss 0.328 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.562, lat_loss 6.693
09/20 03:01:22 AM | Train: [180/180] Step 650/1249 Loss 0.327 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.562, lat_loss 6.693
09/20 03:01:45 AM | Train: [180/180] Step 700/1249 Loss 0.322 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.561, lat_loss 6.693
09/20 03:02:09 AM | Train: [180/180] Step 750/1249 Loss 0.324 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.561, lat_loss 6.693
09/20 03:02:33 AM | Train: [180/180] Step 800/1249 Loss 0.324 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.561, lat_loss 6.693
09/20 03:02:57 AM | Train: [180/180] Step 850/1249 Loss 0.321 Prec@(1,3) (92.0%, 99.8%), ce_loss 0.561, lat_loss 6.693
09/20 03:03:22 AM | Train: [180/180] Step 900/1249 Loss 0.327 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.561, lat_loss 6.693
09/20 03:03:47 AM | Train: [180/180] Step 950/1249 Loss 0.327 Prec@(1,3) (91.9%, 99.7%), ce_loss 0.561, lat_loss 6.693
09/20 03:04:11 AM | Train: [180/180] Step 1000/1249 Loss 0.327 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.561, lat_loss 6.693
09/20 03:04:36 AM | Train: [180/180] Step 1050/1249 Loss 0.326 Prec@(1,3) (91.9%, 99.8%), ce_loss 0.561, lat_loss 6.693
09/20 03:05:00 AM | Train: [180/180] Step 1100/1249 Loss 0.329 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.561, lat_loss 6.693
09/20 03:05:25 AM | Train: [180/180] Step 1150/1249 Loss 0.328 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.561, lat_loss 6.693
09/20 03:05:49 AM | Train: [180/180] Step 1200/1249 Loss 0.329 Prec@(1,3) (91.8%, 99.8%), ce_loss 0.561, lat_loss 6.693
09/20 03:06:12 AM | Train: [180/180] Step 1249/1249 Loss 0.331 Prec@(1,3) (91.8%, 99.7%), ce_loss 0.561, lat_loss 6.693
09/20 03:06:12 AM | _w_step_train: [180/180] Final Prec@1 91.7850% Time 605.36
09/20 03:06:12 AM | Start to train theta for epoch 179
09/20 03:06:33 AM | Train: [180/180] Step 050/312 Loss 0.687 Prec@(1,3) (84.2%, 98.8%), ce_loss 0.561, lat_loss 6.693
09/20 03:06:54 AM | Train: [180/180] Step 100/312 Loss 0.685 Prec@(1,3) (84.5%, 98.9%), ce_loss 0.561, lat_loss 6.693
09/20 03:07:15 AM | Train: [180/180] Step 150/312 Loss 0.653 Prec@(1,3) (85.1%, 99.0%), ce_loss 0.561, lat_loss 6.693
09/20 03:07:35 AM | Train: [180/180] Step 200/312 Loss 0.633 Prec@(1,3) (85.3%, 99.0%), ce_loss 0.561, lat_loss 6.693
09/20 03:07:56 AM | Train: [180/180] Step 250/312 Loss 0.618 Prec@(1,3) (85.6%, 99.1%), ce_loss 0.561, lat_loss 6.693
09/20 03:08:17 AM | Train: [180/180] Step 300/312 Loss 0.614 Prec@(1,3) (85.6%, 99.2%), ce_loss 0.561, lat_loss 6.693
09/20 03:08:22 AM | Train: [180/180] Step 312/312 Loss 0.613 Prec@(1,3) (85.7%, 99.2%), ce_loss 0.561, lat_loss 6.693
09/20 03:08:22 AM | _theta_step_train: [180/180] Final Prec@1 85.6600% Time 130.15
09/20 03:08:27 AM | Valid: [180/180] Step 050/312 Loss 1.013 Prec@(1,3) (77.0%, 95.6%), ce_loss 0.561, lat_loss 6.693
09/20 03:08:32 AM | Valid: [180/180] Step 100/312 Loss 0.983 Prec@(1,3) (78.8%, 95.6%), ce_loss 0.561, lat_loss 6.693
09/20 03:08:36 AM | Valid: [180/180] Step 150/312 Loss 0.918 Prec@(1,3) (80.1%, 96.3%), ce_loss 0.561, lat_loss 6.693
09/20 03:08:41 AM | Valid: [180/180] Step 200/312 Loss 0.885 Prec@(1,3) (80.5%, 96.7%), ce_loss 0.561, lat_loss 6.693
09/20 03:08:46 AM | Valid: [180/180] Step 250/312 Loss 0.852 Prec@(1,3) (80.9%, 97.1%), ce_loss 0.561, lat_loss 6.693
09/20 03:08:51 AM | Valid: [180/180] Step 300/312 Loss 0.856 Prec@(1,3) (81.0%, 97.2%), ce_loss 0.561, lat_loss 6.693
09/20 03:08:52 AM | Valid: [180/180] Step 312/312 Loss 0.870 Prec@(1,3) (80.8%, 97.1%), ce_loss 0.561, lat_loss 6.693
09/20 03:08:52 AM | val: [180/180] Final Prec@1 80.8400% Time 29.90
